# Grammar Compilation Pipeline
# Compiles grammar definitions into optimized runtime structures

import parser.treesitter.{Grammar, GrammarRule, Token}
import parser.treesitter.language_detect as detect
import core.collections as collections

# Compiled grammar with optimizations
class CompiledGrammar:
    name: String
    rules: Dict<String, CompiledRule>
    entry_point: String
    token_types: List<String>
    # Optimizations
    first_sets: Dict<String, Set<String>>   # First tokens for each rule
    follow_sets: Dict<String, Set<String>>  # Follow tokens for each rule
    nullable_rules: Set<String>             # Rules that can match empty

    fn new(name: String, entry_point: String) -> CompiledGrammar:
        CompiledGrammar(
            name: name,
            rules: {},
            entry_point: entry_point,
            token_types: [],
            first_sets: {},
            follow_sets: {},
            nullable_rules: Set()
        )

    # Get rule by name
    fn get_rule(name: String) -> Option<CompiledRule>:
        self.rules.get(name)

    # Check if rule is nullable (can match empty)
    fn is_nullable(rule_name: String) -> Bool:
        self.nullable_rules.contains(rule_name)

    # Get first tokens for a rule
    fn get_first_set(rule_name: String) -> Set<String>:
        match self.first_sets.get(rule_name):
            case Some(set):
                return set
            case None:
                return Set()

    # Get follow tokens for a rule
    fn get_follow_set(rule_name: String) -> Set<String>:
        match self.follow_sets.get(rule_name):
            case Some(set):
                return set
            case None:
                return Set()

# Compiled grammar rule with optimizations
class CompiledRule:
    name: String
    pattern: RulePattern
    is_terminal: Bool
    is_nullable: Bool

    fn new(name: String, pattern: RulePattern) -> CompiledRule:
        CompiledRule(
            name: name,
            pattern: pattern,
            is_terminal: false,
            is_nullable: false
        )

# Rule pattern (simplified for compilation)
enum RulePattern:
    Token(token_type: String)
    Sequence(patterns: List<RulePattern>)
    Choice(patterns: List<RulePattern>)
    Repeat(pattern: RulePattern)
    Optional(pattern: RulePattern)
    Reference(rule_name: String)

impl RulePattern:
    # =========================================================================
    # Helper Methods
    # =========================================================================

    fn is_token() -> bool:
        """Check if pattern is Token.

        Returns:
            true for Token

        Example:
            RulePattern::Token("identifier").is_token()  # → true
        """
        match self:
            case Token(_): true
            case _: false

    fn is_sequence() -> bool:
        """Check if pattern is Sequence.

        Returns:
            true for Sequence

        Example:
            RulePattern::Sequence([...]).is_sequence()  # → true
        """
        match self:
            case Sequence(_): true
            case _: false

    fn is_choice() -> bool:
        """Check if pattern is Choice.

        Returns:
            true for Choice

        Example:
            RulePattern::Choice([...]).is_choice()  # → true
        """
        match self:
            case Choice(_): true
            case _: false

    fn is_repeat() -> bool:
        """Check if pattern is Repeat.

        Returns:
            true for Repeat

        Example:
            RulePattern::Repeat(pattern).is_repeat()  # → true
        """
        match self:
            case Repeat(_): true
            case _: false

    fn is_optional() -> bool:
        """Check if pattern is Optional.

        Returns:
            true for Optional

        Example:
            RulePattern::Optional(pattern).is_optional()  # → true
        """
        match self:
            case Optional(_): true
            case _: false

    fn is_reference() -> bool:
        """Check if pattern is Reference.

        Returns:
            true for Reference

        Example:
            RulePattern::Reference("rule_name").is_reference()  # → true
        """
        match self:
            case Reference(_): true
            case _: false

    fn is_terminal() -> bool:
        """Check if pattern is terminal (Token).

        Returns:
            true for Token

        Example:
            RulePattern::Token("keyword").is_terminal()  # → true
            RulePattern::Reference("rule").is_terminal()  # → false
        """
        return self.is_token()

    fn is_composite() -> bool:
        """Check if pattern is composite (Sequence or Choice).

        Returns:
            true for Sequence or Choice

        Example:
            RulePattern::Sequence([...]).is_composite()  # → true
            RulePattern::Token("id").is_composite()  # → false
        """
        match self:
            case Sequence(_): true
            case Choice(_): true
            case _: false

    fn is_quantified() -> bool:
        """Check if pattern has quantifier (Repeat or Optional).

        Returns:
            true for Repeat or Optional

        Example:
            RulePattern::Repeat(pattern).is_quantified()  # → true
            RulePattern::Optional(pattern).is_quantified()  # → true
        """
        match self:
            case Repeat(_): true
            case Optional(_): true
            case _: false

    fn is_nullable() -> bool:
        """Check if pattern can match empty input.

        Returns:
            true for Optional or Repeat

        Example:
            RulePattern::Optional(pattern).is_nullable()  # → true
            RulePattern::Token("id").is_nullable()  # → false
        """
        match self:
            case Optional(_): true
            case Repeat(_): true
            case _: false

    fn has_children() -> bool:
        """Check if pattern contains sub-patterns.

        Returns:
            true for Sequence, Choice, Repeat, Optional

        Example:
            RulePattern::Sequence([...]).has_children()  # → true
            RulePattern::Token("id").has_children()  # → false
        """
        match self:
            case Sequence(_): true
            case Choice(_): true
            case Repeat(_): true
            case Optional(_): true
            case _: false

    fn to_string() -> String:
        """Convert pattern to string.

        Returns:
            Pattern type name

        Example:
            RulePattern::Token("id").to_string()  # → "token"
        """
        match self:
            case Token(_): "token"
            case Sequence(_): "sequence"
            case Choice(_): "choice"
            case Repeat(_): "repeat"
            case Optional(_): "optional"
            case Reference(_): "reference"

    fn description() -> String:
        """Get pattern description.

        Returns:
            Human-readable description

        Example:
            RulePattern::Token("identifier").description()
            # → "Token: identifier"
        """
        match self:
            case Token(t): "Token: {t}"
            case Sequence(patterns): "Sequence of {patterns.len()} patterns"
            case Choice(patterns): "Choice between {patterns.len()} alternatives"
            case Repeat(pattern): "Repeat (zero or more)"
            case Optional(pattern): "Optional (zero or one)"
            case Reference(name): "Reference to rule: {name}"

    fn summary() -> String:
        """Get summary of rule pattern.

        Returns:
            Human-readable summary

        Example:
            RulePattern::Repeat(pattern).summary()
            # → "RulePattern: repeat (quantified, nullable, has children)"
        """
        let name = self.to_string()
        let mut attrs: List<String> = []

        if self.is_terminal():
            attrs.push("terminal")
        if self.is_composite():
            attrs.push("composite")
        if self.is_quantified():
            attrs.push("quantified")
        if self.is_nullable():
            attrs.push("nullable")
        if self.has_children():
            attrs.push("has children")

        let attrs_str = attrs.join(", ")
        return if attrs.is_empty():
            "RulePattern: {name}"
        else:
            "RulePattern: {name} ({attrs_str})"

# Grammar compiler
class GrammarCompiler:
    fn new() -> GrammarCompiler:
        GrammarCompiler()

    # Compile a grammar
    fn compile(grammar: Grammar) -> Result<CompiledGrammar, String>:
        let mut compiled = CompiledGrammar.new(grammar.name, grammar.entry_point)

        # Step 1: Convert rules to compiled format
        for (name, rule) in grammar.rules.items():
            let compiled_rule = self.compile_rule(name, rule)?
            compiled.rules[name] = compiled_rule

        # Step 2: Compute nullable rules
        self.compute_nullable_rules(&mut compiled)?

        # Step 3: Compute first sets
        self.compute_first_sets(&mut compiled)?

        # Step 4: Compute follow sets
        self.compute_follow_sets(&mut compiled)?

        # Step 5: Extract token types
        self.extract_token_types(&mut compiled)?

        Ok(compiled)

    # Compile a single rule
    fn compile_rule(name: String, rule: GrammarRule) -> Result<CompiledRule, String>:
        # Simplified compilation - just wrap the rule for now
        # In real implementation, would analyze and optimize the pattern
        let pattern = RulePattern.Reference(name)  # Placeholder
        Ok(CompiledRule.new(name, pattern))

    # Compute which rules can match empty
    fn compute_nullable_rules(compiled: &mut CompiledGrammar) -> Result<Nil, String>:
        # Fixed-point iteration
        let mut changed = true
        while changed:
            changed = false

            for (name, rule) in compiled.rules.items():
                if not compiled.nullable_rules.contains(name):
                    if self.is_pattern_nullable(rule.pattern, compiled):
                        compiled.nullable_rules.insert(name)
                        changed = true

        Ok(nil)

    # Check if pattern is nullable
    fn is_pattern_nullable(pattern: RulePattern, compiled: &CompiledGrammar) -> Bool:
        match pattern:
            case Token(_):
                return false
            case Sequence(patterns):
                # All must be nullable
                for p in patterns:
                    if not self.is_pattern_nullable(p, compiled):
                        return false
                return true
            case Choice(patterns):
                # Any can be nullable
                for p in patterns:
                    if self.is_pattern_nullable(p, compiled):
                        return true
                return false
            case Repeat(_):
                return true  # Can match zero times
            case Optional(_):
                return true  # Can be absent
            case Reference(rule_name):
                return compiled.nullable_rules.contains(rule_name)

    # Compute first sets (which tokens can start each rule)
    fn compute_first_sets(compiled: &mut CompiledGrammar) -> Result<Nil, String>:
        # Initialize empty sets
        for (name, _) in compiled.rules.items():
            compiled.first_sets[name] = Set()

        # Fixed-point iteration
        let mut changed = true
        while changed:
            changed = false

            for (name, rule) in compiled.rules.items():
                let old_size = compiled.first_sets[name].size()
                self.add_first_tokens(rule.pattern, compiled, &mut compiled.first_sets[name])
                if compiled.first_sets[name].size() > old_size:
                    changed = true

        Ok(nil)

    # Add first tokens from pattern to set
    fn add_first_tokens(pattern: RulePattern,
        compiled: &CompiledGrammar,
        first_set: &mut Set<String>
    ):
        match pattern:
            case Token(token_type):
                first_set.insert(token_type)
            case Sequence(patterns):
                for p in patterns:
                    self.add_first_tokens(p, compiled, first_set)
                    if not self.is_pattern_nullable(p, compiled):
                        break
            case Choice(patterns):
                for p in patterns:
                    self.add_first_tokens(p, compiled, first_set)
            case Repeat(p):
                self.add_first_tokens(p, compiled, first_set)
            case Optional(p):
                self.add_first_tokens(p, compiled, first_set)
            case Reference(rule_name):
                match compiled.first_sets.get(rule_name):
                    case Some(set):
                        first_set.union(set)
                    case None:
                        pass

    # Compute follow sets (which tokens can follow each rule)
    fn compute_follow_sets(compiled: &mut CompiledGrammar) -> Result<Nil, String>:
        # Initialize empty sets
        for (name, _) in compiled.rules.items():
            compiled.follow_sets[name] = Set()

        # Entry point can be followed by EOF
        compiled.follow_sets[compiled.entry_point].insert("EOF")

        # Fixed-point iteration
        let mut changed = true
        while changed:
            changed = false

            for (name, rule) in compiled.rules.items():
                let old_sizes = self.get_total_follow_set_size(compiled)
                self.propagate_follow_sets(name, rule.pattern, compiled)
                if self.get_total_follow_set_size(compiled) > old_sizes:
                    changed = true

        Ok(nil)

    # Get total size of all follow sets (for change detection)
    fn get_total_follow_set_size(compiled: &CompiledGrammar) -> Int:
        let mut total = 0
        for (_, set) in compiled.follow_sets.items():
            total = total + set.size()
        total

    # Propagate follow sets through pattern
    fn propagate_follow_sets(rule_name: String,
        pattern: RulePattern,
        compiled: &mut CompiledGrammar
    ):
        match pattern:
            case Token(_):
                pass  # Terminals don't have follow sets
            case Sequence(patterns):
                # Each element's follow includes first of next (if not nullable)
                for i in 0..patterns.len():
                    if i + 1 < patterns.len():
                        # TODO: [parser][P3] Propagate follow sets through sequence
                        pass
            case Choice(patterns):
                for p in patterns:
                    self.propagate_follow_sets(rule_name, p, compiled)
            case Repeat(p):
                self.propagate_follow_sets(rule_name, p, compiled)
            case Optional(p):
                self.propagate_follow_sets(rule_name, p, compiled)
            case Reference(ref_name):
                # Propagate this rule's follow to referenced rule
                match compiled.follow_sets.get(rule_name):
                    case Some(follow):
                        compiled.follow_sets[ref_name].union(follow)
                    case None:
                        pass

    # Extract all token types used in grammar
    fn extract_token_types(compiled: &mut CompiledGrammar) -> Result<Nil, String>:
        let mut token_set: Set<String> = Set()

        for (_, rule) in compiled.rules.items():
            self.collect_token_types(rule.pattern, &mut token_set)

        compiled.token_types = token_set.to_list()

        Ok(nil)

    # Collect token types from pattern
    fn collect_token_types(pattern: RulePattern, token_set: &mut Set<String>):
        match pattern:
            case Token(token_type):
                token_set.insert(token_type)
            case Sequence(patterns):
                for p in patterns:
                    self.collect_token_types(p, token_set)
            case Choice(patterns):
                for p in patterns:
                    self.collect_token_types(p, token_set)
            case Repeat(p):
                self.collect_token_types(p, token_set)
            case Optional(p):
                self.collect_token_types(p, token_set)
            case Reference(_):
                pass  # References don't contain tokens directly

# Grammar cache for compiled grammars
class GrammarCache:
    cache: Dict<String, CompiledGrammar>

    fn new() -> GrammarCache:
        GrammarCache(cache: {})

    # Get compiled grammar from cache
    fn get(language: String) -> Option<CompiledGrammar>:
        self.cache.get(language)

    # Add compiled grammar to cache
    me add(language: String, compiled: CompiledGrammar):
        self.cache[language] = compiled

    # Check if language is cached
    fn contains(language: String) -> Bool:
        self.cache.contains_key(language)

    # Clear cache
    me clear():
        self.cache = {}

    # Get cache size
    fn size() -> Int:
        self.cache.len()

# Grammar compilation pipeline
class GrammarPipeline:
    compiler: GrammarCompiler
    cache: GrammarCache

    fn new() -> GrammarPipeline:
        GrammarPipeline(
            compiler: GrammarCompiler.new(),
            cache: GrammarCache.new()
        )

    # Compile grammar with caching
    me compile(grammar: Grammar) -> Result<CompiledGrammar, String>:
        # Check cache first
        match self.cache.get(grammar.name):
            case Some(compiled):
                return Ok(compiled)
            case None:
                pass

        # Compile grammar
        let compiled = self.compiler.compile(grammar)?

        # Add to cache
        self.cache.add(grammar.name, compiled)

        Ok(compiled)

    # Compile grammar for language name
    me compile_language(language: String) -> Result<CompiledGrammar, String>:
        # Check cache first
        match self.cache.get(language):
            case Some(compiled):
                return Ok(compiled)
            case None:
                pass

        # Load grammar for language
        # TODO: [parser][P1] Implement grammar loading
        Err("Grammar for language '{language}' not found")

    # Clear compilation cache
    me clear_cache():
        self.cache.clear()

# Convenience functions

# Compile a grammar
fn compile_grammar(grammar: Grammar) -> Result<CompiledGrammar, String>:
    let compiler = GrammarCompiler.new()
    compiler.compile(grammar)

# Compile grammar for a language
fn compile_language(language: String) -> Result<CompiledGrammar, String>:
    let mut pipeline = GrammarPipeline.new()
    pipeline.compile_language(language)
