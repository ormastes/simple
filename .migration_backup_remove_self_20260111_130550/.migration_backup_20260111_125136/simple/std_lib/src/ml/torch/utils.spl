# PyTorch Utilities - TensorBoard, Model Loading, and Training Utilities
#
# Utilities for logging, visualization, model management, and training enhancements.
#
# ## Classes
# - `SummaryWriter`: TensorBoard logging
# - `ModelCheckpoint`: Save/load model checkpoints
# - `PretrainedModel`: Load pretrained models
# - `ShapeTracker`: Optional static shape tracking
# - `AMP`: Automatic Mixed Precision training
#
# ## Example
# ```simple
# import ml.torch.utils as utils
# import ml.torch as torch
#
# # TensorBoard logging
# let writer = utils.SummaryWriter(log_dir="./runs/experiment1")
# writer.add_scalar("loss", 0.5, step=1)
# writer.add_histogram("weights", model.fc.weight, step=1)
# writer.close()
#
# # Model checkpointing
# let checkpoint = utils.ModelCheckpoint(
#     filepath="./checkpoints/best_model.pt",
#     monitor="val_loss",
#     mode="min"
# )
# checkpoint.save(model, optimizer, epoch=10, metrics={"val_loss": 0.25})
#
# # Load pretrained model
# let model = utils.PretrainedModel::load("resnet50", pretrained=true)
# ```

export SummaryWriter, ModelCheckpoint, PretrainedModel, ShapeTracker, AMP, GradScaler

import ml.torch.tensor_class.{Tensor}


import .. as torch
import ..nn as nn


# ============================================================================
# TensorBoard Logging - SummaryWriter
# ============================================================================

class SummaryWriter:
    """TensorBoard summary writer for logging training metrics.

    Logs scalars, histograms, images, and other data to TensorBoard.

    Attributes:
        log_dir: Directory for log files
        handle: Native handle for C++ writer

    Example:
        ```simple
        let writer = SummaryWriter(log_dir="./runs/exp1")

        # Log training metrics
        for epoch in range(100):
            writer.add_scalar("loss/train", train_loss, epoch)
            writer.add_scalar("accuracy/train", train_acc, epoch)
            writer.add_scalar("accuracy/val", val_acc, epoch)

        # Log model parameters
        writer.add_histogram("weights/fc1", model.fc1.weight, epoch)

        writer.close()
        ```
    """
    log_dir: str
    handle: u64

    fn __init__(log_dir: str = "./runs", comment: str = ""):
        """Initialize TensorBoard writer.

        Args:
            log_dir: Directory to save log files (default: "./runs")
            comment: Comment to append to log directory name

        FFI:
            Calls rt_torch_tensorboard_create(log_dir, comment)
        """
        self.log_dir = log_dir

        let log_dir_ptr = log_dir.as_ptr()
        let log_dir_len = log_dir.len() as i32
        let comment_ptr = comment.as_ptr()
        let comment_len = comment.len() as i32

        self.handle = @rt_torch_tensorboard_create(
            log_dir_ptr, log_dir_len,
            comment_ptr, comment_len
        )

    fn add_scalar(tag: str, value: f64, step: i64):
        """Log scalar value.

        Args:
            tag: Data identifier (e.g., "loss/train")
            value: Scalar value to log
            step: Global step (usually epoch or iteration)

        Example:
            ```simple
            writer.add_scalar("loss/train", 0.5, step=100)
            writer.add_scalar("accuracy/val", 0.95, step=100)
            ```
        """
        let tag_ptr = tag.as_ptr()
        let tag_len = tag.len() as i32

        @rt_torch_tensorboard_add_scalar(
            self.handle,
            tag_ptr, tag_len,
            value,
            step
        )

    fn add_histogram(tag: str, values: Tensor, step: i64):
        """Log histogram of values.

        Args:
            tag: Data identifier (e.g., "weights/fc1")
            values: Tensor containing values to histogram
            step: Global step

        Example:
            ```simple
            writer.add_histogram("gradients/fc1", grads, step=epoch)
            ```
        """
        let tag_ptr = tag.as_ptr()
        let tag_len = tag.len() as i32

        @rt_torch_tensorboard_add_histogram(
            self.handle,
            tag_ptr, tag_len,
            values.handle,
            step
        )

    fn add_image(tag: str, image: Tensor, step: i64):
        """Log image.

        Args:
            tag: Data identifier
            image: Image tensor (CHW format)
            step: Global step

        Note:
            Image should be in [C, H, W] format with values in [0, 1]
        """
        let tag_ptr = tag.as_ptr()
        let tag_len = tag.len() as i32

        @rt_torch_tensorboard_add_image(
            self.handle,
            tag_ptr, tag_len,
            image.handle,
            step
        )

    fn add_graph(model: nn.Module, input_tensor: Tensor):
        """Log model graph.

        Args:
            model: Neural network model
            input_tensor: Example input for tracing

        Example:
            ```simple
            let dummy_input = torch.randn([1, 3, 224, 224])
            writer.add_graph(model, dummy_input)
            ```
        """
        # Graph tracing requires model forward pass
        @rt_torch_tensorboard_add_graph(
            self.handle,
            model.handle,
            input_tensor.handle
        )

    fn flush():
        """Flush pending writes to disk."""
        @rt_torch_tensorboard_flush(self.handle)

    fn close():
        """Close writer and release resources."""
        @rt_torch_tensorboard_close(self.handle)


# ============================================================================
# Model Checkpointing
# ============================================================================

class ModelCheckpoint:
    """Save and load model checkpoints during training.

    Monitors a metric and saves the best model.

    Attributes:
        filepath: Path to save checkpoint
        monitor: Metric to monitor (e.g., "val_loss")
        mode: "min" or "max" for monitored metric
        best_value: Best monitored value seen

    Example:
        ```simple
        let checkpoint = ModelCheckpoint(
            filepath="./checkpoints/best_model.pt",
            monitor="val_loss",
            mode="min"
        )

        # During training
        for epoch in range(100):
            # ... training code ...

            let metrics = {"val_loss": val_loss, "val_acc": val_acc}
            checkpoint.save(model, optimizer, epoch, metrics)
        ```
    """
    filepath: str
    monitor: str
    mode: str
    best_value: f64

    fn __init__(filepath: str, monitor: str = "val_loss", mode: str = "min"):
        """Initialize checkpoint manager.

        Args:
            filepath: Path to save checkpoint file
            monitor: Metric name to monitor
            mode: "min" (lower is better) or "max" (higher is better)
        """
        self.filepath = filepath
        self.monitor = monitor
        self.mode = mode
        self.best_value = if mode == "min" then f64::INFINITY else -f64::INFINITY

    fn save(model: nn.Module, optimizer: any, epoch: i64, metrics: {str: f64}) -> bool:
        """Save checkpoint if metric improved.

        Args:
            model: Model to save
            optimizer: Optimizer state to save
            epoch: Current epoch
            metrics: Dictionary of metric values

        Returns:
            True if checkpoint was saved, False otherwise

        Example:
            ```simple
            let saved = checkpoint.save(
                model, optimizer, epoch=10,
                metrics={"val_loss": 0.25, "val_acc": 0.95}
            )
            if saved:
                print("Saved new best model!")
            ```
        """
        if self.monitor not in metrics:
            return false

        let current_value = metrics[self.monitor]
        let mut improved = false

        if self.mode == "min":
            improved = current_value < self.best_value
        else:
            improved = current_value > self.best_value

        if improved:
            self.best_value = current_value

            # Save checkpoint
            let filepath_ptr = self.filepath.as_ptr()
            let filepath_len = self.filepath.len() as i32

            @rt_torch_save_checkpoint(
                filepath_ptr, filepath_len,
                model.handle,
                optimizer.handle,
                epoch,
                current_value
            )

            return true

        return false

    fn load(model: nn.Module, optimizer: any = None) -> i64:
        """Load checkpoint from file.

        Args:
            model: Model to load weights into
            optimizer: Optional optimizer to load state into

        Returns:
            Epoch number from checkpoint

        Example:
            ```simple
            let epoch = checkpoint.load(model, optimizer)
            print("Resumed from epoch {epoch}")
            ```
        """
        let filepath_ptr = self.filepath.as_ptr()
        let filepath_len = self.filepath.len() as i32

        let mut epoch = 0i64
        let optimizer_handle = if optimizer is not None then optimizer.handle else 0u64

        @rt_torch_load_checkpoint(
            filepath_ptr, filepath_len,
            model.handle,
            optimizer_handle,
            &epoch
        )

        return epoch


# ============================================================================
# Pretrained Model Loading
# ============================================================================

class PretrainedModel:
    """Load pretrained models from torchvision or other sources.

    Provides access to popular pretrained architectures like ResNet, VGG, etc.

    Example:
        ```simple
        # Load pretrained ResNet50
        let model = PretrainedModel::load("resnet50", pretrained=true)

        # Use for transfer learning
        model.fc = nn.Linear(2048, 10)  # Replace final layer

        # Freeze early layers
        for param in model.parameters():
            param.requires_grad = false
        model.fc.parameters().requires_grad = true
        ```
    """

    @staticmethod
    fn load(model_name: str, pretrained: bool = true, num_classes: i64 = 1000) -> nn.Module:
        """Load pretrained model by name.

        Args:
            model_name: Model architecture name (e.g., "resnet50", "vgg16")
            pretrained: Whether to load pretrained ImageNet weights
            num_classes: Number of output classes (default: 1000 for ImageNet)

        Returns:
            Loaded model

        Supported models:
            - ResNet: "resnet18", "resnet34", "resnet50", "resnet101", "resnet152"
            - VGG: "vgg11", "vgg13", "vgg16", "vgg19"
            - DenseNet: "densenet121", "densenet169", "densenet201"
            - MobileNet: "mobilenet_v2", "mobilenet_v3_small", "mobilenet_v3_large"
            - EfficientNet: "efficientnet_b0" through "efficientnet_b7"
        """
        let name_ptr = model_name.as_ptr()
        let name_len = model_name.len() as i32

        let mut handle = 0u64

        @rt_torch_load_pretrained_model(
            name_ptr, name_len,
            pretrained as i32,
            num_classes,
            &handle
        )

        # Wrap in Module
        let model = nn.Module(handle)
        return model

    @staticmethod
    fn list_available() -> [str]:
        """List all available pretrained models.

        Returns:
            List of model names
        """
        let mut models = []

        # ResNet family
        models.append("resnet18")
        models.append("resnet34")
        models.append("resnet50")
        models.append("resnet101")
        models.append("resnet152")

        # VGG family
        models.append("vgg11")
        models.append("vgg13")
        models.append("vgg16")
        models.append("vgg19")

        # DenseNet family
        models.append("densenet121")
        models.append("densenet169")
        models.append("densenet201")

        # MobileNet family
        models.append("mobilenet_v2")
        models.append("mobilenet_v3_small")
        models.append("mobilenet_v3_large")

        # EfficientNet family
        for i in range(8):
            models.append("efficientnet_b{i}")

        return models


# ============================================================================
# Static Shape Tracking
# ============================================================================

class ShapeTracker:
    """Optional static shape tracking for compile-time optimization.

    Tracks tensor shapes through operations to enable static optimizations.

    Attributes:
        shapes: Dictionary mapping tensor IDs to shapes
        enabled: Whether tracking is enabled

    Example:
        ```simple
        let tracker = ShapeTracker()

        # Track shapes through network
        let x = torch.randn([32, 3, 224, 224])
        tracker.track(x, "input")

        let conv_out = conv_layer(x)
        tracker.track(conv_out, "conv1")

        # Get tracked shapes
        let shapes = tracker.get_all_shapes()
        print("Input shape: {shapes['input']}")
        print("Conv1 shape: {shapes['conv1']}")
        ```
    """
    shapes: {str: [i64]}
    enabled: bool

    fn __init__(enabled: bool = true):
        """Initialize shape tracker.

        Args:
            enabled: Whether to enable tracking (default: true)
        """
        self.shapes = {}
        self.enabled = enabled

    fn track(tensor: Tensor, name: str):
        """Track tensor shape.

        Args:
            tensor: Tensor to track
            name: Name/identifier for this tensor
        """
        if not self.enabled:
            return

        self.shapes[name] = tensor.shape()

    fn get_shape(name: str) -> [i64]:
        """Get tracked shape by name.

        Args:
            name: Tensor identifier

        Returns:
            Shape as list of dimensions
        """
        return self.shapes[name]

    fn get_all_shapes() -> {str: [i64]}:
        """Get all tracked shapes.

        Returns:
            Dictionary mapping names to shapes
        """
        return self.shapes

    fn verify_shape(tensor: Tensor, expected_shape: [i64]) -> bool:
        """Verify tensor matches expected shape.

        Args:
            tensor: Tensor to verify
            expected_shape: Expected shape

        Returns:
            True if matches, False otherwise
        """
        let actual_shape = tensor.shape()

        if actual_shape.len() != expected_shape.len():
            return false

        for i in range(actual_shape.len()):
            if expected_shape[i] != -1 and actual_shape[i] != expected_shape[i]:
                return false

        return true


# ============================================================================
# Automatic Mixed Precision (AMP)
# ============================================================================

class GradScaler:
    """Gradient scaler for automatic mixed precision training.

    Scales gradients to prevent underflow when using float16.

    Attributes:
        scale: Current scale factor
        growth_factor: Factor to increase scale by
        backoff_factor: Factor to decrease scale by
        growth_interval: Steps between scale increases

    Example:
        ```simple
        let scaler = GradScaler()

        for epoch in range(epochs):
            for (inputs, targets) in dataloader:
                optimizer.zero_grad()

                # Forward in float16
                outputs = model(inputs.half())
                loss = criterion(outputs, targets)

                # Scale loss and backward
                scaler.scale(loss).backward()

                # Unscale and step
                scaler.step(optimizer)
                scaler.update()
        ```
    """
    scale: f64
    growth_factor: f64
    backoff_factor: f64
    growth_interval: i64
    steps_since_update: i64

    fn __init__(init_scale: f64 = 65536.0,
        growth_factor: f64 = 2.0,
        backoff_factor: f64 = 0.5,
        growth_interval: i64 = 2000
    ):
        """Initialize gradient scaler.

        Args:
            init_scale: Initial scale factor
            growth_factor: Factor to multiply scale by when growing
            backoff_factor: Factor to multiply scale by when backing off
            growth_interval: Number of steps before attempting scale growth
        """
        self.scale = init_scale
        self.growth_factor = growth_factor
        self.backoff_factor = backoff_factor
        self.growth_interval = growth_interval
        self.steps_since_update = 0

    fn scale(loss: Tensor) -> Tensor:
        """Scale loss for backward pass.

        Args:
            loss: Loss tensor

        Returns:
            Scaled loss
        """
        return loss * self.scale

    fn step(optimizer: any):
        """Unscale gradients and call optimizer.step().

        Args:
            optimizer: Optimizer to step
        """
        # Unscale gradients
        @rt_torch_amp_unscale_gradients(optimizer.handle, self.scale)

        # Check for inf/nan gradients
        let has_inf_nan = @rt_torch_amp_check_inf_nan(optimizer.handle)

        if not has_inf_nan:
            # Step optimizer
            optimizer.step()
            self.steps_since_update = self.steps_since_update + 1
        else:
            # Skip step and reduce scale
            self.scale = self.scale * self.backoff_factor
            self.steps_since_update = 0

    fn update():
        """Update scale factor based on training progress."""
        if self.steps_since_update >= self.growth_interval:
            self.scale = self.scale * self.growth_factor
            self.steps_since_update = 0


class AMP:
    """Automatic Mixed Precision utilities.

    Provides context managers and utilities for AMP training.

    Example:
        ```simple
        # Enable AMP for model
        model = AMP::convert_model(model)

        # Training loop with AMP
        let scaler = GradScaler()
        for (inputs, targets) in dataloader:
            optimizer.zero_grad()

            # Forward in mixed precision
            let outputs = AMP::autocast() {
                model(inputs)
            }

            let loss = criterion(outputs, targets)
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
        ```
    """

    @staticmethod
    fn convert_model(model: nn.Module) -> nn.Module:
        """Convert model to use mixed precision.

        Args:
            model: Model to convert

        Returns:
            Converted model
        """
        @rt_torch_amp_convert_model(model.handle)
        return model

    @staticmethod
    fn is_available() -> bool:
        """Check if AMP is available on current hardware.

        Returns:
            True if AMP is supported
        """
        return torch.cuda_available()


# FFI Function Declarations (for documentation)
# These are called via @ syntax but documented here for reference:
#
# extern fn rt_torch_tensorboard_create(log_dir: *u8, log_dir_len: i32, comment: *u8, comment_len: i32) -> u64
# extern fn rt_torch_tensorboard_add_scalar(handle: u64, tag: *u8, tag_len: i32, value: f64, step: i64)
# extern fn rt_torch_tensorboard_add_histogram(handle: u64, tag: *u8, tag_len: i32, values: u64, step: i64)
# extern fn rt_torch_tensorboard_add_image(handle: u64, tag: *u8, tag_len: i32, image: u64, step: i64)
# extern fn rt_torch_tensorboard_add_graph(handle: u64, model: u64, input: u64)
# extern fn rt_torch_tensorboard_flush(handle: u64)
# extern fn rt_torch_tensorboard_close(handle: u64)
# extern fn rt_torch_save_checkpoint(filepath: *u8, filepath_len: i32, model: u64, optimizer: u64, epoch: i64, metric: f64)
# extern fn rt_torch_load_checkpoint(filepath: *u8, filepath_len: i32, model: u64, optimizer: u64, epoch: *i64)
# extern fn rt_torch_load_pretrained_model(name: *u8, name_len: i32, pretrained: i32, num_classes: i64, handle: *u64)
# extern fn rt_torch_amp_unscale_gradients(optimizer: u64, scale: f64)
# extern fn rt_torch_amp_check_inf_nan(optimizer: u64) -> bool
# extern fn rt_torch_amp_convert_model(model: u64)
