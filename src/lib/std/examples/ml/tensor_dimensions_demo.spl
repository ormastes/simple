# Tensor Dimension Inference - Working Demo
# Workaround for interpreter bug: top-level match statements cause early termination

print("============================================================")
print("  TENSOR DIMENSION INFERENCE - COMPLETE DEMO")
print("============================================================")
print("")

# ============================================================================
# Core Types
# ============================================================================

enum Dim:
    Literal(value: i32)
    Named(name: text, lo: i32, hi: i32)
    Var(id: i32)
    Unknown
    Broadcast

enum ShapeError:
    LiteralMismatch(expected: i32, actual: i32)
    RankMismatch(left_rank: i32, right_rank: i32)
    MatmulIncompatible(k1: i32, k2: i32)
    ReshapeMismatch(input_elems: i32, output_elems: i32)

struct TensorShape:
    dims: List<Dim>

enum ShapeResult:
    Ok(shape: TensorShape)
    Err(error: ShapeError)

# ============================================================================
# Utilities
# ============================================================================

fn dim_to_string(d: Dim) -> text:
    match d:
        case Dim::Literal(v):
            return "{v}"
        case Dim::Named(n, lo, hi):
            if lo == hi:
                return "{n}={lo}"
            else:
                return "{n}:{lo}..{hi}"
        case Dim::Var(id):
            return "α{id}"
        case Dim::Unknown:
            return "*"
        case Dim::Broadcast:
            return "?"

fn shape_to_string(shape: TensorShape) -> text:
    if shape.dims.len() == 0:
        return "[]"
    if shape.dims.len() == 1:
        return "[" + dim_to_string(shape.dims[0]) + "]"
    if shape.dims.len() == 2:
        return "[" + dim_to_string(shape.dims[0]) + ", " + dim_to_string(shape.dims[1]) + "]"
    if shape.dims.len() == 3:
        return "[" + dim_to_string(shape.dims[0]) + ", " + dim_to_string(shape.dims[1]) + ", " + dim_to_string(shape.dims[2]) + "]"
    return "[...{shape.dims.len()} dims...]"

# ============================================================================
# Dimension Operations
# ============================================================================

fn can_unify_dims(d1: Dim, d2: Dim) -> bool:
    match (d1, d2):
        case (Dim::Literal(v1), Dim::Literal(v2)):
            return v1 == v2
        case (Dim::Named(n1, _, _), Dim::Named(n2, _, _)):
            return n1 == n2
        case (Dim::Unknown, _):
            return true
        case (_, Dim::Unknown):
            return true
        case (Dim::Var(_), _):
            return true
        case (_, Dim::Var(_)):
            return true
        case (Dim::Broadcast, Dim::Literal(1)):
            return true
        case (Dim::Literal(1), Dim::Broadcast):
            return true
        case (Dim::Broadcast, _):
            return true
        case (_, Dim::Broadcast):
            return true
        case _:
            return false

fn unify_dim(d1: Dim, d2: Dim) -> Dim:
    match (d1, d2):
        case (Dim::Literal(v1), Dim::Literal(v2)):
            if v1 == v2:
                return d1
            else:
                return Dim.Unknown
        case (Dim::Named(n1, lo1, hi1), Dim::Named(n2, lo2, hi2)):
            if n1 == n2:
                val new_lo = if lo1 > lo2: lo1 else: lo2
                val new_hi = if hi1 < hi2: hi1 else: hi2
                return Dim.Named(name: n1, lo: new_lo, hi: new_hi)
            else:
                return Dim.Unknown
        case (Dim::Unknown, d):
            return d
        case (d, Dim::Unknown):
            return d
        case (Dim::Var(_), d):
            return d
        case (d, Dim::Var(_)):
            return d
        case (Dim::Broadcast, Dim::Literal(1)):
            return Dim.Literal(value: 1)
        case (Dim::Literal(1), Dim::Broadcast):
            return Dim.Literal(value: 1)
        case (Dim::Broadcast, d):
            return d
        case (d, Dim::Broadcast):
            return d
        case _:
            return Dim.Unknown

fn infer_matmul_shape(left: TensorShape, right: TensorShape) -> ShapeResult:
    if left.dims.len() != 2 or right.dims.len() != 2:
        return ShapeResult.Err(error: ShapeError.RankMismatch(
            left_rank: left.dims.len(),
            right_rank: right.dims.len()
        ))

    val m = left.dims[0]
    val k1 = left.dims[1]
    val k2 = right.dims[0]
    val n = right.dims[1]

    if not can_unify_dims(d1=k1, d2=k2):
        return ShapeResult.Err(error: ShapeError.MatmulIncompatible(
            k1: 0,
            k2: 0
        ))

    val k = unify_dim(d1=k1, d2=k2)
    return ShapeResult.Ok(shape: TensorShape(dims: [m, n]))

# ============================================================================
# Examples as Functions (Workaround for interpreter bug)
# ============================================================================

fn example1():
    print("Example 1: Basic Matrix Multiplication")
    print("------------------------------------------------------------")

    val a = TensorShape(dims: [Dim.Literal(value: 4), Dim.Literal(value: 8)])
    val b = TensorShape(dims: [Dim.Literal(value: 8), Dim.Literal(value: 16)])

    print("Matrix A: {shape_to_string(a)}")
    print("Matrix B: {shape_to_string(b)}")

    val result = infer_matmul_shape(left=a, right=b)
    match result:
        case ShapeResult.Ok(shape):
            print("✓ Result: {shape_to_string(shape)}")
            print("  [4,8] @ [8,16] -> [4,16]")
        case ShapeResult.Err(err):
            print("✗ Unexpected error!")

    print("")

fn example2():
    print("Example 2: MNIST Neural Network")
    print("------------------------------------------------------------")

    val input = TensorShape(dims: [
        Dim.Named(name: "batch", lo: 1, hi: 64),
        Dim.Literal(value: 784)
    ])
    val w1 = TensorShape(dims: [Dim.Literal(value: 784), Dim.Literal(value: 256)])
    val w2 = TensorShape(dims: [Dim.Literal(value: 256), Dim.Literal(value: 10)])

    print("Input:    {shape_to_string(input)}")
    print("Weight 1: {shape_to_string(w1)}")
    print("Weight 2: {shape_to_string(w2)}")

    val h1_result = infer_matmul_shape(left=input, right=w1)
    match h1_result:
        case ShapeResult.Ok(h1):
            print("Hidden 1: {shape_to_string(h1)}")

            val output_result = infer_matmul_shape(left=h1, right=w2)
            match output_result:
                case ShapeResult.Ok(output):
                    print("Output:   {shape_to_string(output)}")
                    print("✓ Dimensions propagated through 2-layer network!")
                case ShapeResult.Err(e):
                    print("✗ Layer 2 failed")
        case ShapeResult.Err(e):
            print("✗ Layer 1 failed")

    print("")

fn example3():
    print("Example 3: Error Detection")
    print("------------------------------------------------------------")

    val input = TensorShape(dims: [
        Dim.Named(name: "batch", lo: 1, hi: 64),
        Dim.Literal(value: 784)
    ])
    val bad_weight = TensorShape(dims: [
        Dim.Literal(value: 512),  # Wrong! Should be 784
        Dim.Literal(value: 10)
    ])

    print("Input:      {shape_to_string(input)}")
    print("Bad weight: {shape_to_string(bad_weight)}")

    val result = infer_matmul_shape(left=input, right=bad_weight)
    match result:
        case ShapeResult.Ok(shape):
            print("✗ Should have detected mismatch!")
        case ShapeResult.Err(err):
            print("✓ Caught error: K dimensions don't match (784 vs 512)")

    print("")

fn example4():
    print("Example 4: Named Dimensions with Ranges")
    print("------------------------------------------------------------")

    val input = TensorShape(dims: [
        Dim.Named(name: "batch", lo: 1, hi: 64),
        Dim.Literal(value: 784)
    ])
    val weight = TensorShape(dims: [
        Dim.Literal(value: 784),
        Dim.Named(name: "classes", lo: 10, hi: 10)
    ])

    print("Input:  {shape_to_string(input)}")
    print("Weight: {shape_to_string(weight)}")

    val result = infer_matmul_shape(left=input, right=weight)
    match result:
        case ShapeResult.Ok(shape):
            print("Output: {shape_to_string(shape)}")
            print("✓ Named dimensions preserved!")
        case ShapeResult.Err(err):
            print("✗ Unexpected error!")

    print("")

# ============================================================================
# Run All Examples
# ============================================================================

example1()
example2()
example3()
example4()

# ============================================================================
# Summary
# ============================================================================

print("============================================================")
print("  SUMMARY")
print("============================================================")
print("")
print("Successfully demonstrated:")
print("  ✓ Matrix multiplication shape inference")
print("  ✓ Multi-layer network dimension propagation")
print("  ✓ Shape mismatch detection")
print("  ✓ Named dimensions with range constraints")
print("")
print("Key Features:")
print("  • Compile-time dimension tracking")
print("  • Shape inference through operations")
print("  • Type-safe tensor operations")
print("")
