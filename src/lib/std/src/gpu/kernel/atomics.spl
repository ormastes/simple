# GPU Atomics - Atomic operations for GPU synchronization
#
# Provides atomic operations for thread-safe GPU memory access.

# Memory ordering for atomic operations
enum MemoryOrder:
    Relaxed      # No ordering guarantees
    Acquire      # Subsequent reads see effects of prior release
    Release      # Prior writes visible to subsequent acquires
    AcqRel       # Both acquire and release
    SeqCst       # Sequential consistency

# Atomic integer (32-bit)
struct AtomicI32:
    value: i32

    static fn new(value: i32) -> AtomicI32:
        return AtomicI32(value: value)

    # Load atomically
    @gpu_intrinsic("atomic_load_i32")
    fn load(order: MemoryOrder) -> i32:
        return self.value

    # Store atomically
    @gpu_intrinsic("atomic_store_i32")
    me store(value: i32, order: MemoryOrder):
        self.value = value

    # Exchange (swap)
    @gpu_intrinsic("atomic_exchange_i32")
    me exchange(value: i32, order: MemoryOrder) -> i32:
        val old = self.value
        self.value = value
        return old

    # Compare and swap
    @gpu_intrinsic("atomic_compare_exchange_i32")
    me compare_exchange(expected: i32, desired: i32, order: MemoryOrder) -> (bool, i32):
        if self.value == expected:
            self.value = desired
            return (true, expected)
        return (false, self.value)

    # Fetch and add
    @gpu_intrinsic("atomic_fetch_add_i32")
    me fetch_add(value: i32, order: MemoryOrder) -> i32:
        val old = self.value
        self.value = self.value + value
        return old

    # Fetch and subtract
    @gpu_intrinsic("atomic_fetch_sub_i32")
    me fetch_sub(value: i32, order: MemoryOrder) -> i32:
        val old = self.value
        self.value = self.value - value
        return old

    # Fetch and AND
    @gpu_intrinsic("atomic_fetch_and_i32")
    me fetch_and(value: i32, order: MemoryOrder) -> i32:
        val old = self.value
        self.value = self.value & value
        return old

    # Fetch and OR
    @gpu_intrinsic("atomic_fetch_or_i32")
    me fetch_or(value: i32, order: MemoryOrder) -> i32:
        val old = self.value
        self.value = self.value | value
        return old

    # Fetch and XOR
    @gpu_intrinsic("atomic_fetch_xor_i32")
    me fetch_xor(value: i32, order: MemoryOrder) -> i32:
        val old = self.value
        self.value = self.value xor value
        return old

    # Fetch and min
    @gpu_intrinsic("atomic_fetch_min_i32")
    me fetch_min(value: i32, order: MemoryOrder) -> i32:
        val old = self.value
        if value < self.value:
            self.value = value
        return old

    # Fetch and max
    @gpu_intrinsic("atomic_fetch_max_i32")
    me fetch_max(value: i32, order: MemoryOrder) -> i32:
        val old = self.value
        if value > self.value:
            self.value = value
        return old

# Atomic unsigned integer (32-bit)
struct AtomicU32:
    value: u32

    static fn new(value: u32) -> AtomicU32:
        return AtomicU32(value: value)

    @gpu_intrinsic("atomic_load_u32")
    fn load(order: MemoryOrder) -> u32:
        return self.value

    @gpu_intrinsic("atomic_store_u32")
    me store(value: u32, order: MemoryOrder):
        self.value = value

    @gpu_intrinsic("atomic_exchange_u32")
    me exchange(value: u32, order: MemoryOrder) -> u32:
        val old = self.value
        self.value = value
        return old

    @gpu_intrinsic("atomic_fetch_add_u32")
    me fetch_add(value: u32, order: MemoryOrder) -> u32:
        val old = self.value
        self.value = self.value + value
        return old

# Atomic float (32-bit)
struct AtomicF32:
    value: f32

    static fn new(value: f32) -> AtomicF32:
        return AtomicF32(value: value)

    @gpu_intrinsic("atomic_load_f32")
    fn load(order: MemoryOrder) -> f32:
        return self.value

    @gpu_intrinsic("atomic_store_f32")
    me store(value: f32, order: MemoryOrder):
        self.value = value

    @gpu_intrinsic("atomic_exchange_f32")
    me exchange(value: f32, order: MemoryOrder) -> f32:
        val old = self.value
        self.value = value
        return old

    # Atomic add (commonly used for accumulation)
    @gpu_intrinsic("atomic_add_f32")
    me add(value: f32, order: MemoryOrder) -> f32:
        val old = self.value
        self.value = self.value + value
        return old

# Memory fence/barrier
@gpu_intrinsic("memory_fence")
fn memory_fence(order: MemoryOrder):
    # Ensures all prior memory operations complete before subsequent ones
    pass

# Workgroup barrier (synchronize all threads in workgroup)
@gpu_intrinsic("workgroup_barrier")
fn workgroup_barrier():
    pass

# Storage barrier (synchronize storage buffer access)
@gpu_intrinsic("storage_barrier")
fn storage_barrier():
    pass

# Texture barrier
@gpu_intrinsic("texture_barrier")
fn texture_barrier():
    pass

pub use MemoryOrder
pub use AtomicI32, AtomicU32, AtomicF32
pub use memory_fence, workgroup_barrier, storage_barrier, texture_barrier
