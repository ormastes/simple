///
Module: sdn.lexer

SDN lexer with INDENT/DEDENT handling for Python-style indentation.

Features:
- Character-by-character tokenization
- INDENT/DEDENT state machine (like Python)
- Bracket depth tracking (disables indentation inside [], {}, ())
- Number parsing (integers, floats, scientific notation, underscores)
- text parsing (bare strings, quoted strings, escape sequences)
- Comment handling (# line comments)
- Line/column tracking for error reporting

Usage:
    import sdn.lexer
    val lexer = Lexer.new("name: Alice\nage: 30")
    val tokens = lexer.tokenize()
///

import error.Span
import token.{Token, TokenKind}

# Public exports
export Lexer, tokenize

/// SDN lexer with indentation tracking
class Lexer:
    source: text
    chars: List<Char>
    pos: i32
    line: i32
    column: i32
    indent_stack: List<i32>
    pending_tokens: List<Token>
    at_line_start: bool
    bracket_depth: i32

    fn new(source: text) -> Lexer:
        """Create a new lexer for the given source"""
        return Lexer(
            source: source,
            chars: source.chars(),
            pos: 0,
            line: 1,
            column: 1,
            indent_stack: [0],
            pending_tokens: [],
            at_line_start: True,
            bracket_depth: 0
        )

    var fn tokenize() -> List<Token>:
        """Tokenize the entire source into a vector of tokens"""
        var tokens = []

        loop:
            val token = self.next_token()
            val is_eof = match token.kind:
                case TokenKind.Eof:
                    True
                case _:
                    False

            tokens.push(token)

            if is_eof:
                break

        return tokens

    var fn next_token() -> Token:
        """Get the next token from the source"""
        # Return pending tokens first (for INDENT/DEDENT)
        if self.pending_tokens.len > 0:
            return self.pending_tokens.pop()

        # Handle indentation at line start (but not inside brackets)
        if self.at_line_start:
            self.at_line_start = False

            if self.bracket_depth == 0:
                match self.handle_indentation():
                    case Some(token):
                        return token
                    case None:
                        pass
            else:
                # Skip whitespace at line start when inside brackets
                loop:
                    match self.peek():
                        case Some(' '):
                            self.advance()
                        case Some('\t'):
                            self.advance()
                        case Some('\n'):
                            self.advance()
                            self.line += 1
                            self.column = 1
                        case _:
                            break

        self.skip_whitespace()

        val start_pos = self.pos
        val start_line = self.line
        val start_column = self.column

        # Check for EOF
        match self.advance():
            case None:
                # Generate remaining DEDENTs at EOF
                while self.indent_stack.len > 1:
                    self.indent_stack.pop()
                    val dedent_token = Token.new(
                        kind: TokenKind.Dedent,
                        span: Span.new(start_pos, start_pos, start_line, start_column),
                        lexeme: ""
                    )
                    self.pending_tokens.push(dedent_token)

                if self.pending_tokens.len > 0:
                    return self.pending_tokens.pop()

                return Token.new(
                    kind: TokenKind.Eof,
                    span: Span.new(start_pos, start_pos, start_line, start_column),
                    lexeme: ""
                )

            case Some(ch):
                # Determine token kind based on character
                val kind = match ch:
                    case '\n':
                        self.line += 1
                        self.column = 1
                        self.at_line_start = True
                        TokenKind.Newline

                    # Brackets - track depth
                    case '(':
                        self.bracket_depth += 1
                        TokenKind.LParen

                    case ')':
                        self.bracket_depth = max(0, self.bracket_depth - 1)
                        TokenKind.RParen

                    case '[':
                        self.bracket_depth += 1
                        TokenKind.LBracket

                    case ']':
                        self.bracket_depth = max(0, self.bracket_depth - 1)
                        TokenKind.RBracket

                    case '{':
                        self.bracket_depth += 1
                        TokenKind.LBrace

                    case '}':
                        self.bracket_depth = max(0, self.bracket_depth - 1)
                        TokenKind.RBrace

                    # Punctuation
                    case ',':
                        TokenKind.Comma

                    case ':':
                        TokenKind.Colon

                    case '=':
                        TokenKind.Equals

                    case '|':
                        TokenKind.Pipe

                    # Comments
                    case '#':
                        self.skip_comment()
                        return self.next_token()  # Recursively get next token

                    # Strings
                    case '"':
                        self.scan_string()

                    # Negative numbers
                    case '-':
                        match self.peek():
                            case Some(next_ch):
                                if next_ch.is_digit():
                                    self.scan_number(ch)
                                else:
                                    # Just a minus sign, skip and continue
                                    return self.next_token()
                            case None:
                                return self.next_token()

                    case _:
                        # Numbers
                        if ch.is_digit():
                            self.scan_number(ch)
                        # Identifiers and keywords
                        elif ch.is_alphabetic() or ch == '_':
                            self.scan_identifier(ch)
                        else:
                            # Unknown character - skip and try again
                            return self.next_token()

                val end_pos = self.pos
                val lexeme = self.source.substring(start_pos, end_pos)

                return Token.new(
                    kind: kind,
                    span: Span.new(start_pos, end_pos, start_line, start_column),
                    lexeme: lexeme
                )

    # Helper methods

    fn peek() -> Option<Char>:
        """Look at the current character without consuming it"""
        if self.pos < self.chars.len:
            return Some(self.chars[self.pos])
        return None

    fn peek_at(offset: i32) -> Option<Char>:
        """Look ahead by offset characters"""
        val idx = self.pos + offset
        if idx < self.chars.len:
            return Some(self.chars[idx])
        return None

    var fn advance() -> Option<Char>:
        """Consume and return the current character"""
        if self.pos < self.chars.len:
            val ch = self.chars[self.pos]
            self.pos += 1
            self.column += 1
            return Some(ch)
        return None

    var fn skip_whitespace():
        """Skip spaces and tabs (but not newlines)"""
        loop:
            match self.peek():
                case Some(' '):
                    self.advance()
                case Some('\t'):
                    self.advance()
                case _:
                    break

    var fn skip_comment():
        """Skip a # comment to end of line"""
        loop:
            match self.peek():
                case Some('\n'):
                    break
                case Some(_):
                    self.advance()
                case None:
                    break

    var fn handle_indentation() -> Option<Token>:
        """
        Handle indentation at the start of a line.

        Returns INDENT, DEDENT, or None if indent level unchanged.
        May queue multiple DEDENT tokens in pending_tokens.
        """
        val start_pos = self.pos
        val start_line = self.line

        # Count spaces at start of line
        var indent = 0

        loop:
            match self.peek():
                case Some(' '):
                    indent += 1
                    self.advance()

                case Some('\t'):
                    indent += 4  # Tab = 4 spaces
                    self.advance()

                case Some('\n'):
                    # Empty line - skip and check again
                    self.advance()
                    self.line += 1
                    self.column = 1
                    indent = 0

                case Some('#'):
                    # Comment line - skip entire line
                    self.skip_comment()
                    match self.peek():
                        case Some('\n'):
                            self.advance()
                            self.line += 1
                            self.column = 1
                            indent = 0
                        case _:
                            # EOF after comment
                            break

                case _:
                    break

        val current_indent = self.indent_stack.last()

        if indent > current_indent:
            # INDENT
            self.indent_stack.push(indent)
            return Some(Token.new(
                kind: TokenKind.Indent,
                span: Span.new(start_pos, self.pos, start_line, 1),
                lexeme: ""
            ))

        elif indent < current_indent:
            # DEDENT(s) - may need multiple
            loop:
                val top = self.indent_stack.last()
                if top > indent:
                    self.indent_stack.pop()
                    val dedent_token = Token.new(
                        kind: TokenKind.Dedent,
                        span: Span.new(start_pos, self.pos, start_line, 1),
                        lexeme: ""
                    )
                    self.pending_tokens.push(dedent_token)
                else:
                    break

            # Return first DEDENT
            if self.pending_tokens.len > 0:
                return Some(self.pending_tokens.pop())
            else:
                return None
        else:
            # Same indent level
            return None

    var fn scan_string() -> TokenKind:
        """Scan a quoted string with escape sequences"""
        var value = ""

        loop:
            match self.peek():
                case Some('"'):
                    # Closing quote
                    self.advance()
                    break

                case Some('\\'):
                    # Escape sequence
                    self.advance()
                    match self.peek():
                        case Some('n'):
                            self.advance()
                            value += "\n"
                        case Some('t'):
                            self.advance()
                            value += "\t"
                        case Some('r'):
                            self.advance()
                            value += "\r"
                        case Some('\\'):
                            self.advance()
                            value += "\\"
                        case Some('"'):
                            self.advance()
                            value += "\""
                        case Some(other):
                            # Unknown escape - keep literal
                            self.advance()
                            value += "\\"
                            value += other
                        case None:
                            break

                case Some(ch):
                    self.advance()
                    value += ch

                case None:
                    # Unclosed string - will be caught by parser
                    break

        return TokenKind.text(value)

    var fn scan_number(first: Char) -> TokenKind:
        """Scan an integer or f32 (with optional scientific notation)"""
        var value = ""
        value += first

        var has_dot = False
        var has_exp = False

        loop:
            match self.peek():
                case Some(ch):
                    if ch >= '0' and ch <= '9':
                        # Digit
                        self.advance()
                        value += ch

                    elif ch == '_':
                        # Underscore separator - skip
                        self.advance()

                    elif ch == '.' and not has_dot and not has_exp:
                        # Decimal point - check next char is digit
                        match self.peek_at(1):
                            case Some(next_ch):
                                if next_ch.is_digit():
                                    self.advance()
                                    value += '.'
                                    has_dot = True
                                else:
                                    break
                            case None:
                                break

                    elif (ch == 'e' or ch == 'E') and not has_exp:
                        # Scientific notation
                        self.advance()
                        value += ch
                        has_exp = True

                        # Handle optional sign after exponent
                        match self.peek():
                            case Some(sign):
                                if sign == '+' or sign == '-':
                                    self.advance()
                                    value += sign
                            case None:
                                pass

                    else:
                        break

                case None:
                    break

        # Parse the value
        if has_dot or has_exp:
            # f32
            match value.to_float():
                case Some(f):
                    return TokenKind.f32(f)
                case None:
                    return TokenKind.f32(0.0)
        else:
            # Integer
            match value.to_int():
                case Some(i):
                    return TokenKind.Integer(i)
                case None:
                    return TokenKind.Integer(0)

    var fn scan_identifier(first: Char) -> TokenKind:
        """Scan an identifier or keyword (including bare strings)"""
        var value = ""
        value += first

        loop:
            match self.peek():
                case Some(ch):
                    if ch.is_alphanumeric() or ch == '_' or ch == '/' or ch == '.' or ch == '-':
                        self.advance()
                        value += ch
                    else:
                        break
                case None:
                    break

        # Check for keywords
        match value:
            case "true":
                return TokenKind.bool(True)
            case "false":
                return TokenKind.bool(False)
            case "null":
                return TokenKind.Null
            case "nil":
                return TokenKind.Null
            case "table":
                return TokenKind.Table
            case _:
                return TokenKind.Identifier(value)

/// Tokenize a complete SDN source string
fn tokenize(source: text) -> List<Token>:
    var lexer = Lexer.new(source)
    return lexer.tokenize()
