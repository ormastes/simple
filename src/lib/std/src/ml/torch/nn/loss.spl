# Loss Functions
#
# Provides common loss functions for training neural networks.
#
# ## Classes
# - `MSELoss`: Mean Squared Error loss for regression
# - `CrossEntropyLoss`: Cross entropy loss for multi-class classification
# - `BCELoss`: Binary cross entropy loss for binary classification
#
# ## Example
# ```simple
# import ml.torch as torch
# import ml.torch.nn as nn
#
# # Regression
# val mse = nn.MSELoss()
# val loss = mse.forward(predictions, targets)
#
# # Classification
# val ce = nn.CrossEntropyLoss()
# val loss = ce.forward(logits, class_indices)
#
# # Binary classification
# val bce = nn.BCELoss()
# val probs = nn.sigmoid(logits)
# val loss = bce.forward(probs, targets)
# ```

pub use MSELoss, CrossEntropyLoss, BCELoss

use ml.torch.tensor_class.{Tensor}


# ============================================================================
# Loss Functions
# ============================================================================

class MSELoss:
    """Mean Squared Error loss.

    Computes the mean squared error between predictions and targets:
        loss = mean((predictions - targets)Â²)

    Example:
        ```simple
        val criterion = nn.MSELoss()
        val predictions = torch.tensor([[1.0, 2.0], [3.0, 4.0]])
        val targets = torch.tensor([[1.5, 2.5], [3.5, 4.5]])
        val loss = criterion.forward(predictions, targets)
        ```
    """
    reduction: str

    fn __init__(reduction: str = "mean"):
        """Initialize MSE loss.

        Args:
            reduction: Reduction mode - "mean", "sum", or "none" (default: "mean")
        """
        self.reduction = reduction

    fn forward(predictions: Tensor, targets: Tensor) -> Tensor:
        """Compute MSE loss.

        Args:
            predictions: Predicted values
            targets: Target values

        Returns:
            Loss tensor (scalar if reduction is "mean" or "sum")
        """
        val handle = @rt_torch_mse_loss(
            predictions.handle,
            targets.handle,
            self.reduction.as_ptr(),
            self.reduction.len() as i32
        )
        if handle == 0:
            panic("MSE loss computation failed")
        return Tensor(handle)


class CrossEntropyLoss:
    """Cross entropy loss for classification.

    Combines LogSoftmax and NLLLoss. Expects raw logits (no softmax).

    For multi-class classification:
        loss = -log(softmax(logits)[target_class])

    Example:
        ```simple
        val criterion = nn.CrossEntropyLoss()
        val logits = torch.tensor([[2.0, 1.0, 0.1]])  # 3 classes
        val targets = torch.tensor([0])  # Target is class 0
        val loss = criterion.forward(logits, targets)
        ```
    """
    reduction: str

    fn __init__(reduction: str = "mean"):
        """Initialize cross entropy loss.

        Args:
            reduction: Reduction mode - "mean", "sum", or "none" (default: "mean")
        """
        self.reduction = reduction

    fn forward(predictions: Tensor, targets: Tensor) -> Tensor:
        """Compute cross entropy loss.

        Args:
            predictions: Raw logits [batch_size, num_classes]
            targets: Target class indices [batch_size]

        Returns:
            Loss tensor
        """
        val handle = @rt_torch_cross_entropy_loss(
            predictions.handle,
            targets.handle,
            self.reduction.as_ptr(),
            self.reduction.len() as i32
        )
        if handle == 0:
            panic("Cross entropy loss computation failed")
        return Tensor(handle)


class BCELoss:
    """Binary cross entropy loss.

    For binary classification with sigmoid activation:
        loss = -[target * log(pred) + (1 - target) * log(1 - pred)]

    Input predictions should be probabilities (0-1 range, after sigmoid).

    Example:
        ```simple
        val criterion = nn.BCELoss()
        val predictions = nn.sigmoid(logits)  # Convert to probabilities
        val targets = torch.tensor([[1.0], [0.0], [1.0]])
        val loss = criterion.forward(predictions, targets)
        ```
    """
    reduction: str

    fn __init__(reduction: str = "mean"):
        """Initialize BCE loss.

        Args:
            reduction: Reduction mode - "mean", "sum", or "none" (default: "mean")
        """
        self.reduction = reduction

    fn forward(predictions: Tensor, targets: Tensor) -> Tensor:
        """Compute binary cross entropy loss.

        Args:
            predictions: Predicted probabilities [0-1] (after sigmoid)
            targets: Target values (0 or 1)

        Returns:
            Loss tensor
        """
        val handle = @rt_torch_bce_loss(
            predictions.handle,
            targets.handle,
            self.reduction.as_ptr(),
            self.reduction.len() as i32
        )
        if handle == 0:
            panic("BCE loss computation failed")
        return Tensor(handle)


# ============================================================================
# External FFI Functions
# ============================================================================

extern fn rt_torch_mse_loss(predictions: u64, targets: u64, reduction: *u8, reduction_len: i32) -> u64
extern fn rt_torch_cross_entropy_loss(predictions: u64, targets: u64, reduction: *u8, reduction_len: i32) -> u64
extern fn rt_torch_bce_loss(predictions: u64, targets: u64, reduction: *u8, reduction_len: i32) -> u64
