# Convolutional Layers
#
# Provides 2D and 3D convolutional layers for neural networks.
#
# ## Classes
# - `Conv2d`: 2D convolutional layer for images and 2D feature maps
# - `Conv3d`: 3D convolutional layer for video and 3D data
#
# ## Example
# ```simple
# import ml.torch as torch
# import ml.torch.nn as nn
#
# # 2D convolution for images
# val conv2d = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)
# val img = torch.randn([1, 3, 32, 32])  # [batch, channels, height, width]
# val features = conv2d(img)  # [1, 16, 32, 32]
#
# # 3D convolution for video
# val conv3d = nn.Conv3d(in_channels=3, out_channels=16, kernel_size=3, padding=1)
# val video = torch.randn([1, 3, 16, 32, 32])  # [batch, channels, depth, height, width]
# val features = conv3d(video)  # [1, 16, 16, 32, 32]
# ```

pub use Conv2d, Conv3d

use base.{FFIModule}


# ============================================================================
# Conv2d Layer
# ============================================================================

class Conv2d(FFIModule):
    """2D convolutional layer.

    Applies 2D convolution over input tensor.

    Example:
        ```simple
        # Input: [batch, 3, 32, 32] (RGB images)
        # Output: [batch, 16, 32, 32] (16 feature maps)
        val conv = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)
        val output = conv(input)
        ```
    """
    in_channels: i32
    out_channels: i32
    kernel_size: i32

    fn __init__(in_channels: i32, out_channels: i32, kernel_size: i32, stride: i32 = 1, padding: i32 = 0):
        """Initialize 2D convolution layer.

        Args:
            in_channels: Number of input channels
            out_channels: Number of output channels (filters)
            kernel_size: Size of convolution kernel
            stride: Stride for convolution (default: 1)
            padding: Zero-padding added to both sides (default: 0)
        """
        super().__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.kernel_size = kernel_size

        # Create module via FFI
        self.module_handle = @rt_torch_conv2d_new(
            in_channels,
            out_channels,
            kernel_size,
            stride,
            padding
        )
        self.validate_handle("Conv2d")

    fn forward(x: Tensor) -> Tensor:
        """Apply 2D convolution.

        Args:
            x: Input tensor [batch, in_channels, height, width]

        Returns:
            Output tensor [batch, out_channels, out_height, out_width]
        """
        val handle = @rt_torch_conv2d_forward(self.module_handle, x.handle)
        return self.wrap_output(handle, "Conv2d forward")


# ============================================================================
# Conv3d Layer
# ============================================================================

class Conv3d(FFIModule):
    """3D convolutional layer.

    Applies 3D convolution over input tensor (video, 3D medical imaging).

    Example:
        ```simple
        # Input: [batch, 3, depth, height, width] (video frames)
        # Output: [batch, 16, depth, height, width] (16 feature maps)
        val conv = nn.Conv3d(in_channels=3, out_channels=16, kernel_size=3, padding=1)
        val output = conv(input)
        ```
    """
    in_channels: i32
    out_channels: i32
    kernel_size: i32

    fn __init__(in_channels: i32, out_channels: i32, kernel_size: i32, stride: i32 = 1, padding: i32 = 0):
        """Initialize 3D convolution layer.

        Args:
            in_channels: Number of input channels
            out_channels: Number of output channels (filters)
            kernel_size: Size of convolution kernel
            stride: Stride for convolution (default: 1)
            padding: Zero-padding added to both sides (default: 0)
        """
        super().__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.kernel_size = kernel_size

        # Create module via FFI
        self.module_handle = @rt_torch_conv3d_new(
            in_channels,
            out_channels,
            kernel_size,
            stride,
            padding
        )
        self.validate_handle("Conv3d")

    fn forward(x: Tensor) -> Tensor:
        """Apply 3D convolution.

        Args:
            x: Input tensor [batch, in_channels, depth, height, width]

        Returns:
            Output tensor [batch, out_channels, out_depth, out_height, out_width]
        """
        val handle = @rt_torch_conv3d_forward(self.module_handle, x.handle)
        return self.wrap_output(handle, "Conv3d forward")


# ============================================================================
# External FFI Functions
# ============================================================================

extern fn rt_torch_conv2d_new(in_ch: i32, out_ch: i32, kernel: i32, stride: i32, padding: i32) -> u64
extern fn rt_torch_conv2d_forward(module: u64, input: u64) -> u64

extern fn rt_torch_conv3d_new(in_ch: i32, out_ch: i32, kernel: i32, stride: i32, padding: i32) -> u64
extern fn rt_torch_conv3d_forward(module: u64, input: u64) -> u64

extern fn rt_torch_module_free(module: u64) -> i32
