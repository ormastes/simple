# PyTorch Data Loading - Dataset and DataLoader
#
# Provides data loading infrastructure for training neural networks.
# Includes Dataset base class, DataLoader for batching, and samplers.
#
# ## Classes
# - `Dataset`: Abstract base class for datasets
# - `DataLoader`: Efficient batching and iteration over datasets
# - `Sampler`: Base class for sampling strategies
# - `SequentialSampler`: Sequential iteration
# - `RandomSampler`: Random shuffling
#
# ## Example
# ```simple
# import ml.torch.data as data
#
# class MyDataset(data.Dataset):
#     fn __len__(self) -> i64:
#         return 1000
#
#     fn __getitem__(self, index: i64) -> (Tensor, Tensor):
#         val x = torch.randn([10])
#         val y = torch.tensor([index % 10])
#         return (x, y)
#
# val dataset = MyDataset()
# val loader = data.DataLoader(dataset, batch_size=32, shuffle=true)
#
# for batch in loader:
#     val (inputs, labels) = batch
#     # Train with batch
# ```

export Dataset, DataLoader, Sampler, SequentialSampler, RandomSampler

import ml.torch.tensor_class.{Tensor}

import .. as torch


# ============================================================================
# Dataset Base Class
# ============================================================================

class Dataset:
    """Abstract base class for datasets.

    All datasets should inherit from this and implement __len__ and __getitem__.

    Example:
        ```simple
        class ImageDataset(Dataset):
            images: [str]
            labels: [i32]

            fn __init__(image_paths: [str], labels: [i32]):
                self.images = image_paths
                self.labels = labels

            fn __len__() -> i64:
                return self.images.len() as i64

            fn __getitem__(index: i64) -> (Tensor, i32):
                val image = load_image(self.images[index as usize])
                val label = self.labels[index as usize]
                return (image, label)
        ```
    """

    fn __len__() -> i64:
        """Return the number of samples in the dataset.

        Returns:
            Number of samples

        Note:
            Subclasses must override this method.
        """
        panic("__len__ must be implemented by subclass")

    fn __getitem__(index: i64) -> any:
        """Get a sample by index.

        Args:
            index: Sample index

        Returns:
            Sample (can be tuple, tensor, or any type)

        Note:
            Subclasses must override this method.
        """
        panic("__getitem__ must be implemented by subclass")


# ============================================================================
# Samplers
# ============================================================================

class Sampler:
    """Base class for sampling strategies.

    Samplers determine the order in which dataset indices are accessed.
    """
    dataset_size: i64

    fn __init__(dataset_size: i64):
        """Initialize sampler.

        Args:
            dataset_size: Size of the dataset
        """
        self.dataset_size = dataset_size

    fn __iter__() -> [i64]:
        """Return list of indices.

        Returns:
            List of indices in sampling order

        Note:
            Subclasses must override this method.
        """
        panic("__iter__ must be implemented by subclass")


class SequentialSampler(Sampler):
    """Sequential sampler - iterates indices in order 0, 1, 2, ...

    Example:
        ```simple
        val sampler = SequentialSampler(100)
        val indices = sampler.__iter__()  # [0, 1, 2, ..., 99]
        ```
    """

    fn __iter__() -> [i64]:
        """Return sequential indices.

        Returns:
            List [0, 1, 2, ..., dataset_size-1]
        """
        var indices = []
        for i in range(self.dataset_size):
            indices.append(i)
        return indices


class RandomSampler(Sampler):
    """Random sampler - shuffles indices for each epoch.

    Example:
        ```simple
        val sampler = RandomSampler(100)
        val indices = sampler.__iter__()  # Random permutation of [0..99]
        ```
    """

    fn __iter__() -> [i64]:
        """Return randomly shuffled indices.

        Returns:
            List of shuffled indices
        """
        # Create sequential indices
        var indices = []
        for i in range(self.dataset_size):
            indices.append(i)

        # Fisher-Yates shuffle
        for i in range(self.dataset_size - 1, 0, -1):
            val j = (rand() * (i + 1) as f64) as i64
            # Swap
            val temp = indices[i as usize]
            indices[i as usize] = indices[j as usize]
            indices[j as usize] = temp

        return indices


# ============================================================================
# DataLoader
# ============================================================================

class DataLoader:
    """DataLoader for batching and iterating over datasets.

    Provides efficient batching, shuffling, and iteration over datasets.

    Attributes:
        dataset: Dataset to load from
        batch_size: Number of samples per batch
        shuffle: Whether to shuffle data each epoch
        drop_last: Whether to drop incomplete final batch

    Example:
        ```simple
        val dataset = MyDataset()
        val loader = DataLoader(
            dataset,
            batch_size=32,
            shuffle=true,
            drop_last=false
        )

        for epoch in range(10):
            for batch in loader:
                val (inputs, targets) = batch
                # Training code here
        ```
    """
    dataset: Dataset
    batch_size: i64
    shuffle: bool
    drop_last: bool
    sampler: Sampler

    fn __init__(dataset: Dataset,
        batch_size: i64 = 1,
        shuffle: bool = false,
        drop_last: bool = false
    ):
        """Initialize DataLoader.

        Args:
            dataset: Dataset to load from
            batch_size: Number of samples per batch (default: 1)
            shuffle: Whether to shuffle data (default: false)
            drop_last: Drop incomplete final batch (default: false)
        """
        self.dataset = dataset
        self.batch_size = batch_size
        self.shuffle = shuffle
        self.drop_last = drop_last

        # Create appropriate sampler
        val dataset_size = dataset.__len__()
        if shuffle:
            self.sampler = RandomSampler(dataset_size)
        else:
            self.sampler = SequentialSampler(dataset_size)

    fn __iter__() -> [[any]]:
        """Iterate over batches.

        Returns:
            List of batches, where each batch is a list of samples

        Example:
            ```simple
            val loader = DataLoader(dataset, batch_size=32)
            for batch in loader:
                # batch is a list of 32 samples (or fewer for last batch)
                process_batch(batch)
            ```
        """
        # Get shuffled/sequential indices
        val indices = self.sampler.__iter__()
        val dataset_size = indices.len() as i64

        # Create batches
        var batches = []
        var current_batch = []

        for i in range(dataset_size):
            val index = indices[i as usize]
            val sample = self.dataset.__getitem__(index)
            current_batch.append(sample)

            # Check if batch is full
            if current_batch.len() as i64 >= self.batch_size:
                batches.append(current_batch)
                current_batch = []

        # Handle remaining samples
        if current_batch.len() > 0 and not self.drop_last:
            batches.append(current_batch)

        return batches

    fn __len__() -> i64:
        """Return number of batches.

        Returns:
            Number of batches in one epoch
        """
        val dataset_size = self.dataset.__len__()
        if self.drop_last:
            return dataset_size / self.batch_size
        else:
            return (dataset_size + self.batch_size - 1) / self.batch_size  # Ceiling division


# ============================================================================
# Utility Functions
# ============================================================================

fn collate_tensors(batch: [any]) -> (Tensor, Tensor):
    """Collate a batch of (tensor, tensor) tuples into batched tensors.

    Takes a list of (input, target) tuples and stacks them into batch tensors.

    Args:
        batch: List of (input_tensor, target_tensor) tuples

    Returns:
        Tuple of (batched_inputs, batched_targets)

    Example:
        ```simple
        # Batch of individual samples
        val batch = [
            (torch.tensor([1, 2]), torch.tensor([0])),
            (torch.tensor([3, 4]), torch.tensor([1])),
            (torch.tensor([5, 6]), torch.tensor([0]))
        ]

        val (inputs, targets) = collate_tensors(batch)
        # inputs: shape [3, 2] = [[1, 2], [3, 4], [5, 6]]
        # targets: shape [3, 1] = [[0], [1], [0]]
        ```

    Note:
        All tensors in the batch must have the same shape (except batch dimension).
    """
    if batch.len() == 0:
        panic("Cannot collate empty batch")

    # Extract inputs and targets
    var inputs = []
    var targets = []

    for sample in batch:
        val (input_tensor, target_tensor) = sample
        inputs.append(input_tensor)
        targets.append(target_tensor)

    # Stack tensors (concatenate along new batch dimension)
    val batched_inputs = torch.stack(inputs, dim=0)
    val batched_targets = torch.stack(targets, dim=0)

    return (batched_inputs, batched_targets)


# ============================================================================
# MNIST Dataset
# ============================================================================

class MNISTDataset(Dataset):
    """MNIST handwritten digit dataset.

    The MNIST database contains 60,000 training images and 10,000 test images
    of handwritten digits (0-9), each 28x28 pixels in grayscale.

    Attributes:
        root: Root directory where dataset is stored
        train: If True, load training set; otherwise load test set
        transform: Optional transform to apply to images
        download: If True, download dataset if not present
        images: Tensor of images [N, 28, 28]
        labels: Tensor of labels [N]

    Example:
        ```simple
        import ml.torch.data as data

        # Load training set
        val train_dataset = data.MNISTDataset(
            root="./data",
            train=true,
            download=true
        )

        # Load test set
        val test_dataset = data.MNISTDataset(
            root="./data",
            train=false
        )

        # Create data loader
        val train_loader = data.DataLoader(
            train_dataset,
            batch_size=64,
            shuffle=true
        )

        # Training loop
        for epoch in range(10):
            for (images, labels) in train_loader:
                # images: [batch_size, 28, 28]
                # labels: [batch_size]
                # Training code here
                pass
        ```

    Dataset structure:
        root/MNIST/raw/
            train-images-idx3-ubyte
            train-labels-idx1-ubyte
            t10k-images-idx3-ubyte
            t10k-labels-idx1-ubyte
    """
    root: str
    train: bool
    transform: any
    images: Tensor
    labels: Tensor
    num_samples: i64

    fn __init__(root: str = "./data", train: bool = true, transform: any = None, download: bool = false):
        """Initialize MNIST dataset.

        Args:
            root: Root directory for dataset storage (default: "./data")
            train: Load training set if True, test set if False (default: True)
            transform: Optional transform function (default: None)
            download: Download dataset if not present (default: False)
        """
        self.root = root
        self.train = train
        self.transform = transform

        # Load or download dataset
        if download:
            self._download()

        self._load_data()

    fn _download():
        """Download MNIST dataset from internet.

        Downloads the four MNIST files:
        - train-images-idx3-ubyte.gz (9.9 MB)
        - train-labels-idx1-ubyte.gz (29 KB)
        - t10k-images-idx3-ubyte.gz (1.6 MB)
        - t10k-labels-idx1-ubyte.gz (5 KB)
        """
        # Call FFI to download MNIST
        val root_ptr = self.root.as_ptr()
        val root_len = self.root.len() as i32
        val result = rt_torch_mnist_download(root_ptr, root_len)

        if result != 0:
            panic("Failed to download MNIST dataset to {self.root}")

    fn _load_data():
        """Load MNIST images and labels from disk."""
        val root_ptr = self.root.as_ptr()
        val root_len = self.root.len() as i32
        val is_train = self.train as i32

        # Load images and labels via FFI
        var images_handle = 0u64
        var labels_handle = 0u64

        val result = rt_torch_mnist_load(root_ptr, root_len, is_train, &images_handle, &labels_handle)

        if result != 0:
            panic("Failed to load MNIST dataset from {self.root}")

        self.images = Tensor(images_handle)
        self.labels = Tensor(labels_handle)
        self.num_samples = self.images.shape()[0]

    fn __len__() -> i64:
        """Get number of samples in dataset.

        Returns:
            Number of samples (60,000 for train, 10,000 for test)
        """
        return self.num_samples

    fn __getitem__(index: i64) -> (Tensor, Tensor):
        """Get sample at index.

        Args:
            index: Sample index (0 to len-1)

        Returns:
            Tuple of (image, label) where:
                - image: [28, 28] tensor
                - label: scalar tensor with digit (0-9)
        """
        val image = self.images[index]
        val label = self.labels[index]

        # Apply transform if provided
        if self.transform is not None:
            image = self.transform(image)

        return (image, label)


# ============================================================================
# CIFAR-10 Dataset
# ============================================================================

class CIFAR10Dataset(Dataset):
    """CIFAR-10 image classification dataset.

    The CIFAR-10 dataset consists of 60,000 32x32 color images in 10 classes,
    with 6,000 images per class. There are 50,000 training images and 10,000 test images.

    Classes:
        0: airplane
        1: automobile
        2: bird
        3: cat
        4: deer
        5: dog
        6: frog
        7: horse
        8: ship
        9: truck

    Attributes:
        root: Root directory where dataset is stored
        train: If True, load training set; otherwise load test set
        transform: Optional transform to apply to images
        download: If True, download dataset if not present
        images: Tensor of images [N, 3, 32, 32]
        labels: Tensor of labels [N]

    Example:
        ```simple
        import ml.torch.data as data

        # Load training set
        val train_dataset = data.CIFAR10Dataset(
            root="./data",
            train=true,
            download=true
        )

        # Load test set
        val test_dataset = data.CIFAR10Dataset(
            root="./data",
            train=false
        )

        # Create data loader
        val train_loader = data.DataLoader(
            train_dataset,
            batch_size=128,
            shuffle=true
        )

        # Training loop
        for epoch in range(100):
            for (images, labels) in train_loader:
                # images: [batch_size, 3, 32, 32] (RGB)
                # labels: [batch_size]
                # Training code here
                pass
        ```

    Dataset structure:
        root/cifar-10-batches-py/
            data_batch_1
            data_batch_2
            data_batch_3
            data_batch_4
            data_batch_5
            test_batch
    """
    root: str
    train: bool
    transform: any
    images: Tensor
    labels: Tensor
    num_samples: i64

    fn __init__(root: str = "./data", train: bool = true, transform: any = None, download: bool = false):
        """Initialize CIFAR-10 dataset.

        Args:
            root: Root directory for dataset storage (default: "./data")
            train: Load training set if True, test set if False (default: True)
            transform: Optional transform function (default: None)
            download: Download dataset if not present (default: False)
        """
        self.root = root
        self.train = train
        self.transform = transform

        # Load or download dataset
        if download:
            self._download()

        self._load_data()

    fn _download():
        """Download CIFAR-10 dataset from internet.

        Downloads cifar-10-python.tar.gz (163 MB) and extracts it.
        """
        val root_ptr = self.root.as_ptr()
        val root_len = self.root.len() as i32
        val result = rt_torch_cifar10_download(root_ptr, root_len)

        if result != 0:
            panic("Failed to download CIFAR-10 dataset to {self.root}")

    fn _load_data():
        """Load CIFAR-10 images and labels from disk."""
        val root_ptr = self.root.as_ptr()
        val root_len = self.root.len() as i32
        val is_train = self.train as i32

        # Load images and labels via FFI
        var images_handle = 0u64
        var labels_handle = 0u64

        val result = rt_torch_cifar10_load(root_ptr, root_len, is_train, &images_handle, &labels_handle)

        if result != 0:
            panic("Failed to load CIFAR-10 dataset from {self.root}")

        self.images = Tensor(images_handle)
        self.labels = Tensor(labels_handle)
        self.num_samples = self.images.shape()[0]

    fn __len__() -> i64:
        """Get number of samples in dataset.

        Returns:
            Number of samples (50,000 for train, 10,000 for test)
        """
        return self.num_samples

    fn __getitem__(index: i64) -> (Tensor, Tensor):
        """Get sample at index.

        Args:
            index: Sample index (0 to len-1)

        Returns:
            Tuple of (image, label) where:
                - image: [3, 32, 32] tensor (RGB channels)
                - label: scalar tensor with class (0-9)
        """
        val image = self.images[index]
        val label = self.labels[index]

        # Apply transform if provided
        if self.transform is not None:
            image = self.transform(image)

        return (image, label)


# ============================================================================
# External FFI Functions
# ============================================================================

extern fn rt_torch_mnist_download(root: *u8, root_len: i32) -> i32
extern fn rt_torch_mnist_load(root: *u8, root_len: i32, is_train: i32, images: *u64, labels: *u64) -> i32

extern fn rt_torch_cifar10_download(root: *u8, root_len: i32) -> i32
extern fn rt_torch_cifar10_load(root: *u8, root_len: i32, is_train: i32, images: *u64, labels: *u64) -> i32
