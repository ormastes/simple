# Training Engine
#
# Event-driven training loops inspired by PyTorch Ignite.
# Eliminates boilerplate while maintaining flexibility.
#
# ## Features
# - Generic Engine for any training/evaluation process
# - Event system (STARTED, EPOCH_COMPLETED, etc.)
# - Periodic events (every=N, once=N)
# - Custom events
# - Reusable handlers (Checkpoint, EarlyStopping)
# - Metrics computation
#
# ## Example
# ```simple
# import ml.engine.{Engine, Events}
#
# fn train_step(engine: Engine, batch: any):
#     model.train()
#     x, y = batch
#     pred = model(x)
#     loss = loss_fn(pred, y)
#     loss.backward()
#     optimizer.step()
#     return {"loss": loss.item()}
#
# val trainer = Engine(train_step)
#
# @trainer.on(EPOCH_COMPLETED)
# fn log_metrics(engine: Engine):
#     print(f"Epoch {engine.state.epoch}: loss={engine.state.output.loss}")
#
# trainer.run(train_loader, max_epochs=10)
# ```

pub use Engine, State, Metric, Loss, Accuracy, MSE, MAE, RMSE
pub use Precision, Recall, F1Score, ConfusionMatrix
pub use EarlyStopping, ModelCheckpoint, GradientClipper, ProgressBar
pub use LRFinder, ModelSummary
pub use ITERATION_COMPLETED_EVERY, EPOCH_COMPLETED_EVERY
pub use STARTED, EPOCH_STARTED, ITERATION_STARTED, ITERATION_COMPLETED
pub use EPOCH_COMPLETED, COMPLETED, EXCEPTION_RAISED


# ============================================================================
# Events - Built-in engine events
# ============================================================================

# Events fired during engine execution:
# - STARTED: Engine started
# - EPOCH_STARTED: Epoch started
# - ITERATION_STARTED: Before batch processing
# - ITERATION_COMPLETED: After batch processing
# - EPOCH_COMPLETED: Epoch completed
# - COMPLETED: Engine completed all epochs
# - EXCEPTION_RAISED: Exception during execution

val STARTED: str = "started"
val EPOCH_STARTED: str = "epoch_started"
val ITERATION_STARTED: str = "iteration_started"
val ITERATION_COMPLETED: str = "iteration_completed"
val EPOCH_COMPLETED: str = "epoch_completed"
val COMPLETED: str = "completed"
val EXCEPTION_RAISED: str = "exception_raised"


fn ITERATION_COMPLETED_EVERY(n: i64) -> str:
    """Create periodic event (every N iterations).

    Args:
        n: Iteration frequency

    Returns:
        Event name
    """
    return "iteration_completed_every_{n}"


fn EPOCH_COMPLETED_EVERY(n: i64) -> str:
    """Create periodic event (every N epochs).

    Args:
        n: Epoch frequency

    Returns:
        Event name
    """
    return "epoch_completed_every_{n}"


# ============================================================================
# Helper Functions
# ============================================================================

fn _sort_handlers_by_priority(handlers: any):
    """Sort handlers by priority (descending) in place.

    Uses insertion sort since we typically have few handlers.
    Each handler is a (priority, fn) tuple.

    Args:
        handlers: List of (priority, handler) tuples
    """
    val n = handlers.len()
    for i in 1..n:
        val key = handlers[i]
        val key_priority = key[0]
        var j = i - 1

        # Move elements with lower priority to the right
        while j >= 0 and handlers[j][0] < key_priority:
            handlers[j + 1] = handlers[j]
            j = j - 1

        handlers[j + 1] = key


# ============================================================================
# State Class
# ============================================================================

class State:
    """Engine state.

    Tracks current progress and output during execution.

    Attributes:
        epoch: Current epoch (0-indexed)
        iteration: Global iteration counter
        epoch_iteration: Iteration within current epoch
        max_epochs: Total epochs to run
        output: Return value of process function
        metrics: Computed metrics dict
        dataloader: Current dataloader
        batch: Current batch
    """
    epoch: i64 = 0
    iteration: i64 = 0
    epoch_iteration: i64 = 0
    max_epochs: i64 = 0
    output: any = 0
    metrics: any = {}
    dataloader: any = 0
    batch: any = 0


# ============================================================================
# Metric Base Class
# ============================================================================

class Metric:
    """Base class for metrics.

    Subclasses must implement reset(), update(), and compute().

    Example:
        ```simple
        class Accuracy(Metric):
            static fn new():
                self.correct = 0
                self.total = 0

            me reset():
                self.correct = 0
                self.total = 0

            me update(output: any):
                pred, labels = output
                self.correct += (pred == labels).sum()
                self.total += labels.len()

            fn compute() -> f64:
                return self.correct / self.total
        ```
    """

    me reset():
        """Reset metric state for new epoch."""
        return

    me update(output: any):
        """Update metric with batch output.

        Args:
            output: Process function output
        """
        return

    fn compute() -> f64:
        """Compute final metric value.

        Returns:
            Metric value
        """
        return 0.0


# ============================================================================
# Engine Class
# ============================================================================

class Engine:
    """Generic training/evaluation engine.

    Executes a process function on each batch and fires events.

    Example:
        ```simple
        fn train_step(engine: Engine, batch: any):
            # Training logic here
            return {"loss": loss.item()}

        val trainer = Engine(train_step)

        @trainer.on(ITERATION_COMPLETED)
        fn log(engine):
            print("Step {engine.state.iteration}")

        trainer.run(dataloader, max_epochs=10)
        ```

    Attributes:
        process_function: Function to execute per batch
        state: Engine state
        _event_handlers: Event handlers dict
        _metrics: Metrics dict
        _should_terminate: Termination flag
    """
    process_function: any
    state: State
    _event_handlers: any
    _metrics: any
    _should_terminate: bool

    fn __init__(process_function: any):
        """Initialize engine.

        Args:
            process_function: Function(engine, batch) -> output
        """
        self.process_function = process_function
        self.state = State()
        self._event_handlers = {}
        self._metrics = {}
        self._should_terminate = false

    fn attach_handler(event: str, handler: any, priority: i32):
        """Attach event handler.

        Args:
            event: Event name
            handler: Handler function(engine)
            priority: Priority (higher = earlier)

        Example:
            ```simple
            trainer.attach_handler(EPOCH_COMPLETED, log_epoch, 0)
            ```
        """
        if not event in self._event_handlers:
            self._event_handlers[event] = []

        # Add handler with priority
        self._event_handlers[event].append((priority, handler))

        # Sort by priority (descending) using simple insertion
        # Workaround for lambda not being supported yet
        _sort_handlers_by_priority(self._event_handlers[event])

    fn fire_event(event: str):
        """Fire event and execute handlers.

        Args:
            event: Event name
        """
        if event in self._event_handlers:
            for (priority, handler) in self._event_handlers[event]:
                handler(self)

    fn add_metric(metric: Metric, name: str):
        """Add metric to engine.

        Args:
            metric: Metric instance
            name: Metric name
        """
        self._metrics[name] = metric

    fn add_metrics(metrics: any):
        """Add multiple metrics.

        Args:
            metrics: Dict of name -> metric
        """
        for (name, metric) in metrics.items():
            self.add_metric(metric, name)

    fn run(data: any, max_epochs: i64):
        """Run engine on data.

        Args:
            data: Iterable dataloader
            max_epochs: Number of epochs to run

        Example:
            ```simple
            trainer.run(train_loader, max_epochs=10)
            ```
        """
        self.state.max_epochs = max_epochs
        self.state.dataloader = data

        # Fire STARTED event
        self.fire_event(STARTED)

        try:
            for epoch in range(max_epochs):
                if self._should_terminate:
                    break

                self.state.epoch = epoch
                self.state.epoch_iteration = 0

                # Reset metrics for new epoch
                for metric in self._metrics.values():
                    metric.reset()

                # Fire EPOCH_STARTED event
                self.fire_event(EPOCH_STARTED)

                # Iterate over data
                for batch in data:
                    if self._should_terminate:
                        break

                    self.state.batch = batch
                    self.state.epoch_iteration += 1
                    self.state.iteration += 1

                    # Fire ITERATION_STARTED event
                    self.fire_event(ITERATION_STARTED)

                    # Execute process function
                    self.state.output = self.process_function(self, batch)

                    # Update metrics
                    for metric in self._metrics.values():
                        metric.update(self.state.output)

                    # Fire ITERATION_COMPLETED event
                    self.fire_event(ITERATION_COMPLETED)

                    # Fire periodic events
                    self._fire_periodic_events()

                # Compute final metrics for epoch
                for (name, metric) in self._metrics.items():
                    self.state.metrics[name] = metric.compute()

                # Fire EPOCH_COMPLETED event
                self.fire_event(EPOCH_COMPLETED)

                # Fire periodic epoch events
                self._fire_periodic_epoch_events()

        except Exception as e:
            # Fire EXCEPTION_RAISED event
            self.fire_event(EXCEPTION_RAISED)
            raise e

        # Fire COMPLETED event
        self.fire_event(COMPLETED)

    fn terminate():
        """Terminate engine execution."""
        self._should_terminate = true

    # ========================================================================
    # Helper Methods
    # ========================================================================

    fn _fire_periodic_events():
        """Fire periodic iteration events."""
        # Check for every_N events
        for event_name in self._event_handlers.keys():
            if event_name.startswith("iteration_completed_every_"):
                # Extract N from event name
                val parts = event_name.split("_")
                val n = i32(parts[-1])

                if self.state.iteration % n == 0:
                    self.fire_event(event_name)

    fn _fire_periodic_epoch_events():
        """Fire periodic epoch events."""
        # Check for every_N events
        for event_name in self._event_handlers.keys():
            if event_name.startswith("epoch_completed_every_"):
                # Extract N from event name
                val parts = event_name.split("_")
                val n = i32(parts[-1])

                if (self.state.epoch + 1) % n == 0:
                    self.fire_event(event_name)


# ============================================================================
# Common Metrics
# ============================================================================

class Accuracy(Metric):
    """Accuracy metric for classification.

    Expects output to be dict with "pred" and "labels" keys, or tuple (pred, labels).
    Predictions and labels can be lists/arrays of class indices.

    Example:
        ```simple
        val accuracy = Accuracy()
        trainer.add_metric(accuracy, "acc")

        # Output format options:
        # 1. Dict: {"pred": [0, 1, 2], "labels": [0, 1, 1]}
        # 2. Tuple: ([0, 1, 2], [0, 1, 1])
        ```
    """
    correct: i64
    total: i64

    static fn new():
        """Initialize accuracy metric."""
        self.correct = 0
        self.total = 0

    me reset():
        """Reset for new epoch."""
        self.correct = 0
        self.total = 0

    me update(output: any):
        """Update with batch output.

        Args:
            output: Dict with "pred" and "labels" keys

        Supported formats:
            - Dict: {"pred": [0, 1, 2], "labels": [0, 1, 1]}
            - Dict: {"y_pred": [...], "y_true": [...]}
        """
        var pred = []
        var labels = []

        # Extract predictions and labels from output dict
        if "pred" in output and "labels" in output:
            pred = output["pred"]
            labels = output["labels"]
        elif "y_pred" in output and "y_true" in output:
            pred = output["y_pred"]
            labels = output["y_true"]

        # Compute matches
        if len(pred) > 0 and len(labels) > 0:
            val n = min(len(pred), len(labels))
            for i in range(n):
                self.total += 1
                if pred[i] == labels[i]:
                    self.correct += 1

    fn compute() -> f64:
        """Compute accuracy.

        Returns:
            Accuracy value in range [0.0, 1.0]
        """
        if self.total == 0:
            return 0.0
        return (self.correct.to_float()) / (self.total.to_float())


class ConfusionMatrix:
    """Confusion matrix for binary and multi-class classification.

    Tracks true positives, false positives, true negatives, false negatives
    for each class.

    Example:
        ```simple
        val cm = ConfusionMatrix(num_classes=3)
        cm.update([0, 1, 2], [0, 1, 1])  # pred, labels
        print(cm.tp(1))  # True positives for class 1
        ```
    """
    num_classes: i64
    _matrix: any  # 2D array [actual][predicted]

    fn __init__(num_classes: i64 = 2):
        """Initialize confusion matrix.

        Args:
            num_classes: Number of classes (default: 2 for binary)
        """
        self.num_classes = num_classes
        # Initialize NxN matrix with zeros
        self._matrix = []
        for i in range(num_classes):
            var row = []
            for j in range(num_classes):
                row = row + [0]
            self._matrix = self._matrix + [row]

    me reset():
        """Reset confusion matrix."""
        for i in range(self.num_classes):
            for j in range(self.num_classes):
                self._matrix[i][j] = 0

    me update(pred: any, labels: any):
        """Update confusion matrix with predictions.

        Args:
            pred: Predicted class indices
            labels: True class indices
        """
        val n = min(len(pred), len(labels))
        for i in range(n):
            val actual = labels[i]
            val predicted = pred[i]
            if actual >= 0 and actual < self.num_classes:
                if predicted >= 0 and predicted < self.num_classes:
                    self._matrix[actual][predicted] += 1

    fn tp(class_idx: i64) -> i64:
        """True positives for a class."""
        return self._matrix[class_idx][class_idx]

    fn fp(class_idx: i64) -> i64:
        """False positives for a class (predicted as class but was other)."""
        var total: i64 = 0
        for i in range(self.num_classes):
            if i != class_idx:
                total += self._matrix[i][class_idx]
        return total

    fn fn_(class_idx: i64) -> i64:
        """False negatives for a class (was class but predicted as other)."""
        var total: i64 = 0
        for j in range(self.num_classes):
            if j != class_idx:
                total += self._matrix[class_idx][j]
        return total

    fn tn(class_idx: i64) -> i64:
        """True negatives for a class."""
        var total: i64 = 0
        for i in range(self.num_classes):
            for j in range(self.num_classes):
                if i != class_idx and j != class_idx:
                    total += self._matrix[i][j]
        return total

    fn total_samples() -> i64:
        """Total samples in confusion matrix."""
        var total: i64 = 0
        for i in range(self.num_classes):
            for j in range(self.num_classes):
                total += self._matrix[i][j]
        return total


class Precision(Metric):
    """Precision metric for classification.

    Precision = TP / (TP + FP)

    For multi-class, computes macro-averaged precision.

    Example:
        ```simple
        val precision = Precision(num_classes=3)
        trainer.add_metric(precision, "precision")
        ```
    """
    num_classes: i64
    _cm: ConfusionMatrix

    fn __init__(num_classes: i64 = 2):
        """Initialize precision metric.

        Args:
            num_classes: Number of classes
        """
        self.num_classes = num_classes
        self._cm = ConfusionMatrix(num_classes)

    me reset():
        """Reset for new epoch."""
        self._cm.reset()

    me update(output: any):
        """Update with batch output.

        Args:
            output: Dict with "pred" and "labels" keys
        """
        var pred = []
        var labels = []

        if "pred" in output and "labels" in output:
            pred = output["pred"]
            labels = output["labels"]
        elif "y_pred" in output and "y_true" in output:
            pred = output["y_pred"]
            labels = output["y_true"]

        if len(pred) > 0:
            self._cm.update(pred, labels)

    fn compute() -> f64:
        """Compute macro-averaged precision.

        Returns:
            Precision value in range [0.0, 1.0]
        """
        var total_precision = 0.0
        var valid_classes = 0

        for c in range(self.num_classes):
            val tp = self._cm.tp(c)
            val fp = self._cm.fp(c)
            val denominator = tp + fp
            if denominator > 0:
                total_precision += tp.to_float() / denominator.to_float()
                valid_classes += 1

        if valid_classes == 0:
            return 0.0
        return total_precision / valid_classes.to_float()

    fn compute_per_class(class_idx: i64) -> f64:
        """Compute precision for a specific class.

        Args:
            class_idx: Class index

        Returns:
            Precision for the specified class
        """
        val tp = self._cm.tp(class_idx)
        val fp = self._cm.fp(class_idx)
        val denominator = tp + fp
        if denominator == 0:
            return 0.0
        return tp.to_float() / denominator.to_float()


class Recall(Metric):
    """Recall metric for classification.

    Recall = TP / (TP + FN)

    For multi-class, computes macro-averaged recall.

    Example:
        ```simple
        val recall = Recall(num_classes=3)
        trainer.add_metric(recall, "recall")
        ```
    """
    num_classes: i64
    _cm: ConfusionMatrix

    fn __init__(num_classes: i64 = 2):
        """Initialize recall metric.

        Args:
            num_classes: Number of classes
        """
        self.num_classes = num_classes
        self._cm = ConfusionMatrix(num_classes)

    me reset():
        """Reset for new epoch."""
        self._cm.reset()

    me update(output: any):
        """Update with batch output.

        Args:
            output: Dict with "pred" and "labels" keys
        """
        var pred = []
        var labels = []

        if "pred" in output and "labels" in output:
            pred = output["pred"]
            labels = output["labels"]
        elif "y_pred" in output and "y_true" in output:
            pred = output["y_pred"]
            labels = output["y_true"]

        if len(pred) > 0:
            self._cm.update(pred, labels)

    fn compute() -> f64:
        """Compute macro-averaged recall.

        Returns:
            Recall value in range [0.0, 1.0]
        """
        var total_recall = 0.0
        var valid_classes = 0

        for c in range(self.num_classes):
            val tp = self._cm.tp(c)
            val false_neg = self._cm.fn_(c)
            val denominator = tp + false_neg
            if denominator > 0:
                total_recall += tp.to_float() / denominator.to_float()
                valid_classes += 1

        if valid_classes == 0:
            return 0.0
        return total_recall / valid_classes.to_float()

    fn compute_per_class(class_idx: i64) -> f64:
        """Compute recall for a specific class.

        Args:
            class_idx: Class index

        Returns:
            Recall for the specified class
        """
        val tp = self._cm.tp(class_idx)
        val false_neg = self._cm.fn_(class_idx)
        val denominator = tp + false_neg
        if denominator == 0:
            return 0.0
        return tp.to_float() / denominator.to_float()


class F1Score(Metric):
    """F1 Score metric for classification.

    F1 = 2 * (Precision * Recall) / (Precision + Recall)

    Harmonic mean of precision and recall.

    Example:
        ```simple
        val f1 = F1Score(num_classes=3)
        trainer.add_metric(f1, "f1")
        ```
    """
    num_classes: i64
    _cm: ConfusionMatrix

    fn __init__(num_classes: i64 = 2):
        """Initialize F1 metric.

        Args:
            num_classes: Number of classes
        """
        self.num_classes = num_classes
        self._cm = ConfusionMatrix(num_classes)

    me reset():
        """Reset for new epoch."""
        self._cm.reset()

    me update(output: any):
        """Update with batch output.

        Args:
            output: Dict with "pred" and "labels" keys
        """
        var pred = []
        var labels = []

        if "pred" in output and "labels" in output:
            pred = output["pred"]
            labels = output["labels"]
        elif "y_pred" in output and "y_true" in output:
            pred = output["y_pred"]
            labels = output["y_true"]

        if len(pred) > 0:
            self._cm.update(pred, labels)

    fn compute() -> f64:
        """Compute macro-averaged F1 score.

        Returns:
            F1 score in range [0.0, 1.0]
        """
        var total_f1 = 0.0
        var valid_classes = 0

        for c in range(self.num_classes):
            val tp = self._cm.tp(c)
            val fp = self._cm.fp(c)
            val false_neg = self._cm.fn_(c)

            val precision_denom = tp + fp
            val recall_denom = tp + false_neg

            if precision_denom > 0 and recall_denom > 0:
                val precision = tp.to_float() / precision_denom.to_float()
                val recall = tp.to_float() / recall_denom.to_float()

                if precision + recall > 0.0:
                    val f1 = 2.0 * precision * recall / (precision + recall)
                    total_f1 += f1
                    valid_classes += 1

        if valid_classes == 0:
            return 0.0
        return total_f1 / valid_classes.to_float()

    fn compute_per_class(class_idx: i64) -> f64:
        """Compute F1 score for a specific class.

        Args:
            class_idx: Class index

        Returns:
            F1 score for the specified class
        """
        val tp = self._cm.tp(class_idx)
        val fp = self._cm.fp(class_idx)
        val false_neg = self._cm.fn_(class_idx)

        val precision_denom = tp + fp
        val recall_denom = tp + false_neg

        if precision_denom == 0 or recall_denom == 0:
            return 0.0

        val precision = tp.to_float() / precision_denom.to_float()
        val recall = tp.to_float() / recall_denom.to_float()

        if precision + recall == 0.0:
            return 0.0

        return 2.0 * precision * recall / (precision + recall)


class Loss(Metric):
    """Average loss metric.

    Example:
        ```simple
        val loss_metric = Loss()
        trainer.add_metric(loss_metric, "loss")
        ```
    """
    total_loss: f64
    count: i64

    static fn new():
        """Initialize loss metric."""
        self.total_loss = 0.0
        self.count = 0

    me reset():
        """Reset for new epoch."""
        self.total_loss = 0.0
        self.count = 0

    me update(output: any):
        """Update with batch output.

        Args:
            output: Dict with "loss" key
        """
        # Check for dict with "loss" key
        if "loss" in output:
            self.total_loss += output["loss"]
            self.count += 1

    fn compute() -> f64:
        """Compute average loss.

        Returns:
            Average loss
        """
        if self.count == 0:
            return 0.0
        return self.total_loss / (self.count.to_float())


# ============================================================================
# Regression Metrics
# ============================================================================

class MSE(Metric):
    """Mean Squared Error metric for regression.

    Computes: (1/n) * sum((pred - actual)^2)

    Example:
        ```simple
        val mse = MSE()
        trainer.add_metric(mse, "mse")

        # Output format: {"pred": [1.0, 2.0], "actual": [1.1, 2.2]}
        ```
    """
    total_squared_error: f64 = 0.0
    count: i64 = 0

    me reset():
        """Reset for new epoch."""
        self.total_squared_error = 0.0
        self.count = 0

    me update(output: any):
        """Update with batch output.

        Args:
            output: Dict with "pred" and "actual" keys
        """
        var pred = []
        var actual = []

        # Extract predictions and actuals from output dict
        if "pred" in output and "actual" in output:
            pred = output["pred"]
            actual = output["actual"]
        elif "y_pred" in output and "y_true" in output:
            pred = output["y_pred"]
            actual = output["y_true"]

        # Compute squared errors
        if len(pred) > 0 and len(actual) > 0:
            val n = min(len(pred), len(actual))
            for i in range(n):
                val p = pred[i]
                val a = actual[i]
                val diff = p - a
                self.total_squared_error += diff * diff
                self.count += 1

    fn compute() -> f64:
        """Compute mean squared error.

        Returns:
            MSE value
        """
        if self.count == 0:
            return 0.0
        return self.total_squared_error / (self.count.to_float())


class MAE(Metric):
    """Mean Absolute Error metric for regression.

    Computes: (1/n) * sum(|pred - actual|)

    Example:
        ```simple
        val mae = MAE()
        trainer.add_metric(mae, "mae")

        # Output format: {"pred": [1.0, 2.0], "actual": [1.1, 2.2]}
        ```
    """
    total_absolute_error: f64 = 0.0
    count: i64 = 0

    me reset():
        """Reset for new epoch."""
        self.total_absolute_error = 0.0
        self.count = 0

    me update(output: any):
        """Update with batch output.

        Args:
            output: Dict with "pred" and "actual" keys
        """
        var pred = []
        var actual = []

        # Extract predictions and actuals from output dict
        if "pred" in output and "actual" in output:
            pred = output["pred"]
            actual = output["actual"]
        elif "y_pred" in output and "y_true" in output:
            pred = output["y_pred"]
            actual = output["y_true"]

        # Compute absolute errors
        if len(pred) > 0 and len(actual) > 0:
            val n = min(len(pred), len(actual))
            for i in range(n):
                val p = pred[i]
                val a = actual[i]
                val diff = p - a
                self.total_absolute_error += abs(diff)
                self.count += 1

    fn compute() -> f64:
        """Compute mean absolute error.

        Returns:
            MAE value
        """
        if self.count == 0:
            return 0.0
        return self.total_absolute_error / (self.count.to_float())


class RMSE(Metric):
    """Root Mean Squared Error metric for regression.

    Computes: sqrt((1/n) * sum((pred - actual)^2))

    Example:
        ```simple
        val rmse = RMSE()
        trainer.add_metric(rmse, "rmse")
        ```
    """
    total_squared_error: f64 = 0.0
    count: i64 = 0

    me reset():
        """Reset for new epoch."""
        self.total_squared_error = 0.0
        self.count = 0

    me update(output: any):
        """Update with batch output.

        Args:
            output: Dict with "pred" and "actual" keys
        """
        var pred = []
        var actual = []

        # Extract predictions and actuals from output dict
        if "pred" in output and "actual" in output:
            pred = output["pred"]
            actual = output["actual"]
        elif "y_pred" in output and "y_true" in output:
            pred = output["y_pred"]
            actual = output["y_true"]

        # Compute squared errors
        if len(pred) > 0 and len(actual) > 0:
            val n = min(len(pred), len(actual))
            for i in range(n):
                val p = pred[i]
                val a = actual[i]
                val diff = p - a
                self.total_squared_error += diff * diff
                self.count += 1

    fn compute() -> f64:
        """Compute root mean squared error.

        Returns:
            RMSE value
        """
        if self.count == 0:
            return 0.0
        val mse_val = self.total_squared_error / (self.count.to_float())
        return sqrt(mse_val)


# ============================================================================
# Helper Functions
# ============================================================================

fn abs(x: f64) -> f64:
    """Absolute value."""
    if x < 0.0:
        return -x
    return x


fn sqrt(x: f64) -> f64:
    """Square root using Newton's method."""
    if x <= 0.0:
        return 0.0
    var guess = x / 2.0
    for _ in range(20):  # Newton iterations
        guess = (guess + x / guess) / 2.0
    return guess


fn min(a: i64, b: i64) -> i64:
    """Minimum of two integers."""
    if a < b:
        return a
    return b


fn max(a: i64, b: i64) -> i64:
    """Maximum of two integers."""
    if a > b:
        return a
    return b


# ============================================================================
# Training Handlers
# ============================================================================

class EarlyStopping:
    """Early stopping handler to terminate training when metric stops improving.

    Monitors a metric and stops training if no improvement is seen
    for a specified number of epochs (patience).

    Attributes:
        patience: Number of epochs with no improvement to wait
        min_delta: Minimum change to qualify as improvement
        mode: 'min' or 'max' - whether lower or higher is better

    Example:
        ```simple
        val early_stop = EarlyStopping(
            patience=10,
            min_delta=0.001,
            mode="min"
        )

        trainer.attach_handler(EPOCH_COMPLETED, early_stop.check, priority=0)
        trainer.run(data, max_epochs=100)
        ```
    """
    patience: i64
    min_delta: f64
    mode: str
    metric_name: str
    _best: f64
    _counter: i64
    _stopped_epoch: i64

    fn __init__(patience: i64 = 10, min_delta: f64 = 0.0, mode: str = "min", metric_name: str = "loss"):
        """Initialize early stopping.

        Args:
            patience: Epochs to wait before stopping
            min_delta: Minimum improvement threshold
            mode: 'min' or 'max'
            metric_name: Name of metric to monitor
        """
        self.patience = patience
        self.min_delta = min_delta
        self.mode = mode
        self.metric_name = metric_name
        self._counter = 0
        self._stopped_epoch = 0

        if mode == "min":
            self._best = 1e30
        else:
            self._best = -1e30

    fn check(engine: Engine):
        """Check if training should stop.

        Called as handler on EPOCH_COMPLETED.

        Args:
            engine: Training engine
        """
        if not self.metric_name in engine.state.metrics:
            return

        val current = engine.state.metrics[self.metric_name]
        val improved = self._is_improvement(current)

        if improved:
            self._best = current
            self._counter = 0
        else:
            self._counter += 1

        if self._counter >= self.patience:
            self._stopped_epoch = engine.state.epoch
            engine.terminate()

    fn _is_improvement(current: f64) -> bool:
        """Check if current value is an improvement."""
        if self.mode == "min":
            return current < self._best - self.min_delta
        else:
            return current > self._best + self.min_delta

    fn stopped_epoch() -> i64:
        """Get epoch when training stopped (-1 if not stopped)."""
        return self._stopped_epoch

    fn best_value() -> f64:
        """Get best metric value seen."""
        return self._best


class ModelCheckpoint:
    """Handler to save model checkpoints during training.

    Saves model state when monitored metric improves, or at regular intervals.

    Attributes:
        filepath: Path template for saved checkpoints
        monitor: Metric name to monitor
        mode: 'min' or 'max'
        save_best_only: Only save when metric improves
        period: Save every N epochs (if not save_best_only)

    Example:
        ```simple
        val checkpoint = ModelCheckpoint(
            filepath="checkpoints/model_{epoch}.pt",
            monitor="val_loss",
            mode="min",
            save_best_only=true
        )

        trainer.attach_handler(EPOCH_COMPLETED, checkpoint.save, priority=0)
        ```
    """
    filepath: str
    monitor: str
    mode: str
    save_best_only: bool
    period: i64
    _best: f64
    _last_saved_epoch: i64
    save_fn: any  # Function to save model

    fn __init__(filepath: str, monitor: str = "loss", mode: str = "min",
                save_best_only: bool = true, period: i64 = 1, save_fn: any = nil):
        """Initialize checkpoint handler.

        Args:
            filepath: Path template (use {epoch}, {metric} for substitution)
            monitor: Metric to monitor
            mode: 'min' or 'max'
            save_best_only: Only save on improvement
            period: Save frequency if not save_best_only
            save_fn: Custom save function(engine, path)
        """
        self.filepath = filepath
        self.monitor = monitor
        self.mode = mode
        self.save_best_only = save_best_only
        self.period = period
        self.save_fn = save_fn
        self._last_saved_epoch = -1

        if mode == "min":
            self._best = 1e30
        else:
            self._best = -1e30

    fn save(engine: Engine):
        """Save checkpoint if conditions are met.

        Args:
            engine: Training engine
        """
        val epoch = engine.state.epoch

        if self.save_best_only:
            if self.monitor not in engine.state.metrics:
                return

            val current = engine.state.metrics[self.monitor]
            val improved = self._is_improvement(current)

            if improved:
                self._best = current
                self._save_checkpoint(engine, epoch, current)
        else:
            if (epoch + 1) % self.period == 0:
                val current = 0.0
                if self.monitor in engine.state.metrics:
                    current = engine.state.metrics[self.monitor]
                self._save_checkpoint(engine, epoch, current)

    fn _is_improvement(current: f64) -> bool:
        """Check if metric improved."""
        if self.mode == "min":
            return current < self._best
        else:
            return current > self._best

    fn _save_checkpoint(engine: Engine, epoch: i64, metric: f64):
        """Actually save the checkpoint."""
        var path = self.filepath
        path = path.replace("{epoch}", str(epoch))
        path = path.replace("{metric}", str(metric))

        if self.save_fn is not nil:
            self.save_fn(engine, path)
        else:
            # Default: just log that we would save
            print("Saving checkpoint to {path}")

        self._last_saved_epoch = epoch

    fn best_value() -> f64:
        """Get best metric value."""
        return self._best


class GradientClipper:
    """Gradient clipping handler to prevent exploding gradients.

    Clips gradients by value or by norm after backward pass.

    Attributes:
        max_norm: Maximum gradient norm (for norm clipping)
        max_value: Maximum gradient value (for value clipping)
        clip_type: 'norm' or 'value'

    Example:
        ```simple
        val clipper = GradientClipper(max_norm=1.0)

        # In training step, after loss.backward():
        clipper.clip(model.parameters())
        optimizer.step()
        ```
    """
    max_norm: f64
    max_value: f64
    clip_type: str
    _total_norm: f64

    fn __init__(max_norm: f64 = 0.0, max_value: f64 = 0.0, clip_type: str = "norm"):
        """Initialize gradient clipper.

        Args:
            max_norm: Maximum gradient norm (for norm clipping)
            max_value: Maximum gradient value (for value clipping)
            clip_type: 'norm' or 'value'
        """
        self.max_norm = max_norm
        self.max_value = max_value
        self.clip_type = clip_type
        self._total_norm = 0.0

        if max_norm > 0.0:
            self.clip_type = "norm"
        elif max_value > 0.0:
            self.clip_type = "value"

    fn clip(parameters: any) -> f64:
        """Clip gradients and return total norm.

        Args:
            parameters: Model parameters (list of tensors)

        Returns:
            Total gradient norm before clipping
        """
        if self.clip_type == "norm":
            return self._clip_by_norm(parameters)
        else:
            return self._clip_by_value(parameters)

    fn _clip_by_norm(parameters: any) -> f64:
        """Clip gradients by global norm.

        Scales all gradients so total norm <= max_norm.
        """
        # Compute total norm
        var total_norm = 0.0
        for param in parameters:
            if param.grad is not nil:
                val grad_norm = param.grad.norm()
                total_norm += grad_norm * grad_norm

        total_norm = sqrt(total_norm)
        self._total_norm = total_norm

        # Scale if needed
        if total_norm > self.max_norm:
            val scale = self.max_norm / (total_norm + 1e-6)
            for param in parameters:
                if param.grad is not nil:
                    param.grad = param.grad.mul_scalar(scale)

        return total_norm

    fn _clip_by_value(parameters: any) -> f64:
        """Clip gradients by value.

        Clamps each gradient element to [-max_value, max_value].
        """
        var total_norm = 0.0
        for param in parameters:
            if param.grad is not nil:
                val grad_norm = param.grad.norm()
                total_norm += grad_norm * grad_norm
                param.grad = param.grad.clamp(-self.max_value, self.max_value)

        self._total_norm = sqrt(total_norm)
        return self._total_norm

    fn total_norm() -> f64:
        """Get total gradient norm from last clip call."""
        return self._total_norm


class ProgressBar:
    """Progress bar handler for training visualization.

    Shows epoch and iteration progress with metrics.

    Example:
        ```simple
        val pbar = ProgressBar()
        trainer.attach_handler(ITERATION_COMPLETED, pbar.update, priority=-1)
        trainer.attach_handler(EPOCH_COMPLETED, pbar.epoch_complete, priority=-1)
        ```
    """
    _width: i64
    _show_metrics: bool

    fn __init__(width: i64 = 50, show_metrics: bool = true):
        """Initialize progress bar.

        Args:
            width: Bar width in characters
            show_metrics: Whether to show metrics
        """
        self._width = width
        self._show_metrics = show_metrics

    fn update(engine: Engine):
        """Update progress bar.

        Args:
            engine: Training engine
        """
        val epoch = engine.state.epoch + 1
        val iteration = engine.state.epoch_iteration

        # Get total iterations if possible
        var total = 0
        if engine.state.dataloader is not nil:
            total = len(engine.state.dataloader)

        if total > 0:
            val progress = iteration.to_float() / total.to_float()
            val filled = (progress * self._width.to_float()) as i64
            val bar = "=" * filled + ">" + " " * (self._width - filled - 1)
            print("\rEpoch {epoch} [{bar}] {iteration}/{total}", end="")
        else:
            print("\rEpoch {epoch} - Iteration {iteration}", end="")

    fn epoch_complete(engine: Engine):
        """Called when epoch completes.

        Args:
            engine: Training engine
        """
        print("")  # New line after progress bar

        if self._show_metrics:
            var metrics_str = ""
            for (name, value) in engine.state.metrics.items():
                metrics_str += "{name}: {value:.4f}  "
            if metrics_str != "":
                print("  Metrics: {metrics_str}")


# ============================================================================
# Learning Rate Finder
# ============================================================================

class LRFinder:
    """Learning rate range test to find optimal LR.

    Runs training with exponentially increasing LR and plots loss.
    Optimal LR is typically 1/10 of the LR where loss starts increasing.

    Based on "Cyclical Learning Rates for Training Neural Networks" paper.

    Example:
        ```simple
        val lr_finder = LRFinder(min_lr=1e-7, max_lr=10.0, num_iter=100)

        fn train_step(engine, batch):
            # Set LR from finder
            optimizer.lr = lr_finder.get_lr(engine.state.iteration)
            # Training step...
            return {"loss": loss}

        trainer = Engine(train_step)
        trainer.attach_handler(ITERATION_COMPLETED, lr_finder.record, priority=0)
        trainer.run(data, max_epochs=1)

        val suggested_lr = lr_finder.suggestion()
        ```
    """
    min_lr: f64
    max_lr: f64
    num_iter: i64
    _lrs: any
    _losses: any
    _best_loss: f64
    _diverge_threshold: f64

    fn __init__(min_lr: f64 = 1e-7, max_lr: f64 = 10.0, num_iter: i64 = 100,
                diverge_threshold: f64 = 5.0):
        """Initialize LR finder.

        Args:
            min_lr: Starting learning rate
            max_lr: Maximum learning rate
            num_iter: Number of iterations for the test
            diverge_threshold: Stop if loss > best_loss * threshold
        """
        self.min_lr = min_lr
        self.max_lr = max_lr
        self.num_iter = num_iter
        self._diverge_threshold = diverge_threshold
        self._lrs = []
        self._losses = []
        self._best_loss = 1e30

    fn get_lr(iteration: i64) -> f64:
        """Get learning rate for current iteration.

        Args:
            iteration: Current iteration number

        Returns:
            Learning rate (exponentially increasing)
        """
        val progress = iteration.to_float() / self.num_iter.to_float()
        val log_min = _log10(self.min_lr)
        val log_max = _log10(self.max_lr)
        val log_lr = log_min + progress * (log_max - log_min)
        return _pow10(log_lr)

    fn record(engine: Engine):
        """Record loss at current LR.

        Args:
            engine: Training engine
        """
        if "loss" not in engine.state.output:
            return

        val lr = self.get_lr(engine.state.iteration)
        val loss = engine.state.output["loss"]

        self._lrs = self._lrs + [lr]
        self._losses = self._losses + [loss]

        if loss < self._best_loss:
            self._best_loss = loss

        # Check for divergence
        if loss > self._best_loss * self._diverge_threshold:
            engine.terminate()

    fn suggestion() -> f64:
        """Get suggested learning rate.

        Returns:
            Suggested LR (steepest descent point / 10)
        """
        if len(self._losses) < 3:
            return self.min_lr

        # Find steepest negative gradient
        var best_idx = 0
        var best_grad = 0.0

        for i in range(1, len(self._losses) - 1):
            val grad = self._losses[i - 1] - self._losses[i + 1]
            if grad > best_grad:
                best_grad = grad
                best_idx = i

        # Return LR at steepest point / 10
        if best_idx > 0 and best_idx < len(self._lrs):
            return self._lrs[best_idx] / 10.0
        return self.min_lr

    fn lrs() -> any:
        """Get recorded learning rates."""
        return self._lrs

    fn losses() -> any:
        """Get recorded losses."""
        return self._losses


# ============================================================================
# Model Summary
# ============================================================================

class ModelSummary:
    """Generate summary of model architecture.

    Shows layer names, output shapes, and parameter counts.

    Example:
        ```simple
        val summary = ModelSummary(model, input_size=(1, 3, 224, 224))
        print(summary.to_string())
        ```
    """
    _layers: any
    _total_params: i64
    _trainable_params: i64
    _input_size: any

    fn __init__(model: any = nil, input_size: any = nil):
        """Initialize model summary.

        Args:
            model: Model to summarize
            input_size: Input tensor shape (batch, channels, height, width)
        """
        self._layers = []
        self._total_params = 0
        self._trainable_params = 0
        self._input_size = input_size

        if model is not nil:
            self._analyze(model)

    fn _analyze(model: any):
        """Analyze model structure."""
        # Walk through model layers
        if hasattr(model, "modules"):
            for (name, module) in model.named_modules():
                val layer_info = self._analyze_layer(name, module)
                self._layers = self._layers + [layer_info]

    fn _analyze_layer(name: str, module: any) -> any:
        """Analyze single layer."""
        var num_params: i64 = 0
        var trainable: i64 = 0

        if hasattr(module, "parameters"):
            for param in module.parameters():
                val count = param.numel()
                num_params += count
                if param.requires_grad:
                    trainable += count

        self._total_params += num_params
        self._trainable_params += trainable

        return {
            "name": name,
            "type": type(module).__name__,
            "params": num_params,
            "trainable": trainable
        }

    fn total_params() -> i64:
        """Get total parameter count."""
        return self._total_params

    fn trainable_params() -> i64:
        """Get trainable parameter count."""
        return self._trainable_params

    fn non_trainable_params() -> i64:
        """Get non-trainable parameter count."""
        return self._total_params - self._trainable_params

    fn to_string() -> str:
        """Generate summary string."""
        var result = "=" * 60 + "\n"
        result += "Model Summary\n"
        result += "=" * 60 + "\n"
        result += "Layer (type)                 Params\n"
        result += "-" * 60 + "\n"

        for layer in self._layers:
            val name = layer["name"]
            val ltype = layer["type"]
            val params = layer["params"]
            result += "{name} ({ltype})".ljust(30) + "{params}\n"

        result += "=" * 60 + "\n"
        result += "Total params: {self._total_params}\n"
        result += "Trainable params: {self._trainable_params}\n"
        result += "Non-trainable params: {self._total_params - self._trainable_params}\n"
        result += "=" * 60 + "\n"

        return result


# ============================================================================
# Additional Helper Functions
# ============================================================================

fn _log10(x: f64) -> f64:
    """Compute log base 10."""
    if x <= 0.0:
        return -30.0  # Very negative
    # Use natural log and convert: log10(x) = ln(x) / ln(10)
    val ln10 = 2.302585093
    return _ln(x) / ln10


fn _ln(x: f64) -> f64:
    """Compute natural logarithm using series expansion."""
    if x <= 0.0:
        return -1e30

    # Normalize to [0.5, 1.5] range for better convergence
    var normalized = x
    var exponent: i64 = 0

    while normalized > 2.0:
        normalized = normalized / 2.0
        exponent += 1
    while normalized < 0.5:
        normalized = normalized * 2.0
        exponent -= 1

    # Use Taylor series around 1: ln(1+y) = y - y^2/2 + y^3/3 - ...
    val y = normalized - 1.0
    var result = 0.0
    var term = y
    for n in range(1, 30):
        if n % 2 == 1:
            result += term / n.to_float()
        else:
            result -= term / n.to_float()
        term = term * y

    # Add back the exponent: ln(x) = ln(normalized) + exponent * ln(2)
    val ln2 = 0.693147181
    return result + exponent.to_float() * ln2


fn _pow10(x: f64) -> f64:
    """Compute 10^x."""
    # 10^x = e^(x * ln(10))
    val ln10 = 2.302585093
    return _exp(x * ln10)


fn _exp(x: f64) -> f64:
    """Compute e^x using Taylor series."""
    # Clamp to prevent overflow
    if x > 30.0:
        return 1e30
    if x < -30.0:
        return 0.0

    var result = 1.0
    var term = 1.0
    for n in range(1, 30):
        term = term * x / n.to_float()
        result += term

    return result
