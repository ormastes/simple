# Test Execution Engine
# Executes registered tests with hook support and result capture
# Extended with resource-limited execution support

use spec.registry.{ExampleGroup, Example, Hook, MockMode, get_all_groups}
use spec.runner.filter.{TestFilter}
use spec.runtime.{Runtime, ExampleState}
use spec.progress.{init_progress, reset_progress}
use core.time.{Timer}
use concurrency.resource_limits.{ResourceLimits, LimitViolation, LimitedResult}
use concurrency.threads.{spawn_limited, LimitedThreadHandle}

# FFI declarations for mock policy
extern fn __mock_policy_init_all() -> ()
extern fn __mock_policy_init_hal_only() -> ()
extern fn __mock_policy_disable() -> ()

# Test result status
enum TestStatus:
    Passed
    Failed(message: text)
    Pending
    Skipped
    ResourceLimitViolation(violation: LimitViolation)

# Individual test result
class TestResult:
    example: Example
    group: ExampleGroup
    status: TestStatus
    duration_ms: f64
    failure_message: Option<text>

impl TestResult:
    fn new(example: Example, group: ExampleGroup) -> TestResult:
        return TestResult {
            example: example,
            group: group,
            status: TestStatus.Pending,
            duration_ms: 0.0,
            failure_message: None
        }

    fn mark_passed(duration_ms: f64) -> void:
        """Mark this test as passed."""
        self.status = TestStatus.Passed
        self.duration_ms = duration_ms

    fn mark_failed(message: text, duration_ms: f64) -> void:
        """Mark this test as failed with error message."""
        self.status = TestStatus.Failed(message)
        self.failure_message = Some(message)
        self.duration_ms = duration_ms

    fn mark_pending() -> void:
        """Mark this test as pending/skipped."""
        self.status = TestStatus.Pending

    fn mark_skipped() -> void:
        """Mark this test as skipped."""
        self.status = TestStatus.Skipped

    fn mark_resource_limit_violation(violation: LimitViolation, duration_ms: f64) -> void:
        """Mark this test as failed due to resource limit violation."""
        self.status = TestStatus.ResourceLimitViolation(violation)
        self.failure_message = Some(violation.message())
        self.duration_ms = duration_ms

    fn is_passed() -> bool:
        """Check if test passed."""
        match self.status:
            case TestStatus.Passed:
                return true
            case _:
                return false

    fn is_failed() -> bool:
        """Check if test failed (including resource limit violations)."""
        match self.status:
            case TestStatus.Failed(_):
                return true
            case TestStatus.ResourceLimitViolation(_):
                return true
            case _:
                return false

    fn is_resource_limit_violation() -> bool:
        """Check if test failed due to resource limit violation."""
        match self.status:
            case TestStatus.ResourceLimitViolation(_):
                return true
            case _:
                return false

    fn is_pending() -> bool:
        """Check if test is pending."""
        match self.status:
            case TestStatus.Pending:
                return true
            case _:
                return false

    fn is_skipped() -> bool:
        """Check if test is skipped."""
        match self.status:
            case TestStatus.Skipped:
                return true
            case _:
                return false

    fn full_description() -> text:
        """Get the full hierarchical test description."""
        return self.group.full_description() + " " + self.example.description

# Test information for listing
class TestInfo:
    full_description: text
    tags: List<text>
    is_slow: bool
    is_skipped: bool

# Test suite execution results
class ExecutionResults:
    results: List<TestResult>
    total_duration_ms: f64
    start_time: f64

impl ExecutionResults:
    fn new() -> ExecutionResults:
        return ExecutionResults {
            results: [],
            total_duration_ms: 0.0,
            start_time: 0.0
        }

    fn add_result(result: TestResult) -> void:
        """Add a test result."""
        self.results.push(result)

    fn passed_count() -> i32:
        """Count passed tests."""
        return self.results.filter(\r: r.is_passed()).len()

    fn failed_count() -> i32:
        """Count failed tests."""
        return self.results.filter(\r: r.is_failed()).len()

    fn pending_count() -> i32:
        """Count pending tests."""
        return self.results.filter(\r: r.is_pending()).len()

    fn skipped_count() -> i32:
        """Count skipped tests."""
        return self.results.filter(\r: r.is_skipped()).len()

    fn total_count() -> i32:
        """Count total tests."""
        return self.results.len()

    fn success_rate() -> f64:
        """Calculate success rate (0.0 to 1.0)."""
        if self.total_count() == 0:
            return 1.0
        return self.passed_count() as f64 / self.total_count() as f64

    fn all_passed() -> bool:
        """Check if all tests passed."""
        return self.failed_count() == 0 and self.pending_count() == 0

    fn has_failures() -> bool:
        """Check if there are any failures."""
        return self.failed_count() > 0

    fn failures() -> List<TestResult>:
        """Get all failed test results."""
        return self.results.filter(\r: r.is_failed())

    fn summary() -> text:
        """Get summary string."""
        val total = self.total_count()
        val passed = self.passed_count()
        val failed = self.failed_count()
        val pending = self.pending_count()
        val duration = self.total_duration_ms / 1000.0

        return "Finished in {duration}s\n{total} examples, {failed} failures, {pending} pending"

# Test executor - runs tests and captures results
class TestExecutor:
    runtime: Runtime
    run_slow_tests: bool
    filter_tags: List<text>
    filter_pattern: Option<text>
    filter: Option<TestFilter>

impl TestExecutor:
    fn new() -> TestExecutor:
        return TestExecutor {
            runtime: Runtime.new(),
            run_slow_tests: false,
            filter_tags: [],
            filter_pattern: None,
            filter: None
        }

    fn with_slow_tests(run_slow: bool) -> TestExecutor:
        """Enable/disable slow test execution."""
        self.run_slow_tests = run_slow
        return self

    fn with_tags(tags: List<text>) -> TestExecutor:
        """Filter tests by tags."""
        self.filter_tags = tags
        return self

    fn with_pattern(pattern: text) -> TestExecutor:
        """Filter tests by description pattern."""
        self.filter_pattern = Some(pattern)
        return self

    fn with_filter(test_filter: TestFilter) -> TestExecutor:
        """Apply comprehensive test filter."""
        self.filter = Some(test_filter)
        return self

    fn should_run_example(example: Example, group: ExampleGroup) -> bool:
        """Check if example should run based on filters."""
        # Check if example should run (not skipped, slow test handling)
        if not example.should_run(self.run_slow_tests):
            return false

        # Use comprehensive filter if provided
        match self.filter:
            case Some(filter):
                return filter.matches_example(example, group)
            case None:
                # Fall back to simple tag and pattern filters
                # Check tag filters
                if not self.filter_tags.is_empty():
                    var has_matching_tag = false
                    for tag in self.filter_tags:
                        if example.has_tag(tag):
                            has_matching_tag = true
                            break
                    if not has_matching_tag:
                        return false

                # Check pattern filter
                match self.filter_pattern:
                    case Some(pattern):
                        val full_desc = group.full_description() + " " + example.description
                        if not full_desc.contains(pattern):
                            return false
                    case None:
                        pass

                return true

    fn execute_hooks(hooks: List<Any>) -> void:
        """Execute a list of hooks."""
        for hook_block in hooks:
            # Call the hook block
            hook_block()

    fn init_mock_policy_for_mode(mode: MockMode):
        """Initialize mock policy based on the mode."""
        match mode:
            case MockMode.All:
                __mock_policy_init_all()
            case MockMode.HalOnly:
                __mock_policy_init_hal_only()
            case MockMode.Disabled:
                __mock_policy_disable()
            case MockMode.Custom:
                # Custom mode requires patterns, fall back to all for now
                __mock_policy_init_all()

    fn execute_example(example: Example, group: ExampleGroup) -> TestResult:
        """Execute a single test example."""
        val result = TestResult.new(example, group)

        # Check if should run
        if not self.should_run_example(example, group):
            result.mark_skipped()
            return result

        # Check if pending
        if example.is_pending():
            result.mark_pending()
            return result

        # Determine mock mode: example-specific, group-inherited, or default
        val mock_mode = example.mock_mode

        # Initialize mock policy for this test
        self.init_mock_policy_for_mode(mock_mode)

        # Get hooks from group hierarchy (uses cached O(1) lookup)
        val before_hooks = group.get_all_before_each_hooks()
        val after_hooks = group.get_all_after_each_hooks()

        # Start timer
        val timer = Timer.start()

        # Reset example state
        self.runtime.reset_example_state()

        # Initialize progress tracking for this test
        init_progress()

        # Execute before_each hooks
        self.execute_hooks(before_hooks)

        # Check if example has resource limits
        if example.has_resource_limits():
            # Execute with resource limits in isolated thread
            match example.get_resource_limits():
                case Some(limits):
                    val execution_result = self.execute_with_limits(example, limits)
                    val duration = timer.elapsed_ms()

                    match execution_result:
                        case LimitedResult.Success(_):
                            result.mark_passed(duration)
                        case LimitedResult.Killed(violation):
                            result.mark_resource_limit_violation(violation, duration)
                        case LimitedResult.Error(msg):
                            result.mark_failed(msg, duration)
                case None:
                    # Should not happen, but fall back to normal execution
                    val test_passed = safe_execute_example(example)
                    val duration = timer.elapsed_ms()
                    if test_passed:
                        result.mark_passed(duration)
                    else:
                        result.mark_failed("Test execution failed", duration)
        else:
            # Execute the test normally with error handling
            val test_passed = safe_execute_example(example)
            val duration = timer.elapsed_ms()

            if test_passed:
                result.mark_passed(duration)
            else:
                result.mark_failed("Test execution failed - error handling not yet supported", duration)

        # Execute after_each hooks (always run)
        self.execute_hooks(after_hooks)

        # Reset progress tracking
        reset_progress()

        return result

    fn execute_with_limits(example: Example, limits: ResourceLimits) -> LimitedResult<Any>:
        """Execute an example in an isolated thread with resource limits."""
        # Wrap the example block in a closure that can be passed to spawn_limited
        val block_fn = example.block

        # Spawn a limited thread to execute the test
        val handle = spawn_limited(block_fn, limits) \block:
            # Execute the test block
            block()
            return nil

        # Wait for the thread to complete and get the result
        return handle.join_result()

    # REMOVED: Old O(n²) hook collection methods replaced with cached O(1) methods
    # The functionality is now in ExampleGroup.get_all_before_each_hooks() and
    # ExampleGroup.get_all_after_each_hooks() which use caching to avoid
    # the performance issue.
    #
    # Previous bug: These methods recursively walked the parent chain and copied
    # hooks at each level, resulting in O(n²) complexity for deeply nested contexts.
    # With N nested contexts and M tests, total cost was O(N² × M).

    fn execute_group(group: ExampleGroup, results: ExecutionResults) -> void:
        """Execute all examples in a group and its children."""
        # Execute before_all hooks
        self.execute_hooks(group.get_before_all_hooks())

        # Execute examples in this group
        for example in group.test_examples:
            val result = self.execute_example(example, group)
            results.add_result(result)

        # Execute child groups recursively
        for child in group.children:
            self.execute_group(child, results)

        # Execute after_all hooks
        self.execute_hooks(group.get_after_all_hooks())

    fn collect_tests_from_group(group: ExampleGroup, test_list: List<TestInfo>) -> void:
        """Collect test information from a group and its children."""
        # Collect examples from this group
        for example in group.test_examples:
            val should_include = match self.filter:
                case Some(filter):
                    filter.matches_example(example, group)
                case None:
                    true

            if should_include:
                val full_desc = group.full_description() + " " + example.description
                val test_info = TestInfo {
                    full_description: full_desc,
                    tags: example.tags,
                    is_slow: example.has_tag("slow"),
                    is_skipped: not example.should_run(self.run_slow_tests)
                }
                test_list.push(test_info)

        # Collect from child groups recursively
        for child in group.children:
            self.collect_tests_from_group(child, test_list)

    fn list_tests() -> List<TestInfo>:
        """List all tests that would run with current filter settings."""
        var test_list: List<TestInfo> = []
        val groups = get_all_groups()

        for group in groups:
            self.collect_tests_from_group(group, test_list)

        return test_list

    fn run() -> ExecutionResults:
        """Execute all registered tests and return results."""
        val results = ExecutionResults.new()
        results.start_time = Timer.now()

        val groups = get_all_groups()

        # Precompute hook caches for all groups to avoid O(n²) performance
        # This is critical for tests with deeply nested contexts (10+ levels)
        print "[DEBUG] Precomputing hooks for {groups.len()} groups"
        for group in groups:
            print "[DEBUG] Precomputing hooks for group: {group.description}"
            group.precompute_hooks()
        print "[DEBUG] Hook precomputation complete"

        for group in groups:
            self.execute_group(group, results)

        results.total_duration_ms = Timer.now() - results.start_time

        return results

# =========================================================================
# Error Handling Helpers (until try/catch is supported)
# =========================================================================

class ExecutionError:
    """Error information from test execution."""
    message: text
    error_type: text  # "panic", "assertion", "timeout", "unknown"
    stacktrace: Option<text>

    static fn new(message: text, error_type: text) -> ExecutionError:
        return ExecutionError {
            message: message,
            error_type: error_type,
            stacktrace: None
        }

fn safe_execute_example(example: Example) -> bool:
    """Safely execute example with comprehensive error handling.

    Since try/catch is not yet supported, this provides a framework
    for error recovery. Returns true if execution succeeded, false otherwise.

    This function wraps example execution and attempts to catch/handle errors
    at the execution boundary. Phase 2 will integrate proper try/catch support.

    TODO: Add proper error handling when try/catch is supported
    """
    # Attempt to run the example
    # Implementation strategy for Phase 2:
    # 1. Set panic hook to capture panic messages
    # 2. Use signal handlers for timeout detection
    # 3. Wrap assertions to catch failures
    # 4. Restore normal error handling on completion

    # For now, execute and assume success if no panic
    example.run()
    return true  # Assume success if we got here

fn wrap_example_execution(example: Example) -> Result<(), ExecutionError>:
    """Wrap example execution with result type (Phase 2 ready).

    When try/catch is implemented, this will properly handle errors:
    ```
    try:
        example.run()
        Ok(())
    catch panic_info:
        Err(ExecutionError.new(panic_info.message(), "panic"))
    catch timeout:
        Err(ExecutionError.new("Test timed out", "timeout"))
    ```
    """
    # Phase 2: Implement with actual try/catch
    example.run()
    Ok(())

# =========================================================================
# Convenience Functions
# =========================================================================

# Convenience function to run all tests
fn run_tests() -> ExecutionResults:
    """Run all registered tests with default settings."""
    val executor = TestExecutor.new()
    return executor.run()

# Run tests with slow tests enabled
fn run_all_tests() -> ExecutionResults:
    """Run all tests including slow tests."""
    val executor = TestExecutor.new().with_slow_tests(true)
    return executor.run()

pub use TestStatus, TestResult, ExecutionResults, TestExecutor, TestInfo
pub use run_tests, run_all_tests
