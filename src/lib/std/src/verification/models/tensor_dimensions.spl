# Tensor Dimension Inference Model
# Provides compile-time dimension tracking with range constraints.
# Dimensions can be inferred through operations like matmul, reshape, etc.

# ============================================================================
# Dimension Representation
# ============================================================================

# Dimension variable for inference (like type variables)
class DimVar:
    id: i32
    name: Option<text>  # Optional name: "batch", "seq_len", etc.
    bound: Option<Dim>

    fn new(id: i32) -> DimVar:
        DimVar(id: id, name: nil, bound: nil)

    fn named(id: i32, name: text) -> DimVar:
        DimVar(id: id, name: Some(name), bound: nil)

    me set_bound(dim: Dim):
        self.bound = Some(dim)

    fn is_bound() -> bool:
        self.bound.is_some()

# Dimension: can be literal, variable, or dynamic
enum Dim:
    # Fixed dimension size
    Literal(value: i32)
    # Dimension variable (for inference)
    Var(variable: DimVar)
    # Named dimension with optional range constraint
    Named(name: text, range: Option<(i32, i32)>)
    # Dynamic dimension (unknown at compile time, checked at runtime)
    Dynamic
    # Broadcast dimension (can be 1 or match)
    Broadcast

    fn to_string() -> text:
        match self:
            case Literal(v): "{v}"
            case Var(v):
                match v.name:
                    case Some(n): "?{n}"
                    case nil: "?{v.id}"
            case Named(n, range):
                match range:
                    case Some((lo, hi)): "{n}: {lo}..{hi}"
                    case nil: "{n}"
            case Dynamic: "?"
            case Broadcast: "#"

    fn is_concrete() -> bool:
        match self:
            case Literal(_): true
            case Named(_, nil): true
            case _: false

    fn get_value() -> Option<i32>:
        match self:
            case Literal(v): Some(v)
            case _: nil

    fn get_range() -> Option<(i32, i32)>:
        match self:
            case Literal(v): Some((v, v))
            case Named(_, range): range
            case _: nil

    fn is_literal() -> bool:
        """Check if this is Literal dimension.
        Returns: true for Literal
        Example: Dim.Literal(value: 10).is_literal()  # → True
        """
        match self:
            case Literal(_): true
            case _: false

    fn is_var() -> bool:
        """Check if this is Var dimension.
        Returns: true for Var
        Example: Dim.Var(variable: v).is_var()  # → True
        """
        match self:
            case Var(_): true
            case _: false

    fn is_named() -> bool:
        """Check if this is Named dimension.
        Returns: true for Named
        Example: Dim.Named(name: "batch", range: nil).is_named()  # → True
        """
        match self:
            case Named(_, _): true
            case _: false

    fn is_dynamic() -> bool:
        """Check if this is Dynamic dimension.
        Returns: true for Dynamic
        Example: Dim.Dynamic.is_dynamic()  # → True
        """
        match self:
            case Dynamic: true
            case _: false

    fn is_broadcast() -> bool:
        """Check if this is Broadcast dimension.
        Returns: true for Broadcast
        Example: Dim.Broadcast.is_broadcast()  # → True
        """
        match self:
            case Broadcast: true
            case _: false

    fn is_inferred() -> bool:
        """Check if dimension requires inference (Var or Dynamic).
        Returns: true for Var or Dynamic
        Example: Dim.Var(variable: v).is_inferred()  # → True
        """
        match self:
            case Var(_): true
            case Dynamic: true
            case _: false

    fn has_range() -> bool:
        """Check if dimension has range constraints.
        Returns: true if Named with range or Literal
        Example: Dim.Named(name: "batch", range: Some((1, 64))).has_range()  # → True
        """
        self.get_range().is_some()

    fn description() -> text:
        """Get human-readable description of the dimension kind.
        Returns: descriptive explanation
        Example: Dim.Literal(value: 10).description()  # → "Fixed dimension size: 10"
        """
        match self:
            case Literal(v): "Fixed dimension size: {v}"
            case Var(v):
                match v.name:
                    case Some(n): "Dimension variable: {n} (id={v.id})"
                    case nil: "Dimension variable: id={v.id}"
            case Named(n, range):
                match range:
                    case Some((lo, hi)): "Named dimension: {n} in range [{lo}, {hi}]"
                    case nil: "Named dimension: {n}"
            case Dynamic: "Dynamic dimension (runtime-determined)"
            case Broadcast: "Broadcast dimension (flexible)"

    fn summary() -> text:
        """Get comprehensive summary of the dimension.
        Returns: summary with type, representation, and properties
        Example: Dim.Named(name: "batch", range: Some((1, 64))).summary()
                # → "Dim: batch: 1..64 (Named dimension: batch in range [1, 64], has range, inferred=false)"
        """
        val dim_repr = self.to_string()
        val desc = self.description()
        var props = []

        if self.is_concrete():
            props.push("concrete")
        if self.has_range():
            props.push("has range")
        if self.is_inferred():
            props.push("inferred=true")
        else:
            props.push("inferred=false")

        val props_str = if props.len() > 0: ", " + props.join(", ") else: ""

        "Dim: {dim_repr} ({desc}{props_str})"

# Dimension constraint for verification
enum DimConstraint:
    # Two dimensions must be equal
    Equal(d1: Dim, d2: Dim)
    # Dimension must be greater than value
    GreaterThan(d: Dim, min: i32)
    # Dimension must be less than value
    LessThan(d: Dim, max: i32)
    # Dimension must be in range
    InRange(d: Dim, min: i32, max: i32)
    # Product of dimensions must equal value
    ProductEquals(dims: List<Dim>, value: i32)
    # Two products must be equal (for reshape)
    ProductsEqual(dims1: List<Dim>, dims2: List<Dim>)

    fn to_string() -> text:
        match self:
            case Equal(d1, d2): "{d1.to_string()} = {d2.to_string()}"
            case GreaterThan(d, min): "{d.to_string()} > {min}"
            case LessThan(d, max): "{d.to_string()} < {max}"
            case InRange(d, min, max): "{min} <= {d.to_string()} <= {max}"
            case ProductEquals(dims, value):
                val dims_str = dims.mapped(\d: d.to_string()).join(" * ")
                "{dims_str} = {value}"
            case ProductsEqual(d1s, d2s):
                val s1 = d1s.mapped(|d| d.to_string()).join(" * ")
                val s2 = d2s.mapped(|d| d.to_string()).join(" * ")
                "{s1} = {s2}"

    fn is_equal() -> bool:
        """Check if this is Equal constraint.
        Returns: true for Equal
        Example: DimConstraint.Equal(d1: d1, d2: d2).is_equal()  # → True
        """
        match self:
            case Equal(_, _): true
            case _: false

    fn is_greater_than() -> bool:
        """Check if this is GreaterThan constraint.
        Returns: true for GreaterThan
        Example: DimConstraint.GreaterThan(d: d, min: 1).is_greater_than()  # → True
        """
        match self:
            case GreaterThan(_, _): true
            case _: false

    fn is_less_than() -> bool:
        """Check if this is LessThan constraint.
        Returns: true for LessThan
        Example: DimConstraint.LessThan(d: d, max: 100).is_less_than()  # → True
        """
        match self:
            case LessThan(_, _): true
            case _: false

    fn is_in_range() -> bool:
        """Check if this is InRange constraint.
        Returns: true for InRange
        Example: DimConstraint.InRange(d: d, min: 1, max: 100).is_in_range()  # → True
        """
        match self:
            case InRange(_, _, _): true
            case _: false

    fn is_product_equals() -> bool:
        """Check if this is ProductEquals constraint.
        Returns: true for ProductEquals
        Example: DimConstraint.ProductEquals(dims: ds, value: 100).is_product_equals()  # → True
        """
        match self:
            case ProductEquals(_, _): true
            case _: false

    fn is_products_equal() -> bool:
        """Check if this is ProductsEqual constraint.
        Returns: true for ProductsEqual
        Example: DimConstraint.ProductsEqual(dims1: d1s, dims2: d2s).is_products_equal()  # → True
        """
        match self:
            case ProductsEqual(_, _): true
            case _: false

    fn is_equality_constraint() -> bool:
        """Check if constraint enforces equality.
        Returns: true for Equal or ProductsEqual
        Example: DimConstraint.Equal(d1: d1, d2: d2).is_equality_constraint()  # → True
        """
        match self:
            case Equal(_, _): true
            case ProductsEqual(_, _): true
            case _: false

    fn is_range_constraint() -> bool:
        """Check if constraint enforces range bounds.
        Returns: true for GreaterThan, LessThan, or InRange
        Example: DimConstraint.InRange(d: d, min: 1, max: 100).is_range_constraint()  # → True
        """
        match self:
            case GreaterThan(_, _): true
            case LessThan(_, _): true
            case InRange(_, _, _): true
            case _: false

    fn is_product_constraint() -> bool:
        """Check if constraint involves product of dimensions.
        Returns: true for ProductEquals or ProductsEqual
        Example: DimConstraint.ProductEquals(dims: ds, value: 100).is_product_constraint()  # → True
        """
        match self:
            case ProductEquals(_, _): true
            case ProductsEqual(_, _): true
            case _: false

    fn description() -> text:
        """Get human-readable description of the constraint.
        Returns: descriptive explanation
        Example: DimConstraint.Equal(d1: d1, d2: d2).description()
                # → "Equality constraint: two dimensions must be equal"
        """
        match self:
            case Equal(_, _): "Equality constraint: two dimensions must be equal"
            case GreaterThan(_, _): "Lower bound constraint: dimension must exceed minimum"
            case LessThan(_, _): "Upper bound constraint: dimension must not exceed maximum"
            case InRange(_, _, _): "Range constraint: dimension must be within bounds"
            case ProductEquals(_, _): "Product constraint: product of dimensions must equal value"
            case ProductsEqual(_, _): "Product equality constraint: two products must be equal"

    fn summary() -> text:
        """Get comprehensive summary of the constraint.
        Returns: summary with constraint expression, description, and category
        Example: DimConstraint.InRange(d: d, min: 1, max: 100).summary()
                # → "DimConstraint: 1 <= d <= 100 (Range constraint: dimension must be within bounds, range constraint)"
        """
        val expr = self.to_string()
        val desc = self.description()
        var category = "other"

        if self.is_equality_constraint():
            category = "equality constraint"
        elif self.is_range_constraint():
            category = "range constraint"
        elif self.is_product_constraint():
            category = "product constraint"

        "DimConstraint: {expr} ({desc}, {category})"

# ============================================================================
# Tensor Shape
# ============================================================================

# Tensor shape: list of dimensions
class TensorShape:
    dims: List<Dim>

    fn new(dims: List<Dim>) -> TensorShape:
        TensorShape(dims: dims)

    fn from_literals(sizes: List<i32>) -> TensorShape:
        TensorShape(dims: sizes.mapped(|s| Dim.Literal(value: s)))

    fn ndim() -> i32:
        self.dims.len()

    fn to_string() -> text:
        val dim_strs = self.dims.mapped(|d| d.to_string())
        "[" + dim_strs.join(", ") + "]"

    fn get(idx: i32) -> Option<Dim>:
        if idx >= 0 and idx < self.dims.len():
            Some(self.dims[idx])
        else if idx < 0 and -idx <= self.dims.len():
            Some(self.dims[self.dims.len() + idx])
        else:
            nil

    fn is_concrete() -> bool:
        self.dims.all(|d| d.is_concrete())

    # Get minimum total elements (from range minimums)
    fn min_elements() -> Option<i32>:
        var product = 1
        for d in self.dims:
            match d.get_range():
                case Some((lo, _)):
                    product = product * lo
                case nil:
                    return nil
        Some(product)

    # Get maximum total elements (from range maximums)
    fn max_elements() -> Option<i32>:
        var product = 1
        for d in self.dims:
            match d.get_range():
                case Some((_, hi)):
                    product = product * hi
                case nil:
                    return nil
        Some(product)

# ============================================================================
# Shape Environment
# ============================================================================

# Environment tracking dimension bindings and constraints
class ShapeEnv:
    bindings: Dict<i32, Dim>       # Variable ID -> bound dimension
    named_dims: Dict<text, Dim>  # Named dimension -> value/range
    constraints: List<DimConstraint>

    static fn new() -> ShapeEnv:
        ShapeEnv(bindings: {}, named_dims: {}, constraints: [])

    me bind_var(var_id: i32, dim: Dim):
        self.bindings[var_id] = dim

    me bind_named(name: text, dim: Dim):
        self.named_dims[name] = dim

    me add_constraint(c: DimConstraint):
        self.constraints.push(c)

    fn lookup_var(var_id: i32) -> Option<Dim>:
        self.bindings.get(var_id)

    fn lookup_named(name: text) -> Option<Dim>:
        self.named_dims.get(name)

    fn apply(dim: Dim) -> Dim:
        match dim:
            case Dim.Var(v):
                match self.lookup_var(v.id):
                    case Some(bound):
                        self.apply(bound)
                    case nil:
                        dim
            case Dim.Named(n, _):
                match self.lookup_named(n):
                    case Some(bound):
                        self.apply(bound)
                    case nil:
                        dim
            case _:
                dim

    fn apply_shape(shape: TensorShape) -> TensorShape:
        TensorShape(dims: shape.dims.mapped(|d| self.apply(d)))

# ============================================================================
# Shape Errors
# ============================================================================

enum ShapeError:
    RankMismatch(expected: i32, actual: i32)
    DimMismatch(dim_idx: i32, expected: Dim, actual: Dim)
    DimOutOfRange(dim_idx: i32, value: i32, min: i32, max: i32)
    MatmulShapeMismatch(left: TensorShape, right: TensorShape)
    ReshapeElementsMismatch(input: TensorShape, output: TensorShape)
    BroadcastIncompatible(shapes: List<TensorShape>)
    InferenceError(message: text)

    fn to_string() -> text:
        match self:
            case RankMismatch(e, a):
                "Rank mismatch: expected {e} dimensions, got {a}"
            case DimMismatch(idx, e, a):
                "Dimension {idx} mismatch: expected {e.to_string()}, got {a.to_string()}"
            case DimOutOfRange(idx, v, min, max):
                "Dimension {idx} out of range: {v} not in [{min}, {max}]"
            case MatmulShapeMismatch(l, r):
                "Matmul shape mismatch: {l.to_string()} @ {r.to_string()}"
            case ReshapeElementsMismatch(i, o):
                "Reshape elements mismatch: {i.to_string()} -> {o.to_string()}"
            case BroadcastIncompatible(shapes):
                val ss = shapes.mapped(|s| s.to_string()).join(", ")
                "Broadcast incompatible shapes: {ss}"
            case InferenceError(msg):
                "Inference error: {msg}"

    fn is_rank_mismatch() -> bool:
        """Check if this is RankMismatch error.
        Returns: true for RankMismatch
        Example: ShapeError.RankMismatch(expected: 3, actual: 2).is_rank_mismatch()  # → True
        """
        match self:
            case RankMismatch(_, _): true
            case _: false

    fn is_dim_mismatch() -> bool:
        """Check if this is DimMismatch error.
        Returns: true for DimMismatch
        Example: ShapeError.DimMismatch(dim_idx: 0, expected: d1, actual: d2).is_dim_mismatch()  # → True
        """
        match self:
            case DimMismatch(_, _, _): true
            case _: false

    fn is_dim_out_of_range() -> bool:
        """Check if this is DimOutOfRange error.
        Returns: true for DimOutOfRange
        Example: ShapeError.DimOutOfRange(dim_idx: 0, value: 200, min: 1, max: 100).is_dim_out_of_range()  # → True
        """
        match self:
            case DimOutOfRange(_, _, _, _): true
            case _: false

    fn is_matmul_shape_mismatch() -> bool:
        """Check if this is MatmulShapeMismatch error.
        Returns: true for MatmulShapeMismatch
        Example: ShapeError.MatmulShapeMismatch(left: l, right: r).is_matmul_shape_mismatch()  # → True
        """
        match self:
            case MatmulShapeMismatch(_, _): true
            case _: false

    fn is_reshape_elements_mismatch() -> bool:
        """Check if this is ReshapeElementsMismatch error.
        Returns: true for ReshapeElementsMismatch
        Example: ShapeError.ReshapeElementsMismatch(input: i, output: o).is_reshape_elements_mismatch()  # → True
        """
        match self:
            case ReshapeElementsMismatch(_, _): true
            case _: false

    fn is_broadcast_incompatible() -> bool:
        """Check if this is BroadcastIncompatible error.
        Returns: true for BroadcastIncompatible
        Example: ShapeError.BroadcastIncompatible(shapes: ss).is_broadcast_incompatible()  # → True
        """
        match self:
            case BroadcastIncompatible(_): true
            case _: false

    fn is_inference_error() -> bool:
        """Check if this is InferenceError.
        Returns: true for InferenceError
        Example: ShapeError.InferenceError(message: "failed").is_inference_error()  # → True
        """
        match self:
            case InferenceError(_): true
            case _: false

    fn is_shape_mismatch() -> bool:
        """Check if error is related to shape incompatibility.
        Returns: true for MatmulShapeMismatch, ReshapeElementsMismatch, or BroadcastIncompatible
        Example: ShapeError.MatmulShapeMismatch(left: l, right: r).is_shape_mismatch()  # → True
        """
        match self:
            case MatmulShapeMismatch(_, _): true
            case ReshapeElementsMismatch(_, _): true
            case BroadcastIncompatible(_): true
            case _: false

    fn is_dimension_error() -> bool:
        """Check if error is related to individual dimension issues.
        Returns: true for DimMismatch or DimOutOfRange
        Example: ShapeError.DimOutOfRange(dim_idx: 0, value: 200, min: 1, max: 100).is_dimension_error()  # → True
        """
        match self:
            case DimMismatch(_, _, _): true
            case DimOutOfRange(_, _, _, _): true
            case _: false

    fn is_structural_error() -> bool:
        """Check if error is related to structural incompatibility.
        Returns: true for RankMismatch or shape mismatches
        Example: ShapeError.RankMismatch(expected: 3, actual: 2).is_structural_error()  # → True
        """
        match self:
            case RankMismatch(_, _): true
            case MatmulShapeMismatch(_, _): true
            case ReshapeElementsMismatch(_, _): true
            case BroadcastIncompatible(_): true
            case _: false

    fn description() -> text:
        """Get human-readable description of the error kind.
        Returns: descriptive explanation
        Example: ShapeError.RankMismatch(expected: 3, actual: 2).description()
                # → "Rank mismatch: tensor has wrong number of dimensions"
        """
        match self:
            case RankMismatch(_, _): "Rank mismatch: tensor has wrong number of dimensions"
            case DimMismatch(_, _, _): "Dimension mismatch: dimension size doesn't match expected value"
            case DimOutOfRange(_, _, _, _): "Dimension out of range: dimension size violates range constraint"
            case MatmulShapeMismatch(_, _): "Matrix multiplication shape mismatch: incompatible shapes for matmul"
            case ReshapeElementsMismatch(_, _): "Reshape elements mismatch: total elements don't match"
            case BroadcastIncompatible(_): "Broadcast incompatible: shapes cannot be broadcast together"
            case InferenceError(_): "Inference error: dimension inference failed"

    fn summary() -> text:
        """Get comprehensive summary of the error.
        Returns: summary with error message, description, and category
        Example: ShapeError.RankMismatch(expected: 3, actual: 2).summary()
                # → "ShapeError: Rank mismatch: expected 3 dimensions, got 2 (Rank mismatch: tensor has wrong number of dimensions, structural error)"
        """
        val msg = self.to_string()
        val desc = self.description()
        var category = "other"

        if self.is_structural_error():
            category = "structural error"
        elif self.is_dimension_error():
            category = "dimension error"
        elif self.is_inference_error():
            category = "inference error"

        "ShapeError: {msg} ({desc}, {category})"

# ============================================================================
# Dimension Inference Context
# ============================================================================

class DimInferenceContext:
    next_var_id: i32
    env: ShapeEnv
    errors: List<ShapeError>

    static fn new() -> DimInferenceContext:
        DimInferenceContext(
            next_var_id: 0,
            env: ShapeEnv.new(),
            errors: []
        )

    me fresh_var() -> Dim:
        val id = self.next_var_id
        self.next_var_id = self.next_var_id + 1
        Dim.Var(variable: DimVar.new(id))

    me fresh_named_var(name: text) -> Dim:
        val id = self.next_var_id
        self.next_var_id = self.next_var_id + 1
        Dim.Var(variable: DimVar.named(id, name))

    me add_error(err: ShapeError):
        self.errors.push(err)

    fn has_errors() -> bool:
        self.errors.len() > 0

# ============================================================================
# Dimension Unification
# ============================================================================

# Unify two dimensions
fn unify_dims(ctx: mut DimInferenceContext, d1: Dim, d2: Dim) -> Result<Dim, ShapeError>:
    val d1_applied = ctx.env.apply(d1)
    val d2_applied = ctx.env.apply(d2)

    match (d1_applied, d2_applied):
        # Same literal
        case (Dim.Literal(v1), Dim.Literal(v2)):
            if v1 == v2:
                Ok(d1_applied)
            else:
                Err(ShapeError.DimMismatch(dim_idx: 0, expected: d1_applied, actual: d2_applied))

        # Variable on left - bind it
        case (Dim.Var(v), _):
            ctx.env.bind_var(v.id, d2_applied)
            Ok(d2_applied)

        # Variable on right - bind it
        case (_, Dim.Var(v)):
            ctx.env.bind_var(v.id, d1_applied)
            Ok(d1_applied)

        # Named with same name
        case (Dim.Named(n1, r1), Dim.Named(n2, r2)):
            if n1 == n2:
                # Merge ranges (intersection)
                match r1:
                    case Some((lo1, hi1)):
                        match r2:
                            case Some((lo2, hi2)):
                                val lo = max(lo1, lo2)
                                val hi = min(hi1, hi2)
                                if lo <= hi:
                                    Ok(Dim.Named(name: n1, range: Some((lo, hi))))
                                else:
                                    Err(ShapeError.InferenceError(message: "Range intersection empty for dimension '{n1}': [{lo1}..{hi1}] ∩ [{lo2}..{hi2}] = ∅"))
                            case nil:
                                Ok(Dim.Named(name: n1, range: Some((lo1, hi1))))
                    case nil:
                        match r2:
                            case Some((lo2, hi2)):
                                Ok(Dim.Named(name: n1, range: Some((lo2, hi2))))
                            case nil:
                                Ok(Dim.Named(name: n1, range: nil))
            else:
                # Different names - add equality constraint
                ctx.env.add_constraint(DimConstraint.Equal(d1: d1_applied, d2: d2_applied))
                Ok(d1_applied)

        # Named with literal - bind named to literal
        case (Dim.Named(n, range), Dim.Literal(v)):
            # Check range constraint
            match range:
                case Some((lo, hi)):
                    if v < lo or v > hi:
                        return Err(ShapeError.DimOutOfRange(dim_idx: 0, value: v, min: lo, max: hi))
                case nil:
                    ()
            ctx.env.bind_named(n, Dim.Literal(value: v))
            Ok(Dim.Literal(value: v))

        case (Dim.Literal(v), Dim.Named(n, range)):
            # Check range constraint
            match range:
                case Some((lo, hi)):
                    if v < lo or v > hi:
                        return Err(ShapeError.DimOutOfRange(dim_idx: 0, value: v, min: lo, max: hi))
                case nil:
                    ()
            ctx.env.bind_named(n, Dim.Literal(value: v))
            Ok(Dim.Literal(value: v))

        # Dynamic matches anything
        case (Dim.Dynamic, _): Ok(d2_applied)
        case (_, Dim.Dynamic): Ok(d1_applied)

        # Broadcast rules
        case (Dim.Broadcast, Dim.Literal(1)): Ok(Dim.Literal(value: 1))
        case (Dim.Literal(1), Dim.Broadcast): Ok(Dim.Literal(value: 1))
        case (Dim.Broadcast, _): Ok(d2_applied)
        case (_, Dim.Broadcast): Ok(d1_applied)

        case _:
            Err(ShapeError.DimMismatch(dim_idx: 0, expected: d1_applied, actual: d2_applied))

# Unify two shapes
fn unify_shapes(ctx: mut DimInferenceContext, s1: TensorShape, s2: TensorShape) -> Result<TensorShape, ShapeError>:
    if s1.ndim() != s2.ndim():
        return Err(ShapeError.RankMismatch(expected: s1.ndim(), actual: s2.ndim()))

    var result_dims: List<Dim> = []
    for i in 0..s1.ndim():
        val d1 = s1.dims[i]
        val d2 = s2.dims[i]
        match unify_dims(ctx, d1, d2):
            case Ok(unified):
                result_dims.push(unified)
            case Err(e):
                match e:
                    case ShapeError.DimMismatch(_, exp, act):
                        return Err(ShapeError.DimMismatch(dim_idx: i, expected: exp, actual: act))
                    case _:
                        return Err(e)

    Ok(TensorShape(dims: result_dims))

# ============================================================================
# Shape Inference for Operations
# ============================================================================

# Infer output shape of matrix multiplication
# matmul: [..., M, K] @ [..., K, N] -> [..., M, N]
fn infer_matmul_shape(ctx: mut DimInferenceContext, left: TensorShape, right: TensorShape) -> Result<TensorShape, ShapeError>:
    if left.ndim() < 2 or right.ndim() < 2:
        return Err(ShapeError.MatmulShapeMismatch(left: left, right: right))

    # Get contraction dimensions
    val left_k = left.get(-1).unwrap()
    val right_k = right.get(-2).unwrap()

    # Unify contraction dimension
    match unify_dims(ctx, left_k, right_k):
        case Err(_):
            return Err(ShapeError.MatmulShapeMismatch(left: left, right: right))
        case Ok(_):
            ()

    # Output shape: [..., M, N]
    val m = left.get(-2).unwrap()
    val n = right.get(-1).unwrap()

    # Handle batch dimensions
    val left_batch = left.dims[0..left.ndim()-2]
    val right_batch = right.dims[0..right.ndim()-2]

    # Broadcast batch dimensions
    val batch: List<Dim>
    if left_batch.len() == 0:
        batch = right_batch
    else if right_batch.len() == 0:
        batch = left_batch
    else:
        # Simple case: same batch dims
        batch = left_batch

    var result_dims = batch.to_list()
    result_dims.push(m)
    result_dims.push(n)

    Ok(TensorShape(dims: result_dims))

# Infer broadcast shape for element-wise operations
fn infer_broadcast_shape(ctx: mut DimInferenceContext, shapes: List<TensorShape>) -> Result<TensorShape, ShapeError>:
    if shapes.len() == 0:
        return Err(ShapeError.InferenceError(message: "Cannot infer broadcast shape: empty shape list provided"))

    if shapes.len() == 1:
        return Ok(shapes[0])

    # Find max rank
    val max_rank = shapes.mapped(|s| s.ndim()).max().unwrap_or(0)

    # Pad shapes to max rank (from the right)
    var padded: List<List<Dim> > = []
    for s in shapes:
        val pad_count = max_rank - s.ndim()
        var dims: List<Dim> = []
        for _ in 0..pad_count:
            dims.push(Dim.Literal(value: 1))
        for d in s.dims:
            dims.push(d)
        padded.push(dims)

    # Broadcast each dimension
    var result_dims: List<Dim> = []
    for i in 0..max_rank:
        val dims_at_i = padded.mapped(|p| p[i])
        var result_dim = dims_at_i[0]

        for j in 1..dims_at_i.len():
            val d = dims_at_i[j]
            match broadcast_dim(ctx, result_dim, d):
                case Ok(broadcasted):
                    result_dim = broadcasted
                case Err(_):
                    return Err(ShapeError.BroadcastIncompatible(shapes: shapes))

        result_dims.push(result_dim)

    Ok(TensorShape(dims: result_dims))

# Broadcast two dimensions
fn broadcast_dim(ctx: mut DimInferenceContext, d1: Dim, d2: Dim) -> Result<Dim, ShapeError>:
    val d1_applied = ctx.env.apply(d1)
    val d2_applied = ctx.env.apply(d2)

    match (d1_applied, d2_applied):
        # Same dimension
        case (Dim.Literal(v1), Dim.Literal(v2)):
            if v1 == v2:
                Ok(d1_applied)
            else if v1 == 1:
                Ok(d2_applied)
            else if v2 == 1:
                Ok(d1_applied)
            else:
                Err(ShapeError.DimMismatch(dim_idx: 0, expected: d1_applied, actual: d2_applied))

        # One is literal 1 - broadcast to other
        case (Dim.Literal(1), _): Ok(d2_applied)
        case (_, Dim.Literal(1)): Ok(d1_applied)

        # Variables and named dims
        case _:
            unify_dims(ctx, d1_applied, d2_applied)

# Verify reshape is valid (same total elements)
fn verify_reshape(ctx: mut DimInferenceContext, input: TensorShape, output: TensorShape) -> Result<(), ShapeError>:
    # Add constraint that products must be equal
    ctx.env.add_constraint(DimConstraint.ProductsEqual(dims1: input.dims, dims2: output.dims))

    # If both shapes are concrete, verify immediately
    if input.is_concrete() and output.is_concrete():
        val in_prod = input.dims.mapped(|d| d.get_value().unwrap_or(1)).product()
        val out_prod = output.dims.mapped(|d| d.get_value().unwrap_or(1)).product()
        if in_prod != out_prod:
            return Err(ShapeError.ReshapeElementsMismatch(input: input, output: output))

    Ok(())

# Infer shape after transpose
fn infer_transpose_shape(shape: TensorShape, dim0: i32, dim1: i32) -> Result<TensorShape, ShapeError>:
    val n = shape.ndim()
    if dim0 < 0 or dim0 >= n or dim1 < 0 or dim1 >= n:
        return Err(ShapeError.InferenceError(message: "Invalid transpose dimensions: dim0={dim0}, dim1={dim1} for shape with {n} dimensions"))

    var new_dims = shape.dims.clone()
    val tmp = new_dims[dim0]
    new_dims[dim0] = new_dims[dim1]
    new_dims[dim1] = tmp

    Ok(TensorShape(dims: new_dims))

# Infer shape after reduction (sum, mean, etc.)
fn infer_reduction_shape(shape: TensorShape, dim: i32, keepdim: bool) -> Result<TensorShape, ShapeError>:
    val n = shape.ndim()
    val actual_dim = if dim < 0: n + dim else: dim

    if actual_dim < 0 or actual_dim >= n:
        return Err(ShapeError.InferenceError(message: "Invalid reduction dimension: dim={dim} (normalized to {actual_dim}) for shape with {n} dimensions"))

    var new_dims: List<Dim> = []
    for i in 0..n:
        if i == actual_dim:
            if keepdim:
                new_dims.push(Dim.Literal(value: 1))
        else:
            new_dims.push(shape.dims[i])

    Ok(TensorShape(dims: new_dims))

# ============================================================================
# Runtime Verification
# ============================================================================

# Verify actual shape matches declared shape with constraints
fn verify_shape_at_runtime(actual: List<i32>, declared: TensorShape) -> Result<(), ShapeError>:
    if actual.len() != declared.ndim():
        return Err(ShapeError.RankMismatch(expected: declared.ndim(), actual: actual.len()))

    for i in 0..actual.len():
        val actual_dim = actual[i]
        val declared_dim = declared.dims[i]

        match declared_dim:
            case Dim.Literal(v):
                if actual_dim != v:
                    return Err(ShapeError.DimMismatch(
                        dim_idx: i,
                        expected: declared_dim,
                        actual: Dim.Literal(value: actual_dim)
                    ))
            case Dim.Named(_, range):
                match range:
                    case Some((lo, hi)):
                        if actual_dim < lo or actual_dim > hi:
                            return Err(ShapeError.DimOutOfRange(
                                dim_idx: i,
                                value: actual_dim,
                                min: lo,
                                max: hi
                            ))
                    case nil:
                        ()  # No constraint
            case Dim.Dynamic:
                ()  # Always valid
            case Dim.Broadcast:
                ()  # Always valid
            case Dim.Var(_):
                ()  # Should be bound by inference

    Ok(())

# ============================================================================
# Memory Estimation
# ============================================================================

# Estimate memory bounds for a tensor
fn estimate_tensor_memory(shape: TensorShape, element_bytes: i32) -> (i32, i32):
    match (shape.min_elements(), shape.max_elements()):
        case (Some(min_e), Some(max_e)):
            (min_e * element_bytes, max_e * element_bytes)
        case _:
            (0, 0)  # Unknown

# Helper functions
fn max(a: i32, b: i32) -> i32:
    if a > b:
        a
    else:
        b

fn min(a: i32, b: i32) -> i32:
    if a < b:
        a
    else:
        b

# ============================================================================
# Exports
# ============================================================================

export Dim, DimVar, DimConstraint, TensorShape, ShapeEnv
export DimInferenceContext, ShapeError
export unify_dims, unify_shapes, infer_matmul_shape, infer_broadcast_shape
export verify_reshape, verify_shape_at_runtime, estimate_tensor_memory
export max, min
