# PyTorch SFFI Bindings (Tier 2)
# External FFI declarations that map to Rust wrapper functions
#
# These are the raw FFI bindings - Tier 3 (mod.spl) wraps these
# with idiomatic Simple API.

# ============================================================================
# Opaque Handle Types
# ============================================================================
# These are opaque pointers to C++ torch::Tensor objects
# Simple code never directly dereferences these - only passes them to FFI

extern type TorchTensorHandle

# ============================================================================
# Library Information
# ============================================================================

extern fn rt_torch_available() -> bool
extern fn rt_torch_version() -> text
extern fn rt_torch_cuda_available() -> bool

# ============================================================================
# Tensor Creation
# ============================================================================

# Create zero tensor
# Args: dims - array of dimensions (e.g., [2, 3] for 2x3 matrix)
# Returns: opaque handle to tensor
extern fn rt_torch_tensor_zeros(dims: [i64]) -> TorchTensorHandle

# Create ones tensor
extern fn rt_torch_tensor_ones(dims: [i64]) -> TorchTensorHandle

# Create random normal tensor (mean=0, std=1)
extern fn rt_torch_tensor_randn(dims: [i64]) -> TorchTensorHandle

# Free tensor (release memory)
# IMPORTANT: Must be called when done with tensor to avoid memory leaks
extern fn rt_torch_tensor_free(handle: TorchTensorHandle)

# ============================================================================
# Tensor Operations
# ============================================================================

# Element-wise addition
# Returns: new tensor (caller owns, must free)
extern fn rt_torch_tensor_add(a: TorchTensorHandle, b: TorchTensorHandle) -> TorchTensorHandle

# Element-wise multiplication
extern fn rt_torch_tensor_mul(a: TorchTensorHandle, b: TorchTensorHandle) -> TorchTensorHandle

# Matrix multiplication
extern fn rt_torch_tensor_matmul(a: TorchTensorHandle, b: TorchTensorHandle) -> TorchTensorHandle

# ============================================================================
# Tensor Properties
# ============================================================================

# Get tensor shape
# Args: handle - tensor handle
#       dims_out - output buffer for dimensions
#       max_dims - size of output buffer
# Returns: number of dimensions, or -1 on error
extern fn rt_torch_tensor_shape(handle: TorchTensorHandle, dims_out: [i64], max_dims: i64) -> i64

# Get number of dimensions
extern fn rt_torch_tensor_ndim(handle: TorchTensorHandle) -> i64

# Get total number of elements
extern fn rt_torch_tensor_numel(handle: TorchTensorHandle) -> i64

# ============================================================================
# Activations
# ============================================================================

# ReLU activation: max(0, x)
extern fn rt_torch_relu(x: TorchTensorHandle) -> TorchTensorHandle

# Sigmoid activation: 1 / (1 + exp(-x))
extern fn rt_torch_sigmoid(x: TorchTensorHandle) -> TorchTensorHandle

# Tanh activation: (exp(x) - exp(-x)) / (exp(x) + exp(-x))
extern fn rt_torch_tanh(x: TorchTensorHandle) -> TorchTensorHandle

# ============================================================================
# Device Management
# ============================================================================

# Move tensor to device
# Args: handle - tensor handle
#       device - 0 for CPU, 1 for CUDA
# Returns: new tensor on specified device
extern fn rt_torch_tensor_to_device(handle: TorchTensorHandle, device: i64) -> TorchTensorHandle

# ============================================================================
# Export Public API
# ============================================================================
# Export the opaque type so mod.spl can use it

export TorchTensorHandle
