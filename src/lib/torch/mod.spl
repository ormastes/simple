# PyTorch Simple API
# User-facing idiomatic Simple API for tensor operations
#
# Pure Simple implementation - no external FFI required.
# Uses lib.pure.tensor for all tensor operations.

use lib.pure.tensor.{PureTensor, tensor_from_data, tensor_zeros, tensor_ones, tensor_randn}
use lib.pure.torch_ffi.{add_pure, mul_pure, matmul_pure, relu_pure, sigmoid_pure, tanh_pure}

# ============================================================================
# Backend Detection
# ============================================================================

fn get_backend() -> text:
    """Detect which backend is available. Always returns 'pure'."""
    "pure"

fn torch_available() -> bool:
    """Check if tensor library is available."""
    true

fn torch_version() -> text:
    """Get version string."""
    "Pure Simple DL v1.0 (100% Simple, zero dependencies)"

fn cuda_available() -> bool:
    """Check if CUDA GPU acceleration is available."""
    false

# ============================================================================
# Tensor Type
# ============================================================================

class Tensor:
    """High-level tensor abstraction using pure Simple backend."""
    pure_tensor: PureTensor<f64>

    # ========================================================================
    # Properties
    # ========================================================================

    fn shape() -> [i64]:
        """Get tensor shape (dimensions)."""
        self.pure_tensor.shape

    fn ndim() -> i64:
        """Get number of dimensions."""
        self.pure_tensor.shape.len()

    fn numel() -> i64:
        """Get total number of elements."""
        self.pure_tensor.numel()

    # ========================================================================
    # Operations
    # ========================================================================

    fn add(other: Tensor) -> Tensor:
        """Element-wise addition."""
        val result = add_pure(self.pure_tensor, other.pure_tensor)
        Tensor(pure_tensor: result)

    fn mul(other: Tensor) -> Tensor:
        """Element-wise multiplication."""
        val result = mul_pure(self.pure_tensor, other.pure_tensor)
        Tensor(pure_tensor: result)

    fn matmul(other: Tensor) -> Tensor:
        """Matrix multiplication."""
        val result = matmul_pure(self.pure_tensor, other.pure_tensor)
        Tensor(pure_tensor: result)

    # ========================================================================
    # Activations
    # ========================================================================

    fn relu() -> Tensor:
        """ReLU activation: max(0, x)."""
        val result = relu_pure(self.pure_tensor)
        Tensor(pure_tensor: result)

    fn sigmoid() -> Tensor:
        """Sigmoid activation: 1 / (1 + exp(-x))."""
        val result = sigmoid_pure(self.pure_tensor)
        Tensor(pure_tensor: result)

    fn tanh() -> Tensor:
        """Tanh activation."""
        val result = tanh_pure(self.pure_tensor)
        Tensor(pure_tensor: result)

    # ========================================================================
    # Device Management (no-ops for pure Simple)
    # ========================================================================

    fn cpu() -> Tensor:
        """Move tensor to CPU (no-op)."""
        self

    fn cuda() -> Tensor:
        """Move tensor to CUDA (no-op, always stays on CPU)."""
        self

    fn to_device(device: text) -> Tensor:
        """Move tensor to specified device (no-op)."""
        self

# ============================================================================
# Factory Functions
# ============================================================================

fn torch_zeros(shape: [i64]) -> Tensor:
    """Create tensor filled with zeros."""
    val pure = tensor_zeros(shape)
    Tensor(pure_tensor: pure)

fn torch_ones(shape: [i64]) -> Tensor:
    """Create tensor filled with ones."""
    val pure = tensor_ones(shape)
    Tensor(pure_tensor: pure)

fn torch_randn(shape: [i64]) -> Tensor:
    """Create tensor with pseudo-random values."""
    val pure = tensor_randn(shape)
    Tensor(pure_tensor: pure)

fn torch_from_array(data: [f64], shape: [i64]) -> Tensor:
    """Create tensor from data array."""
    val pure = tensor_from_data(data, shape)
    Tensor(pure_tensor: pure)

# ============================================================================
# Operator Overloading
# ============================================================================

fn +(a: Tensor, b: Tensor) -> Tensor:
    """Element-wise addition operator."""
    a.add(b)

fn *(a: Tensor, b: Tensor) -> Tensor:
    """Element-wise multiplication operator."""
    a.mul(b)

fn @(a: Tensor, b: Tensor) -> Tensor:
    """Matrix multiplication operator."""
    a.matmul(b)

# ============================================================================
# Export Public API
# ============================================================================

export Tensor
export torch_zeros, torch_ones, torch_randn, torch_from_array
export torch_available, torch_version, cuda_available, get_backend
