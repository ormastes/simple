# Standard Library Data Structure Benchmarks
# Comprehensive performance measurements for Map, Set, and List

import std.testing.benchmark as bench
import map
import set

# ============================================================================
# Map Benchmarks
# ============================================================================

fn benchmark_map_operations():
    print "=== Map Benchmarks ==="
    print ""

    val benchmarks = Map.new()

    # Insert benchmarks
    benchmarks.insert("Map: Insert 10 items", \:
        val m = Map.new()
        for i in 0..10:
            m.insert("key{i}", i)
    )

    benchmarks.insert("Map: Insert 100 items", \:
        val m = Map.new()
        for i in 0..100:
            m.insert("key{i}", i)
    )

    benchmarks.insert("Map: Insert 1000 items", \:
        val m = Map.with_capacity(1024)
        for i in 0..1000:
            m.insert("key{i}", i)
    )

    // Lookup benchmarks
    benchmarks.insert("Map: Lookup 100 items (hit)", \:
        val m = Map.new()
        for i in 0..100:
            m.insert("key{i}", i)

        for i in 0..100:
            m.get("key{i}")
    )

    benchmarks.insert("Map: Lookup 100 items (miss)", \:
        val m = Map.new()
        for i in 0..100:
            m.insert("key{i}", i)

        for i in 0..100:
            m.get("missing{i}")
    )

    // Remove benchmarks
    benchmarks.insert("Map: Remove 50% of items", \:
        val m = Map.new()
        for i in 0..100:
            m.insert("key{i}", i)

        for i in 0..50:
            m.remove("key{i}")
    )

    // Iteration benchmarks
    benchmarks.insert("Map: Iterate 100 entries", \:
        val m = Map.new()
        for i in 0..100:
            m.insert("key{i}", i)

        for (k, v) in m.entries():
            val _ = v  // Use value
    )

    // Utility benchmarks
    benchmarks.insert("Map: Clone 100 items", \:
        val m = Map.new()
        for i in 0..100:
            m.insert("key{i}", i)

        m.clone()
    )

    benchmarks.insert("Map: Filter 100 items (50% match)", \:
        val m = Map.new()
        for i in 0..100:
            m.insert("key{i}", i)

        m.map.filter(\k, v: v % 2 == 0)
    )

    benchmarks.insert("Map: Merge two maps (50 items each)", \:
        val m1 = Map.new()
        val m2 = Map.new()

        for i in 0..50:
            m1.insert("key{i}", i)
            m2.insert("other{i}", i)

        m1.merge(m2)
    )

    // Run all benchmarks
    val results = bench.compare_default(benchmarks)

    // Display results
    for (name, stats) in results.entries():
        print "{name}:"
        print "  Mean: {BenchmarkStats.format_time(stats.mean_ns)}"
        print "  Median: {BenchmarkStats.format_time(stats.median_ns)}"
        print ""

# ============================================================================
# Set Benchmarks
# ============================================================================

fn benchmark_set_operations():
    print "=== Set Benchmarks ==="
    print ""

    val benchmarks = Map.new()

    // Insert benchmarks
    benchmarks.insert("Set: Insert 10 items", \:
        val s = Set.new()
        for i in 0..10:
            s.insert("item{i}")
    )

    benchmarks.insert("Set: Insert 100 items", \:
        val s = Set.new()
        for i in 0..100:
            s.insert("item{i}")
    )

    benchmarks.insert("Set: Insert 1000 items", \:
        val s = Set.with_capacity(1024)
        for i in 0..1000:
            s.insert("item{i}")
    )

    // Lookup benchmarks
    benchmarks.insert("Set: Contains 100 items (hit)", \:
        val s = Set.new()
        for i in 0..100:
            s.insert("item{i}")

        for i in 0..100:
            s.contains("item{i}")
    )

    benchmarks.insert("Set: Contains 100 items (miss)", \:
        val s = Set.new()
        for i in 0..100:
            s.insert("item{i}")

        for i in 0..100:
            s.contains("missing{i}")
    )

    // Set operations
    benchmarks.insert("Set: Union (50 + 50 items)", \:
        val s1 = Set.new()
        val s2 = Set.new()

        for i in 0..50:
            s1.insert("item{i}")
            s2.insert("item{i + 25}")

        s1.union(s2)
    )

    benchmarks.insert("Set: Intersection (50 + 50 items)", \:
        val s1 = Set.new()
        val s2 = Set.new()

        for i in 0..50:
            s1.insert("item{i}")
            s2.insert("item{i + 25}")

        s1.intersection(s2)
    )

    benchmarks.insert("Set: Difference (50 + 50 items)", \:
        val s1 = Set.new()
        val s2 = Set.new()

        for i in 0..50:
            s1.insert("item{i}")
            s2.insert("item{i + 25}")

        s1.difference(s2)
    )

    benchmarks.insert("Set: Is subset check", \:
        val s1 = Set.new()
        val s2 = Set.new()

        for i in 0..50:
            s1.insert("item{i}")
            s2.insert("item{i}")

        s1.is_subset(s2)
    )

    // Utility operations
    benchmarks.insert("Set: Clone 100 items", \:
        val s = Set.new()
        for i in 0..100:
            s.insert("item{i}")

        s.clone()
    )

    benchmarks.insert("Set: Filter 100 items (50% match)", \:
        val s = Set.new()
        for i in 0..100:
            s.insert("{i}")

        s.filter(\x: x.parse_int() % 2 == 0)
    )

    benchmarks.insert("Set: Convert to list (100 items)", \:
        val s = Set.new()
        for i in 0..100:
            s.insert("item{i}")

        s.to_list()
    )

    // Run all benchmarks
    val results = bench.compare_default(benchmarks)

    // Display results
    for (name, stats) in results.entries():
        print "{name}:"
        print "  Mean: {BenchmarkStats.format_time(stats.mean_ns)}"
        print "  Median: {BenchmarkStats.format_time(stats.median_ns)}"
        print ""

# ============================================================================
# Comparison: Map vs List
# ============================================================================

fn benchmark_map_vs_list():
    print "=== Map vs List Comparison ==="
    print ""

    val benchmarks = Map.new()

    // Lookup comparison
    benchmarks.insert("Map: Lookup in 100 items", \:
        val m = Map.new()
        for i in 0..100:
            m.insert("key{i}", i)

        for i in 0..100:
            m.get("key50")
    )

    benchmarks.insert("List: Contains in 100 items", \:
        var list = []
        for i in 0..100:
            list.append("key{i}")

        for i in 0..100:
            list.contains("key50")
    )

    // Insert comparison
    benchmarks.insert("Map: Insert 100 items", \:
        val m = Map.new()
        for i in 0..100:
            m.insert("key{i}", i)
    )

    benchmarks.insert("List: Append 100 items", \:
        var list = []
        for i in 0..100:
            list.append("key{i}")
    )

    // Iteration comparison
    benchmarks.insert("Map: Iterate 100 entries", \:
        val m = Map.new()
        for i in 0..100:
            m.insert("key{i}", i)

        var sum = 0
        for (k, v) in m.entries():
            sum = sum + v
    )

    benchmarks.insert("List: Iterate 100 items", \:
        var list = []
        for i in 0..100:
            list.append(i)

        var sum = 0
        for item in list:
            sum = sum + item
    )

    // Run all benchmarks
    val results = bench.compare_default(benchmarks)

    // Display results
    for (name, stats) in results.entries():
        print "{name}:"
        print "  Mean: {BenchmarkStats.format_time(stats.mean_ns)}"
        print ""

# ============================================================================
# Scalability Tests
# ============================================================================

fn benchmark_scalability():
    print "=== Scalability Benchmarks ==="
    print ""

    val sizes = [10, 100, 1000]

    for size in sizes:
        print "Size: {size} items"

        // Map insert
        val map_stats = bench.benchmark_default(
            "Map insert {size}",
            \:
                val m = Map.with_capacity(size * 2)
                for i in 0..size:
                    m.insert("key{i}", i)
        )
        print "  Map insert: {BenchmarkStats.format_time(map_stats.mean_ns)}"

        // Set insert
        val set_stats = bench.benchmark_default(
            "Set insert {size}",
            \:
                val s = Set.with_capacity(size * 2)
                for i in 0..size:
                    s.insert("item{i}")
        )
        print "  Set insert: {BenchmarkStats.format_time(set_stats.mean_ns)}"

        // List append
        val list_stats = bench.benchmark_default(
            "List append {size}",
            \:
                var list = []
                for i in 0..size:
                    list.append("item{i}")
        )
        print "  List append: {BenchmarkStats.format_time(list_stats.mean_ns)}"

        print ""

# ============================================================================
# Main Entry Point
# ============================================================================

fn main():
    print "Standard Library Data Structure Benchmarks"
    print "=" .repeat(70)
    print ""

    benchmark_map_operations()
    print "=".repeat(70)
    print ""

    benchmark_set_operations()
    print "=".repeat(70)
    print ""

    benchmark_map_vs_list()
    print "=".repeat(70)
    print ""

    benchmark_scalability()
    print "=".repeat(70)
    print ""

    print "Benchmark suite complete! ğŸ‰"
