# Pure Simple Tensor Operations
#
# All tensor operations implemented in pure Simple
# Zero external dependencies

use lib.pure.tensor.{PureTensor, tensor_from_data}

# ============================================================================
# Element-wise Operations
# ============================================================================

fn add(a: PureTensor<f64>, b: PureTensor<f64>) -> PureTensor<f64>:
    """Element-wise addition."""
    var result_data: [f64] = []
    var i = 0
    while i < a.data.len():
        result_data.push(a.data[i] + b.data[i])
        i = i + 1
    tensor_from_data(result_data, a.shape)

fn sub(a: PureTensor<f64>, b: PureTensor<f64>) -> PureTensor<f64>:
    """Element-wise subtraction."""
    var result_data: [f64] = []
    var i = 0
    while i < a.data.len():
        result_data.push(a.data[i] - b.data[i])
        i = i + 1
    tensor_from_data(result_data, a.shape)

fn mul(a: PureTensor<f64>, b: PureTensor<f64>) -> PureTensor<f64>:
    """Element-wise multiplication."""
    var result_data: [f64] = []
    var i = 0
    while i < a.data.len():
        result_data.push(a.data[i] * b.data[i])
        i = i + 1
    tensor_from_data(result_data, a.shape)

fn div(a: PureTensor<f64>, b: PureTensor<f64>) -> PureTensor<f64>:
    """Element-wise division."""
    var result_data: [f64] = []
    var i = 0
    while i < a.data.len():
        result_data.push(a.data[i] / b.data[i])
        i = i + 1
    tensor_from_data(result_data, a.shape)

fn mul_scalar(t: PureTensor<f64>, scalar: f64) -> PureTensor<f64>:
    """Multiply tensor by scalar."""
    var result_data: [f64] = []
    for v in t.data:
        result_data.push(v * scalar)
    tensor_from_data(result_data, t.shape)

fn add_scalar(t: PureTensor<f64>, scalar: f64) -> PureTensor<f64>:
    """Add scalar to tensor."""
    var result_data: [f64] = []
    for v in t.data:
        result_data.push(v + scalar)
    tensor_from_data(result_data, t.shape)

# ============================================================================
# Matrix Operations
# ============================================================================

fn matmul(a: PureTensor<f64>, b: PureTensor<f64>) -> PureTensor<f64>:
    """Matrix multiplication: C = A @ B

    Assumes: A is [M, K], B is [K, N] -> C is [M, N]
    Algorithm: Naive triple loop (O(nÂ³))
    """
    val M = a.shape[0]
    val K = a.shape[1]
    val N = b.shape[1]

    var result_data: [f64] = []
    var i = 0
    while i < M:
        var j = 0
        while j < N:
            var sum = 0.0
            var k = 0
            while k < K:
                sum = sum + a.get([i, k]) * b.get([k, j])
                k = k + 1
            result_data.push(sum)
            j = j + 1
        i = i + 1

    tensor_from_data(result_data, [M, N])

fn transpose(t: PureTensor<f64>) -> PureTensor<f64>:
    """Transpose 2D tensor."""
    val rows = t.shape[0]
    val cols = t.shape[1]

    var result_data: [f64] = []
    var i = 0
    while i < cols:
        var j = 0
        while j < rows:
            result_data.push(t.get([j, i]))
            j = j + 1
        i = i + 1

    tensor_from_data(result_data, [cols, rows])

# ============================================================================
# Reductions
# ============================================================================

fn sum(t: PureTensor<f64>) -> f64:
    """Sum all elements."""
    var total = 0.0
    for v in t.data:
        total = total + v
    total

fn mean(t: PureTensor<f64>) -> f64:
    """Mean of all elements."""
    sum(t) / t.numel()

fn max(t: PureTensor<f64>) -> f64:
    """Maximum element."""
    var max_val = t.data[0]
    for v in t.data:
        if v > max_val:
            max_val = v
    max_val

fn min(t: PureTensor<f64>) -> f64:
    """Minimum element."""
    var min_val = t.data[0]
    for v in t.data:
        if v < min_val:
            min_val = v
    min_val

# ============================================================================
# Math Helpers
# ============================================================================

fn exp(x: f64) -> f64:
    """Exponential function using Taylor series."""
    var result = 1.0
    var term = 1.0
    var i = 1
    while i < 20:
        term = term * x / i
        result = result + term
        i = i + 1
    result

# ============================================================================
# Activation Functions
# ============================================================================

fn relu(x: PureTensor<f64>) -> PureTensor<f64>:
    """ReLU: max(0, x)."""
    var result_data: [f64] = []
    for v in x.data:
        result_data.push(if v > 0.0: v else: 0.0)
    tensor_from_data(result_data, x.shape)

fn sigmoid(x: PureTensor<f64>) -> PureTensor<f64>:
    """Sigmoid: 1 / (1 + exp(-x))."""
    var result_data: [f64] = []
    for v in x.data:
        val exp_neg = exp(-v)
        val sig = 1.0 / (1.0 + exp_neg)
        result_data.push(sig)
    tensor_from_data(result_data, x.shape)

fn tanh(x: PureTensor<f64>) -> PureTensor<f64>:
    """Tanh: (exp(x) - exp(-x)) / (exp(x) + exp(-x))."""
    var result_data: [f64] = []
    for v in x.data:
        val exp_pos = exp(v)
        val exp_neg = exp(-v)
        val tanh_val = (exp_pos - exp_neg) / (exp_pos + exp_neg)
        result_data.push(tanh_val)
    tensor_from_data(result_data, x.shape)

# ============================================================================
# Exports
# ============================================================================

export add, sub, mul, div, mul_scalar, add_scalar
export matmul, transpose
export sum, mean, max, min
export relu, sigmoid, tanh
