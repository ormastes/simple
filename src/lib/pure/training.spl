# Pure Simple Training Utilities
#
# Training loops, loss functions, and optimizers
# Zero external dependencies

use lib.pure.tensor.{PureTensor, tensor_from_data}
use lib.pure.tensor_ops.{sub, mul, mean, sum}

# ============================================================================
# Loss Functions
# ============================================================================

fn mse_loss(pred: PureTensor<f64>, target: PureTensor<f64>) -> f64:
    """Mean Squared Error loss."""
    val diff = sub(pred, target)
    val squared = mul(diff, diff)
    mean(squared)

fn mae_loss(pred: PureTensor<f64>, target: PureTensor<f64>) -> f64:
    """Mean Absolute Error loss."""
    val diff = sub(pred, target)
    var abs_sum = 0.0
    for v in diff.data:
        abs_sum = abs_sum + (if v < 0.0: -v else: v)
    abs_sum / diff.numel()

# ============================================================================
# Simple Linear Model (for demos)
# ============================================================================

class LinearModel:
    """Simple linear model: y = w*x + b"""
    w: f64
    b: f64

    fn forward(x: PureTensor<f64>) -> PureTensor<f64>:
        """Forward: y = w*x + b"""
        var result: [f64] = []
        for v in x.data:
            result.push(self.w * v + self.b)
        tensor_from_data(result, x.shape)

    fn predict(x: f64) -> f64:
        """Predict single value."""
        self.w * x + self.b

fn compute_mse(pred: PureTensor<f64>, target: PureTensor<f64>) -> f64:
    """Compute MSE loss (alias for mse_loss)."""
    mse_loss(pred, target)

fn compute_gradients(model: LinearModel, x: PureTensor<f64>, y: PureTensor<f64>) -> (f64, f64):
    """Compute gradients for LinearModel.

    Returns: (grad_w, grad_b)
    """
    val pred = model.forward(x)

    var grad_w = 0.0
    var grad_b = 0.0
    var i = 0
    while i < x.data.len():
        val error = pred.data[i] - y.data[i]
        grad_w = grad_w + 2.0 * error * x.data[i]
        grad_b = grad_b + 2.0 * error
        i = i + 1

    (grad_w / x.data.len(), grad_b / x.data.len())

# ============================================================================
# Exports
# ============================================================================

export mse_loss, mae_loss, compute_mse
export LinearModel, compute_gradients
