# Optimization Types Module
# Core data structures for optimization algorithms

class OptimizationResult:
    solution: List<f64>          # Optimal solution found
    objective_value: f64         # Objective function value at solution
    iterations: i64              # Number of iterations performed
    converged: bool              # Whether algorithm converged
    gradient_norm: f64           # Final gradient norm
    message: text                # Status message

class LineSearchResult:
    alpha: f64                   # Step size
    new_point: List<f64>         # New point after line search
    new_value: f64               # Function value at new point
    success: bool                # Whether line search succeeded
    iterations: i64              # Number of iterations

class OptimizationConfig:
    max_iterations: i64          # Maximum iterations
    tolerance: f64               # Convergence tolerance
    learning_rate: f64           # Initial learning rate
    verbose: bool                # Print progress
    gradient_tolerance: f64      # Gradient convergence threshold
    value_tolerance: f64         # Function value change threshold
    parameter_tolerance: f64     # Parameter change threshold

class AdamState:
    m: List<f64>                 # First moment estimate
    v: List<f64>                 # Second moment estimate
    beta1: f64                   # Exponential decay rate for first moment
    beta2: f64                   # Exponential decay rate for second moment
    epsilon: f64                 # Small constant for numerical stability
    t: i64                       # Time step

class RMSpropState:
    cache: List<f64>             # Cache of squared gradients
    decay_rate: f64              # Decay rate
    epsilon: f64                 # Small constant for numerical stability

class AdaGradState:
    cache: List<f64>             # Sum of squared gradients
    epsilon: f64                 # Small constant for numerical stability

class BFGSState:
    H: List<List<f64>>           # Inverse Hessian approximation
    prev_gradient: List<f64>     # Previous gradient
    prev_point: List<f64>        # Previous point

class Particle:
    position: List<f64>
    velocity: List<f64>
    best_position: List<f64>
    best_value: f64

fn create_default_config() -> OptimizationConfig:
    OptimizationConfig(
        max_iterations: 1000,
        tolerance: 1e-6,
        learning_rate: 0.01,
        verbose: false,
        gradient_tolerance: 1e-6,
        value_tolerance: 1e-9,
        parameter_tolerance: 1e-8
    )
