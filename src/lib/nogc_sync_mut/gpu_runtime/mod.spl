# GPU Runtime-Compatible API (NoGC)
# Simplified version that works with runtime parser.
#
# NoGC differences from gc_async_mut/gpu_runtime:
#   - No borrowed-view pattern (no TorchTensorWrapper/TorchStream with owns_handle: false)
#   - Direct FFI calls via rt_torch_* functions
#   - No temporary wrapper allocations

use std.nogc_sync_mut.torch.ffi.{
    rt_torch_cuda_available,
    rt_torch_tensor_zeros,
    rt_torch_tensor_ones,
    rt_torch_torchtensor_cuda,
    rt_torch_torchtensor_is_cuda,
    rt_torch_torchtensor_numel,
    rt_torch_stream_create,
    rt_torch_torchstream_sync,
    rt_torch_torchstream_query
}

# CUDA device count FFI
extern fn rt_cuda_device_count() -> i32

# ============================================================================
# Backend Detection (Functions Only)
# ============================================================================

fn gpu_available() -> bool:
    """Check if GPU is available."""
    rt_torch_cuda_available()

fn gpu_backend_name() -> text:
    """Get GPU backend name."""
    if rt_torch_cuda_available():
        "CUDA"
    else:
        "CPU"

fn gpu_device_count() -> i32:
    """Get number of GPU devices."""
    if rt_torch_cuda_available():
        rt_cuda_device_count()
    else:
        0

# ============================================================================
# Simple Tensor Operations (Runtime Compatible)
# ============================================================================

fn gpu_tensor_zeros(rows: i64, cols: i64) -> i64:
    """Create zero tensor and return handle.

    Returns handle (use with other gpu_tensor_* functions).
    """
    rt_torch_tensor_zeros([rows, cols])

fn gpu_tensor_ones(rows: i64, cols: i64) -> i64:
    """Create ones tensor and return handle."""
    rt_torch_tensor_ones([rows, cols])

fn gpu_tensor_to_cuda(tensor_handle: i64, device_id: i32) -> i64:
    """Move tensor to GPU.

    Args:
        tensor_handle: Tensor handle from gpu_tensor_*
        device_id: GPU device (0 = first GPU, 1 = second, etc.)

    Returns:
        New handle for GPU tensor
    """
    # NoGC: direct FFI call — no temporary wrapper needed
    rt_torch_torchtensor_cuda(tensor_handle, device_id)

fn gpu_tensor_is_cuda(tensor_handle: i64) -> bool:
    """Check if tensor is on GPU."""
    # NoGC: direct FFI call — no temporary wrapper needed
    rt_torch_torchtensor_is_cuda(tensor_handle)

fn gpu_tensor_numel(tensor_handle: i64) -> i64:
    """Get number of elements in tensor."""
    # NoGC: direct FFI call — no temporary wrapper needed
    rt_torch_torchtensor_numel(tensor_handle)

# ============================================================================
# Stream Operations (Runtime Compatible)
# ============================================================================

fn gpu_stream_create(device_id: i32) -> i64:
    """Create CUDA stream for async operations.

    Returns:
        Stream handle
    """
    rt_torch_stream_create(device_id)

fn gpu_stream_sync(stream_handle: i64):
    """Wait for stream to complete (blocking)."""
    # NoGC: direct FFI call — no temporary wrapper needed
    rt_torch_torchstream_sync(stream_handle)

fn gpu_stream_query(stream_handle: i64) -> bool:
    """Check if stream is complete (non-blocking)."""
    # NoGC: direct FFI call — no temporary wrapper needed
    rt_torch_torchstream_query(stream_handle)

# ============================================================================
# High-Level Helpers
# ============================================================================

fn gpu_alloc_zeros(rows: i64, cols: i64, use_gpu: bool, device_id: i32) -> i64:
    """Allocate zero tensor, optionally on GPU.

    Args:
        rows: Number of rows
        cols: Number of columns
        use_gpu: If true, allocate on GPU
        device_id: Which GPU to use (if use_gpu=true)

    Returns:
        Tensor handle
    """
    val t_handle = gpu_tensor_zeros(rows, cols)

    if use_gpu and gpu_available():
        gpu_tensor_to_cuda(t_handle, device_id)
    else:
        t_handle

fn gpu_alloc_ones(rows: i64, cols: i64, use_gpu: bool, device_id: i32) -> i64:
    """Allocate ones tensor, optionally on GPU."""
    val t_handle = gpu_tensor_ones(rows, cols)

    if use_gpu and gpu_available():
        gpu_tensor_to_cuda(t_handle, device_id)
    else:
        t_handle

# ============================================================================
# Context-Style API (Function-Based)
# ============================================================================

fn gpu_ctx_info():
    """Print GPU context information."""
    print "GPU Backend: {gpu_backend_name()}"
    print "CUDA Available: {gpu_available()}"

    if gpu_available():
        print "Device Count: {gpu_device_count()}"
        print "Status: Ready"
    else:
        print "Status: CPU fallback"

fn gpu_ctx_alloc_zeros(rows: i64, cols: i64, device_id: i32) -> i64:
    """Context-style: allocate zeros on GPU.

    Simplified version of ctx.alloc_zeros[f32](rows * cols)
    """
    gpu_alloc_zeros(rows, cols, use_gpu: true, device_id: device_id)

fn gpu_ctx_alloc_ones(rows: i64, cols: i64, device_id: i32) -> i64:
    """Context-style: allocate ones on GPU."""
    gpu_alloc_ones(rows, cols, use_gpu: true, device_id: device_id)

# ============================================================================
# Async Pipeline Helpers
# ============================================================================

fn gpu_async_upload_batch(rows: i64, cols: i64, device_id: i32, stream_handle: i64) -> i64:
    """Upload batch to GPU asynchronously.

    Returns:
        Tensor handle (on GPU)
    """
    val t = gpu_tensor_zeros(rows, cols)
    gpu_tensor_to_cuda(t, device_id)

fn gpu_async_wait(stream_handle: i64):
    """Wait for async operations to complete."""
    gpu_stream_sync(stream_handle)

# ============================================================================
# Exports
# ============================================================================

export gpu_available
export gpu_backend_name
export gpu_device_count
export gpu_ctx_info

export gpu_tensor_zeros
export gpu_tensor_ones
export gpu_tensor_to_cuda
export gpu_tensor_is_cuda
export gpu_tensor_numel

export gpu_stream_create
export gpu_stream_sync
export gpu_stream_query

export gpu_alloc_zeros
export gpu_alloc_ones

export gpu_ctx_alloc_zeros
export gpu_ctx_alloc_ones

export gpu_async_upload_batch
export gpu_async_wait
