# Cache Utility Functions
#
# Purpose: Statistics, helpers, and convenience functions
#
# Contains:
# - Cache statistics (hits, misses, hit rate)
# - Helper functions (is_empty, is_full)
# - Get-or-default, get-or-compute patterns
# - Memoization call function
# - Example usage functions

# ============================================================================
# Statistics Functions
# ============================================================================

fn cache_lru_stats(cache):
    """Get LRU cache statistics.

    Returns dictionary with:
    - hits: Number of cache hits
    - misses: Number of cache misses
    - hit_rate: Hit rate as percentage (0.0 to 100.0)
    - size: Current number of entries
    - capacity: Maximum capacity
    """
    val hits = cache['hits']
    val misses = cache['misses']
    val total = hits + misses

    var hit_rate = 0.0
    if total > 0:
        hit_rate = (hits * 100.0) / total

    {
        'hits': hits,
        'misses': misses,
        'hit_rate': hit_rate,
        'size': cache_lru_size(cache),
        'capacity': cache['capacity']
    }

fn cache_fifo_stats(cache):
    """Get FIFO cache statistics."""
    val hits = cache['hits']
    val misses = cache['misses']
    val total = hits + misses

    var hit_rate = 0.0
    if total > 0:
        hit_rate = (hits * 100.0) / total

    {
        'hits': hits,
        'misses': misses,
        'hit_rate': hit_rate,
        'size': cache_fifo_size(cache),
        'capacity': cache['capacity']
    }

fn cache_lfu_stats(cache):
    """Get LFU cache statistics."""
    val hits = cache['hits']
    val misses = cache['misses']
    val total = hits + misses

    var hit_rate = 0.0
    if total > 0:
        hit_rate = (hits * 100.0) / total

    {
        'hits': hits,
        'misses': misses,
        'hit_rate': hit_rate,
        'size': cache_lfu_size(cache),
        'capacity': cache['capacity']
    }

fn cache_ttl_stats(cache):
    """Get TTL cache statistics."""
    val hits = cache['hits']
    val misses = cache['misses']
    val total = hits + misses

    var hit_rate = 0.0
    if total > 0:
        hit_rate = (hits * 100.0) / total

    {
        'hits': hits,
        'misses': misses,
        'hit_rate': hit_rate,
        'size': cache_ttl_size(cache),
        'capacity': cache['capacity'],
        'ttl': cache['ttl']
    }

fn cache_stats(cache):
    """Generic cache stats operation. Works with any cache type."""
    val cache_type = cache['type']
    if cache_type == 'lru':
        cache_lru_stats(cache)
    elif cache_type == 'fifo':
        cache_fifo_stats(cache)
    elif cache_type == 'lfu':
        cache_lfu_stats(cache)
    elif cache_type == 'ttl':
        cache_ttl_stats(cache)
    else:
        {'hits': 0, 'misses': 0, 'hit_rate': 0.0, 'size': 0, 'capacity': 0}

fn memo_stats(memo_cache):
    """Get memoization cache statistics."""
    cache_lru_stats(memo_cache)

# ============================================================================
# Helper Functions
# ============================================================================

fn cache_hit_rate(cache) -> f64:
    """Calculate hit rate for cache."""
    val stats = cache_stats(cache)
    stats['hit_rate']

fn cache_miss_rate(cache) -> f64:
    """Calculate miss rate for cache."""
    100.0 - cache_hit_rate(cache)

fn cache_is_empty(cache) -> bool:
    """Check if cache is empty."""
    cache_size(cache) == 0

fn cache_is_full(cache) -> bool:
    """Check if cache is at capacity."""
    cache_size(cache) >= cache['capacity']

fn cache_get_or_default(cache, key: text, default_value):
    """Get value from cache or return default if not found."""
    val value = cache_get(cache, key)
    if value == nil:
        default_value
    else:
        value

fn cache_get_or_compute(cache, key: text, compute_fn):
    """Get value from cache or compute and cache if not found."""
    val value = cache_get(cache, key)
    if value == nil:
        val computed = compute_fn()
        cache_put(cache, key, computed)
        return computed
    else:
        return value

# ============================================================================
# Memoization
# ============================================================================

fn memo_call(memo_cache, key: text, compute_fn):
    """Call function with memoization.

    Args:
    - memo_cache: Memoization cache created with memo_create
    - key: String key for this computation
    - compute_fn: Function to call if result not cached (takes no args)

    Returns: Cached or computed result.
    """
    val cached = cache_lru_get(memo_cache, key)
    if cached != nil:
        return cached

    # Not cached - compute and store
    val result = compute_fn()
    cache_lru_put(memo_cache, key, result)
    result

# ============================================================================
# Example Usage Functions
# ============================================================================

fn cache_example_lru():
    """Example of using LRU cache."""
    val cache = cache_lru_new(3)

    # Add entries
    cache_lru_put(cache, "a", 1)
    cache_lru_put(cache, "b", 2)
    cache_lru_put(cache, "c", 3)

    # Access to update order
    val val_a = cache_lru_get(cache, "a")

    # Add one more - should evict "b" (least recently used)
    cache_lru_put(cache, "d", 4)

    # Get stats
    cache_lru_stats(cache)

fn cache_example_fifo():
    """Example of using FIFO cache."""
    val cache = cache_fifo_new(3)

    cache_fifo_put(cache, "a", 1)
    cache_fifo_put(cache, "b", 2)
    cache_fifo_put(cache, "c", 3)

    # Add one more - should evict "a" (first in)
    cache_fifo_put(cache, "d", 4)

    cache_fifo_stats(cache)

fn cache_example_lfu():
    """Example of using LFU cache."""
    val cache = cache_lfu_new(3)

    cache_lfu_put(cache, "a", 1)
    cache_lfu_put(cache, "b", 2)
    cache_lfu_put(cache, "c", 3)

    # Access "a" multiple times
    cache_lfu_get(cache, "a")
    cache_lfu_get(cache, "a")
    cache_lfu_get(cache, "a")

    # Add one more - should evict "b" or "c" (least frequently used)
    cache_lfu_put(cache, "d", 4)

    cache_lfu_stats(cache)

fn cache_example_ttl():
    """Example of using TTL cache."""
    val cache = cache_ttl_new(10, 60)

    cache_ttl_put(cache, "session_123", "user_data")
    cache_ttl_put(cache, "session_456", "admin_data")

    # Get value (within TTL)
    val session = cache_ttl_get(cache, "session_123")

    # Clean up expired entries
    cache_ttl_cleanup(cache)

    cache_ttl_stats(cache)

fn cache_example_memo():
    """Example of using memoization."""
    val memo = memo_create(100)

    # Expensive computation
    fn expensive_computation():
        var sum = 0
        var i = 0
        while i < 1000:
            sum = sum + i
            i = i + 1
        sum

    # First call - computes
    val result1 = memo_call(memo, "sum_1000", expensive_computation)

    # Second call - cached
    val result2 = memo_call(memo, "sum_1000", expensive_computation)

    memo_stats(memo)

# ============================================================================
# Helper stub functions
# ============================================================================

fn cache_lru_size(cache) -> i64:
    val keys = cache['keys']
    keys.len()

fn cache_fifo_size(cache) -> i64:
    val keys = cache['keys']
    keys.len()

fn cache_lfu_size(cache) -> i64:
    val keys = cache['keys']
    keys.len()

fn cache_ttl_size(cache) -> i64:
    val keys = cache['keys']
    keys.len()

fn cache_size(cache) -> i64:
    val keys = cache['keys']
    keys.len()

fn cache_get(cache, key: text):
    nil

fn cache_put(cache, key: text, value):
    cache

fn cache_lru_get(cache, key: text):
    nil

fn cache_lru_put(cache, key: text, value):
    cache

fn cache_fifo_new(capacity: i64):
    {'type': 'fifo', 'keys': [], 'values': [], 'capacity': capacity, 'hits': 0, 'misses': 0}

fn cache_fifo_put(cache, key: text, value):
    cache

fn cache_fifo_get(cache, key: text):
    nil

fn cache_lfu_new(capacity: i64):
    {'type': 'lfu', 'keys': [], 'values': [], 'frequencies': [], 'capacity': capacity, 'hits': 0, 'misses': 0}

fn cache_lfu_put(cache, key: text, value):
    cache

fn cache_lfu_get(cache, key: text):
    nil

fn cache_ttl_new(capacity: i64, ttl_seconds: i64):
    {'type': 'ttl', 'keys': [], 'values': [], 'expiry_times': [], 'capacity': capacity, 'ttl': ttl_seconds, 'hits': 0, 'misses': 0}

fn cache_ttl_put(cache, key: text, value):
    cache

fn cache_ttl_get(cache, key: text):
    nil

fn cache_ttl_cleanup(cache):
    cache

fn cache_lru_new(capacity: i64):
    {'type': 'lru', 'keys': [], 'values': [], 'capacity': capacity, 'hits': 0, 'misses': 0}

fn memo_create(capacity: i64):
    cache_lru_new(capacity)

export cache_lru_stats, cache_fifo_stats, cache_lfu_stats, cache_ttl_stats, cache_stats
export memo_stats
export cache_hit_rate, cache_miss_rate, cache_is_empty, cache_is_full
export cache_get_or_default, cache_get_or_compute
export memo_call
export cache_example_lru, cache_example_fifo, cache_example_lfu
export cache_example_ttl, cache_example_memo
