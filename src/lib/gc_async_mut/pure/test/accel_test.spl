# Acceleration Layer Test - Standalone
# Tests decision logic and configuration

# ============================================================================
# Inline accel.spl (since module system doesn't work yet)
# ============================================================================

enum AccelMode:
    PureSimple
    PyTorchFFI
    Auto

var current_mode = AccelMode.PureSimple
var ffi_available = false

val MATMUL_THRESHOLD = 1_000_000
val ELEMENTWISE_THRESHOLD = 10_000_000
val REDUCTION_THRESHOLD = 5_000_000

fn set_acceleration(mode: AccelMode):
    current_mode = mode

fn get_acceleration() -> AccelMode:
    current_mode

fn is_pure_simple_mode() -> bool:
    match current_mode:
        case PureSimple: true
        case _: false

fn set_ffi_available(available: bool):
    ffi_available = available

fn is_ffi_available() -> bool:
    ffi_available

fn should_use_ffi(op: text, numel: i64) -> bool:
    match current_mode:
        case PureSimple:
            return false
        case PyTorchFFI:
            return ffi_available
        case Auto:
            if not ffi_available:
                return false
            val threshold = get_threshold(op)
            return numel > threshold

fn get_threshold(op: text) -> i64:
    if op == "matmul":
        MATMUL_THRESHOLD
    elif op == "add" or op == "sub" or op == "mul" or op == "div":
        ELEMENTWISE_THRESHOLD
    elif op == "sum" or op == "mean" or op == "max" or op == "min":
        REDUCTION_THRESHOLD
    elif op == "relu" or op == "sigmoid" or op == "tanh":
        999_999_999_999
    else:
        MATMUL_THRESHOLD

var stats_pure_simple_count = 0
var stats_ffi_count = 0
var stats_ffi_fallback_count = 0

fn record_pure_simple():
    stats_pure_simple_count = stats_pure_simple_count + 1

fn record_ffi():
    stats_ffi_count = stats_ffi_count + 1

fn record_ffi_fallback():
    stats_ffi_fallback_count = stats_ffi_fallback_count + 1

fn get_stats() -> (i64, i64, i64):
    (stats_pure_simple_count, stats_ffi_count, stats_ffi_fallback_count)

fn reset_stats():
    stats_pure_simple_count = 0
    stats_ffi_count = 0
    stats_ffi_fallback_count = 0

# ============================================================================
# Test Helper
# ============================================================================

var test_count = 0
var pass_count = 0
var fail_count = 0

fn test(name: text, condition: bool):
    test_count = test_count + 1
    if condition:
        pass_count = pass_count + 1
        print "✅ {name}"
    else:
        fail_count = fail_count + 1
        print "❌ {name}"

# ============================================================================
# Tests
# ============================================================================

print "Acceleration Layer - Standalone Tests"
print "======================================"
print ""

# Test 1: Default mode
print "Test Group: Default Configuration"
test("Default mode is PureSimple", is_pure_simple_mode())
test("FFI not available by default", not is_ffi_available())
test("should_use_ffi returns false in PureSimple mode", not should_use_ffi("matmul", 10_000_000))
print ""

# Test 2: PureSimple mode (never use FFI)
print "Test Group: PureSimple Mode"
set_acceleration(AccelMode.PureSimple)
set_ffi_available(true)  # Even with FFI available
test("PureSimple: small matmul -> Pure Simple", not should_use_ffi("matmul", 100))
test("PureSimple: large matmul -> Pure Simple", not should_use_ffi("matmul", 10_000_000))
test("PureSimple: never uses FFI", not should_use_ffi("matmul", 999_999_999))
print ""

# Test 3: PyTorchFFI mode (always use FFI if available)
print "Test Group: PyTorchFFI Mode"
set_acceleration(AccelMode.PyTorchFFI)
set_ffi_available(true)
test("PyTorchFFI: small matmul -> FFI", should_use_ffi("matmul", 100))
test("PyTorchFFI: large matmul -> FFI", should_use_ffi("matmul", 10_000_000))
set_ffi_available(false)
test("PyTorchFFI: no FFI available -> Pure Simple", not should_use_ffi("matmul", 10_000_000))
print ""

# Test 4: Auto mode (threshold-based)
print "Test Group: Auto Mode"
set_acceleration(AccelMode.Auto)
set_ffi_available(true)

# Matmul threshold: 1M
test("Auto: matmul 100x100 (10k) -> Pure Simple", not should_use_ffi("matmul", 10_000))
test("Auto: matmul 1000x1000 (1M) -> Pure Simple", not should_use_ffi("matmul", 1_000_000))
test("Auto: matmul 1001x1001 (>1M) -> FFI", should_use_ffi("matmul", 1_002_001))
test("Auto: matmul 2000x2000 (4M) -> FFI", should_use_ffi("matmul", 4_000_000))
print ""

# Test 5: Element-wise threshold (10M)
print "Test Group: Element-wise Operations"
test("Auto: add 1M elements -> Pure Simple", not should_use_ffi("add", 1_000_000))
test("Auto: add 10M elements -> Pure Simple", not should_use_ffi("add", 10_000_000))
test("Auto: add 11M elements -> FFI", should_use_ffi("add", 11_000_000))
test("Auto: mul 5M elements -> Pure Simple", not should_use_ffi("mul", 5_000_000))
print ""

# Test 6: Activation functions (never use FFI)
print "Test Group: Activation Functions"
test("Auto: relu 100M elements -> Pure Simple", not should_use_ffi("relu", 100_000_000))
test("Auto: sigmoid 1B elements -> Pure Simple", not should_use_ffi("sigmoid", 1_000_000_000))
test("Auto: tanh huge -> Pure Simple", not should_use_ffi("tanh", 999_999_999_999))
print ""

# Test 7: Threshold values
print "Test Group: Threshold Values"
test("MATMUL_THRESHOLD is 1M", MATMUL_THRESHOLD == 1_000_000)
test("ELEMENTWISE_THRESHOLD is 10M", ELEMENTWISE_THRESHOLD == 10_000_000)
test("REDUCTION_THRESHOLD is 5M", REDUCTION_THRESHOLD == 5_000_000)
test("matmul threshold correct", get_threshold("matmul") == 1_000_000)
test("add threshold correct", get_threshold("add") == 10_000_000)
test("relu threshold very high", get_threshold("relu") == 999_999_999_999)
print ""

# Test 8: Statistics tracking
print "Test Group: Statistics Tracking"
reset_stats()
record_pure_simple()
record_pure_simple()
record_ffi()
record_ffi_fallback()
val stats = get_stats()
test("Pure Simple count: 2", stats.0 == 2)
test("FFI count: 1", stats.1 == 1)
test("FFI fallback count: 1", stats.2 == 1)
print ""

# Test 9: FFI availability
print "Test Group: FFI Availability"
set_ffi_available(true)
test("FFI can be enabled", is_ffi_available())
set_ffi_available(false)
test("FFI can be disabled", not is_ffi_available())
set_acceleration(AccelMode.Auto)
test("Auto mode respects FFI unavailable", not should_use_ffi("matmul", 10_000_000))
print ""

# Test 10: Edge cases
print "Test Group: Edge Cases"
set_ffi_available(true)
set_acceleration(AccelMode.Auto)
test("Auto: exactly at threshold -> Pure Simple", not should_use_ffi("matmul", 1_000_000))
test("Auto: one over threshold -> FFI", should_use_ffi("matmul", 1_000_001))
test("Auto: zero elements -> Pure Simple", not should_use_ffi("matmul", 0))
test("Auto: one element -> Pure Simple", not should_use_ffi("matmul", 1))
print ""

# Summary
print "======================================"
print "Test Summary:"
print "  Total:  {test_count}"
print "  Passed: {pass_count}"
print "  Failed: {fail_count}"
print ""

if fail_count == 0:
    print "✅ All tests passed!"
    print ""
    print "Acceleration Layer Status:"
    print "  ✅ Default configuration works"
    print "  ✅ PureSimple mode (never FFI)"
    print "  ✅ PyTorchFFI mode (always FFI)"
    print "  ✅ Auto mode (threshold-based)"
    print "  ✅ Threshold logic correct"
    print "  ✅ Statistics tracking works"
    print "  ✅ FFI availability check works"
    print "  ✅ Edge cases handled"
else:
    print "❌ {fail_count} test(s) failed"
