# torch SFFI Bindings (Tier 2)
# Auto-generated extern fn declarations
#
# These map to Rust FFI exports in .build/rust/ffi_torch/

# ============================================================================
# Opaque Handle Types (represented as i64 pointers)
# ============================================================================

# TorchTensor: Opaque handle (pointer cast to i64)
# TorchStream: Opaque handle (pointer cast to i64)

# ============================================================================
# Library Information
# ============================================================================

# Check if PyTorch/libtorch is available at runtime
extern fn rt_torch_available() -> bool

# Get PyTorch version string
extern fn rt_torch_version() -> text

# Check if CUDA is available for GPU acceleration
extern fn rt_torch_cuda_available() -> bool

# ============================================================================
# Tensor Creation Functions
# ============================================================================

# Create tensor filled with zeros
# Args: dims - shape as array of i64
# Returns: tensor handle (i64 pointer)
extern fn rt_torch_tensor_zeros(dims: [i64]) -> i64

# Create tensor filled with ones
extern fn rt_torch_tensor_ones(dims: [i64]) -> i64

# Create tensor with random normal distribution (mean=0, std=1)
extern fn rt_torch_tensor_randn(dims: [i64]) -> i64

# Create tensor with random uniform distribution [0, 1)
extern fn rt_torch_tensor_rand(dims: [i64]) -> i64

# Create tensor filled with a scalar value
extern fn rt_torch_tensor_full(dims: [i64], value: f64) -> i64

# Create tensor from array data
extern fn rt_torch_tensor_from_data(data: [f64], dims: [i64]) -> i64

# Create evenly spaced values in interval [start, end)
extern fn rt_torch_tensor_arange(start: f64, end: f64, step: f64) -> i64

# Create evenly spaced values with count steps
extern fn rt_torch_tensor_linspace(start: f64, end: f64, steps: i64) -> i64

# Create identity matrix
extern fn rt_torch_tensor_eye(n: i64) -> i64

# Create empty tensor (uninitialized)
extern fn rt_torch_tensor_empty(dims: [i64]) -> i64

# ============================================================================
# Element-wise Arithmetic Operations
# ============================================================================

# Element-wise addition: a + b
extern fn rt_torch_torchtensor_add(handle: i64, other: i64) -> i64

# Element-wise subtraction: a - b
extern fn rt_torch_torchtensor_sub(handle: i64, other: i64) -> i64

# Element-wise multiplication: a * b
extern fn rt_torch_torchtensor_mul(handle: i64, other: i64) -> i64

# Element-wise division: a / b
extern fn rt_torch_torchtensor_div(handle: i64, other: i64) -> i64

# Element-wise power: a ** b
extern fn rt_torch_torchtensor_pow(handle: i64, exponent: f64) -> i64

# Element-wise negation: -a
extern fn rt_torch_torchtensor_neg(handle: i64) -> i64

# Element-wise absolute value
extern fn rt_torch_torchtensor_abs(handle: i64) -> i64

# Element-wise square root
extern fn rt_torch_torchtensor_sqrt(handle: i64) -> i64

# Element-wise exponential: e^x
extern fn rt_torch_torchtensor_exp(handle: i64) -> i64

# Element-wise natural logarithm
extern fn rt_torch_torchtensor_log(handle: i64) -> i64

# Scalar addition: tensor + scalar
extern fn rt_torch_torchtensor_add_scalar(handle: i64, scalar: f64) -> i64

# Scalar multiplication: tensor * scalar
extern fn rt_torch_torchtensor_mul_scalar(handle: i64, scalar: f64) -> i64

# ============================================================================
# Activation Functions
# ============================================================================

# ReLU activation: max(0, x)
extern fn rt_torch_torchtensor_relu(handle: i64) -> i64

# Sigmoid activation: 1 / (1 + e^(-x))
extern fn rt_torch_torchtensor_sigmoid(handle: i64) -> i64

# Tanh activation: (e^x - e^(-x)) / (e^x + e^(-x))
extern fn rt_torch_torchtensor_tanh(handle: i64) -> i64

# Leaky ReLU: max(negative_slope * x, x)
extern fn rt_torch_torchtensor_leaky_relu(handle: i64, negative_slope: f64) -> i64

# GELU activation (Gaussian Error Linear Unit)
extern fn rt_torch_torchtensor_gelu(handle: i64) -> i64

# Softmax along dimension
extern fn rt_torch_torchtensor_softmax(handle: i64, dim: i64) -> i64

# Log softmax along dimension
extern fn rt_torch_torchtensor_log_softmax(handle: i64, dim: i64) -> i64

# ============================================================================
# Linear Algebra Operations
# ============================================================================

# Matrix multiplication: a @ b
extern fn rt_torch_torchtensor_matmul(handle: i64, other: i64) -> i64

# Dot product (1D tensors)
extern fn rt_torch_torchtensor_dot(handle: i64, other: i64) -> i64

# Matrix transpose
extern fn rt_torch_torchtensor_transpose(handle: i64, dim0: i64, dim1: i64) -> i64

# Matrix transpose (2D only, swap rows/cols)
extern fn rt_torch_torchtensor_t(handle: i64) -> i64

# Matrix norm (Frobenius norm by default)
extern fn rt_torch_torchtensor_norm(handle: i64) -> f64

# Matrix determinant
extern fn rt_torch_torchtensor_det(handle: i64) -> f64

# Matrix inverse
extern fn rt_torch_torchtensor_inverse(handle: i64) -> i64

# Singular Value Decomposition
extern fn rt_torch_torchtensor_svd(handle: i64) -> i64

# Eigenvalues and eigenvectors
extern fn rt_torch_torchtensor_eig(handle: i64) -> i64

# ============================================================================
# Reduction Operations
# ============================================================================

# Sum all elements
extern fn rt_torch_torchtensor_sum(handle: i64) -> f64

# Sum along dimension
extern fn rt_torch_torchtensor_sum_dim(handle: i64, dim: i64, keepdim: bool) -> i64

# Mean of all elements
extern fn rt_torch_torchtensor_mean(handle: i64) -> f64

# Mean along dimension
extern fn rt_torch_torchtensor_mean_dim(handle: i64, dim: i64, keepdim: bool) -> i64

# Maximum element value
extern fn rt_torch_torchtensor_max(handle: i64) -> f64

# Maximum along dimension (returns values and indices)
extern fn rt_torch_torchtensor_max_dim(handle: i64, dim: i64, keepdim: bool) -> i64

# Minimum element value
extern fn rt_torch_torchtensor_min(handle: i64) -> f64

# Minimum along dimension
extern fn rt_torch_torchtensor_min_dim(handle: i64, dim: i64, keepdim: bool) -> i64

# Index of maximum element
extern fn rt_torch_torchtensor_argmax(handle: i64, dim: i64, keepdim: bool) -> i64

# Index of minimum element
extern fn rt_torch_torchtensor_argmin(handle: i64, dim: i64, keepdim: bool) -> i64

# Standard deviation
extern fn rt_torch_torchtensor_std(handle: i64) -> f64

# Variance
extern fn rt_torch_torchtensor_var(handle: i64) -> f64

# ============================================================================
# Shape Manipulation
# ============================================================================

# Get number of dimensions
extern fn rt_torch_torchtensor_ndim(handle: i64) -> i64

# Get total number of elements
extern fn rt_torch_torchtensor_numel(handle: i64) -> i64

# Get shape as array
extern fn rt_torch_torchtensor_shape(handle: i64) -> [i64]

# Reshape tensor (must have same number of elements)
extern fn rt_torch_torchtensor_reshape(handle: i64, dims: [i64]) -> i64

# View tensor (alias, shares memory)
extern fn rt_torch_torchtensor_view(handle: i64, dims: [i64]) -> i64

# Permute dimensions
extern fn rt_torch_torchtensor_permute(handle: i64, dims: [i64]) -> i64

# Remove dimensions of size 1
extern fn rt_torch_torchtensor_squeeze(handle: i64) -> i64

# Remove specific dimension of size 1
extern fn rt_torch_torchtensor_squeeze_dim(handle: i64, dim: i64) -> i64

# Add dimension of size 1
extern fn rt_torch_torchtensor_unsqueeze(handle: i64, dim: i64) -> i64

# Flatten to 1D
extern fn rt_torch_torchtensor_flatten(handle: i64) -> i64

# Make tensor contiguous in memory
extern fn rt_torch_torchtensor_contiguous(handle: i64) -> i64

# ============================================================================
# Indexing and Slicing
# ============================================================================

# Select slice along dimension
extern fn rt_torch_torchtensor_slice(handle: i64, dim: i64, start: i64, end: i64, step: i64) -> i64

# Index select (gather specific indices)
extern fn rt_torch_torchtensor_index_select(handle: i64, dim: i64, indices: i64) -> i64

# Gather values along dimension
extern fn rt_torch_torchtensor_gather(handle: i64, dim: i64, indices: i64) -> i64

# Concatenate tensors along dimension
extern fn rt_torch_torchtensor_cat(tensors: [i64], dim: i64) -> i64

# Stack tensors along new dimension
extern fn rt_torch_torchtensor_stack(tensors: [i64], dim: i64) -> i64

# Split tensor into chunks
extern fn rt_torch_torchtensor_chunk(handle: i64, chunks: i64, dim: i64) -> [i64]

# ============================================================================
# Neural Network Operations
# ============================================================================

# 2D Convolution
# Args: input, weight, bias (optional), stride, padding, dilation, groups
extern fn rt_torch_nn_conv2d(input: i64, weight: i64, bias: i64, stride: [i64], padding: [i64], dilation: [i64], groups: i64) -> i64

# 2D Max Pooling
extern fn rt_torch_nn_max_pool2d(input: i64, kernel_size: [i64], stride: [i64], padding: [i64]) -> i64

# 2D Average Pooling
extern fn rt_torch_nn_avg_pool2d(input: i64, kernel_size: [i64], stride: [i64], padding: [i64]) -> i64

# Batch Normalization (training mode)
extern fn rt_torch_nn_batch_norm(input: i64, running_mean: i64, running_var: i64, weight: i64, bias: i64, training: bool, momentum: f64, eps: f64) -> i64

# Layer Normalization
extern fn rt_torch_nn_layer_norm(input: i64, normalized_shape: [i64], weight: i64, bias: i64, eps: f64) -> i64

# Dropout (training mode)
extern fn rt_torch_nn_dropout(input: i64, p: f64, training: bool) -> i64

# Linear transformation: y = xA^T + b
extern fn rt_torch_nn_linear(input: i64, weight: i64, bias: i64) -> i64

# Embedding lookup
extern fn rt_torch_nn_embedding(input: i64, weight: i64) -> i64

# ============================================================================
# Loss Functions
# ============================================================================

# Mean Squared Error loss
extern fn rt_torch_nn_mse_loss(input: i64, target: i64) -> f64

# Cross Entropy loss
extern fn rt_torch_nn_cross_entropy(input: i64, target: i64) -> f64

# Binary Cross Entropy loss
extern fn rt_torch_nn_binary_cross_entropy(input: i64, target: i64) -> f64

# Negative Log Likelihood loss
extern fn rt_torch_nn_nll_loss(input: i64, target: i64) -> f64

# ============================================================================
# Autograd Operations
# ============================================================================

# Enable gradient computation for tensor
extern fn rt_torch_autograd_set_requires_grad(handle: i64, requires_grad: bool)

# Check if tensor requires gradients
extern fn rt_torch_autograd_requires_grad(handle: i64) -> bool

# Get gradient tensor (returns handle or 0 if no gradient)
extern fn rt_torch_autograd_grad(handle: i64) -> i64

# Compute gradients (backward pass)
extern fn rt_torch_autograd_backward(handle: i64)

# Zero out gradients
extern fn rt_torch_autograd_zero_grad(handle: i64)

# Detach tensor from computation graph (no gradient)
extern fn rt_torch_autograd_detach(handle: i64) -> i64

# Disable gradient computation context
extern fn rt_torch_autograd_no_grad_begin()

# Re-enable gradient computation context
extern fn rt_torch_autograd_no_grad_end()

# ============================================================================
# Device Management
# ============================================================================

# Move tensor to CUDA device
extern fn rt_torch_torchtensor_cuda(handle: i64, device_id: i32) -> i64

# Move tensor to CPU
extern fn rt_torch_torchtensor_cpu(handle: i64) -> i64

# Check if tensor is on CUDA device
extern fn rt_torch_torchtensor_is_cuda(handle: i64) -> bool

# Get device ID (-1 for CPU, >= 0 for CUDA)
extern fn rt_torch_torchtensor_device(handle: i64) -> i32

# Move tensor to device with stream
extern fn rt_torch_torchtensor_to_stream(handle: i64, device_id: i32, stream: i64) -> i64

# Clone tensor (deep copy)
extern fn rt_torch_torchtensor_clone(handle: i64) -> i64

# ============================================================================
# CUDA Stream Operations
# ============================================================================

# Create CUDA stream for async operations
extern fn rt_torch_stream_create(device_id: i32) -> i64

# Synchronize stream (wait for completion)
extern fn rt_torch_torchstream_sync(handle: i64)

# Query stream status (true if idle)
extern fn rt_torch_torchstream_query(handle: i64) -> bool

# Free stream handle
extern fn rt_torch_torchstream_free(handle: i64)

# ============================================================================
# Memory Management
# ============================================================================

# Free tensor handle (release memory)
extern fn rt_torch_torchtensor_free(handle: i64)

# Get memory allocated on device (bytes)
extern fn rt_torch_cuda_memory_allocated(device_id: i32) -> i64

# Get peak memory allocated (bytes)
extern fn rt_torch_cuda_max_memory_allocated(device_id: i32) -> i64

# Empty CUDA cache
extern fn rt_torch_cuda_empty_cache()

# ============================================================================
# Trigonometric Functions
# ============================================================================

# Element-wise sine
extern fn rt_torch_torchtensor_sin(handle: i64) -> i64

# Element-wise cosine
extern fn rt_torch_torchtensor_cos(handle: i64) -> i64

# Element-wise tangent
extern fn rt_torch_torchtensor_tan(handle: i64) -> i64

# Element-wise arc sine
extern fn rt_torch_torchtensor_asin(handle: i64) -> i64

# Element-wise arc cosine
extern fn rt_torch_torchtensor_acos(handle: i64) -> i64

# Element-wise atan2(y, x)
extern fn rt_torch_torchtensor_atan2(handle: i64, other: i64) -> i64

# ============================================================================
# Integer Tensor Creation
# ============================================================================

# Create int64 arange tensor
extern fn rt_torch_tensor_arange_int(start: i64, end: i64, step: i64) -> i64

# Create int64 zeros tensor (1D)
extern fn rt_torch_tensor_zeros_int_1d(d0: i64) -> i64

# Create int64 zeros tensor (2D)
extern fn rt_torch_tensor_zeros_int_2d(d0: i64, d1: i64) -> i64

# Create int64 ones tensor (1D)
extern fn rt_torch_tensor_ones_int_1d(d0: i64) -> i64

# Create int64 ones tensor (2D)
extern fn rt_torch_tensor_ones_int_2d(d0: i64, d1: i64) -> i64

# Create int64 full tensor (1D)
extern fn rt_torch_tensor_full_int_1d(d0: i64, value: i64) -> i64

# Create int64 full tensor (2D)
extern fn rt_torch_tensor_full_int_2d(d0: i64, d1: i64, value: i64) -> i64

# Create int64 tensor from array data
extern fn rt_torch_tensor_from_i64_data(data: [i64], dims: [i64]) -> i64

# Cast tensor to float64
extern fn rt_torch_torchtensor_to_float(handle: i64) -> i64

# Cast tensor to int64
extern fn rt_torch_torchtensor_to_int(handle: i64) -> i64

# Cast tensor to float32
extern fn rt_torch_torchtensor_to_float32(handle: i64) -> i64

# ============================================================================
# Tensor Serialization
# ============================================================================

# Save tensor to file (native path)
extern fn rt_torch_tensor_save(handle: i64, path: text)

# Load tensor from file (native path)
extern fn rt_torch_tensor_load(path: text) -> i64

# ============================================================================
# Safetensors Loading
# ============================================================================

# Open safetensors file (returns file handle)
extern fn rt_torch_safetensors_open(path: text) -> i64

# Close safetensors file
extern fn rt_torch_safetensors_close(handle: i64)

# Get number of tensors in safetensors file
extern fn rt_torch_safetensors_num_tensors(handle: i64) -> i64

# List tensor names (newline-delimited)
extern fn rt_torch_safetensors_list_names(handle: i64) -> text

# Get tensor by name from safetensors file
extern fn rt_torch_safetensors_get_tensor(sf_handle: i64, name: text) -> i64

# ============================================================================
# Exports (handle types are i64, no need to export)
# ============================================================================

# All extern functions are automatically available when imported

