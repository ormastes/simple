# GPU Device Management (NoGC)
#
# Provides device enumeration and backend selection.
# Imports shared types from common/gpu/device.

use std.common.gpu.device.{GpuBackend, Gpu, gpu_cuda, gpu_vulkan, gpu_none}
use std.nogc_async_mut.torch.{cuda_available}

# ============================================================================
# Backend Detection
# ============================================================================

fn detect_backends() -> [GpuBackend]:
    """Detect available GPU backends.

    Checks in priority order:
    1. CUDA (via PyTorch)
    2. Vulkan compute (future)
    3. CPU fallback (always available)

    Returns:
        Array of available backends
    """
    var backends: [GpuBackend] = []

    # Check CUDA via PyTorch
    if cuda_available():
        backends.push(GpuBackend.Cuda)

    # Vulkan support (future)
    # if vulkan_available():
    #     backends.push(GpuBackend.Vulkan)

    backends

fn preferred_backend() -> GpuBackend:
    """Get preferred backend (first available).

    Returns:
        Best available backend, or None_ for CPU fallback
    """
    val backends = detect_backends()
    if backends.len() > 0:
        backends[0]
    else:
        GpuBackend.None

# ============================================================================
# Re-exports
# ============================================================================

export GpuBackend, Gpu
export detect_backends, preferred_backend
export gpu_cuda, gpu_vulkan, gpu_none
