# Pure Simple Lexer
# Tokenize Simple source code in pure Simple

export Token, TokenKind, lex_source
export is_keyword, is_operator

# Token types
enum TokenKind:
    Identifier(text)
    Number(text)
    String(text)
    Keyword(text)
    Operator(text)
    Newline
    Indent
    Dedent
    Eof
    Error(text)

# Token with location
struct Token:
    kind: TokenKind
    line: i64
    column: i64

# Lex source code into tokens with indentation tracking
fn lex_source(source: text) -> [Token]:
    var tokens: [Token] = []
    var line = 1
    var column = 1
    var i = 0
    var indent_stack: [i64] = [0]  # Track indentation levels
    var at_line_start = true

    while i < source.len():
        val ch = source[i:i + 1]
        var handled = false

        # Handle indentation at line start
        if at_line_start and ch != "\n" and ch != "#":
            val (indent_level, spaces_consumed) = measure_indentation(source[i:])

            # Emit Indent/Dedent tokens
            val current_indent = indent_stack[indent_stack.len() - 1]
            if indent_level > current_indent:
                indent_stack.push(indent_level)
                tokens.push(Token(kind: TokenKind.Indent, line: line, column: column))
            elif indent_level < current_indent:
                # Emit dedents for all popped levels
                while indent_stack.len() > 0 and indent_stack[indent_stack.len() - 1] > indent_level:
                    indent_stack.pop()
                    tokens.push(Token(kind: TokenKind.Dedent, line: line, column: column))

            i = i + spaces_consumed
            column = column + spaces_consumed
            at_line_start = false
            handled = true

        # Skip whitespace (except newlines)
        if not handled and (ch == " " or ch == "\t"):
            i = i + 1
            column = column + 1
            handled = true

        # Newlines
        if not handled and ch == "\n":
            tokens.push(Token(kind: TokenKind.Newline, line: line, column: column))
            line = line + 1
            column = 1
            i = i + 1
            at_line_start = true
            handled = true

        # Comments
        if not handled and ch == "#":
            # Skip until end of line
            while i < source.len() and source[i:i + 1] != "\n":
                i = i + 1
            handled = true

        # Numbers
        if not handled and is_digit(ch):
            val (num, len) = lex_number(source[i:])
            tokens.push(Token(kind: TokenKind.Number(num), line: line, column: column))
            i = i + len
            column = column + len
            handled = true

        # Strings
        if not handled and ch == "\"":
            val (str, len) = lex_string(source[i:])
            tokens.push(Token(kind: TokenKind.String(str), line: line, column: column))
            i = i + len
            column = column + len
            handled = true

        # Identifiers and keywords
        if not handled and (is_alpha(ch) or ch == "_"):
            val (id, len) = lex_identifier(source[i:])
            val kind = if is_keyword(id): TokenKind.Keyword(id) else: TokenKind.Identifier(id)
            tokens.push(Token(kind: kind, line: line, column: column))
            i = i + len
            column = column + len
            handled = true

        # Operators and punctuation
        if not handled:
            val (op, len) = lex_operator(source[i:])
            if len > 0:
                tokens.push(Token(kind: TokenKind.Operator(op), line: line, column: column))
                i = i + len
                column = column + len
                handled = true

        # Unknown character
        if not handled:
            tokens.push(Token(kind: TokenKind.Error("Unknown: {ch}"), line: line, column: column))
            i = i + 1

    # Emit remaining dedents at EOF
    while indent_stack.len() > 1:
        indent_stack.pop()
        tokens.push(Token(kind: TokenKind.Dedent, line: line, column: column))

    tokens.push(Token(kind: TokenKind.Eof, line: line, column: column))
    tokens

# Measure indentation at start of line
fn measure_indentation(source: text) -> (i64, i64):
    var spaces = 0
    var i = 0
    while i < source.len():
        val ch = source[i:i + 1]
        if ch == " ":
            spaces = spaces + 1
            i = i + 1
        elif ch == "\t":
            spaces = spaces + 4  # Tab = 4 spaces
            i = i + 1
        else:
            break
    (spaces, i)

# Lex number
fn lex_number(source: text) -> (text, i64):
    var num = ""
    var i = 0
    var has_dot = false

    while i < source.len():
        val ch = source[i:i + 1]
        if is_digit(ch):
            num = num + ch
            i = i + 1
        elif ch == "." and not has_dot:
            num = num + ch
            has_dot = true
            i = i + 1
        else:
            break

    (num, i)

# Lex string
fn lex_string(source: text) -> (text, i64):
    var str = "\""
    var i = 1  # Skip opening quote

    while i < source.len():
        val ch = source[i:i + 1]
        str = str + ch
        if ch == "\"":
            i = i + 1
            break
        i = i + 1

    (str, i)

# Lex identifier
fn lex_identifier(source: text) -> (text, i64):
    var id = ""
    var i = 0

    while i < source.len():
        val ch = source[i:i + 1]
        if is_alpha(ch) or is_digit(ch) or ch == "_":
            id = id + ch
            i = i + 1
        else:
            break

    (id, i)

# Lex operator
fn lex_operator(source: text) -> (text, i64):
    # Three-character operators
    if source.len() >= 3:
        val three_char = source[0:3]
        if three_char == ">>>" or three_char == "<<=" or three_char == ">>=" or three_char == "**=":
            return (three_char, 3)

    # Two-character operators
    if source.len() >= 2:
        val two_char = source[0:2]
        if two_char == "->" or two_char == "=>" or two_char == "==" or two_char == "!=" or two_char == "<=" or two_char == ">=" or two_char == "&&" or two_char == "||" or two_char == "|>" or two_char == "<<" or two_char == ">>" or two_char == "~>" or two_char == "//" or two_char == "**" or two_char == "?." or two_char == "??" or two_char == ".+" or two_char == ".-" or two_char == ".*" or two_char == "./" or two_char == ".^" or two_char == "+=" or two_char == "-=" or two_char == "*=" or two_char == "/=" or two_char == "%=" or two_char == "&=" or two_char == "|=" or two_char == "^=":
            return (two_char, 2)

    # Single-character operators
    val ch = source[0:1]
    if ch == "+" or ch == "-" or ch == "*" or ch == "/" or ch == "%" or ch == "=" or ch == "<" or ch == ">" or ch == "!" or ch == "?" or ch == "&" or ch == "|" or ch == "^" or ch == "~" or ch == "(" or ch == ")" or ch == "{" or ch == "}" or ch == "[" or ch == "]" or ch == ":" or ch == "," or ch == "." or ch == "@" or ch == "\\":
        return (ch, 1)

    ("", 0)

# Check if character is digit
fn is_digit(ch: text) -> bool:
    ch >= "0" and ch <= "9"

# Check if character is alphabetic
fn is_alpha(ch: text) -> bool:
    (ch >= "a" and ch <= "z") or (ch >= "A" and ch <= "Z")

# Check if identifier is keyword
fn is_keyword(id: text) -> bool:
    id == "fn" or id == "val" or id == "var" or id == "if" or id == "else" or id == "while" or id == "for" or id == "in" or id == "return" or id == "break" or id == "class" or id == "struct" or id == "enum" or id == "trait" or id == "impl" or id == "use" or id == "export" or id == "import" or id == "match" or id == "case" or id == "true" or id == "false" or id == "None" or id == "Some" or id == "Ok" or id == "Err"

# Check if string is operator
fn is_operator(op: text) -> bool:
    op == "+" or op == "-" or op == "*" or op == "/" or op == "%" or op == "**" or op == "==" or op == "!=" or op == "<" or op == ">" or op == "<=" or op == ">=" or op == "&&" or op == "||" or op == "!" or op == "=" or op == "+=" or op == "-=" or op == "*=" or op == "/=" or op == "%=" or op == "|>" or op == ">>" or op == "<<" or op == "~>" or op == "//" or op == "?." or op == "??" or op == "?" or op == ".+" or op == ".-" or op == ".*" or op == "./" or op == ".^" or op == "&" or op == "|" or op == "^" or op == "~" or op == "<<=" or op == ">>=" or op == "->" or op == "=>" or op == "@" or op == "\\"
