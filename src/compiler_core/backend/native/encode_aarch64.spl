# AArch64 Instruction Encoder
#
# Encodes MachInst to raw bytes for AArch64 architecture.
# AArch64 is fixed-length: ALL instructions are exactly 4 bytes (32-bit), little-endian.
#
# Encoding formats:
#   R-type:  opcode | Rm | option/shift | Rn | Rd
#   I-type:  opcode | imm12 | Rn | Rd
#   D-type:  opcode | imm19 | Rd (PC-relative)
#   B-type:  opcode | imm26 (branches)
#   CB-type: opcode | imm19 | Rt (CBZ/CBNZ)

use compiler.backend.native.mach_inst.{MachReg, MachRegKind, physical_reg, reg_id, Operand, OperandKind, MachInst, MachBlock, MachFunction, MachModule, EncodedReloc, EncodedFunction, new_encoded_function}
use compiler.backend.native.mach_inst.{AARCH64_X0, AARCH64_X1, AARCH64_X2, AARCH64_X3, AARCH64_X4, AARCH64_X5, AARCH64_X6, AARCH64_X7, AARCH64_X8, AARCH64_X9, AARCH64_X10, AARCH64_X11, AARCH64_X12, AARCH64_X13, AARCH64_X14, AARCH64_X15, AARCH64_X16, AARCH64_X17, AARCH64_X18, AARCH64_X19, AARCH64_X20, AARCH64_X21, AARCH64_X22, AARCH64_X23, AARCH64_X24, AARCH64_X25, AARCH64_X26, AARCH64_X27, AARCH64_X28, AARCH64_X29, AARCH64_X30, AARCH64_SP}
use compiler.backend.native.mach_inst.{A64_OP_MOV, A64_OP_MOVZ, A64_OP_MOVK, A64_OP_ADD, A64_OP_SUB, A64_OP_MUL, A64_OP_SDIV, A64_OP_AND, A64_OP_ORR, A64_OP_EOR, A64_OP_LSL, A64_OP_ASR, A64_OP_LSR, A64_OP_NEG, A64_OP_CMP, A64_OP_CSET, A64_OP_B, A64_OP_BEQ, A64_OP_BNE, A64_OP_BLT, A64_OP_BGE, A64_OP_BGT, A64_OP_BLE, A64_OP_BL, A64_OP_RET, A64_OP_LDR, A64_OP_STR, A64_OP_STP, A64_OP_LDP, A64_OP_ADRP, A64_OP_ADD_IMM, A64_OP_SUB_IMM, A64_OP_NOP, A64_OP_CBZ, A64_OP_CBNZ}

# ============================================================================
# Encoding Helpers
# ============================================================================

# Emit a 32-bit instruction as 4 little-endian bytes
fn emit_u32_le(buf: [i64], value: i64) -> [i64]:
    var masked = value
    if masked < 0:
        masked = masked + 4294967296
    val b0 = masked % 256
    val b1 = (masked / 256) % 256
    val b2 = (masked / 65536) % 256
    val b3 = (masked / 16777216) % 256
    var result = buf
    result = result + [b0, b1, b2, b3]
    result

# ============================================================================
# Operand Extraction
# ============================================================================

fn a64_get_phys_reg_id(op: Operand) -> i64:
    match op.kind:
        case Reg(reg):
            match reg.kind:
                case Physical(id): id
                case Virtual(id): id
        case _: 0

fn a64_get_mem_base_id(op: Operand) -> i64:
    match op.kind:
        case Mem(base, _):
            match base.kind:
                case Physical(id): id
                case Virtual(id): id
        case _: 0

fn a64_get_mem_offset(op: Operand) -> i64:
    match op.kind:
        case Mem(_, offset): offset
        case _: 0

fn a64_get_imm_value(op: Operand) -> i64:
    match op.kind:
        case Imm(v): v
        case _: 0

fn a64_get_label_id(op: Operand) -> i64:
    match op.kind:
        case Label(id): id
        case _: 0

fn a64_get_sym_name(op: Operand) -> text:
    match op.kind:
        case Sym(name): name
        case _: ""

# ============================================================================
# Condition Code Helpers
# ============================================================================

# AArch64 condition codes
val COND_EQ = 0
val COND_NE = 1
val COND_GE = 10
val COND_LT = 11
val COND_GT = 12
val COND_LE = 13

# Inverted condition for CSET (CSINC Xd, XZR, XZR, cond_inv)
fn invert_cond(cond: i64) -> i64:
    if cond == COND_EQ: COND_NE
    elif cond == COND_NE: COND_EQ
    elif cond == COND_LT: COND_GE
    elif cond == COND_GE: COND_LT
    elif cond == COND_GT: COND_LE
    elif cond == COND_LE: COND_GT
    else: cond xor 1

# Map branch opcode to condition code for B.cond
fn branch_opcode_to_cond(opcode: i64) -> i64:
    if opcode == A64_OP_BEQ: COND_EQ
    elif opcode == A64_OP_BNE: COND_NE
    elif opcode == A64_OP_BLT: COND_LT
    elif opcode == A64_OP_BGE: COND_GE
    elif opcode == A64_OP_BGT: COND_GT
    elif opcode == A64_OP_BLE: COND_LE
    else: COND_EQ

# ============================================================================
# Encode Context
# ============================================================================

struct A64EncodeContext:
    code: [i64]
    relocations: [EncodedReloc]
    block_offsets: Dict<i64, i64>
    pending_jumps: [A64PendingJump]

struct A64PendingJump:
    code_offset: i64
    target_block: i64
    jump_kind: i64

# Jump kinds
val JUMP_B = 0           # Unconditional B (imm26)
val JUMP_BCOND = 1       # Conditional B.cond (imm19)
val JUMP_CBZ = 2         # CBZ (imm19)
val JUMP_CBNZ = 3        # CBNZ (imm19)

fn a64_new_encode_context() -> A64EncodeContext:
    A64EncodeContext(code: [], relocations: [], block_offsets: {}, pending_jumps: [])

# ============================================================================
# Instruction Encoding
# ============================================================================

fn encode_inst_aarch64(ectx: A64EncodeContext, inst: MachInst) -> A64EncodeContext:
    var code = ectx.code
    var relocs = ectx.relocations
    var pending = ectx.pending_jumps

    if inst.opcode == A64_OP_NOP:
        # NOP: 0xD503201F
        code = emit_u32_le(code, 0xD503201F)

    elif inst.opcode == A64_OP_RET:
        # RET x30: 0xD65F03C0
        code = emit_u32_le(code, 0xD65F03C0)

    elif inst.opcode == A64_OP_MOV:
        # MOV Xd, Xn -> ORR Xd, XZR, Xn
        # 0xAA0003E0 | (Xn << 16) | Xd
        val rd = a64_get_phys_reg_id(inst.operands[0])
        val rn = a64_get_phys_reg_id(inst.operands[1])
        val encoding = 0xAA0003E0 or (rn << 16) or rd
        code = emit_u32_le(code, encoding)

    elif inst.opcode == A64_OP_MOVZ:
        # MOVZ Xd, #imm16 (shift=0)
        # 0xD2800000 | (imm16 << 5) | Rd
        val rd = a64_get_phys_reg_id(inst.operands[0])
        val imm = a64_get_imm_value(inst.operands[1])
        val imm16 = imm and 0xFFFF
        val encoding = 0xD2800000 or (imm16 << 5) or rd
        code = emit_u32_le(code, encoding)

    elif inst.opcode == A64_OP_MOVK:
        # MOVK Xd, #imm16, LSL#shift
        # operands: [Rd, Imm(imm16), Imm(shift)]
        val rd = a64_get_phys_reg_id(inst.operands[0])
        val imm = a64_get_imm_value(inst.operands[1])
        val shift = a64_get_imm_value(inst.operands[2])
        val imm16 = imm and 0xFFFF
        # Base opcode depends on shift: 0=0xF2800000, 16=0xF2A00000, 32=0xF2C00000, 48=0xF2E00000
        var base = 0xF2800000
        if shift == 16:
            base = 0xF2A00000
        elif shift == 32:
            base = 0xF2C00000
        elif shift == 48:
            base = 0xF2E00000
        val encoding = base or (imm16 << 5) or rd
        code = emit_u32_le(code, encoding)

    elif inst.opcode == A64_OP_ADD:
        # ADD Xd, Xn, Xm: 0x8B000000 | (Rm << 16) | (Rn << 5) | Rd
        val rd = a64_get_phys_reg_id(inst.operands[0])
        val rn = a64_get_phys_reg_id(inst.operands[1])
        val rm = a64_get_phys_reg_id(inst.operands[2])
        val encoding = 0x8B000000 or (rm << 16) or (rn << 5) or rd
        code = emit_u32_le(code, encoding)

    elif inst.opcode == A64_OP_SUB:
        # SUB Xd, Xn, Xm: 0xCB000000 | (Rm << 16) | (Rn << 5) | Rd
        val rd = a64_get_phys_reg_id(inst.operands[0])
        val rn = a64_get_phys_reg_id(inst.operands[1])
        val rm = a64_get_phys_reg_id(inst.operands[2])
        val encoding = 0xCB000000 or (rm << 16) or (rn << 5) or rd
        code = emit_u32_le(code, encoding)

    elif inst.opcode == A64_OP_MUL:
        # MUL Xd, Xn, Xm: 0x9B007C00 | (Rm << 16) | (Rn << 5) | Rd
        val rd = a64_get_phys_reg_id(inst.operands[0])
        val rn = a64_get_phys_reg_id(inst.operands[1])
        val rm = a64_get_phys_reg_id(inst.operands[2])
        val encoding = 0x9B007C00 or (rm << 16) or (rn << 5) or rd
        code = emit_u32_le(code, encoding)

    elif inst.opcode == A64_OP_SDIV:
        # SDIV Xd, Xn, Xm: 0x9AC00C00 | (Rm << 16) | (Rn << 5) | Rd
        val rd = a64_get_phys_reg_id(inst.operands[0])
        val rn = a64_get_phys_reg_id(inst.operands[1])
        val rm = a64_get_phys_reg_id(inst.operands[2])
        val encoding = 0x9AC00C00 or (rm << 16) or (rn << 5) or rd
        code = emit_u32_le(code, encoding)

    elif inst.opcode == A64_OP_AND:
        # AND Xd, Xn, Xm: 0x8A000000 | (Rm << 16) | (Rn << 5) | Rd
        val rd = a64_get_phys_reg_id(inst.operands[0])
        val rn = a64_get_phys_reg_id(inst.operands[1])
        val rm = a64_get_phys_reg_id(inst.operands[2])
        val encoding = 0x8A000000 or (rm << 16) or (rn << 5) or rd
        code = emit_u32_le(code, encoding)

    elif inst.opcode == A64_OP_ORR:
        # ORR Xd, Xn, Xm: 0xAA000000 | (Rm << 16) | (Rn << 5) | Rd
        val rd = a64_get_phys_reg_id(inst.operands[0])
        val rn = a64_get_phys_reg_id(inst.operands[1])
        val rm = a64_get_phys_reg_id(inst.operands[2])
        val encoding = 0xAA000000 or (rm << 16) or (rn << 5) or rd
        code = emit_u32_le(code, encoding)

    elif inst.opcode == A64_OP_EOR:
        # EOR Xd, Xn, Xm: 0xCA000000 | (Rm << 16) | (Rn << 5) | Rd
        val rd = a64_get_phys_reg_id(inst.operands[0])
        val rn = a64_get_phys_reg_id(inst.operands[1])
        val rm = a64_get_phys_reg_id(inst.operands[2])
        val encoding = 0xCA000000 or (rm << 16) or (rn << 5) or rd
        code = emit_u32_le(code, encoding)

    elif inst.opcode == A64_OP_LSL:
        # LSL Xd, Xn, Xm: 0x9AC02000 | (Rm << 16) | (Rn << 5) | Rd
        val rd = a64_get_phys_reg_id(inst.operands[0])
        val rn = a64_get_phys_reg_id(inst.operands[1])
        val rm = a64_get_phys_reg_id(inst.operands[2])
        val encoding = 0x9AC02000 or (rm << 16) or (rn << 5) or rd
        code = emit_u32_le(code, encoding)

    elif inst.opcode == A64_OP_ASR:
        # ASR Xd, Xn, Xm: 0x9AC02800 | (Rm << 16) | (Rn << 5) | Rd
        val rd = a64_get_phys_reg_id(inst.operands[0])
        val rn = a64_get_phys_reg_id(inst.operands[1])
        val rm = a64_get_phys_reg_id(inst.operands[2])
        val encoding = 0x9AC02800 or (rm << 16) or (rn << 5) or rd
        code = emit_u32_le(code, encoding)

    elif inst.opcode == A64_OP_LSR:
        # LSR Xd, Xn, Xm: 0x9AC02400 | (Rm << 16) | (Rn << 5) | Rd
        val rd = a64_get_phys_reg_id(inst.operands[0])
        val rn = a64_get_phys_reg_id(inst.operands[1])
        val rm = a64_get_phys_reg_id(inst.operands[2])
        val encoding = 0x9AC02400 or (rm << 16) or (rn << 5) or rd
        code = emit_u32_le(code, encoding)

    elif inst.opcode == A64_OP_NEG:
        # NEG Xd, Xm -> SUB Xd, XZR, Xm
        # 0xCB0003E0 | (Rm << 16) | Rd
        val rd = a64_get_phys_reg_id(inst.operands[0])
        val rm = a64_get_phys_reg_id(inst.operands[1])
        val encoding = 0xCB0003E0 or (rm << 16) or rd
        code = emit_u32_le(code, encoding)

    elif inst.opcode == A64_OP_CMP:
        # CMP Xn, Xm -> SUBS XZR, Xn, Xm
        # 0xEB00001F | (Rm << 16) | (Rn << 5)
        val rn = a64_get_phys_reg_id(inst.operands[0])
        val rm = a64_get_phys_reg_id(inst.operands[1])
        val encoding = 0xEB00001F or (rm << 16) or (rn << 5)
        code = emit_u32_le(code, encoding)

    elif inst.opcode == A64_OP_CSET:
        # CSET Xd, cond -> CSINC Xd, XZR, XZR, cond_inv
        # 0x9A9F07E0 | (cond_inv << 12) | Rd
        val rd = a64_get_phys_reg_id(inst.operands[0])
        val cond = a64_get_imm_value(inst.operands[1])
        val cond_inv = invert_cond(cond)
        val encoding = 0x9A9F07E0 or (cond_inv << 12) or rd
        code = emit_u32_le(code, encoding)

    elif inst.opcode == A64_OP_ADD_IMM:
        # ADD Xd, Xn, #imm12: 0x91000000 | (imm12 << 10) | (Rn << 5) | Rd
        val rd = a64_get_phys_reg_id(inst.operands[0])
        val rn = a64_get_phys_reg_id(inst.operands[1])
        val imm12 = a64_get_imm_value(inst.operands[2]) and 0xFFF
        val encoding = 0x91000000 or (imm12 << 10) or (rn << 5) or rd
        code = emit_u32_le(code, encoding)

    elif inst.opcode == A64_OP_SUB_IMM:
        # SUB Xd, Xn, #imm12: 0xD1000000 | (imm12 << 10) | (Rn << 5) | Rd
        val rd = a64_get_phys_reg_id(inst.operands[0])
        val rn = a64_get_phys_reg_id(inst.operands[1])
        val imm12 = a64_get_imm_value(inst.operands[2]) and 0xFFF
        val encoding = 0xD1000000 or (imm12 << 10) or (rn << 5) or rd
        code = emit_u32_le(code, encoding)

    elif inst.opcode == A64_OP_LDR:
        # LDR Xd, [Xn, #off]: 0xF9400000 | ((off/8) << 10) | (Rn << 5) | Rd
        val rd = a64_get_phys_reg_id(inst.operands[0])
        val base = a64_get_mem_base_id(inst.operands[1])
        val offset = a64_get_mem_offset(inst.operands[1])
        val scaled_off = (offset / 8) and 0xFFF
        val encoding = 0xF9400000 or (scaled_off << 10) or (base << 5) or rd
        code = emit_u32_le(code, encoding)

    elif inst.opcode == A64_OP_STR:
        # STR Xd, [Xn, #off]: 0xF9000000 | ((off/8) << 10) | (Rn << 5) | Rd
        val rd = a64_get_phys_reg_id(inst.operands[0])
        val base = a64_get_mem_base_id(inst.operands[1])
        val offset = a64_get_mem_offset(inst.operands[1])
        val scaled_off = (offset / 8) and 0xFFF
        val encoding = 0xF9000000 or (scaled_off << 10) or (base << 5) or rd
        code = emit_u32_le(code, encoding)

    elif inst.opcode == A64_OP_STP:
        # STP Rt1, Rt2, [Xn, #off]
        # 0xA9000000 | ((off/8 & 0x7F) << 15) | (Rt2 << 10) | (Rn << 5) | Rt1
        val rt1 = a64_get_phys_reg_id(inst.operands[0])
        val rt2 = a64_get_phys_reg_id(inst.operands[1])
        val base = a64_get_mem_base_id(inst.operands[2])
        val offset = a64_get_mem_offset(inst.operands[2])
        val simm7 = (offset / 8) and 0x7F
        val encoding = 0xA9000000 or (simm7 << 15) or (rt2 << 10) or (base << 5) or rt1
        code = emit_u32_le(code, encoding)

    elif inst.opcode == A64_OP_LDP:
        # LDP Rt1, Rt2, [Xn, #off]
        # 0xA9400000 | ((off/8 & 0x7F) << 15) | (Rt2 << 10) | (Rn << 5) | Rt1
        val rt1 = a64_get_phys_reg_id(inst.operands[0])
        val rt2 = a64_get_phys_reg_id(inst.operands[1])
        val base = a64_get_mem_base_id(inst.operands[2])
        val offset = a64_get_mem_offset(inst.operands[2])
        val simm7 = (offset / 8) and 0x7F
        val encoding = 0xA9400000 or (simm7 << 15) or (rt2 << 10) or (base << 5) or rt1
        code = emit_u32_le(code, encoding)

    elif inst.opcode == A64_OP_B:
        # B offset: 0x14000000 | (imm26)
        match inst.operands[0].kind:
            case Label(block_id):
                # Emit placeholder, patch later
                val jump_offset = code_len(code)
                code = emit_u32_le(code, 0x14000000)
                pending = pending + [A64PendingJump(code_offset: jump_offset, target_block: block_id, jump_kind: JUMP_B)]
            case _:
                code = emit_u32_le(code, 0x14000000)

    elif inst.opcode == A64_OP_BL:
        # BL offset: 0x94000000 | (imm26)
        match inst.operands[0].kind:
            case Sym(name):
                # Record relocation for linker
                val reloc_offset = code_len(code)
                code = emit_u32_le(code, 0x94000000)
                val reloc = EncodedReloc(
                    offset: reloc_offset,
                    symbol_name: name,
                    reloc_type: 283,
                    addend: 0
                )
                relocs = relocs + [reloc]
            case Label(block_id):
                val jump_offset = code_len(code)
                code = emit_u32_le(code, 0x94000000)
                pending = pending + [A64PendingJump(code_offset: jump_offset, target_block: block_id, jump_kind: JUMP_B)]
            case _:
                code = emit_u32_le(code, 0x94000000)

    elif inst.opcode == A64_OP_BEQ or inst.opcode == A64_OP_BNE or inst.opcode == A64_OP_BLT or inst.opcode == A64_OP_BGE or inst.opcode == A64_OP_BGT or inst.opcode == A64_OP_BLE:
        # B.cond offset: 0x54000000 | ((imm19) << 5) | cond
        val cond = branch_opcode_to_cond(inst.opcode)
        match inst.operands[0].kind:
            case Label(block_id):
                val jump_offset = code_len(code)
                # Emit placeholder with condition code embedded
                val placeholder = 0x54000000 or cond
                code = emit_u32_le(code, placeholder)
                pending = pending + [A64PendingJump(code_offset: jump_offset, target_block: block_id, jump_kind: JUMP_BCOND)]
            case _:
                val placeholder = 0x54000000 or cond
                code = emit_u32_le(code, placeholder)

    elif inst.opcode == A64_OP_CBZ:
        # CBZ Xd, offset: 0xB4000000 | ((imm19) << 5) | Rd
        val rd = a64_get_phys_reg_id(inst.operands[0])
        match inst.operands[1].kind:
            case Label(block_id):
                val jump_offset = code_len(code)
                val placeholder = 0xB4000000 or rd
                code = emit_u32_le(code, placeholder)
                pending = pending + [A64PendingJump(code_offset: jump_offset, target_block: block_id, jump_kind: JUMP_CBZ)]
            case _:
                val placeholder = 0xB4000000 or rd
                code = emit_u32_le(code, placeholder)

    elif inst.opcode == A64_OP_CBNZ:
        # CBNZ Xd, offset: 0xB5000000 | ((imm19) << 5) | Rd
        val rd = a64_get_phys_reg_id(inst.operands[0])
        match inst.operands[1].kind:
            case Label(block_id):
                val jump_offset = code_len(code)
                val placeholder = 0xB5000000 or rd
                code = emit_u32_le(code, placeholder)
                pending = pending + [A64PendingJump(code_offset: jump_offset, target_block: block_id, jump_kind: JUMP_CBNZ)]
            case _:
                val placeholder = 0xB5000000 or rd
                code = emit_u32_le(code, placeholder)

    elif inst.opcode == A64_OP_ADRP:
        # ADRP Xd, symbol - needs relocation
        # 0x90000000 | Rd, linker fills the rest
        val rd = a64_get_phys_reg_id(inst.operands[0])
        match inst.operands[1].kind:
            case Sym(name):
                val reloc_offset = code_len(code)
                val placeholder = 0x90000000 or rd
                code = emit_u32_le(code, placeholder)
                val reloc = EncodedReloc(
                    offset: reloc_offset,
                    symbol_name: name,
                    reloc_type: 275,
                    addend: 0
                )
                relocs = relocs + [reloc]
            case _:
                val placeholder = 0x90000000 or rd
                code = emit_u32_le(code, placeholder)

    else:
        # Unknown opcode - emit BRK #0 (debug trap)
        code = emit_u32_le(code, 0xD4200000)

    A64EncodeContext(code: code, relocations: relocs, block_offsets: ectx.block_offsets, pending_jumps: pending)

# ============================================================================
# Jump Patching
# ============================================================================

# Patch a 32-bit instruction in the code array at a given byte offset.
# Reads the existing instruction, merges in the branch offset, writes it back.
fn patch_branch(code: [i64], byte_offset: i64, rel_offset: i64, kind: i64) -> [i64]:
    var patched = code
    # Read existing instruction from 4 LE bytes
    val b0 = patched[byte_offset]
    val b1 = patched[byte_offset + 1]
    val b2 = patched[byte_offset + 2]
    val b3 = patched[byte_offset + 3]
    val old_inst = b0 or (b1 << 8) or (b2 << 16) or (b3 << 24)

    # Compute imm field from relative byte offset (divide by 4 for instruction words)
    val imm_words = rel_offset / 4

    var new_inst = old_inst
    if kind == JUMP_B:
        # B: bits [25:0] = imm26
        val imm26 = imm_words and 0x3FFFFFF
        # Clear low 26 bits, set new ones
        val high_bits = old_inst and 0xFC000000
        new_inst = high_bits or imm26
    elif kind == JUMP_BCOND:
        # B.cond: bits [23:5] = imm19, bits [4:0] = cond (preserved)
        val imm19 = imm_words and 0x7FFFF
        val cond_bits = old_inst and 0x1F
        new_inst = 0x54000000 or (imm19 << 5) or cond_bits
    elif kind == JUMP_CBZ:
        # CBZ: bits [23:5] = imm19, bits [4:0] = Rt (preserved)
        val imm19 = imm_words and 0x7FFFF
        val rt_bits = old_inst and 0x1F
        new_inst = 0xB4000000 or (imm19 << 5) or rt_bits
    elif kind == JUMP_CBNZ:
        # CBNZ: bits [23:5] = imm19, bits [4:0] = Rt (preserved)
        val imm19 = imm_words and 0x7FFFF
        val rt_bits = old_inst and 0x1F
        new_inst = 0xB5000000 or (imm19 << 5) or rt_bits

    # Handle negative values for new_inst before extracting bytes
    var unsigned_inst = new_inst
    if unsigned_inst < 0:
        unsigned_inst = unsigned_inst + 4294967296

    # Write back as 4 LE bytes
    patched[byte_offset] = unsigned_inst % 256
    patched[byte_offset + 1] = (unsigned_inst / 256) % 256
    patched[byte_offset + 2] = (unsigned_inst / 65536) % 256
    patched[byte_offset + 3] = (unsigned_inst / 16777216) % 256
    patched

# ============================================================================
# Function Encoding (two-pass)
# ============================================================================

fn encode_function_aarch64(func: MachFunction) -> EncodedFunction:
    var ectx = a64_new_encode_context()

    # Pass 1: encode all instructions, record block offsets and pending jumps
    for block in func.blocks:
        var offsets = ectx.block_offsets
        offsets[block.block_id] = ectx.code_len(code)
        ectx = A64EncodeContext(code: ectx.code, relocations: ectx.relocations, block_offsets: offsets, pending_jumps: ectx.pending_jumps)

        for inst in block.insts:
            ectx = encode_inst_aarch64(ectx, inst)

    # Pass 2: patch branch targets
    var final_code = ectx.code
    for i in 0..ectx.pending_jumps_len(pending_jumps):
        val pj = ectx.pending_jumps[i]
        val target_block = pj.target_block
        if ectx.block_offsets_contains(block_offsets, target_block):
            val target_offset = ectx.block_offsets[target_block]
            val rel_offset = target_offset - pj.code_offset
            final_code = patch_branch(final_code, pj.code_offset, rel_offset, pj.jump_kind)

    EncodedFunction(name: func.name, code: final_code, relocations: ectx.relocations)

# ============================================================================
# Module Encoding
# ============================================================================

fn encode_module_aarch64(module: MachModule) -> [EncodedFunction]:
    var results: [EncodedFunction] = []
    for func in module.functions:
        val encoded = encode_function_aarch64(func)
        results = results + [encoded]
    results

# ============================================================================
# Exports
# ============================================================================

export A64EncodeContext, a64_new_encode_context, A64PendingJump
export JUMP_B, JUMP_BCOND, JUMP_CBZ, JUMP_CBNZ
export COND_EQ, COND_NE, COND_GE, COND_LT, COND_GT, COND_LE
export encode_function_aarch64, encode_inst_aarch64, encode_module_aarch64
