# RISC-V 64-bit Instruction Selection
#
# Translates MIR instructions to RISC-V 64-bit (RV64I+M) MachInst sequences.
# Pattern-matches on MirInstKind to produce low-level machine instructions.
# Follows the RISC-V LP64 calling convention for function calls.
#
# RISC-V 64-bit conventions:
# - x0 = zero (hardwired zero), x1 = ra (return address), x2 = sp
# - x3 = gp, x4 = tp, x5-x7 = t0-t2 (temporaries)
# - x8 = s0/fp (frame pointer), x9 = s1
# - x10-x17 = a0-a7 (arguments, a0-a1 = return values)
# - x18-x27 = s2-s11 (callee-saved)
# - x28-x31 = t3-t6 (temporaries)
# - All instructions are 32-bit fixed width (RV64I base + M extension)
#
# Pipeline: MIR -> ISel (this module) -> RegAlloc -> Encode -> ELF

use compiler.mir_data.{MirModule, MirFunction, MirBlock, MirInst, MirInstKind, MirBinOp, MirUnaryOp, MirOperand, MirOperandKind, MirConstValue, MirTerminator, MirType, MirTypeKind, LocalId, LocalKind, BlockId, SwitchCase}
use compiler.backend.native.mach_inst.{MachReg, virtual_reg, physical_reg, reg_id, Operand, OperandKind, op_reg, op_phys, op_virt, op_imm, op_mem, op_label, op_sym, operand_get_reg, MachInst, new_mach_inst, MachBlock, new_mach_block, mach_block_add_inst, MachFunction, new_mach_function, mach_func_add_block, mach_func_set_frame_size, MachModule, DataEntry, new_mach_module, mach_module_add_func, mach_module_add_data, mach_module_add_extern}
use compiler.backend.native.mach_inst.{RV_X0, RV_X1, RV_X2, RV_X3, RV_X4, RV_X5, RV_X6, RV_X7, RV_X8, RV_X9, RV_X10, RV_X11, RV_X12, RV_X13, RV_X14, RV_X15, RV_X16, RV_X17, RV_X18, RV_X19, RV_X20, RV_X21, RV_X22, RV_X23, RV_X24, RV_X25, RV_X26, RV_X27, RV_X28, RV_X29, RV_X30, RV_X31}
use compiler.backend.native.mach_inst.{RV_ARG_REGS, RV_CALLEE_SAVED}
use compiler.backend.native.mach_inst.{RV_OP_ADD, RV_OP_SUB, RV_OP_MUL, RV_OP_DIV, RV_OP_REM, RV_OP_AND, RV_OP_OR, RV_OP_XOR, RV_OP_SLL, RV_OP_SRA, RV_OP_SRL, RV_OP_SLT, RV_OP_SLTU, RV_OP_ADDI, RV_OP_LUI, RV_OP_AUIPC, RV_OP_JAL, RV_OP_JALR, RV_OP_BEQ, RV_OP_BNE, RV_OP_BLT, RV_OP_BGE, RV_OP_LD, RV_OP_SD, RV_OP_LW, RV_OP_SW, RV_OP_MV, RV_OP_LI, RV_OP_NOP, RV_OP_RET, RV_OP_CALL, RV_OP_NEG, RV_OP_NOT, RV_OP_SEQZ, RV_OP_SNEZ}

# ============================================================================
# ISel Context
# ============================================================================

struct ISelContext:
    next_vreg: i64
    frame_slots: Dict<i64, i64>
    next_frame_offset: i64
    extern_symbols: [text]
    data_entries: [DataEntry]
    string_counter: i64

fn new_isel_context() -> ISelContext:
    ISelContext(
        next_vreg: 0,
        frame_slots: {},
        next_frame_offset: 0,
        extern_symbols: [],
        data_entries: [],
        string_counter: 0
    )

fn isel_alloc_vreg(ctx: ISelContext) -> ISelContext:
    ISelContext(
        next_vreg: ctx.next_vreg + 1,
        frame_slots: ctx.frame_slots,
        next_frame_offset: ctx.next_frame_offset,
        extern_symbols: ctx.extern_symbols,
        data_entries: ctx.data_entries,
        string_counter: ctx.string_counter
    )

fn isel_get_vreg(ctx: ISelContext) -> i64:
    ctx.next_vreg - 1

fn isel_alloc_frame_slot(ctx: ISelContext, local_id: i64, size: i64) -> ISelContext:
    val aligned_size = if size < 8: 8 else: size
    val offset = ctx.next_frame_offset + aligned_size
    var slots = ctx.frame_slots
    slots[local_id] = offset
    ISelContext(
        next_vreg: ctx.next_vreg,
        frame_slots: slots,
        next_frame_offset: offset,
        extern_symbols: ctx.extern_symbols,
        data_entries: ctx.data_entries,
        string_counter: ctx.string_counter
    )

fn isel_frame_offset(ctx: ISelContext, local_id: i64) -> i64:
    if ctx.frame_slots_contains(frame_slots, local_id):
        return ctx.frame_slots[local_id]
    0

fn isel_add_extern(ctx: ISelContext, name: text) -> ISelContext:
    var new_ext = ctx.extern_symbols
    new_ext = new_ext + [name]
    ISelContext(
        next_vreg: ctx.next_vreg,
        frame_slots: ctx.frame_slots,
        next_frame_offset: ctx.next_frame_offset,
        extern_symbols: new_ext,
        data_entries: ctx.data_entries,
        string_counter: ctx.string_counter
    )

fn isel_add_string_data(ctx: ISelContext, s: text) -> ISelContext:
    val label = ".LC{ctx.string_counter}"
    var str_bytes: [i64] = []
    for i in 0..s_len(s):
        val ch = s[i]
        var ascii = rv_char_to_ascii(ch)
        str_bytes = str_bytes + [ascii]
    str_bytes = str_bytes + [0]
    val entry = DataEntry(name: label, data: str_bytes, is_readonly: true)
    var new_data = ctx.data_entries
    new_data = new_data + [entry]
    ISelContext(
        next_vreg: ctx.next_vreg,
        frame_slots: ctx.frame_slots,
        next_frame_offset: ctx.next_frame_offset,
        extern_symbols: ctx.extern_symbols,
        data_entries: new_data,
        string_counter: ctx.string_counter + 1
    )

fn isel_last_string_label(ctx: ISelContext) -> text:
    ".LC{ctx.string_counter - 1}"

# ============================================================================
# Character to ASCII (shared utility)
# ============================================================================

fn rv_char_to_ascii(ch: text) -> i64:
    if ch == "a": 97
    elif ch == "b": 98
    elif ch == "c": 99
    elif ch == "d": 100
    elif ch == "e": 101
    elif ch == "f": 102
    elif ch == "g": 103
    elif ch == "h": 104
    elif ch == "i": 105
    elif ch == "j": 106
    elif ch == "k": 107
    elif ch == "l": 108
    elif ch == "m": 109
    elif ch == "n": 110
    elif ch == "o": 111
    elif ch == "p": 112
    elif ch == "q": 113
    elif ch == "r": 114
    elif ch == "s": 115
    elif ch == "t": 116
    elif ch == "u": 117
    elif ch == "v": 118
    elif ch == "w": 119
    elif ch == "x": 120
    elif ch == "y": 121
    elif ch == "z": 122
    elif ch == "A": 65
    elif ch == "B": 66
    elif ch == "C": 67
    elif ch == "D": 68
    elif ch == "E": 69
    elif ch == "F": 70
    elif ch == "G": 71
    elif ch == "H": 72
    elif ch == "I": 73
    elif ch == "J": 74
    elif ch == "K": 75
    elif ch == "L": 76
    elif ch == "M": 77
    elif ch == "N": 78
    elif ch == "O": 79
    elif ch == "P": 80
    elif ch == "Q": 81
    elif ch == "R": 82
    elif ch == "S": 83
    elif ch == "T": 84
    elif ch == "U": 85
    elif ch == "V": 86
    elif ch == "W": 87
    elif ch == "X": 88
    elif ch == "Y": 89
    elif ch == "Z": 90
    elif ch == "0": 48
    elif ch == "1": 49
    elif ch == "2": 50
    elif ch == "3": 51
    elif ch == "4": 52
    elif ch == "5": 53
    elif ch == "6": 54
    elif ch == "7": 55
    elif ch == "8": 56
    elif ch == "9": 57
    elif ch == "_": 95
    elif ch == ".": 46
    elif ch == " ": 32
    elif ch == "\n": 10
    elif ch == "\t": 9
    elif ch == "-": 45
    elif ch == "+": 43
    elif ch == "*": 42
    elif ch == "/": 47
    elif ch == "=": 61
    elif ch == "(": 40
    elif ch == ")": 41
    elif ch == "[": 91
    elif ch == "]": 93
    elif ch == ":": 58
    elif ch == ";": 59
    elif ch == ",": 44
    elif ch == "!": 33
    elif ch == "?": 63
    elif ch == "@": 64
    elif ch == "#": 35
    elif ch == "%": 37
    elif ch == "&": 38
    elif ch == "|": 124
    elif ch == "\\": 92
    elif ch == "'": 39
    elif ch == "\"": 34
    else: 63

# ============================================================================
# Local to Virtual Register Mapping
# ============================================================================

fn rv_local_to_vreg(local_id: i64) -> MachReg:
    virtual_reg(local_id)

fn rv_local_vreg_op(local_id: i64) -> Operand:
    op_reg(virtual_reg(local_id))

# ============================================================================
# Operand Lowering
# ============================================================================

struct LoweredOperand:
    insts: [MachInst]
    result: Operand
    ctx: ISelContext

fn rv_lower_operand(ctx: ISelContext, operand: MirOperand) -> LoweredOperand:
    match operand.kind:
        case Copy(local):
            LoweredOperand(insts: [], result: rv_local_vreg_op(local.id), ctx: ctx)
        case Move(local):
            LoweredOperand(insts: [], result: rv_local_vreg_op(local.id), ctx: ctx)
        case Const(value, type_):
            rv_lower_const(ctx, value, type_)

fn rv_lower_const(ctx: ISelContext, value: MirConstValue, type_: MirType) -> LoweredOperand:
    match value:
        case Int(v):
            rv_lower_const_int(ctx, v)
        case Bool(v):
            val imm_val = if v: 1 else: 0
            var new_ctx = isel_alloc_vreg(ctx)
            val vreg = isel_get_vreg(new_ctx)
            val dest = op_reg(virtual_reg(vreg))
            # LI is a pseudo-instruction that loads an immediate
            val inst = new_mach_inst(RV_OP_LI, [dest, op_imm(imm_val)])
            LoweredOperand(insts: [inst], result: dest, ctx: new_ctx)
        case Str(s):
            var new_ctx = isel_add_string_data(ctx, s)
            val label = isel_last_string_label(new_ctx)
            new_ctx = isel_alloc_vreg(new_ctx)
            val vreg = isel_get_vreg(new_ctx)
            val dest = op_reg(virtual_reg(vreg))
            # AUIPC + ADDI for PC-relative address loading
            val auipc_inst = new_mach_inst(RV_OP_AUIPC, [dest, op_sym(label)])
            val addi_inst = new_mach_inst(RV_OP_ADDI, [dest, dest, op_sym(label)])
            LoweredOperand(insts: [auipc_inst, addi_inst], result: dest, ctx: new_ctx)
        case Zero:
            # MV rd, x0 (zero register)
            var new_ctx = isel_alloc_vreg(ctx)
            val vreg = isel_get_vreg(new_ctx)
            val dest = op_reg(virtual_reg(vreg))
            val inst = new_mach_inst(RV_OP_LI, [dest, op_imm(0)])
            LoweredOperand(insts: [inst], result: dest, ctx: new_ctx)
        case _:
            var new_ctx = isel_alloc_vreg(ctx)
            val vreg = isel_get_vreg(new_ctx)
            val dest = op_reg(virtual_reg(vreg))
            val inst = new_mach_inst(RV_OP_LI, [dest, op_imm(0)])
            LoweredOperand(insts: [inst], result: dest, ctx: new_ctx)

fn rv_lower_const_int(ctx: ISelContext, v: i64) -> LoweredOperand:
    # RISC-V LI is a pseudo-instruction that the assembler/encoder expands
    # to LUI + ADDI (or longer sequences) as needed. At ISel level we emit
    # a single LI pseudo and let the encoder handle materialization.
    var new_ctx = isel_alloc_vreg(ctx)
    val vreg = isel_get_vreg(new_ctx)
    val dest = op_reg(virtual_reg(vreg))
    val inst = new_mach_inst(RV_OP_LI, [dest, op_imm(v)])
    LoweredOperand(insts: [inst], result: dest, ctx: new_ctx)

# ============================================================================
# Instruction Selection - Core Entry Point
# ============================================================================

fn isel_module_riscv64(module: MirModule) -> MachModule:
    var mach_module = new_mach_module(module.name)
    var ctx = new_isel_context()

    val func_keys = module.functions_keys(functions)
    for key in func_keys:
        val func = module.functions[key]
        var result = rv_isel_function(ctx, func)
        ctx = result.ctx
        mach_module = mach_module_add_func(mach_module, result.func)

    # Add data entries from string constants
    for entry in ctx.data_entries:
        mach_module = mach_module_add_data(mach_module, entry)

    # Add extern symbols
    for sym in ctx.extern_symbols:
        mach_module = mach_module_add_extern(mach_module, sym)

    mach_module

struct ISelFuncResult:
    func: MachFunction
    ctx: ISelContext

fn rv_isel_function(ctx: ISelContext, func: MirFunction) -> ISelFuncResult:
    var mach_func = new_mach_function(func.name)

    # Reset vreg counter - use local IDs directly, start high for temps
    var local_ctx = ISelContext(
        next_vreg: func.locals_len(locals) + 100,
        frame_slots: ctx.frame_slots,
        next_frame_offset: 0,
        extern_symbols: ctx.extern_symbols,
        data_entries: ctx.data_entries,
        string_counter: ctx.string_counter
    )

    # Allocate frame slots for locals that need stack space
    for local in func.locals:
        val size = local.type__size_bytes(type_)
        local_ctx = isel_alloc_frame_slot(local_ctx, local.id.id, size)

    # Generate prologue block
    # RISC-V prologue:
    #   ADDI sp, sp, -framesize
    #   SD   ra, framesize-8(sp)
    #   SD   s0, framesize-16(sp)
    #   ADDI s0, sp, framesize
    var prologue_block = new_mach_block("prologue", -1)

    # ADDI sp, sp, -framesize (placeholder, will be patched after frame size is known)
    prologue_block = mach_block_add_inst(prologue_block, new_mach_inst(RV_OP_ADDI, [op_phys(RV_X2), op_phys(RV_X2), op_imm(0)]))
    # SD ra, offset(sp) - save return address
    prologue_block = mach_block_add_inst(prologue_block, new_mach_inst(RV_OP_SD, [op_phys(RV_X1), op_mem(physical_reg(RV_X2), 0)]))
    # SD s0, offset(sp) - save frame pointer
    prologue_block = mach_block_add_inst(prologue_block, new_mach_inst(RV_OP_SD, [op_phys(RV_X8), op_mem(physical_reg(RV_X2), 0)]))
    # ADDI s0, sp, framesize (set frame pointer, placeholder)
    prologue_block = mach_block_add_inst(prologue_block, new_mach_inst(RV_OP_ADDI, [op_phys(RV_X8), op_phys(RV_X2), op_imm(0)]))

    # Move arguments from ABI registers (a0-a7) to virtual registers
    for local in func.locals:
        match local.kind:
            case Arg(index):
                if index < rv_arg_regs_len():
                    val arg_reg = RV_ARG_REGS[index]
                    prologue_block = mach_block_add_inst(prologue_block, new_mach_inst(RV_OP_MV, [rv_local_vreg_op(local.id.id), op_phys(arg_reg)]))
            case _: ()

    mach_func = mach_func_add_block(mach_func, prologue_block)

    # Translate each MIR block
    for block in func.blocks:
        var result = rv_isel_block(local_ctx, block)
        local_ctx = result.ctx
        mach_func = mach_func_add_block(mach_func, result.block)

    # Set frame size (aligned to 16 as required by RISC-V ABI)
    var frame_size = local_ctx.next_frame_offset
    # Add space for ra and s0 (16 bytes minimum)
    frame_size = frame_size + 16
    if frame_size % 16 != 0:
        frame_size = frame_size + (16 - (frame_size % 16))
    mach_func = mach_func_set_frame_size(mach_func, frame_size)

    # Propagate context back
    val out_ctx = ISelContext(
        next_vreg: ctx.next_vreg,
        frame_slots: ctx.frame_slots,
        next_frame_offset: ctx.next_frame_offset,
        extern_symbols: local_ctx.extern_symbols,
        data_entries: local_ctx.data_entries,
        string_counter: local_ctx.string_counter
    )

    ISelFuncResult(func: mach_func, ctx: out_ctx)

struct ISelBlockResult:
    block: MachBlock
    ctx: ISelContext

fn rv_isel_block(ctx: ISelContext, block: MirBlock) -> ISelBlockResult:
    val label = if block.has_label: block.label_value else: "bb{block.id.id}"
    var mach_block = new_mach_block(label, block.id.id)
    var current_ctx = ctx

    # Lower instructions
    for inst in block.instructions:
        var result = rv_isel_inst(current_ctx, inst)
        current_ctx = result.ctx
        for mi in result.insts:
            mach_block = mach_block_add_inst(mach_block, mi)

    # Lower terminator
    var term_result = rv_isel_terminator(current_ctx, block.terminator)
    current_ctx = term_result.ctx
    for mi in term_result.insts:
        mach_block = mach_block_add_inst(mach_block, mi)

    ISelBlockResult(block: mach_block, ctx: current_ctx)

# ============================================================================
# Instruction Selection - Instructions
# ============================================================================

struct ISelInstResult:
    insts: [MachInst]
    ctx: ISelContext

fn rv_isel_inst(ctx: ISelContext, inst: MirInst) -> ISelInstResult:
    match inst.kind:
        case Const(dest, value, type_):
            rv_isel_const(ctx, dest, value, type_)
        case Copy(dest, src):
            rv_isel_copy(ctx, dest, src)
        case Move(dest, src):
            rv_isel_copy(ctx, dest, src)
        case BinOp(dest, op, left, right):
            rv_isel_binop(ctx, dest, op, left, right)
        case UnaryOp(dest, op, operand):
            rv_isel_unaryop(ctx, dest, op, operand)
        case Load(dest, ptr):
            rv_isel_load(ctx, dest, ptr)
        case Store(ptr, value):
            rv_isel_store(ctx, ptr, value)
        case Call(dest, func_op, args):
            rv_isel_call(ctx, dest, func_op, args)
        case GetField(dest, base, field):
            rv_isel_get_field(ctx, dest, base, field)
        case SetField(base, field, value):
            rv_isel_set_field(ctx, base, field, value)
        case Alloc(dest, type_):
            rv_isel_alloc(ctx, dest, type_)
        case Cast(dest, operand, target):
            rv_isel_cast(ctx, dest, operand, target)
        case Nop:
            ISelInstResult(insts: [new_mach_inst(RV_OP_NOP, [])], ctx: ctx)
        case _:
            # Unsupported instruction - emit NOP
            ISelInstResult(insts: [new_mach_inst(RV_OP_NOP, [])], ctx: ctx)

fn rv_isel_const(ctx: ISelContext, dest: LocalId, value: MirConstValue, type_: MirType) -> ISelInstResult:
    val lowered = rv_lower_const(ctx, value, type_)
    val dest_op = rv_local_vreg_op(dest.id)
    # Move the const result to the destination vreg
    var insts = lowered.insts
    insts = insts + [new_mach_inst(RV_OP_MV, [dest_op, lowered.result])]
    ISelInstResult(insts: insts, ctx: lowered.ctx)

fn rv_isel_copy(ctx: ISelContext, dest: LocalId, src: LocalId) -> ISelInstResult:
    # MV rd, rs (pseudo: ADDI rd, rs, 0)
    val inst = new_mach_inst(RV_OP_MV, [rv_local_vreg_op(dest.id), rv_local_vreg_op(src.id)])
    ISelInstResult(insts: [inst], ctx: ctx)

# ============================================================================
# Binary Operations
# ============================================================================

fn rv_isel_binop(ctx: ISelContext, dest: LocalId, op: MirBinOp, left: MirOperand, right: MirOperand) -> ISelInstResult:
    val left_low = rv_lower_operand(ctx, left)
    val right_low = rv_lower_operand(left_low.ctx, right)
    var current_ctx = right_low.ctx
    val dest_op = rv_local_vreg_op(dest.id)
    var insts: [MachInst] = []
    insts = insts + left_low.insts
    insts = insts + right_low.insts

    match op:
        case Add:
            insts = insts + [new_mach_inst(RV_OP_ADD, [dest_op, left_low.result, right_low.result])]
        case Sub:
            insts = insts + [new_mach_inst(RV_OP_SUB, [dest_op, left_low.result, right_low.result])]
        case Mul:
            # RV64M extension: MUL rd, rs1, rs2
            insts = insts + [new_mach_inst(RV_OP_MUL, [dest_op, left_low.result, right_low.result])]
        case Div:
            # RV64M extension: DIV rd, rs1, rs2 (signed)
            insts = insts + [new_mach_inst(RV_OP_DIV, [dest_op, left_low.result, right_low.result])]
        case Rem:
            # RV64M extension: REM rd, rs1, rs2 (signed remainder)
            insts = insts + [new_mach_inst(RV_OP_REM, [dest_op, left_low.result, right_low.result])]
        case BitAnd:
            insts = insts + [new_mach_inst(RV_OP_AND, [dest_op, left_low.result, right_low.result])]
        case BitOr:
            insts = insts + [new_mach_inst(RV_OP_OR, [dest_op, left_low.result, right_low.result])]
        case BitXor:
            insts = insts + [new_mach_inst(RV_OP_XOR, [dest_op, left_low.result, right_low.result])]
        case Shl:
            insts = insts + [new_mach_inst(RV_OP_SLL, [dest_op, left_low.result, right_low.result])]
        case Shr:
            # Arithmetic shift right (sign-extending)
            insts = insts + [new_mach_inst(RV_OP_SRA, [dest_op, left_low.result, right_low.result])]
        case Eq:
            insts = insts + rv_isel_cmp_eq(dest_op, left_low.result, right_low.result, current_ctx)
        case Ne:
            insts = insts + rv_isel_cmp_ne(dest_op, left_low.result, right_low.result, current_ctx)
        case Lt:
            # SLT rd, rs1, rs2 (rd = 1 if rs1 < rs2, signed)
            insts = insts + [new_mach_inst(RV_OP_SLT, [dest_op, left_low.result, right_low.result])]
        case Le:
            # LE: NOT (rs2 < rs1) => SLT tmp, rs2, rs1; SEQZ dest, tmp
            insts = insts + rv_isel_cmp_le(dest_op, left_low.result, right_low.result, current_ctx)
        case Gt:
            # GT: SLT rd, rs2, rs1 (swap operands)
            insts = insts + [new_mach_inst(RV_OP_SLT, [dest_op, right_low.result, left_low.result])]
        case Ge:
            # GE: NOT (rs1 < rs2) => SLT tmp, rs1, rs2; SEQZ dest, tmp
            insts = insts + rv_isel_cmp_ge(dest_op, left_low.result, right_low.result, current_ctx)
        case _:
            # Unsupported binop - zero result
            insts = insts + [new_mach_inst(RV_OP_LI, [dest_op, op_imm(0)])]

    ISelInstResult(insts: insts, ctx: current_ctx)

# RISC-V comparison helpers using SLT/SEQZ/SNEZ/SUB + XOR patterns.
# RISC-V has no flags register; comparisons are done via SLT and branches.

fn rv_isel_cmp_eq(dest: Operand, left: Operand, right: Operand, ctx: ISelContext) -> [MachInst]:
    # EQ: SUB tmp, rs1, rs2; SEQZ dest, tmp
    # SEQZ is pseudo for SLTIU rd, rs, 1
    var insts: [MachInst] = []
    var tmp_ctx = isel_alloc_vreg(ctx)
    val tmp_vreg = isel_get_vreg(tmp_ctx)
    val tmp_op = op_reg(virtual_reg(tmp_vreg))
    insts = insts + [new_mach_inst(RV_OP_SUB, [tmp_op, left, right])]
    insts = insts + [new_mach_inst(RV_OP_SEQZ, [dest, tmp_op])]
    insts

fn rv_isel_cmp_ne(dest: Operand, left: Operand, right: Operand, ctx: ISelContext) -> [MachInst]:
    # NE: SUB tmp, rs1, rs2; SNEZ dest, tmp
    # SNEZ is pseudo for SLTU rd, x0, rs
    var insts: [MachInst] = []
    var tmp_ctx = isel_alloc_vreg(ctx)
    val tmp_vreg = isel_get_vreg(tmp_ctx)
    val tmp_op = op_reg(virtual_reg(tmp_vreg))
    insts = insts + [new_mach_inst(RV_OP_SUB, [tmp_op, left, right])]
    insts = insts + [new_mach_inst(RV_OP_SNEZ, [dest, tmp_op])]
    insts

fn rv_isel_cmp_le(dest: Operand, left: Operand, right: Operand, ctx: ISelContext) -> [MachInst]:
    # LE: NOT (right < left) => SLT tmp, right, left; SEQZ dest, tmp
    var insts: [MachInst] = []
    var tmp_ctx = isel_alloc_vreg(ctx)
    val tmp_vreg = isel_get_vreg(tmp_ctx)
    val tmp_op = op_reg(virtual_reg(tmp_vreg))
    insts = insts + [new_mach_inst(RV_OP_SLT, [tmp_op, right, left])]
    insts = insts + [new_mach_inst(RV_OP_SEQZ, [dest, tmp_op])]
    insts

fn rv_isel_cmp_ge(dest: Operand, left: Operand, right: Operand, ctx: ISelContext) -> [MachInst]:
    # GE: NOT (left < right) => SLT tmp, left, right; SEQZ dest, tmp
    var insts: [MachInst] = []
    var tmp_ctx = isel_alloc_vreg(ctx)
    val tmp_vreg = isel_get_vreg(tmp_ctx)
    val tmp_op = op_reg(virtual_reg(tmp_vreg))
    insts = insts + [new_mach_inst(RV_OP_SLT, [tmp_op, left, right])]
    insts = insts + [new_mach_inst(RV_OP_SEQZ, [dest, tmp_op])]
    insts

# ============================================================================
# Unary Operations
# ============================================================================

fn rv_isel_unaryop(ctx: ISelContext, dest: LocalId, op: MirUnaryOp, operand: MirOperand) -> ISelInstResult:
    val low = rv_lower_operand(ctx, operand)
    val dest_op = rv_local_vreg_op(dest.id)
    var insts = low.insts

    match op:
        case Neg:
            # NEG rd, rs (pseudo: SUB rd, x0, rs)
            insts = insts + [new_mach_inst(RV_OP_NEG, [dest_op, low.result])]
        case Not:
            # NOT rd, rs (pseudo: XORI rd, rs, -1)
            insts = insts + [new_mach_inst(RV_OP_NOT, [dest_op, low.result])]
        case BitNot:
            # Same as Not for integers: XORI rd, rs, -1
            insts = insts + [new_mach_inst(RV_OP_NOT, [dest_op, low.result])]
        case _:
            insts = insts + [new_mach_inst(RV_OP_MV, [dest_op, low.result])]

    ISelInstResult(insts: insts, ctx: low.ctx)

# ============================================================================
# Memory Operations
# ============================================================================

fn rv_isel_load(ctx: ISelContext, dest: LocalId, ptr: MirOperand) -> ISelInstResult:
    val low = rv_lower_operand(ctx, ptr)
    val dest_op = rv_local_vreg_op(dest.id)
    var insts = low.insts
    # LD dest, 0(base) - load doubleword (64-bit)
    insts = insts + [new_mach_inst(RV_OP_LD, [dest_op, op_mem(operand_get_reg(low.result), 0)])]
    ISelInstResult(insts: insts, ctx: low.ctx)

fn rv_isel_store(ctx: ISelContext, ptr: MirOperand, value: MirOperand) -> ISelInstResult:
    val ptr_low = rv_lower_operand(ctx, ptr)
    val val_low = rv_lower_operand(ptr_low.ctx, value)
    var insts = ptr_low.insts
    insts = insts + val_low.insts
    # SD value, 0(base) - store doubleword (64-bit)
    insts = insts + [new_mach_inst(RV_OP_SD, [val_low.result, op_mem(operand_get_reg(ptr_low.result), 0)])]
    ISelInstResult(insts: insts, ctx: val_low.ctx)

fn rv_isel_get_field(ctx: ISelContext, dest: LocalId, base: MirOperand, field: i64) -> ISelInstResult:
    val base_low = rv_lower_operand(ctx, base)
    val dest_op = rv_local_vreg_op(dest.id)
    val offset = field * 8
    var insts = base_low.insts
    # LD dest, offset(base)
    insts = insts + [new_mach_inst(RV_OP_LD, [dest_op, op_mem(operand_get_reg(base_low.result), offset)])]
    ISelInstResult(insts: insts, ctx: base_low.ctx)

fn rv_isel_set_field(ctx: ISelContext, base: MirOperand, field: i64, value: MirOperand) -> ISelInstResult:
    val base_low = rv_lower_operand(ctx, base)
    val val_low = rv_lower_operand(base_low.ctx, value)
    val offset = field * 8
    var insts = base_low.insts
    insts = insts + val_low.insts
    # SD value, offset(base)
    insts = insts + [new_mach_inst(RV_OP_SD, [val_low.result, op_mem(operand_get_reg(base_low.result), offset)])]
    ISelInstResult(insts: insts, ctx: val_low.ctx)

fn rv_isel_alloc(ctx: ISelContext, dest: LocalId, type_: MirType) -> ISelInstResult:
    val size = type__size_bytes(type_)
    val aligned = if size < 16: 16 else: size
    # Round up to multiple of 16
    var alloc_size = aligned
    if alloc_size % 16 != 0:
        alloc_size = alloc_size + (16 - (alloc_size % 16))
    val dest_op = rv_local_vreg_op(dest.id)
    var insts: [MachInst] = []
    # ADDI sp, sp, -size (decrement stack)
    val neg_size = 0 - alloc_size
    insts = insts + [new_mach_inst(RV_OP_ADDI, [op_phys(RV_X2), op_phys(RV_X2), op_imm(neg_size)])]
    # MV dest, sp (capture the address)
    insts = insts + [new_mach_inst(RV_OP_MV, [dest_op, op_phys(RV_X2)])]
    ISelInstResult(insts: insts, ctx: ctx)

fn rv_isel_cast(ctx: ISelContext, dest: LocalId, operand: MirOperand, target: MirType) -> ISelInstResult:
    val low = rv_lower_operand(ctx, operand)
    val dest_op = rv_local_vreg_op(dest.id)
    var insts = low.insts
    # Simple move - truncation/extension handled by encoder based on type
    insts = insts + [new_mach_inst(RV_OP_MV, [dest_op, low.result])]
    ISelInstResult(insts: insts, ctx: low.ctx)

# ============================================================================
# Function Calls
# ============================================================================

fn rv_isel_call(ctx: ISelContext, dest: LocalId?, func_op: MirOperand, args: [MirOperand]) -> ISelInstResult:
    var insts: [MachInst] = []
    var current_ctx = ctx

    # Lower arguments into ABI registers (a0-a7 = x10-x17)
    for i in 0..args_len(args):
        val arg_low = rv_lower_operand(current_ctx, args[i])
        current_ctx = arg_low.ctx
        insts = insts + arg_low.insts
        if i < rv_arg_regs_len():
            val arg_reg = RV_ARG_REGS[i]
            insts = insts + [new_mach_inst(RV_OP_MV, [op_phys(arg_reg), arg_low.result])]
        else:
            # Stack argument: SD value, offset(sp)
            val stack_offset = (i - rv_arg_regs_len()) * 8
            insts = insts + [new_mach_inst(RV_OP_SD, [arg_low.result, op_mem(physical_reg(RV_X2), stack_offset)])]

    # Emit call
    match func_op.kind:
        case Const(mirconstvalue_Str(name), _):
            # Direct call to named function: CALL symbol (pseudo: AUIPC ra + JALR ra)
            current_ctx = isel_add_extern(current_ctx, name)
            insts = insts + [new_mach_inst(RV_OP_CALL, [op_sym(name)])]
        case Copy(local):
            # Indirect call through register: JALR ra, 0(rs)
            insts = insts + [new_mach_inst(RV_OP_JALR, [op_phys(RV_X1), rv_local_vreg_op(local.id), op_imm(0)])]
        case Move(local):
            insts = insts + [new_mach_inst(RV_OP_JALR, [op_phys(RV_X1), rv_local_vreg_op(local.id), op_imm(0)])]
        case _:
            insts = insts + [new_mach_inst(RV_OP_NOP, [])]

    # Move return value from a0 (x10)
    if has_dest:
        val d = dest_value
        insts = insts + [new_mach_inst(RV_OP_MV, [rv_local_vreg_op(d.id), op_phys(RV_X10)])]

    ISelInstResult(insts: insts, ctx: current_ctx)

# ============================================================================
# Instruction Selection - Terminators
# ============================================================================

fn rv_isel_terminator(ctx: ISelContext, term: MirTerminator) -> ISelInstResult:
    match term:
        case Goto(target):
            # JAL x0, target_label (unconditional jump, discard return address)
            val inst = new_mach_inst(RV_OP_JAL, [op_phys(RV_X0), op_label(target.id)])
            ISelInstResult(insts: [inst], ctx: ctx)
        case Return(value):
            rv_isel_return(ctx, value)
        case If(cond, then_, else_):
            rv_isel_if(ctx, cond, then_, else_)
        case Switch(value, targets, default_target):
            rv_isel_switch(ctx, value, targets, default_target)
        case Unreachable:
            ISelInstResult(insts: [new_mach_inst(RV_OP_NOP, [])], ctx: ctx)
        case _:
            ISelInstResult(insts: [new_mach_inst(RV_OP_NOP, [])], ctx: ctx)

fn rv_isel_return(ctx: ISelContext, value: MirOperand?) -> ISelInstResult:
    var insts: [MachInst] = []
    if has_value:
        val v = value_value
        val low = rv_lower_operand(ctx, v)
        insts = insts + low.insts
        # MV a0, result (move return value to a0 = x10)
        insts = insts + [new_mach_inst(RV_OP_MV, [op_phys(RV_X10), low.result])]
    # Epilogue: restore ra, s0, adjust sp, return
    # LD ra, offset(sp)
    insts = insts + [new_mach_inst(RV_OP_LD, [op_phys(RV_X1), op_mem(physical_reg(RV_X2), 0)])]
    # LD s0, offset(sp)
    insts = insts + [new_mach_inst(RV_OP_LD, [op_phys(RV_X8), op_mem(physical_reg(RV_X2), 0)])]
    # ADDI sp, sp, framesize (restore stack, placeholder)
    insts = insts + [new_mach_inst(RV_OP_ADDI, [op_phys(RV_X2), op_phys(RV_X2), op_imm(0)])]
    # RET (pseudo: JALR x0, 0(ra))
    insts = insts + [new_mach_inst(RV_OP_RET, [])]
    ISelInstResult(insts: insts, ctx: ctx)

fn rv_isel_if(ctx: ISelContext, cond: MirOperand, then_: BlockId, else_: BlockId) -> ISelInstResult:
    val cond_low = rv_lower_operand(ctx, cond)
    var insts = cond_low.insts
    # BNE cond, x0, then_label (branch if cond != 0, i.e. true)
    insts = insts + [new_mach_inst(RV_OP_BNE, [cond_low.result, op_phys(RV_X0), op_label(then_.id)])]
    # JAL x0, else_label (unconditional jump to else block)
    insts = insts + [new_mach_inst(RV_OP_JAL, [op_phys(RV_X0), op_label(else_.id)])]
    ISelInstResult(insts: insts, ctx: cond_low.ctx)

fn rv_isel_switch(ctx: ISelContext, value: MirOperand, targets: [SwitchCase], default_target: BlockId) -> ISelInstResult:
    val val_low = rv_lower_operand(ctx, value)
    var insts = val_low.insts
    var current_ctx = val_low.ctx

    # Generate LI + BEQ chain for each case
    for i in 0..targets_len(targets):
        val target = targets[i]
        # Load case value into temp vreg
        current_ctx = isel_alloc_vreg(current_ctx)
        val case_vreg = isel_get_vreg(current_ctx)
        val case_op = op_reg(virtual_reg(case_vreg))
        insts = insts + [new_mach_inst(RV_OP_LI, [case_op, op_imm(target.value)])]
        # BEQ value, case_value, target_label
        insts = insts + [new_mach_inst(RV_OP_BEQ, [val_low.result, case_op, op_label(target.target.id)])]

    # JAL x0, default_label (fall through to default)
    insts = insts + [new_mach_inst(RV_OP_JAL, [op_phys(RV_X0), op_label(default_target.id)])]
    ISelInstResult(insts: insts, ctx: current_ctx)

# ============================================================================
# Exports
# ============================================================================

export ISelContext, new_isel_context
export isel_module_riscv64
export LoweredOperand, ISelFuncResult, ISelBlockResult, ISelInstResult
