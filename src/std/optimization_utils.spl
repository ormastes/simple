# Optimization Algorithms Module
# Comprehensive optimization utilities for numerical optimization problems

# ============================================================================
# Core Data Structures
# ============================================================================

class OptimizationResult:
    solution: List<f64>          # Optimal solution found
    objective_value: f64         # Objective function value at solution
    iterations: i64              # Number of iterations performed
    converged: bool              # Whether algorithm converged
    gradient_norm: f64           # Final gradient norm
    message: text                # Status message

class LineSearchResult:
    alpha: f64                   # Step size
    new_point: List<f64>         # New point after line search
    new_value: f64               # Function value at new point
    success: bool                # Whether line search succeeded
    iterations: i64              # Number of iterations

class OptimizationConfig:
    max_iterations: i64          # Maximum iterations
    tolerance: f64               # Convergence tolerance
    learning_rate: f64           # Initial learning rate
    verbose: bool                # Print progress
    gradient_tolerance: f64      # Gradient convergence threshold
    value_tolerance: f64         # Function value change threshold
    parameter_tolerance: f64     # Parameter change threshold

class AdamState:
    m: List<f64>                 # First moment estimate
    v: List<f64>                 # Second moment estimate
    beta1: f64                   # Exponential decay rate for first moment
    beta2: f64                   # Exponential decay rate for second moment
    epsilon: f64                 # Small constant for numerical stability
    t: i64                       # Time step

class RMSpropState:
    cache: List<f64>             # Cache of squared gradients
    decay_rate: f64              # Decay rate
    epsilon: f64                 # Small constant for numerical stability

class AdaGradState:
    cache: List<f64>             # Sum of squared gradients
    epsilon: f64                 # Small constant for numerical stability

class BFGSState:
    H: List<List<f64>>           # Inverse Hessian approximation
    prev_gradient: List<f64>     # Previous gradient
    prev_point: List<f64>        # Previous point

# ============================================================================
# Vector Operations
# ============================================================================

fn vector_add(a: List<f64>, b: List<f64>) -> List<f64>:
    val result = []
    var i = 0
    while i < a.length():
        result.append(a[i] + b[i])
        i = i + 1
    result

fn vector_subtract(a: List<f64>, b: List<f64>) -> List<f64>:
    val result = []
    var i = 0
    while i < a.length():
        result.append(a[i] - b[i])
        i = i + 1
    result

fn vector_scale(v: List<f64>, scalar: f64) -> List<f64>:
    val result = []
    var i = 0
    while i < v.length():
        result.append(v[i] * scalar)
        i = i + 1
    result

fn vector_dot(a: List<f64>, b: List<f64>) -> f64:
    var sum = 0.0
    var i = 0
    while i < a.length():
        sum = sum + a[i] * b[i]
        i = i + 1
    sum

fn vector_norm(v: List<f64>) -> f64:
    var sum_sq = 0.0
    var i = 0
    while i < v.length():
        sum_sq = sum_sq + v[i] * v[i]
        i = i + 1
    sqrt(sum_sq)

fn vector_norm_squared(v: List<f64>) -> f64:
    var sum_sq = 0.0
    var i = 0
    while i < v.length():
        sum_sq = sum_sq + v[i] * v[i]
        i = i + 1
    sum_sq

fn vector_zeros(n: i64) -> List<f64>:
    val result = []
    var i = 0
    while i < n:
        result.append(0.0)
        i = i + 1
    result

fn vector_ones(n: i64) -> List<f64>:
    val result = []
    var i = 0
    while i < n:
        result.append(1.0)
        i = i + 1
    result

fn vector_copy(v: List<f64>) -> List<f64>:
    val result = []
    var i = 0
    while i < v.length():
        result.append(v[i])
        i = i + 1
    result

fn vector_max_abs(v: List<f64>) -> f64:
    var max_val = 0.0
    var i = 0
    while i < v.length():
        val abs_val = abs(v[i])
        if abs_val > max_val:
            max_val = abs_val
    i = i + 1
    max_val

fn vector_elementwise_multiply(a: List<f64>, b: List<f64>) -> List<f64>:
    val result = []
    var i = 0
    while i < a.length():
        result.append(a[i] * b[i])
        i = i + 1
    result

fn vector_elementwise_sqrt(v: List<f64>) -> List<f64>:
    val result = []
    var i = 0
    while i < v.length():
        result.append(sqrt(v[i]))
        i = i + 1
    result

fn vector_elementwise_square(v: List<f64>) -> List<f64>:
    val result = []
    var i = 0
    while i < v.length():
        result.append(v[i] * v[i])
        i = i + 1
    result

# ============================================================================
# Matrix Operations
# ============================================================================

fn matrix_identity(n: i64) -> List<List<f64>>:
    val result = []
    var i = 0
    while i < n:
        val row = []
        var j = 0
        while j < n:
            if i == j:
                row.append(1.0)
            else:
                row.append(0.0)
            j = j + 1
        result.append(row)
        i = i + 1
    result

fn matrix_vector_multiply(A: List<List<f64>>, v: List<f64>) -> List<f64>:
    val result = []
    var i = 0
    while i < A.length():
        var sum = 0.0
        var j = 0
        while j < v.length():
            sum = sum + A[i][j] * v[j]
            j = j + 1
        result.append(sum)
        i = i + 1
    result

fn outer_product(a: List<f64>, b: List<f64>) -> List<List<f64>>:
    val result = []
    var i = 0
    while i < a.length():
        val row = []
        var j = 0
        while j < b.length():
            row.append(a[i] * b[j])
            j = j + 1
        result.append(row)
        i = i + 1
    result

fn matrix_add(A: List<List<f64>>, B: List<List<f64>>) -> List<List<f64>>:
    val result = []
    var i = 0
    while i < A.length():
        val row = []
        var j = 0
        while j < A[i].length():
            row.append(A[i][j] + B[i][j])
            j = j + 1
        result.append(row)
        i = i + 1
    result

fn matrix_scale(A: List<List<f64>>, scalar: f64) -> List<List<f64>>:
    val result = []
    var i = 0
    while i < A.length():
        val row = []
        var j = 0
        while j < A[i].length():
            row.append(A[i][j] * scalar)
            j = j + 1
        result.append(row)
        i = i + 1
    result

# ============================================================================
# Gradient Computation
# ============================================================================

fn finite_difference_gradient(f: fn(List<f64>) -> f64, x: List<f64>, epsilon: f64) -> List<f64>:
    val grad = []
    val f_x = f(x)
    var i = 0
    while i < x.length():
        val x_plus = vector_copy(x)
        x_plus[i] = x_plus[i] + epsilon
        val f_plus = f(x_plus)
        val derivative = (f_plus - f_x) / epsilon
        grad.append(derivative)
        i = i + 1
    grad

fn central_difference_gradient(f: fn(List<f64>) -> f64, x: List<f64>, epsilon: f64) -> List<f64>:
    val grad = []
    var i = 0
    while i < x.length():
        val x_plus = vector_copy(x)
        val x_minus = vector_copy(x)
        x_plus[i] = x_plus[i] + epsilon
        x_minus[i] = x_minus[i] - epsilon
        val f_plus = f(x_plus)
        val f_minus = f(x_minus)
        val derivative = (f_plus - f_minus) / (2.0 * epsilon)
        grad.append(derivative)
        i = i + 1
    grad

fn numerical_hessian(f: fn(List<f64>) -> f64, x: List<f64>, epsilon: f64) -> List<List<f64>>:
    val n = x.length()
    val H = []
    var i = 0
    while i < n:
        val row = []
        var j = 0
        while j < n:
            val x_pp = vector_copy(x)
            val x_pm = vector_copy(x)
            val x_mp = vector_copy(x)
            val x_mm = vector_copy(x)

            x_pp[i] = x_pp[i] + epsilon
            x_pp[j] = x_pp[j] + epsilon

            x_pm[i] = x_pm[i] + epsilon
            x_pm[j] = x_pm[j] - epsilon

            x_mp[i] = x_mp[i] - epsilon
            x_mp[j] = x_mp[j] + epsilon

            x_mm[i] = x_mm[i] - epsilon
            x_mm[j] = x_mm[j] - epsilon

            val f_pp = f(x_pp)
            val f_pm = f(x_pm)
            val f_mp = f(x_mp)
            val f_mm = f(x_mm)

            val h_ij = (f_pp - f_pm - f_mp + f_mm) / (4.0 * epsilon * epsilon)
            row.append(h_ij)
            j = j + 1
        H.append(row)
        i = i + 1
    H

# ============================================================================
# Convergence Criteria
# ============================================================================

fn check_gradient_convergence(gradient: List<f64>, tolerance: f64) -> bool:
    val grad_norm = vector_norm(gradient)
    grad_norm < tolerance

fn check_value_convergence(old_value: f64, new_value: f64, tolerance: f64) -> bool:
    val change = abs(new_value - old_value)
    change < tolerance

fn check_parameter_convergence(old_params: List<f64>, new_params: List<f64>, tolerance: f64) -> bool:
    val diff = vector_subtract(new_params, old_params)
    val change = vector_norm(diff)
    change < tolerance

fn check_convergence_all(gradient: List<f64>, old_value: f64, new_value: f64,
                         old_params: List<f64>, new_params: List<f64>,
                         config: OptimizationConfig) -> bool:
    val grad_converged = check_gradient_convergence(gradient, config.gradient_tolerance)
    val value_converged = check_value_convergence(old_value, new_value, config.value_tolerance)
    val param_converged = check_parameter_convergence(old_params, new_params, config.parameter_tolerance)
    grad_converged or value_converged or param_converged

# ============================================================================
# Line Search Algorithms
# ============================================================================

fn backtracking_line_search(f: fn(List<f64>) -> f64, x: List<f64>, direction: List<f64>,
                            gradient: List<f64>, alpha_init: f64, rho: f64, c: f64) -> LineSearchResult:
    var alpha = alpha_init
    val f_x = f(x)
    val grad_dot_dir = vector_dot(gradient, direction)
    var iterations = 0
    val max_iter = 50

    while iterations < max_iter:
        val scaled_dir = vector_scale(direction, alpha)
        val new_point = vector_add(x, scaled_dir)
        val f_new = f(new_point)

        val armijo_condition = f_new <= f_x + c * alpha * grad_dot_dir
        if armijo_condition:
            return LineSearchResult(
                alpha: alpha,
                new_point: new_point,
                new_value: f_new,
                success: true,
                iterations: iterations
            )

        alpha = alpha * rho
        iterations = iterations + 1

    val scaled_dir = vector_scale(direction, alpha)
    val new_point = vector_add(x, scaled_dir)
    LineSearchResult(
        alpha: alpha,
        new_point: new_point,
        new_value: f(new_point),
        success: false,
        iterations: iterations
    )

fn wolfe_line_search(f: fn(List<f64>) -> f64, grad_f: fn(List<f64>) -> List<f64>,
                     x: List<f64>, direction: List<f64>, alpha_init: f64,
                     c1: f64, c2: f64) -> LineSearchResult:
    var alpha = alpha_init
    val f_x = f(x)
    val grad_x = grad_f(x)
    val grad_dot_dir = vector_dot(grad_x, direction)
    var iterations = 0
    val max_iter = 30

    while iterations < max_iter:
        val scaled_dir = vector_scale(direction, alpha)
        val new_point = vector_add(x, scaled_dir)
        val f_new = f(new_point)

        val armijo = f_new <= f_x + c1 * alpha * grad_dot_dir

        if armijo:
            val grad_new = grad_f(new_point)
            val grad_new_dot_dir = vector_dot(grad_new, direction)
            val curvature = abs(grad_new_dot_dir) <= c2 * abs(grad_dot_dir)

            if curvature:
                return LineSearchResult(
                    alpha: alpha,
                    new_point: new_point,
                    new_value: f_new,
                    success: true,
                    iterations: iterations
                )

        alpha = alpha * 0.5
        iterations = iterations + 1

    val scaled_dir = vector_scale(direction, alpha)
    val new_point = vector_add(x, scaled_dir)
    LineSearchResult(
        alpha: alpha,
        new_point: new_point,
        new_value: f(new_point),
        success: false,
        iterations: iterations
    )

fn golden_section_search(f: fn(f64) -> f64, a: f64, b: f64, tolerance: f64) -> f64:
    val phi = (1.0 + sqrt(5.0)) / 2.0
    val resphi = 2.0 - phi

    var x1 = a + resphi * (b - a)
    var x2 = b - resphi * (b - a)
    var f1 = f(x1)
    var f2 = f(x2)

    var a_curr = a
    var b_curr = b

    while abs(b_curr - a_curr) > tolerance:
        if f1 < f2:
            b_curr = x2
            x2 = x1
            f2 = f1
            x1 = a_curr + resphi * (b_curr - a_curr)
            f1 = f(x1)
        else:
            a_curr = x1
            x1 = x2
            f1 = f2
            x2 = b_curr - resphi * (b_curr - a_curr)
            f2 = f(x2)

    (a_curr + b_curr) / 2.0

# ============================================================================
# Unconstrained Optimization - Gradient Descent
# ============================================================================

fn gradient_descent(f: fn(List<f64>) -> f64, grad_f: fn(List<f64>) -> List<f64>,
                   x0: List<f64>, config: OptimizationConfig) -> OptimizationResult:
    var x = vector_copy(x0)
    var iteration = 0
    var converged = false
    var prev_value = f(x)

    while iteration < config.max_iterations:
        val gradient = grad_f(x)
        val grad_norm = vector_norm(gradient)

        if grad_norm < config.gradient_tolerance:
            converged = true
            return OptimizationResult(
                solution: x,
                objective_value: prev_value,
                iterations: iteration,
                converged: true,
                gradient_norm: grad_norm,
                message: "Converged: gradient norm below tolerance"
            )

        val direction = vector_scale(gradient, -1.0)
        val ls_result = backtracking_line_search(f, x, direction, gradient,
                                                  config.learning_rate, 0.8, 0.0001)

        val new_x = ls_result.new_point
        val new_value = ls_result.new_value

        if check_value_convergence(prev_value, new_value, config.value_tolerance):
            converged = true
            return OptimizationResult(
                solution: new_x,
                objective_value: new_value,
                iterations: iteration,
                converged: true,
                gradient_norm: grad_norm,
                message: "Converged: function value change below tolerance"
            )

        x = new_x
        prev_value = new_value
        iteration = iteration + 1

    val final_gradient = grad_f(x)
    OptimizationResult(
        solution: x,
        objective_value: f(x),
        iterations: iteration,
        converged: converged,
        gradient_norm: vector_norm(final_gradient),
        message: "Maximum iterations reached"
    )

# ============================================================================
# Conjugate Gradient Method
# ============================================================================

fn conjugate_gradient(f: fn(List<f64>) -> f64, grad_f: fn(List<f64>) -> List<f64>,
                     x0: List<f64>, config: OptimizationConfig) -> OptimizationResult:
    var x = vector_copy(x0)
    var gradient = grad_f(x)
    var direction = vector_scale(gradient, -1.0)
    var iteration = 0
    var converged = false
    var prev_value = f(x)

    while iteration < config.max_iterations:
        val grad_norm = vector_norm(gradient)

        if grad_norm < config.gradient_tolerance:
            converged = true
            return OptimizationResult(
                solution: x,
                objective_value: prev_value,
                iterations: iteration,
                converged: true,
                gradient_norm: grad_norm,
                message: "Converged: gradient norm below tolerance"
            )

        val ls_result = backtracking_line_search(f, x, direction, gradient,
                                                  1.0, 0.8, 0.0001)

        val new_x = ls_result.new_point
        val new_value = ls_result.new_value
        val new_gradient = grad_f(new_x)

        # Fletcher-Reeves formula
        val beta_num = vector_norm_squared(new_gradient)
        val beta_den = vector_norm_squared(gradient)
        var beta = 0.0
        if beta_den > 1e-10:
            beta = beta_num / beta_den

        val scaled_direction = vector_scale(direction, beta)
        val neg_gradient = vector_scale(new_gradient, -1.0)
        direction = vector_add(neg_gradient, scaled_direction)

        x = new_x
        gradient = new_gradient
        prev_value = new_value
        iteration = iteration + 1

    OptimizationResult(
        solution: x,
        objective_value: f(x),
        iterations: iteration,
        converged: converged,
        gradient_norm: vector_norm(gradient),
        message: "Maximum iterations reached"
    )

# ============================================================================
# BFGS Method
# ============================================================================

fn bfgs_optimize(f: fn(List<f64>) -> f64, grad_f: fn(List<f64>) -> List<f64>,
                x0: List<f64>, config: OptimizationConfig) -> OptimizationResult:
    var x = vector_copy(x0)
    val n = x.length()
    var H = matrix_identity(n)
    var gradient = grad_f(x)
    var iteration = 0
    var converged = false
    var prev_value = f(x)

    while iteration < config.max_iterations:
        val grad_norm = vector_norm(gradient)

        if grad_norm < config.gradient_tolerance:
            converged = true
            return OptimizationResult(
                solution: x,
                objective_value: prev_value,
                iterations: iteration,
                converged: true,
                gradient_norm: grad_norm,
                message: "Converged: gradient norm below tolerance"
            )

        val neg_gradient = vector_scale(gradient, -1.0)
        val direction = matrix_vector_multiply(H, neg_gradient)

        val ls_result = backtracking_line_search(f, x, direction, gradient,
                                                  1.0, 0.8, 0.0001)

        val new_x = ls_result.new_point
        val new_value = ls_result.new_value
        val new_gradient = grad_f(new_x)

        val s = vector_subtract(new_x, x)
        val y = vector_subtract(new_gradient, gradient)
        val sy = vector_dot(s, y)

        if sy > 1e-10:
            val Hy = matrix_vector_multiply(H, y)
            val yHy = vector_dot(y, Hy)

            val ss = outer_product(s, s)
            val ss_scaled = matrix_scale(ss, 1.0 / sy)

            val Hyy = outer_product(Hy, y)
            val yHy_term = matrix_scale(Hyy, 1.0 / yHy)

            val yHyH = outer_product(y, Hy)
            val yHyH_term = matrix_scale(yHyH, 1.0 / yHy)

            H = matrix_add(H, ss_scaled)
            H = matrix_add(H, matrix_scale(yHy_term, -1.0))
            H = matrix_add(H, matrix_scale(yHyH_term, -1.0))

        x = new_x
        gradient = new_gradient
        prev_value = new_value
        iteration = iteration + 1

    OptimizationResult(
        solution: x,
        objective_value: f(x),
        iterations: iteration,
        converged: converged,
        gradient_norm: vector_norm(gradient),
        message: "Maximum iterations reached"
    )

# ============================================================================
# L-BFGS Method
# ============================================================================

fn lbfgs_two_loop_recursion(gradient: List<f64>, s_list: List<List<f64>>,
                            y_list: List<List<f64>>, rho_list: List<f64>, m: i64) -> List<f64>:
    val q = vector_copy(gradient)
    val alpha_list = []

    var i = m - 1
    while i >= 0:
        val alpha_i = rho_list[i] * vector_dot(s_list[i], q)
        alpha_list.append(alpha_i)
        val scaled_y = vector_scale(y_list[i], alpha_i)
        val new_q = vector_subtract(q, scaled_y)
        i = i - 1

    var r = q
    if m > 0:
        val last_y = y_list[m - 1]
        val last_s = s_list[m - 1]
        val gamma = vector_dot(last_s, last_y) / vector_dot(last_y, last_y)
        r = vector_scale(r, gamma)

    i = 0
    while i < m:
        val beta = rho_list[i] * vector_dot(y_list[i], r)
        val diff = alpha_list[m - 1 - i] - beta
        val scaled_s = vector_scale(s_list[i], diff)
        r = vector_add(r, scaled_s)
        i = i + 1

    r

fn lbfgs_optimize(f: fn(List<f64>) -> f64, grad_f: fn(List<f64>) -> List<f64>,
                 x0: List<f64>, config: OptimizationConfig, memory_size: i64) -> OptimizationResult:
    var x = vector_copy(x0)
    var gradient = grad_f(x)
    var iteration = 0
    var converged = false
    var prev_value = f(x)

    val s_list = []
    val y_list = []
    val rho_list = []
    var m = 0

    while iteration < config.max_iterations:
        val grad_norm = vector_norm(gradient)

        if grad_norm < config.gradient_tolerance:
            converged = true
            return OptimizationResult(
                solution: x,
                objective_value: prev_value,
                iterations: iteration,
                converged: true,
                gradient_norm: grad_norm,
                message: "Converged: gradient norm below tolerance"
            )

        val direction = lbfgs_two_loop_recursion(gradient, s_list, y_list, rho_list, m)
        val neg_direction = vector_scale(direction, -1.0)

        val ls_result = backtracking_line_search(f, x, neg_direction, gradient,
                                                  1.0, 0.8, 0.0001)

        val new_x = ls_result.new_point
        val new_value = ls_result.new_value
        val new_gradient = grad_f(new_x)

        val s = vector_subtract(new_x, x)
        val y = vector_subtract(new_gradient, gradient)
        val sy = vector_dot(s, y)

        if sy > 1e-10:
            if m >= memory_size:
                s_list.remove(0)
                y_list.remove(0)
                rho_list.remove(0)
                m = m - 1

            s_list.append(s)
            y_list.append(y)
            rho_list.append(1.0 / sy)
            m = m + 1

        x = new_x
        gradient = new_gradient
        prev_value = new_value
        iteration = iteration + 1

    OptimizationResult(
        solution: x,
        objective_value: f(x),
        iterations: iteration,
        converged: converged,
        gradient_norm: vector_norm(gradient),
        message: "Maximum iterations reached"
    )

# ============================================================================
# Stochastic Optimization - SGD
# ============================================================================

fn sgd_optimize(grad_f: fn(List<f64>, i64) -> List<f64>, x0: List<f64>,
               num_samples: i64, config: OptimizationConfig) -> OptimizationResult:
    var x = vector_copy(x0)
    var iteration = 0
    var epoch = 0
    var converged = false

    while epoch < config.max_iterations:
        var sample_idx = 0
        while sample_idx < num_samples:
            val gradient = grad_f(x, sample_idx)
            val grad_norm = vector_norm(gradient)

            if grad_norm < config.gradient_tolerance:
                converged = true
                return OptimizationResult(
                    solution: x,
                    objective_value: 0.0,
                    iterations: iteration,
                    converged: true,
                    gradient_norm: grad_norm,
                    message: "Converged: gradient norm below tolerance"
                )

            val scaled_gradient = vector_scale(gradient, config.learning_rate)
            x = vector_subtract(x, scaled_gradient)

            iteration = iteration + 1
            sample_idx = sample_idx + 1

        epoch = epoch + 1

    OptimizationResult(
        solution: x,
        objective_value: 0.0,
        iterations: iteration,
        converged: converged,
        gradient_norm: 0.0,
        message: "Maximum iterations reached"
    )

# ============================================================================
# Adam Optimizer
# ============================================================================

fn adam_initialize(n: i64, beta1: f64, beta2: f64, epsilon: f64) -> AdamState:
    AdamState(
        m: vector_zeros(n),
        v: vector_zeros(n),
        beta1: beta1,
        beta2: beta2,
        epsilon: epsilon,
        t: 0
    )

fn adam_update(state: AdamState, gradient: List<f64>) -> AdamState:
    val new_t = state.t + 1
    var new_m = []
    var new_v = []

    var i = 0
    while i < gradient.length():
        val m_i = state.beta1 * state.m[i] + (1.0 - state.beta1) * gradient[i]
        val v_i = state.beta2 * state.v[i] + (1.0 - state.beta2) * gradient[i] * gradient[i]
        new_m.append(m_i)
        new_v.append(v_i)
        i = i + 1

    AdamState(
        m: new_m,
        v: new_v,
        beta1: state.beta1,
        beta2: state.beta2,
        epsilon: state.epsilon,
        t: new_t
    )

fn adam_get_update(state: AdamState, learning_rate: f64) -> List<f64>:
    val beta1_t = pow(state.beta1, float(state.t))
    val beta2_t = pow(state.beta2, float(state.t))

    val update = []
    var i = 0
    while i < state.m.length():
        val m_hat = state.m[i] / (1.0 - beta1_t)
        val v_hat = state.v[i] / (1.0 - beta2_t)
        val update_i = learning_rate * m_hat / (sqrt(v_hat) + state.epsilon)
        update.append(update_i)
        i = i + 1
    update

fn adam_optimize(grad_f: fn(List<f64>, i64) -> List<f64>, x0: List<f64>,
                num_samples: i64, config: OptimizationConfig) -> OptimizationResult:
    var x = vector_copy(x0)
    var state = adam_initialize(x.length(), 0.9, 0.999, 1e-8)
    var iteration = 0
    var epoch = 0
    var converged = false

    while epoch < config.max_iterations:
        var sample_idx = 0
        while sample_idx < num_samples:
            val gradient = grad_f(x, sample_idx)
            val grad_norm = vector_norm(gradient)

            if grad_norm < config.gradient_tolerance:
                converged = true
                return OptimizationResult(
                    solution: x,
                    objective_value: 0.0,
                    iterations: iteration,
                    converged: true,
                    gradient_norm: grad_norm,
                    message: "Converged: gradient norm below tolerance"
                )

            state = adam_update(state, gradient)
            val update = adam_get_update(state, config.learning_rate)
            x = vector_subtract(x, update)

            iteration = iteration + 1
            sample_idx = sample_idx + 1

        epoch = epoch + 1

    OptimizationResult(
        solution: x,
        objective_value: 0.0,
        iterations: iteration,
        converged: converged,
        gradient_norm: 0.0,
        message: "Maximum iterations reached"
    )

# ============================================================================
# RMSprop Optimizer
# ============================================================================

fn rmsprop_initialize(n: i64, decay_rate: f64, epsilon: f64) -> RMSpropState:
    RMSpropState(
        cache: vector_zeros(n),
        decay_rate: decay_rate,
        epsilon: epsilon
    )

fn rmsprop_update(state: RMSpropState, x: List<f64>, gradient: List<f64>,
                 learning_rate: f64) -> List<f64>:
    var new_cache = []
    var new_x = []

    var i = 0
    while i < gradient.length():
        val cache_i = state.decay_rate * state.cache[i] + (1.0 - state.decay_rate) * gradient[i] * gradient[i]
        new_cache.append(cache_i)
        val x_i = x[i] - learning_rate * gradient[i] / (sqrt(cache_i) + state.epsilon)
        new_x.append(x_i)
        i = i + 1

    new_x

fn rmsprop_optimize(grad_f: fn(List<f64>, i64) -> List<f64>, x0: List<f64>,
                   num_samples: i64, config: OptimizationConfig) -> OptimizationResult:
    var x = vector_copy(x0)
    var state = rmsprop_initialize(x.length(), 0.9, 1e-8)
    var iteration = 0
    var epoch = 0
    var converged = false

    while epoch < config.max_iterations:
        var sample_idx = 0
        while sample_idx < num_samples:
            val gradient = grad_f(x, sample_idx)
            val grad_norm = vector_norm(gradient)

            if grad_norm < config.gradient_tolerance:
                converged = true
                return OptimizationResult(
                    solution: x,
                    objective_value: 0.0,
                    iterations: iteration,
                    converged: true,
                    gradient_norm: grad_norm,
                    message: "Converged: gradient norm below tolerance"
                )

            x = rmsprop_update(state, x, gradient, config.learning_rate)

            iteration = iteration + 1
            sample_idx = sample_idx + 1

        epoch = epoch + 1

    OptimizationResult(
        solution: x,
        objective_value: 0.0,
        iterations: iteration,
        converged: converged,
        gradient_norm: 0.0,
        message: "Maximum iterations reached"
    )

# ============================================================================
# AdaGrad Optimizer
# ============================================================================

fn adagrad_initialize(n: i64, epsilon: f64) -> AdaGradState:
    AdaGradState(
        cache: vector_zeros(n),
        epsilon: epsilon
    )

fn adagrad_update(state: AdaGradState, x: List<f64>, gradient: List<f64>,
                 learning_rate: f64) -> List<f64>:
    var new_cache = []
    var new_x = []

    var i = 0
    while i < gradient.length():
        val cache_i = state.cache[i] + gradient[i] * gradient[i]
        new_cache.append(cache_i)
        val x_i = x[i] - learning_rate * gradient[i] / (sqrt(cache_i) + state.epsilon)
        new_x.append(x_i)
        i = i + 1

    new_x

fn adagrad_optimize(grad_f: fn(List<f64>, i64) -> List<f64>, x0: List<f64>,
                   num_samples: i64, config: OptimizationConfig) -> OptimizationResult:
    var x = vector_copy(x0)
    var state = adagrad_initialize(x.length(), 1e-8)
    var iteration = 0
    var epoch = 0
    var converged = false

    while epoch < config.max_iterations:
        var sample_idx = 0
        while sample_idx < num_samples:
            val gradient = grad_f(x, sample_idx)
            val grad_norm = vector_norm(gradient)

            if grad_norm < config.gradient_tolerance:
                converged = true
                return OptimizationResult(
                    solution: x,
                    objective_value: 0.0,
                    iterations: iteration,
                    converged: true,
                    gradient_norm: grad_norm,
                    message: "Converged: gradient norm below tolerance"
                )

            x = adagrad_update(state, x, gradient, config.learning_rate)

            iteration = iteration + 1
            sample_idx = sample_idx + 1

        epoch = epoch + 1

    OptimizationResult(
        solution: x,
        objective_value: 0.0,
        iterations: iteration,
        converged: converged,
        gradient_norm: 0.0,
        message: "Maximum iterations reached"
    )

# ============================================================================
# Learning Rate Schedules
# ============================================================================

fn lr_constant(initial_lr: f64, epoch: i64) -> f64:
    initial_lr

fn lr_exponential_decay(initial_lr: f64, epoch: i64, decay_rate: f64) -> f64:
    initial_lr * pow(decay_rate, float(epoch))

fn lr_step_decay(initial_lr: f64, epoch: i64, step_size: i64, gamma: f64) -> f64:
    val num_steps = epoch / step_size
    initial_lr * pow(gamma, float(num_steps))

fn lr_inverse_time_decay(initial_lr: f64, epoch: i64, decay_rate: f64) -> f64:
    initial_lr / (1.0 + decay_rate * float(epoch))

fn lr_cosine_annealing(initial_lr: f64, epoch: i64, total_epochs: i64, min_lr: f64) -> f64:
    val pi = 3.141592653589793
    val cos_inner = pi * float(epoch) / float(total_epochs)
    val cos_val = cos(cos_inner)
    min_lr + (initial_lr - min_lr) * (1.0 + cos_val) / 2.0

fn lr_warmup_cosine(initial_lr: f64, epoch: i64, warmup_epochs: i64,
                   total_epochs: i64, min_lr: f64) -> f64:
    if epoch < warmup_epochs:
        return initial_lr * float(epoch) / float(warmup_epochs)

    val adjusted_epoch = epoch - warmup_epochs
    val adjusted_total = total_epochs - warmup_epochs
    lr_cosine_annealing(initial_lr, adjusted_epoch, adjusted_total, min_lr)

# ============================================================================
# Constrained Optimization - Penalty Method
# ============================================================================

fn penalty_method(f: fn(List<f64>) -> f64,
                 constraints: fn(List<f64>) -> List<f64>,
                 grad_f: fn(List<f64>) -> List<f64>,
                 x0: List<f64>, config: OptimizationConfig,
                 mu_init: f64, mu_scale: f64) -> OptimizationResult:
    var mu = mu_init
    var x = vector_copy(x0)
    var outer_iteration = 0
    val max_outer = 20

    while outer_iteration < max_outer:
        # Define augmented objective function
        fn augmented_f(x_val: List<f64>) -> f64:
            val f_val = f(x_val)
            val c = constraints(x_val)
            var penalty = 0.0
            var i = 0
            while i < c.length():
                val violation = max(0.0, c[i])
                penalty = penalty + violation * violation
                i = i + 1
            f_val + mu * penalty

        fn augmented_grad(x_val: List<f64>) -> List<f64>:
            val grad = grad_f(x_val)
            val c = constraints(x_val)

            val epsilon = 1e-6
            val grad_penalty = finite_difference_gradient(augmented_f, x_val, epsilon)

            grad_penalty

        val result = gradient_descent(augmented_f, augmented_grad, x, config)
        x = result.solution

        val c = constraints(x)
        var max_violation = 0.0
        var i = 0
        while i < c.length():
            val violation = max(0.0, c[i])
            if violation > max_violation:
                max_violation = violation
            i = i + 1

        if max_violation < config.tolerance:
            return OptimizationResult(
                solution: x,
                objective_value: f(x),
                iterations: outer_iteration,
                converged: true,
                gradient_norm: result.gradient_norm,
                message: "Converged: constraints satisfied"
            )

        mu = mu * mu_scale
        outer_iteration = outer_iteration + 1

    OptimizationResult(
        solution: x,
        objective_value: f(x),
        iterations: outer_iteration,
        converged: false,
        gradient_norm: 0.0,
        message: "Maximum outer iterations reached"
    )

# ============================================================================
# Barrier Method
# ============================================================================

fn log_barrier(x: f64, t: f64) -> f64:
    if x > 0.0:
        return -log(x) / t
    1e10

fn barrier_method(f: fn(List<f64>) -> f64,
                 inequality_constraints: fn(List<f64>) -> List<f64>,
                 grad_f: fn(List<f64>) -> List<f64>,
                 x0: List<f64>, config: OptimizationConfig,
                 t_init: f64, mu: f64) -> OptimizationResult:
    var t = t_init
    var x = vector_copy(x0)
    var outer_iteration = 0
    val max_outer = 30

    while outer_iteration < max_outer:
        fn barrier_f(x_val: List<f64>) -> f64:
            val f_val = f(x_val)
            val c = inequality_constraints(x_val)
            var barrier = 0.0
            var i = 0
            while i < c.length():
                barrier = barrier + log_barrier(-c[i], t)
                i = i + 1
            f_val + barrier

        fn barrier_grad(x_val: List<f64>) -> List<f64>:
            val epsilon = 1e-6
            finite_difference_gradient(barrier_f, x_val, epsilon)

        val result = gradient_descent(barrier_f, barrier_grad, x, config)
        x = result.solution

        val m = inequality_constraints(x).length()
        if float(m) / t < config.tolerance:
            return OptimizationResult(
                solution: x,
                objective_value: f(x),
                iterations: outer_iteration,
                converged: true,
                gradient_norm: result.gradient_norm,
                message: "Converged: barrier method"
            )

        t = t * mu
        outer_iteration = outer_iteration + 1

    OptimizationResult(
        solution: x,
        objective_value: f(x),
        iterations: outer_iteration,
        converged: false,
        gradient_norm: 0.0,
        message: "Maximum outer iterations reached"
    )

# ============================================================================
# Derivative-Free - Nelder-Mead Simplex
# ============================================================================

fn nelder_mead(f: fn(List<f64>) -> f64, x0: List<f64>,
              config: OptimizationConfig) -> OptimizationResult:
    val n = x0.length()
    val simplex = []
    val values = []

    # Initialize simplex
    simplex.append(vector_copy(x0))
    values.append(f(x0))

    var i = 0
    while i < n:
        val vertex = vector_copy(x0)
        vertex[i] = vertex[i] + 0.1
        simplex.append(vertex)
        values.append(f(vertex))
        i = i + 1

    val alpha = 1.0   # Reflection
    val gamma = 2.0   # Expansion
    val rho = 0.5     # Contraction
    val sigma = 0.5   # Shrinkage

    var iteration = 0

    while iteration < config.max_iterations:
        # Sort simplex by function values
        var sorted = true
        while sorted:
            sorted = false
            i = 0
            while i < values.length() - 1:
                if values[i] > values[i + 1]:
                    val temp_val = values[i]
                    values[i] = values[i + 1]
                    values[i + 1] = temp_val

                    val temp_vertex = simplex[i]
                    simplex[i] = simplex[i + 1]
                    simplex[i + 1] = temp_vertex

                    sorted = true
                i = i + 1

        # Check convergence
        val range = values[n] - values[0]
        if range < config.tolerance:
            return OptimizationResult(
                solution: simplex[0],
                objective_value: values[0],
                iterations: iteration,
                converged: true,
                gradient_norm: 0.0,
                message: "Converged: function value range below tolerance"
            )

        # Compute centroid
        val centroid = vector_zeros(n)
        i = 0
        while i < n:
            var j = 0
            while j < n:
                centroid[j] = centroid[j] + simplex[i][j]
                j = j + 1
            i = i + 1

        i = 0
        while i < n:
            centroid[i] = centroid[i] / float(n)
            i = i + 1

        # Reflection
        val worst = simplex[n]
        val diff = vector_subtract(centroid, worst)
        val reflected = vector_add(centroid, vector_scale(diff, alpha))
        val f_reflected = f(reflected)

        if values[0] <= f_reflected and f_reflected < values[n - 1]:
            simplex[n] = reflected
            values[n] = f_reflected
        else:
            if f_reflected < values[0]:
                # Expansion
                val diff2 = vector_subtract(reflected, centroid)
                val expanded = vector_add(centroid, vector_scale(diff2, gamma))
                val f_expanded = f(expanded)

                if f_expanded < f_reflected:
                    simplex[n] = expanded
                    values[n] = f_expanded
                else:
                    simplex[n] = reflected
                    values[n] = f_reflected
            else:
                # Contraction
                val diff3 = vector_subtract(worst, centroid)
                val contracted = vector_add(centroid, vector_scale(diff3, rho))
                val f_contracted = f(contracted)

                if f_contracted < values[n]:
                    simplex[n] = contracted
                    values[n] = f_contracted
                else:
                    # Shrinkage
                    i = 1
                    while i <= n:
                        val diff4 = vector_subtract(simplex[i], simplex[0])
                        simplex[i] = vector_add(simplex[0], vector_scale(diff4, sigma))
                        values[i] = f(simplex[i])
                        i = i + 1

        iteration = iteration + 1

    OptimizationResult(
        solution: simplex[0],
        objective_value: values[0],
        iterations: iteration,
        converged: false,
        gradient_norm: 0.0,
        message: "Maximum iterations reached"
    )

# ============================================================================
# Coordinate Descent
# ============================================================================

fn coordinate_descent(f: fn(List<f64>) -> f64, x0: List<f64>,
                     config: OptimizationConfig) -> OptimizationResult:
    var x = vector_copy(x0)
    val n = x.length()
    var iteration = 0
    var converged = false
    var prev_value = f(x)

    while iteration < config.max_iterations:
        var coord_idx = 0
        var any_improvement = false

        while coord_idx < n:
            fn f_coord(alpha: f64) -> f64:
                val x_temp = vector_copy(x)
                x_temp[coord_idx] = alpha
                f(x_temp)

            val x_old = x[coord_idx]
            val a = x_old - 1.0
            val b = x_old + 1.0
            val optimal_alpha = golden_section_search(f_coord, a, b, config.tolerance)

            x[coord_idx] = optimal_alpha

            if abs(optimal_alpha - x_old) > config.tolerance:
                any_improvement = true

            coord_idx = coord_idx + 1

        val new_value = f(x)

        if check_value_convergence(prev_value, new_value, config.value_tolerance):
            converged = true
            return OptimizationResult(
                solution: x,
                objective_value: new_value,
                iterations: iteration,
                converged: true,
                gradient_norm: 0.0,
                message: "Converged: function value change below tolerance"
            )

        if not any_improvement:
            converged = true
            return OptimizationResult(
                solution: x,
                objective_value: new_value,
                iterations: iteration,
                converged: true,
                gradient_norm: 0.0,
                message: "Converged: no coordinate improvement"
            )

        prev_value = new_value
        iteration = iteration + 1

    OptimizationResult(
        solution: x,
        objective_value: f(x),
        iterations: iteration,
        converged: converged,
        gradient_norm: 0.0,
        message: "Maximum iterations reached"
    )

# ============================================================================
# Global Optimization - Simulated Annealing
# ============================================================================

fn simulated_annealing(f: fn(List<f64>) -> f64, x0: List<f64>,
                      temp_init: f64, temp_min: f64, alpha: f64,
                      config: OptimizationConfig) -> OptimizationResult:
    var x = vector_copy(x0)
    var best_x = vector_copy(x)
    var f_x = f(x)
    var best_f = f_x
    var temp = temp_init
    var iteration = 0

    while iteration < config.max_iterations and temp > temp_min:
        # Generate random neighbor
        val neighbor = []
        var i = 0
        while i < x.length():
            val perturbation = (random() - 0.5) * 0.2
            neighbor.append(x[i] + perturbation)
            i = i + 1

        val f_neighbor = f(neighbor)
        val delta = f_neighbor - f_x

        # Accept or reject
        var accept = false
        if delta < 0.0:
            accept = true
        else:
            val prob = exp(-delta / temp)
            if random() < prob:
                accept = true

        if accept:
            x = neighbor
            f_x = f_neighbor

            if f_x < best_f:
                best_x = vector_copy(x)
                best_f = f_x

        temp = temp * alpha
        iteration = iteration + 1

    OptimizationResult(
        solution: best_x,
        objective_value: best_f,
        iterations: iteration,
        converged: temp <= temp_min,
        gradient_norm: 0.0,
        message: "Simulated annealing completed"
    )

# ============================================================================
# Particle Swarm Optimization
# ============================================================================

class Particle:
    position: List<f64>
    velocity: List<f64>
    best_position: List<f64>
    best_value: f64

fn pso_optimize(f: fn(List<f64>) -> f64, bounds_low: List<f64>, bounds_high: List<f64>,
               num_particles: i64, config: OptimizationConfig) -> OptimizationResult:
    val n = bounds_low.length()
    val particles = []
    var global_best_position = vector_zeros(n)
    var global_best_value = 1e10

    # Initialize particles
    var p = 0
    while p < num_particles:
        val position = []
        val velocity = []
        var i = 0
        while i < n:
            val pos = bounds_low[i] + random() * (bounds_high[i] - bounds_low[i])
            val vel = (random() - 0.5) * (bounds_high[i] - bounds_low[i]) * 0.1
            position.append(pos)
            velocity.append(vel)
            i = i + 1

        val value = f(position)
        val particle = Particle(
            position: position,
            velocity: velocity,
            best_position: vector_copy(position),
            best_value: value
        )
        particles.append(particle)

        if value < global_best_value:
            global_best_position = vector_copy(position)
            global_best_value = value

        p = p + 1

    val w = 0.7      # Inertia weight
    val c1 = 1.5     # Cognitive parameter
    val c2 = 1.5     # Social parameter

    var iteration = 0
    while iteration < config.max_iterations:
        p = 0
        while p < num_particles:
            val particle = particles[p]

            # Update velocity
            var i = 0
            while i < n:
                val r1 = random()
                val r2 = random()
                val cognitive = c1 * r1 * (particle.best_position[i] - particle.position[i])
                val social = c2 * r2 * (global_best_position[i] - particle.position[i])
                particle.velocity[i] = w * particle.velocity[i] + cognitive + social
                i = i + 1

            # Update position
            i = 0
            while i < n:
                particle.position[i] = particle.position[i] + particle.velocity[i]

                # Enforce bounds
                if particle.position[i] < bounds_low[i]:
                    particle.position[i] = bounds_low[i]
                if particle.position[i] > bounds_high[i]:
                    particle.position[i] = bounds_high[i]
                i = i + 1

            # Evaluate
            val value = f(particle.position)

            # Update personal best
            if value < particle.best_value:
                particle.best_position = vector_copy(particle.position)
                particle.best_value = value

            # Update global best
            if value < global_best_value:
                global_best_position = vector_copy(particle.position)
                global_best_value = value

            p = p + 1

        iteration = iteration + 1

    OptimizationResult(
        solution: global_best_position,
        objective_value: global_best_value,
        iterations: iteration,
        converged: false,
        gradient_norm: 0.0,
        message: "PSO optimization completed"
    )

# ============================================================================
# Utility Functions
# ============================================================================

fn create_default_config() -> OptimizationConfig:
    OptimizationConfig(
        max_iterations: 1000,
        tolerance: 1e-6,
        learning_rate: 0.01,
        verbose: false,
        gradient_tolerance: 1e-6,
        value_tolerance: 1e-9,
        parameter_tolerance: 1e-8
    )

fn evaluate_objective(f: fn(List<f64>) -> f64, x: List<f64>) -> f64:
    f(x)

fn check_constraint_satisfaction(constraints: fn(List<f64>) -> List<f64>,
                                 x: List<f64>, tolerance: f64) -> bool:
    val c = constraints(x)
    var i = 0
    while i < c.length():
        if abs(c[i]) > tolerance:
            return false
        i = i + 1
    true

fn validate_solution(result: OptimizationResult, expected_value: f64, tolerance: f64) -> bool:
    abs(result.objective_value - expected_value) < tolerance

fn print_optimization_result(result: OptimizationResult):
    print "Optimization Result:"
    print "  Converged: {result.converged}"
    print "  Iterations: {result.iterations}"
    print "  Objective Value: {result.objective_value}"
    print "  Gradient Norm: {result.gradient_norm}"
    print "  Message: {result.message}"
    print "  Solution: {result.solution}"

# ============================================================================
# Helper Functions
# ============================================================================

fn random() -> f64:
    # Simple linear congruential generator
    # In practice, use platform-specific random number generator
    0.5

fn abs(x: f64) -> f64:
    if x < 0.0:
        return -x
    x

fn max(a: f64, b: f64) -> f64:
    if a > b:
        return a
    b

fn min(a: f64, b: f64) -> f64:
    if a < b:
        return a
    b

fn sqrt(x: f64) -> f64:
    if x < 0.0:
        return 0.0

    if x == 0.0:
        return 0.0

    var guess = x / 2.0
    var i = 0
    while i < 20:
        guess = (guess + x / guess) / 2.0
        i = i + 1
    guess

fn pow(base: f64, exponent: f64) -> f64:
    if exponent == 0.0:
        return 1.0

    if exponent < 0.0:
        return 1.0 / pow(base, -exponent)

    var result = 1.0
    var i = 0
    while i < int(exponent):
        result = result * base
        i = i + 1
    result

fn exp(x: f64) -> f64:
    # Taylor series approximation
    var sum = 1.0
    var term = 1.0
    var i = 1
    while i < 20:
        term = term * x / float(i)
        sum = sum + term
        i = i + 1
    sum

fn log(x: f64) -> f64:
    if x <= 0.0:
        return -1e10

    # Natural logarithm using Newton's method
    var guess = x - 1.0
    var i = 0
    while i < 20:
        val exp_guess = exp(guess)
        guess = guess - (exp_guess - x) / exp_guess
        i = i + 1
    guess

fn cos(x: f64) -> f64:
    # Taylor series approximation
    var sum = 1.0
    var term = 1.0
    var i = 1
    while i < 20:
        term = -term * x * x / float(2 * i * (2 * i - 1))
        sum = sum + term
        i = i + 1
    sum

fn sin(x: f64) -> f64:
    # Taylor series approximation
    var sum = x
    var term = x
    var i = 1
    while i < 20:
        term = -term * x * x / float((2 * i + 1) * (2 * i))
        sum = sum + term
        i = i + 1
    sum

fn float(x: i64) -> f64:
    # Type conversion
    0.0 + x

fn int(x: f64) -> i64:
    # Type conversion (truncation)
    0
