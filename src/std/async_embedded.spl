# Async Embedded - Lightweight Runtime for Embedded Systems
#
# Features:
# - No heap allocation (stack + static only)
# - Fixed-capacity collections
# - Polling-based (no wakers)
# - Simple cooperative scheduling
# - Minimal memory footprint
#
# Constraints:
# - MAX_TASKS tasks maximum
# - MAX_FUTURES futures in JoinSet/FuturesUnordered
# - No dynamic growth
#
# Usage:
#   use std.async_core.*
#   use std.async_embedded.*
#
#   val scheduler = EmbeddedScheduler.new()
#   val handle = scheduler.schedule(\: compute())
#   scheduler.run()

use std.async_core.*

# ============================================================================
# Configuration - Compile-time Capacity Limits
# ============================================================================

# Override these with @config or build flags
val MAX_TASKS: usize = 16
val MAX_FUTURES: usize = 32
val MAX_JOIN_SETS: usize = 4

# ============================================================================
# EmbeddedFuture<T> - Stack-based Future
# ============================================================================

struct EmbeddedFuture<T>:
    """Lightweight future for embedded systems.

    Stores state inline - no heap allocation.
    """
    value: Option<T>
    is_complete: bool

    static fn ready(v: T) -> EmbeddedFuture<T>:
        """Create completed future."""
        EmbeddedFuture(value: Some(v), is_complete: true)

    static fn pending() -> EmbeddedFuture<T>:
        """Create pending future."""
        EmbeddedFuture(value: nil, is_complete: false)

    fn poll() -> Poll<T>:
        """Poll future (non-blocking)."""
        if self.is_complete:
            match self.value:
                case Some(v): Poll.Ready(v)
                case None: Poll.Pending
        else:
            Poll.Pending

    fn is_ready() -> bool:
        self.is_complete

    me complete(v: T):
        """Complete future with value."""
        self.value = Some(v)
        self.is_complete = true

# Note: EmbeddedFuture implements FutureCore interface via duck typing

# ============================================================================
# EmbeddedPromise<T> - Stack-based Promise
# ============================================================================

struct EmbeddedPromise<T>:
    """Write-side of a future for embedded systems."""
    future_idx: usize
    completed: bool

    static fn new() -> (EmbeddedFuture<T>, EmbeddedPromise<T>):
        """Create future-promise pair."""
        val future: EmbeddedFuture<T> = EmbeddedFuture.pending()
        val promise = EmbeddedPromise(future_idx: 0, completed: false)
        (future, promise)

    fn is_completed() -> bool:
        self.completed

# ============================================================================
# EmbeddedTaskHandle<T> - Lightweight Task Handle
# ============================================================================

struct EmbeddedTaskHandle<T>:
    """Handle to a spawned task.

    Fixed-size, no heap allocation.
    """
    task_id: usize
    state: TaskState
    result: Option<T>
    priority: Priority

    fn id() -> usize:
        self.task_id

    fn is_finished() -> bool:
        """Non-blocking completion check."""
        self.state.is_terminal()

    fn try_join() -> Option<T>:
        """Non-blocking result retrieval."""
        if self.is_finished():
            self.result
        else:
            nil

    fn state() -> TaskState:
        self.state

# Note: EmbeddedTaskHandle implements TaskHandleCore interface via duck typing

# ============================================================================
# EmbeddedJoinSet<T> - Fixed-Capacity Task Group
# ============================================================================

struct EmbeddedJoinSet<T>:
    """Fixed-capacity task group for embedded systems.

    Spawns tasks and yields results as they complete.

    Example:
        var set = EmbeddedJoinSet<i64>.new()
        set.add_task(compute(1))
        set.add_task(compute(2))

        while val Some((id, val)) = set.try_join_next():
            print "Task {id}: {val}"
    """
    # Arrays with implicit capacity (enforced at runtime)
    task_ids: [usize]
    results: [Option<T>]
    states: [TaskState]
    count: usize
    completed_mask: u64  # Bitmask of completed tasks

    static fn new() -> EmbeddedJoinSet<T>:
        """Create empty join set."""
        EmbeddedJoinSet(
            task_ids: [],
            results: [],
            states: [],
            count: 0,
            completed_mask: 0
        )

    fn len() -> usize:
        self.count

    fn is_empty() -> bool:
        self.count == 0

    fn is_full() -> bool:
        self.count >= MAX_FUTURES

    fn capacity() -> usize:
        MAX_FUTURES

    me add_task(task_id: usize) -> Result<usize, AsyncError>:
        """Add task by ID (for scheduler integration)."""
        if self.is_full():
            return Err(AsyncError.CapacityExceeded)

        val idx = self.count
        self.task_ids[idx] = task_id
        self.states[idx] = TaskState.Pending
        self.results[idx] = nil
        self.count = self.count + 1
        Ok(idx)

    me mark_completed(idx: usize, result: T):
        """Mark task at index as completed."""
        if idx < self.count:
            self.states[idx] = TaskState.Completed
            self.results[idx] = Some(result)
            self.completed_mask = self.completed_mask | (1 << idx)

    fn try_join_next() -> Option<(usize, T)>:
        """Non-blocking: get next completed result."""
        if self.completed_mask == 0:
            return nil

        # Find first completed task
        for idx in 0..self.count:
            if (self.completed_mask & (1 << idx)) != 0:
                match self.results[idx]:
                    case Some(result):
                        val task_id = self.task_ids[idx]
                        # Clear from mask (consume result)
                        self.completed_mask = self.completed_mask & ~(1 << idx)
                        return Some((task_id, result))
                    case None:
                        pass
        nil

    fn pending_count() -> usize:
        """Count of tasks not yet completed."""
        var count: usize = 0
        for idx in 0..self.count:
            if not self.states[idx].is_terminal():
                count = count + 1
        count

    fn all_completed() -> bool:
        """Check if all tasks are done."""
        self.pending_count() == 0

# Note: EmbeddedJoinSet implements JoinSetCore interface via duck typing

# ============================================================================
# EmbeddedFuturesUnordered<T> - Fixed-Capacity Future Stream
# ============================================================================

struct EmbeddedFuturesUnordered<T>:
    """Fixed-capacity collection of futures.

    Polls futures and yields results as they complete.

    Example:
        var futs = EmbeddedFuturesUnordered<i64>.new()
        futs.push(future1)
        futs.push(future2)

        while val Some(result) = futs.try_next():
            print "Got: {result}"
    """
    futures: [EmbeddedFuture<T>]
    active_mask: u64  # Bitmask of active (not-yet-completed) futures
    count: usize

    static fn new() -> EmbeddedFuturesUnordered<T>:
        """Create empty collection."""
        EmbeddedFuturesUnordered(
            futures: [],
            active_mask: 0,
            count: 0
        )

    fn len() -> usize:
        self.count

    fn is_empty() -> bool:
        self.count == 0

    fn capacity() -> usize:
        MAX_FUTURES

    me push(f: EmbeddedFuture<T>) -> Result<usize, AsyncError>:
        """Add future to collection."""
        if self.count >= MAX_FUTURES:
            return Err(AsyncError.CapacityExceeded)

        val idx = self.count
        self.futures[idx] = f
        self.active_mask = self.active_mask | (1 << idx)
        self.count = self.count + 1
        Ok(idx)

    fn try_next() -> Option<T>:
        """Non-blocking: poll all and return first ready."""
        if self.active_mask == 0:
            return nil

        # Poll each active future
        for idx in 0..self.count:
            if (self.active_mask & (1 << idx)) != 0:
                match self.futures[idx].poll():
                    case Poll.Ready(value):
                        # Deactivate this future
                        self.active_mask = self.active_mask & ~(1 << idx)
                        return Some(value)
                    case Poll.Pending:
                        pass
        nil

    fn active_count() -> usize:
        """Count of futures not yet completed."""
        var count: usize = 0
        var mask = self.active_mask
        while mask != 0:
            count = count + (mask & 1)
            mask = mask >> 1
        count

# Note: EmbeddedFuturesUnordered implements FuturesUnorderedCore via duck typing

# ============================================================================
# EmbeddedTask - Internal Task Representation
# ============================================================================

struct EmbeddedTask:
    """Internal task for scheduler."""
    id: usize
    state: TaskState
    priority: Priority
    poll_fn: fn() -> Poll<()>  # Type-erased poll function

# ============================================================================
# EmbeddedScheduler - Cooperative Scheduler
# ============================================================================

struct EmbeddedScheduler:
    """Simple cooperative scheduler for embedded systems.

    Features:
    - Fixed task capacity
    - Priority-based scheduling
    - Round-robin within priority
    - No heap allocation

    Example:
        var scheduler = EmbeddedScheduler.new()

        scheduler.schedule(Priority.Normal, \:
            val x = compute()
            Poll.Ready(())
        )

        scheduler.run()
    """
    tasks: [EmbeddedTask]
    task_count: usize
    next_id: usize
    current_task: usize
    is_running: bool

    static fn new() -> EmbeddedScheduler:
        """Create new scheduler."""
        EmbeddedScheduler(
            tasks: [],
            task_count: 0,
            next_id: 0,
            current_task: 0,
            is_running: false
        )

    me schedule(priority: Priority, poll_fn: fn() -> Poll<()>) -> Result<usize, AsyncError>:
        """Schedule new task with priority."""
        if self.task_count >= MAX_TASKS:
            return Err(AsyncError.CapacityExceeded)

        val id = self.next_id
        self.next_id = self.next_id + 1

        val idx = self.task_count
        self.tasks[idx] = EmbeddedTask(
            id: id,
            state: TaskState.Pending,
            priority: priority,
            poll_fn: poll_fn
        )
        self.task_count = self.task_count + 1

        Ok(id)

    me schedule_default(poll_fn: fn() -> Poll<()>) -> Result<usize, AsyncError>:
        """Schedule with default (Normal) priority."""
        self.schedule(Priority.Normal, poll_fn)

    fn has_runnable() -> bool:
        """Check if any tasks can run."""
        for idx in 0..self.task_count:
            if self.tasks[idx].state.is_runnable():
                return true
        false

    me run_one() -> bool:
        """Run one task iteration. Returns true if work was done."""
        if not self.has_runnable():
            return false

        # Find highest priority runnable task
        var best_idx: usize = 0
        var best_priority: i32 = 999
        var found = false

        for idx in 0..self.task_count:
            val task = self.tasks[idx]
            if task.state.is_runnable():
                val pri = task.priority.to_i32()
                if pri < best_priority:
                    best_priority = pri
                    best_idx = idx
                    found = true

        if not found:
            return false

        # Run selected task
        var task = self.tasks[best_idx]
        task.state = TaskState.Running
        self.current_task = best_idx

        match task.poll_fn():
            case Poll.Ready(_):
                task.state = TaskState.Completed
            case Poll.Pending:
                task.state = TaskState.Suspended

        self.tasks[best_idx] = task
        true

    me run():
        """Run until all tasks complete."""
        self.is_running = true
        while self.is_running and self.has_runnable():
            self.run_one()
        self.is_running = false

    me run_n(n: usize):
        """Run exactly n iterations."""
        for _ in 0..n:
            if not self.run_one():
                break

    me stop():
        """Stop scheduler."""
        self.is_running = false

    fn is_idle() -> bool:
        """Check if scheduler is idle."""
        not self.has_runnable()

    fn task_count() -> usize:
        self.task_count

    fn active_count() -> usize:
        """Count of non-terminal tasks."""
        var count: usize = 0
        for idx in 0..self.task_count:
            if not self.tasks[idx].state.is_terminal():
                count = count + 1
        count

# Note: EmbeddedScheduler implements SchedulerCore via duck typing

# ============================================================================
# Utility Functions
# ============================================================================

fn yield_now() -> Poll<()>:
    """Yield to scheduler (cooperative yield)."""
    Poll.Pending

fn ready<T>(value: T) -> Poll<T>:
    """Create ready poll result."""
    Poll.Ready(value)

fn pending<T>() -> Poll<T>:
    """Create pending poll result."""
    Poll.Pending

# ============================================================================
# Exports
# ============================================================================

export EmbeddedFuture
export EmbeddedPromise
export EmbeddedTaskHandle
export EmbeddedJoinSet
export EmbeddedFuturesUnordered
export EmbeddedTask
export EmbeddedScheduler
export yield_now
export ready
export pending
export MAX_TASKS
export MAX_FUTURES
