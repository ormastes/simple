# GPU Device Management
#
# Provides unified device selection and management across CUDA and Vulkan backends.

use io.cuda_ffi.*
use io.vulkan_ffi.*

# ============================================================================
# GPU Backend Selection
# ============================================================================

"""
Available GPU backends.
"""
enum GpuBackend:
    Cuda       # NVIDIA CUDA
    Vulkan     # Vulkan compute
    None       # No GPU available

"""
Detect which GPU backends are available.
"""
fn detect_backends() -> [GpuBackend]:
    var backends: [GpuBackend] = []
    if cuda_available():
        backends.push(GpuBackend.Cuda)
    if vulkan_available():
        backends.push(GpuBackend.Vulkan)
    backends

"""
Get the preferred GPU backend.
Order of preference: CUDA > Vulkan.
"""
fn preferred_backend() -> GpuBackend:
    if cuda_available():
        GpuBackend.Cuda
    elif vulkan_available():
        GpuBackend.Vulkan
    else:
        GpuBackend.None

# ============================================================================
# Unified GPU Device
# ============================================================================

"""
Unified GPU device abstraction.
Works with both CUDA and Vulkan backends.
"""
struct Gpu:
    backend: GpuBackend
    device_id: i64
    is_initialized: bool

"""
Get the default GPU (uses preferred backend and device 0).
"""
fn gpu_default() -> Gpu:
    val backend = preferred_backend()
    match backend:
        case Cuda:
            cuda_set_device(0)
            Gpu(backend: backend, device_id: 0, is_initialized: true)
        case Vulkan:
            vulkan_init()
            vulkan_select_device(0)
            Gpu(backend: backend, device_id: 0, is_initialized: true)
        case None:
            Gpu(backend: backend, device_id: -1, is_initialized: false)

"""
Get a CUDA device by ID.
"""
fn gpu_cuda(id: i64) -> Gpu:
    if not cuda_available():
        Gpu(backend: GpuBackend.None, device_id: -1, is_initialized: false)
    else:
        cuda_set_device(id)
        Gpu(backend: GpuBackend.Cuda, device_id: id, is_initialized: true)

"""
Get a Vulkan device by ID.
"""
fn gpu_vulkan(id: i64) -> Gpu:
    if not vulkan_available():
        Gpu(backend: GpuBackend.None, device_id: -1, is_initialized: false)
    else:
        vulkan_init()
        vulkan_select_device(id)
        Gpu(backend: GpuBackend.Vulkan, device_id: id, is_initialized: true)

impl Gpu:
    """
    Check if this GPU device is valid and usable.
    """
    fn is_valid() -> bool:
        self.is_initialized and self.backend != GpuBackend.None

    """
    Get the name of this GPU device.
    """
    fn name() -> text:
        if not self.is_valid():
            "No GPU"
        else:
            match self.backend:
                case Cuda:
                    val info = cuda_device_info(self.device_id)
                    info.name
                case Vulkan:
                    val info = vulkan_device_info(self.device_id)
                    info.name
                case None:
                    "No GPU"

    """
    Get the total memory of this GPU device in bytes.
    """
    fn total_memory() -> i64:
        if not self.is_valid():
            0
        else:
            match self.backend:
                case Cuda:
                    val info = cuda_device_info(self.device_id)
                    info.total_memory
                case Vulkan:
                    val info = vulkan_device_info(self.device_id)
                    info.total_memory
                case None:
                    0

    """
    Get backend-specific information.
    """
    fn backend_name() -> text:
        match self.backend:
            case Cuda: "CUDA"
            case Vulkan: "Vulkan"
            case None: "None"

    """
    Synchronize (wait for all operations on this device to complete).
    """
    fn sync() -> bool:
        if not self.is_valid():
            true
        else:
            match self.backend:
                case Cuda: cuda_sync()
                case Vulkan: vulkan_wait_idle()
                case None: true

# ============================================================================
# Device Enumeration
# ============================================================================

"""
List all available GPU devices across all backends.
"""
struct GpuDeviceEntry:
    backend: GpuBackend
    device_id: i64
    name: text
    memory: i64

fn list_all_gpus() -> [GpuDeviceEntry]:
    var devices: [GpuDeviceEntry] = []

    # Enumerate CUDA devices
    if cuda_available():
        val count = cuda_device_count()
        for i in 0..count:
            val info = cuda_device_info(i)
            devices.push(GpuDeviceEntry(
                backend: GpuBackend.Cuda,
                device_id: i,
                name: info.name,
                memory: info.total_memory
            ))

    # Enumerate Vulkan devices
    if vulkan_available():
        vulkan_init()
        val count = vulkan_device_count()
        for i in 0..count:
            val info = vulkan_device_info(i)
            devices.push(GpuDeviceEntry(
                backend: GpuBackend.Vulkan,
                device_id: i,
                name: info.name,
                memory: info.total_memory
            ))

    devices

"""
Check if any GPU is available.
"""
fn gpu_available() -> bool:
    cuda_available() or vulkan_available()

"""
Get the total number of GPUs across all backends.
"""
fn gpu_count() -> i64:
    var count: i64 = 0
    if cuda_available():
        count = count + cuda_device_count()
    if vulkan_available():
        vulkan_init()
        count = count + vulkan_device_count()
    count

# ============================================================================
# Exports
# ============================================================================

export GpuBackend, detect_backends, preferred_backend
export Gpu, gpu_default, gpu_cuda, gpu_vulkan
export GpuDeviceEntry, list_all_gpus, gpu_available, gpu_count
