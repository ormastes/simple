# Regular Expression Engine Utilities
#
# Comprehensive regex engine implementation with NFA/DFA construction.
# Pure Simple implementation - no FFI, no external dependencies.
#
# CRITICAL CONSTRAINTS:
# - NO generics at runtime (use concrete types)
# - NO try/catch/throw (use Option/nil for errors)
# - NO chained methods (use intermediate variables)
# - Tuple-based data structures for states and transitions
#
# FEATURES:
# - Regex syntax: literals, character classes, quantifiers, groups, alternation
# - Character classes: [abc], [^abc], [a-z], \d, \w, \s, \D, \W, \S, .
# - Quantifiers: *, +, ?, {n}, {n,}, {n,m}, lazy variants (*?, +?, ??)
# - Anchors: ^, $, \b, \B
# - Groups: capturing groups (), non-capturing (?:), named groups (?<name>)
# - Alternation: |
# - Escapes: \., \*, \+, \\, etc.
# - NFA construction: Thompson's construction from regex to NFA
# - DFA construction: subset construction from NFA to DFA
# - Matching: find, match, test, exec operations
# - Capture groups: extract matched groups
# - Replace: replace with captured groups ($1, $2, etc.)
# - Utility functions: escape special chars, validate regex syntax
#
# PUBLIC API (85+ functions):
# - Tokenization: tokenize_regex, token_type, token_value
# - Parsing: parse_regex, parse_alternation, parse_concatenation, parse_quantifier
# - NFA: nfa_create, nfa_add_state, nfa_add_transition, nfa_epsilon_closure
# - Thompson's: thompson_literal, thompson_concat, thompson_union, thompson_star
# - DFA: dfa_create, dfa_minimize, subset_construction
# - Matching: regex_match, regex_test, regex_find, regex_exec
# - Groups: extract_groups, group_at, group_count, group_names
# - Replace: regex_replace, regex_replace_all, regex_replace_fn
# - Character classes: char_class_create, char_class_matches, parse_char_class
# - Escapes: escape_regex, unescape_regex, expand_escape
# - Validation: validate_regex, check_balanced_parens, check_valid_quantifier
# - Utilities: optimize_nfa, print_nfa, print_dfa, regex_stats

# ============================================================================
# DATA STRUCTURES
# ============================================================================

class RegexToken:
    """Token from regex lexer."""
    token_type: text    # "literal", "dot", "star", "plus", "question", "pipe", "lparen", "rparen", "lbracket", "rbracket", "lbrace", "rbrace", "caret", "dollar", "escape", "eof"
    value: text         # Token value (character or escape sequence)
    pos: i64            # Position in input string

class RegexAST:
    """Abstract syntax tree node for regex."""
    node_type: text     # "literal", "dot", "char_class", "concat", "alternation", "quantifier", "group", "anchor"
    value: text         # Value for literals, class definition for char_class
    children: [any]     # Child AST nodes
    min_count: i64      # For quantifiers: minimum repetitions
    max_count: i64      # For quantifiers: maximum repetitions (-1 for infinity)
    lazy: bool          # For quantifiers: lazy matching
    negated: bool       # For char_class: negated class [^...]
    group_id: i64       # For groups: group number
    group_name: text    # For named groups: group name

class NFAState:
    """State in NFA automaton."""
    state_id: i64       # Unique state identifier
    is_accept: bool     # True if this is an accepting state
    group_start: i64    # Group ID if this starts a group capture (-1 otherwise)
    group_end: i64      # Group ID if this ends a group capture (-1 otherwise)

class NFATransition:
    """Transition in NFA automaton."""
    from_state: i64     # Source state ID
    to_state: i64       # Destination state ID
    symbol: text        # Input symbol (empty string for epsilon transition)
    char_class: text    # Character class definition if applicable

class NFA:
    """Non-deterministic finite automaton."""
    states: [any]       # Array of NFAState
    transitions: [any]  # Array of NFATransition
    start_state: i64    # Start state ID
    accept_state: i64   # Accept state ID
    next_state_id: i64  # Counter for generating unique state IDs
    group_count: i64    # Number of capture groups

class DFAState:
    """State in DFA automaton."""
    state_id: i64       # Unique state identifier
    is_accept: bool     # True if this is an accepting state
    nfa_states: [i64]   # Set of NFA states this DFA state represents

class DFATransition:
    """Transition in DFA automaton."""
    from_state: i64     # Source state ID
    to_state: i64       # Destination state ID
    symbol: text        # Input symbol

class DFA:
    """Deterministic finite automaton."""
    states: [any]       # Array of DFAState
    transitions: [any]  # Array of DFATransition
    start_state: i64    # Start state ID
    accept_states: [i64] # List of accept state IDs

class MatchState:
    """Current state during regex matching."""
    pos: i64            # Current position in input string
    nfa_states: [i64]   # Current set of NFA states
    groups: [any]       # Captured groups: array of (start, end) tuples
    backtrack_stack: [any] # Stack for backtracking: array of MatchState snapshots

class MatchResult:
    """Result of a regex match operation."""
    matched: bool       # Whether a match was found
    start_pos: i64      # Start position of match in input
    end_pos: i64        # End position of match in input (exclusive)
    groups: [any]       # Captured groups: array of (start, end, text) tuples
    group_names: {text: i64} # Map from group names to group IDs

# ============================================================================
# CHARACTER UTILITIES
# ============================================================================

fn char_code(ch: text) -> i64:
    """Get ASCII code of character."""
    if ch == "": return 0
    if ch == " ": return 32
    if ch == "!": return 33
    if ch == "\"": return 34
    if ch == "#": return 35
    if ch == "$": return 36
    if ch == "%": return 37
    if ch == "&": return 38
    if ch == "'": return 39
    if ch == "(": return 40
    if ch == ")": return 41
    if ch == "*": return 42
    if ch == "+": return 43
    if ch == ",": return 44
    if ch == "-": return 45
    if ch == ".": return 46
    if ch == "/": return 47
    if ch == "0": return 48
    if ch == "1": return 49
    if ch == "2": return 50
    if ch == "3": return 51
    if ch == "4": return 52
    if ch == "5": return 53
    if ch == "6": return 54
    if ch == "7": return 55
    if ch == "8": return 56
    if ch == "9": return 57
    if ch == ":": return 58
    if ch == ";": return 59
    if ch == "<": return 60
    if ch == "=": return 61
    if ch == ">": return 62
    if ch == "?": return 63
    if ch == "@": return 64
    if ch == "A": return 65
    if ch == "B": return 66
    if ch == "C": return 67
    if ch == "D": return 68
    if ch == "E": return 69
    if ch == "F": return 70
    if ch == "G": return 71
    if ch == "H": return 72
    if ch == "I": return 73
    if ch == "J": return 74
    if ch == "K": return 75
    if ch == "L": return 76
    if ch == "M": return 77
    if ch == "N": return 78
    if ch == "O": return 79
    if ch == "P": return 80
    if ch == "Q": return 81
    if ch == "R": return 82
    if ch == "S": return 83
    if ch == "T": return 84
    if ch == "U": return 85
    if ch == "V": return 86
    if ch == "W": return 87
    if ch == "X": return 88
    if ch == "Y": return 89
    if ch == "Z": return 90
    if ch == "[": return 91
    if ch == "\\": return 92
    if ch == "]": return 93
    if ch == "^": return 94
    if ch == "_": return 95
    if ch == "`": return 96
    if ch == "a": return 97
    if ch == "b": return 98
    if ch == "c": return 99
    if ch == "d": return 100
    if ch == "e": return 101
    if ch == "f": return 102
    if ch == "g": return 103
    if ch == "h": return 104
    if ch == "i": return 105
    if ch == "j": return 106
    if ch == "k": return 107
    if ch == "l": return 108
    if ch == "m": return 109
    if ch == "n": return 110
    if ch == "o": return 111
    if ch == "p": return 112
    if ch == "q": return 113
    if ch == "r": return 114
    if ch == "s": return 115
    if ch == "t": return 116
    if ch == "u": return 117
    if ch == "v": return 118
    if ch == "w": return 119
    if ch == "x": return 120
    if ch == "y": return 121
    if ch == "z": return 122
    if ch == "{": return 123
    if ch == "|": return 124
    if ch == "}": return 125
    if ch == "~": return 126
    if ch == "\n": return 10
    if ch == "\t": return 9
    if ch == "\r": return 13
    0

fn is_digit_char(ch: text) -> bool:
    """Check if character is a digit (0-9)."""
    val code = char_code(ch)
    code >= 48 and code <= 57

fn is_alpha_char(ch: text) -> bool:
    """Check if character is alphabetic (a-z, A-Z)."""
    val code = char_code(ch)
    val is_upper = code >= 65 and code <= 90
    val is_lower = code >= 97 and code <= 122
    is_upper or is_lower

fn is_alnum_char(ch: text) -> bool:
    """Check if character is alphanumeric."""
    is_alpha_char(ch) or is_digit_char(ch)

fn is_word_char(ch: text) -> bool:
    """Check if character is a word character (alphanumeric or underscore)."""
    is_alnum_char(ch) or ch == "_"

fn is_whitespace_char(ch: text) -> bool:
    """Check if character is whitespace."""
    ch == " " or ch == "\t" or ch == "\n" or ch == "\r"

fn is_hex_char(ch: text) -> bool:
    """Check if character is hexadecimal digit."""
    val code = char_code(ch)
    val is_num = code >= 48 and code <= 57
    val is_upper = code >= 65 and code <= 70
    val is_lower = code >= 97 and code <= 102
    is_num or is_upper or is_lower

fn is_special_regex_char(ch: text) -> bool:
    """Check if character has special meaning in regex."""
    ch == "." or ch == "*" or ch == "+" or ch == "?" or ch == "|" or ch == "(" or ch == ")" or ch == "[" or ch == "]" or ch == "{" or ch == "}" or ch == "^" or ch == "$" or ch == "\\"

# ============================================================================
# ESCAPE SEQUENCES
# ============================================================================

fn escape_regex(text_str: text) -> text:
    """Escape special regex characters for literal matching."""
    var result = ""
    var i = 0
    while i < text_str.len():
        val ch = text_str[i:i + 1]
        if is_special_regex_char(ch):
            result = result + "\\" + ch
        else:
            result = result + ch
        i = i + 1
    result

fn unescape_regex(text_str: text) -> text:
    """Remove escape backslashes from regex string."""
    var result = ""
    var i = 0
    while i < text_str.len():
        val ch = text_str[i:i + 1]
        if ch == "\\":
            if i + 1 < text_str.len():
                val next_ch = text_str[i + 1:i + 2]
                result = result + next_ch
                i = i + 2
            else:
                result = result + ch
                i = i + 1
        else:
            result = result + ch
            i = i + 1
    result

fn expand_escape(esc: text) -> text:
    """Expand escape sequence like \n, \t, \d, \w, \s."""
    if esc == "n": return "\n"
    if esc == "t": return "\t"
    if esc == "r": return "\r"
    if esc == "d": return "[0-9]"
    if esc == "D": return "[^0-9]"
    if esc == "w": return "[a-zA-Z0-9_]"
    if esc == "W": return "[^a-zA-Z0-9_]"
    if esc == "s": return "[ \t\n\r]"
    if esc == "S": return "[^ \t\n\r]"
    if esc == "b": return "\\b"
    if esc == "B": return "\\B"
    esc

fn is_escape_char(ch: text) -> bool:
    """Check if character can be escaped."""
    ch == "n" or ch == "t" or ch == "r" or ch == "d" or ch == "D" or ch == "w" or ch == "W" or ch == "s" or ch == "S" or ch == "b" or ch == "B"

# ============================================================================
# CHARACTER CLASS UTILITIES
# ============================================================================

fn char_class_create(definition: text, negated: bool) -> any:
    """Create character class from definition string."""
    (definition, negated)

fn char_class_parse(definition: text) -> [text]:
    """Parse character class definition into list of characters."""
    var chars = []
    var i = 0
    while i < definition.len():
        val ch = definition[i:i + 1]
        if i + 2 < definition.len():
            val next = definition[i + 1:i + 2]
            val after = definition[i + 2:i + 3]
            if next == "-":
                val start_code = char_code(ch)
                val end_code = char_code(after)
                var code = start_code
                while code <= end_code:
                    chars.push(string_from_code(code))
                    code = code + 1
                i = i + 3
            else:
                chars.push(ch)
                i = i + 1
        else:
            chars.push(ch)
            i = i + 1
    chars

fn string_from_code(code: i64) -> text:
    """Convert ASCII code to string."""
    if code == 32: return " "
    if code == 33: return "!"
    if code == 34: return "\""
    if code == 35: return "#"
    if code == 36: return "$"
    if code == 37: return "%"
    if code == 38: return "&"
    if code == 39: return "'"
    if code == 40: return "("
    if code == 41: return ")"
    if code == 42: return "*"
    if code == 43: return "+"
    if code == 44: return ","
    if code == 45: return "-"
    if code == 46: return "."
    if code == 47: return "/"
    if code == 48: return "0"
    if code == 49: return "1"
    if code == 50: return "2"
    if code == 51: return "3"
    if code == 52: return "4"
    if code == 53: return "5"
    if code == 54: return "6"
    if code == 55: return "7"
    if code == 56: return "8"
    if code == 57: return "9"
    if code == 58: return ":"
    if code == 59: return ";"
    if code == 60: return "<"
    if code == 61: return "="
    if code == 62: return ">"
    if code == 63: return "?"
    if code == 64: return "@"
    if code == 65: return "A"
    if code == 66: return "B"
    if code == 67: return "C"
    if code == 68: return "D"
    if code == 69: return "E"
    if code == 70: return "F"
    if code == 71: return "G"
    if code == 72: return "H"
    if code == 73: return "I"
    if code == 74: return "J"
    if code == 75: return "K"
    if code == 76: return "L"
    if code == 77: return "M"
    if code == 78: return "N"
    if code == 79: return "O"
    if code == 80: return "P"
    if code == 81: return "Q"
    if code == 82: return "R"
    if code == 83: return "S"
    if code == 84: return "T"
    if code == 85: return "U"
    if code == 86: return "V"
    if code == 87: return "W"
    if code == 88: return "X"
    if code == 89: return "Y"
    if code == 90: return "Z"
    if code == 91: return "["
    if code == 92: return "\\"
    if code == 93: return "]"
    if code == 94: return "^"
    if code == 95: return "_"
    if code == 96: return "`"
    if code == 97: return "a"
    if code == 98: return "b"
    if code == 99: return "c"
    if code == 100: return "d"
    if code == 101: return "e"
    if code == 102: return "f"
    if code == 103: return "g"
    if code == 104: return "h"
    if code == 105: return "i"
    if code == 106: return "j"
    if code == 107: return "k"
    if code == 108: return "l"
    if code == 109: return "m"
    if code == 110: return "n"
    if code == 111: return "o"
    if code == 112: return "p"
    if code == 113: return "q"
    if code == 114: return "r"
    if code == 115: return "s"
    if code == 116: return "t"
    if code == 117: return "u"
    if code == 118: return "v"
    if code == 119: return "w"
    if code == 120: return "x"
    if code == 121: return "y"
    if code == 122: return "z"
    if code == 123: return "{"
    if code == 124: return "|"
    if code == 125: return "}"
    if code == 126: return "~"
    if code == 10: return "\n"
    if code == 9: return "\t"
    if code == 13: return "\r"
    ""

fn char_class_matches(char_class: any, ch: text) -> bool:
    """Check if character matches character class."""
    val definition = char_class.0
    val negated = char_class.1
    val chars = char_class_parse(definition)
    var found = false
    var i = 0
    while i < chars.len():
        if chars[i] == ch:
            found = true
        i = i + 1
    if negated:
        return not found
    found

fn char_class_empty() -> any:
    """Create empty character class."""
    ("", false)

fn char_class_any() -> any:
    """Create character class matching any character (dot)."""
    ("", false)

fn char_class_digit() -> any:
    """Create character class for digits [0-9]."""
    ("0-9", false)

fn char_class_word() -> any:
    """Create character class for word characters [a-zA-Z0-9_]."""
    ("a-zA-Z0-9_", false)

fn char_class_space() -> any:
    """Create character class for whitespace [ \t\n\r]."""
    (" \t\n\r", false)

# ============================================================================
# TOKENIZATION
# ============================================================================

fn tokenize_regex(pattern: text) -> [any]:
    """Tokenize regex pattern into tokens."""
    var tokens = []
    var i = 0
    while i < pattern.len():
        val ch = pattern[i:i + 1]
        if ch == "\\":
            if i + 1 < pattern.len():
                val next = pattern[i + 1:i + 2]
                val token = RegexToken(token_type: "escape", value: next, pos: i)
                tokens.push(token)
                i = i + 2
            else:
                val token = RegexToken(token_type: "literal", value: ch, pos: i)
                tokens.push(token)
                i = i + 1
        else:
            val token_type = get_token_type(ch)
            val token = RegexToken(token_type: token_type, value: ch, pos: i)
            tokens.push(token)
            i = i + 1
    val eof = RegexToken(token_type: "eof", value: "", pos: pattern.len())
    tokens.push(eof)
    tokens

fn get_token_type(ch: text) -> text:
    """Get token type for character."""
    if ch == ".": return "dot"
    if ch == "*": return "star"
    if ch == "+": return "plus"
    if ch == "?": return "question"
    if ch == "|": return "pipe"
    if ch == "(": return "lparen"
    if ch == ")": return "rparen"
    if ch == "[": return "lbracket"
    if ch == "]": return "rbracket"
    if ch == "{": return "lbrace"
    if ch == "}": return "rbrace"
    if ch == "^": return "caret"
    if ch == "$": return "dollar"
    "literal"

fn token_type(token: any) -> text:
    """Get type of token."""
    token.token_type

fn token_value(token: any) -> text:
    """Get value of token."""
    token.value

fn token_pos(token: any) -> i64:
    """Get position of token."""
    token.pos

# ============================================================================
# AST CONSTRUCTION
# ============================================================================

fn ast_literal(ch: text) -> any:
    """Create AST node for literal character."""
    RegexAST(node_type: "literal", value: ch, children: [], min_count: 0, max_count: 0, lazy: false, negated: false, group_id: -1, group_name: "")

fn ast_dot() -> any:
    """Create AST node for dot (any character)."""
    RegexAST(node_type: "dot", value: "", children: [], min_count: 0, max_count: 0, lazy: false, negated: false, group_id: -1, group_name: "")

fn ast_char_class(definition: text, negated: bool) -> any:
    """Create AST node for character class."""
    RegexAST(node_type: "char_class", value: definition, children: [], min_count: 0, max_count: 0, lazy: false, negated: negated, group_id: -1, group_name: "")

fn ast_concat(children: [any]) -> any:
    """Create AST node for concatenation."""
    RegexAST(node_type: "concat", value: "", children: children, min_count: 0, max_count: 0, lazy: false, negated: false, group_id: -1, group_name: "")

fn ast_alternation(children: [any]) -> any:
    """Create AST node for alternation (|)."""
    RegexAST(node_type: "alternation", value: "", children: children, min_count: 0, max_count: 0, lazy: false, negated: false, group_id: -1, group_name: "")

fn ast_quantifier(child: any, min_count: i64, max_count: i64, lazy: bool) -> any:
    """Create AST node for quantifier (*, +, ?, {n,m})."""
    RegexAST(node_type: "quantifier", value: "", children: [child], min_count: min_count, max_count: max_count, lazy: lazy, negated: false, group_id: -1, group_name: "")

fn ast_group(child: any, group_id: i64, group_name: text) -> any:
    """Create AST node for group (capturing or non-capturing)."""
    RegexAST(node_type: "group", value: "", children: [child], min_count: 0, max_count: 0, lazy: false, negated: false, group_id: group_id, group_name: group_name)

fn ast_anchor(anchor_type: text) -> any:
    """Create AST node for anchor (^, $, \b, \B)."""
    RegexAST(node_type: "anchor", value: anchor_type, children: [], min_count: 0, max_count: 0, lazy: false, negated: false, group_id: -1, group_name: "")

# ============================================================================
# REGEX PARSING
# ============================================================================

fn parse_regex(pattern: text) -> any:
    """Parse regex pattern into AST. Returns (success, ast, error_msg)."""
    val tokens = tokenize_regex(pattern)
    var pos = 0
    val result = parse_alternation(tokens, pos)
    result

fn parse_alternation(tokens: [any], start_pos: i64) -> any:
    """Parse alternation (a|b|c). Returns (success, ast, next_pos, error_msg)."""
    var pos = start_pos
    var branches = []
    val first_result = parse_concatenation(tokens, pos)
    val first_success = first_result.0
    if not first_success:
        return first_result
    val first_ast = first_result.1
    val first_next = first_result.2
    branches.push(first_ast)
    pos = first_next
    var done = false
    while not done:
        if pos >= tokens.len():
            done = true
        else:
            val token = tokens[pos]
            val ttype = token_type(token)
            if ttype == "pipe":
                pos = pos + 1
                val branch_result = parse_concatenation(tokens, pos)
                val branch_success = branch_result.0
                if not branch_success:
                    return branch_result
                val branch_ast = branch_result.1
                val branch_next = branch_result.2
                branches.push(branch_ast)
                pos = branch_next
            else:
                done = true
    if branches.len() == 1:
        return (true, branches[0], pos, "")
    val ast = ast_alternation(branches)
    (true, ast, pos, "")

fn parse_concatenation(tokens: [any], start_pos: i64) -> any:
    """Parse concatenation (abc). Returns (success, ast, next_pos, error_msg)."""
    var pos = start_pos
    var items = []
    var done = false
    while not done:
        if pos >= tokens.len():
            done = true
        else:
            val token = tokens[pos]
            val ttype = token_type(token)
            if ttype == "pipe" or ttype == "rparen" or ttype == "eof":
                done = true
            else:
                val item_result = parse_quantifier(tokens, pos)
                val item_success = item_result.0
                if not item_success:
                    return item_result
                val item_ast = item_result.1
                val item_next = item_result.2
                items.push(item_ast)
                pos = item_next
    if items.len() == 0:
        val empty = ast_literal("")
        return (true, empty, pos, "")
    if items.len() == 1:
        return (true, items[0], pos, "")
    val ast = ast_concat(items)
    (true, ast, pos, "")

fn parse_quantifier(tokens: [any], start_pos: i64) -> any:
    """Parse quantifier (*, +, ?, {n,m}). Returns (success, ast, next_pos, error_msg)."""
    val base_result = parse_atom(tokens, start_pos)
    val base_success = base_result.0
    if not base_success:
        return base_result
    val base_ast = base_result.1
    var pos = base_result.2
    if pos >= tokens.len():
        return (true, base_ast, pos, "")
    val token = tokens[pos]
    val ttype = token_type(token)
    if ttype == "star":
        pos = pos + 1
        var lazy = false
        if pos < tokens.len():
            val next_token = tokens[pos]
            val next_type = token_type(next_token)
            if next_type == "question":
                lazy = true
                pos = pos + 1
        val ast = ast_quantifier(base_ast, 0, -1, lazy)
        return (true, ast, pos, "")
    if ttype == "plus":
        pos = pos + 1
        var lazy = false
        if pos < tokens.len():
            val next_token = tokens[pos]
            val next_type = token_type(next_token)
            if next_type == "question":
                lazy = true
                pos = pos + 1
        val ast = ast_quantifier(base_ast, 1, -1, lazy)
        return (true, ast, pos, "")
    if ttype == "question":
        pos = pos + 1
        var lazy = false
        if pos < tokens.len():
            val next_token = tokens[pos]
            val next_type = token_type(next_token)
            if next_type == "question":
                lazy = true
                pos = pos + 1
        val ast = ast_quantifier(base_ast, 0, 1, lazy)
        return (true, ast, pos, "")
    if ttype == "lbrace":
        val quant_result = parse_brace_quantifier(tokens, pos)
        val quant_success = quant_result.0
        if not quant_success:
            return quant_result
        val min_c = quant_result.1
        val max_c = quant_result.2
        val quant_next = quant_result.3
        var lazy = false
        pos = quant_next
        if pos < tokens.len():
            val next_token = tokens[pos]
            val next_type = token_type(next_token)
            if next_type == "question":
                lazy = true
                pos = pos + 1
        val ast = ast_quantifier(base_ast, min_c, max_c, lazy)
        return (true, ast, pos, "")
    (true, base_ast, pos, "")

fn parse_atom(tokens: [any], start_pos: i64) -> any:
    """Parse atomic regex element. Returns (success, ast, next_pos, error_msg)."""
    if start_pos >= tokens.len():
        return (false, nil, start_pos, "Unexpected end of pattern")
    val token = tokens[start_pos]
    val ttype = token_type(token)
    val tvalue = token_value(token)
    if ttype == "literal":
        val ast = ast_literal(tvalue)
        return (true, ast, start_pos + 1, "")
    if ttype == "dot":
        val ast = ast_dot()
        return (true, ast, start_pos + 1, "")
    if ttype == "escape":
        val expanded = expand_escape(tvalue)
        if expanded.starts_with("["):
            val def_end = expanded.len() - 1
            val definition = expanded[1:def_end]
            val negated = definition.starts_with("^")
            val def_text = definition[1:definition.len()]
            val ast = ast_char_class(def_text, negated)
            return (true, ast, start_pos + 1, "")
        if expanded == "\\b" or expanded == "\\B":
            val ast = ast_anchor(expanded)
            return (true, ast, start_pos + 1, "")
        val ast = ast_literal(expanded)
        return (true, ast, start_pos + 1, "")
    if ttype == "caret":
        val ast = ast_anchor("^")
        return (true, ast, start_pos + 1, "")
    if ttype == "dollar":
        val ast = ast_anchor("$")
        return (true, ast, start_pos + 1, "")
    if ttype == "lparen":
        return parse_group(tokens, start_pos)
    if ttype == "lbracket":
        return parse_char_class_bracket(tokens, start_pos)
    (false, nil, start_pos, "Unexpected token: " + ttype)

fn parse_group(tokens: [any], start_pos: i64) -> any:
    """Parse group (...) or (?:...) or (?<name>...). Returns (success, ast, next_pos, error_msg)."""
    var pos = start_pos + 1
    var group_id = 0
    var group_name = ""
    var is_capturing = true
    if pos < tokens.len():
        val token = tokens[pos]
        val ttype = token_type(token)
        if ttype == "question":
            pos = pos + 1
            if pos < tokens.len():
                val next_token = tokens[pos]
                val next_type = token_type(next_token)
                if next_type == "literal":
                    val next_value = token_value(next_token)
                    if next_value == ":":
                        is_capturing = false
                        pos = pos + 1
                    else:
                        if next_value == "<":
                            pos = pos + 1
                            var name_chars = ""
                            var name_done = false
                            while not name_done and pos < tokens.len():
                                val name_token = tokens[pos]
                                val name_value = token_value(name_token)
                                if name_value == ">":
                                    name_done = true
                                    pos = pos + 1
                                else:
                                    name_chars = name_chars + name_value
                                    pos = pos + 1
                            group_name = name_chars
    val inner_result = parse_alternation(tokens, pos)
    val inner_success = inner_result.0
    if not inner_success:
        return inner_result
    val inner_ast = inner_result.1
    pos = inner_result.2
    if pos >= tokens.len():
        return (false, nil, pos, "Unclosed group")
    val close_token = tokens[pos]
    val close_type = token_type(close_token)
    if close_type != "rparen":
        return (false, nil, pos, "Expected )")
    pos = pos + 1
    if is_capturing:
        val ast = ast_group(inner_ast, group_id, group_name)
        return (true, ast, pos, "")
    (true, inner_ast, pos, "")

fn parse_char_class_bracket(tokens: [any], start_pos: i64) -> any:
    """Parse character class [...] or [^...]. Returns (success, ast, next_pos, error_msg)."""
    var pos = start_pos + 1
    var negated = false
    if pos < tokens.len():
        val token = tokens[pos]
        val ttype = token_type(token)
        if ttype == "caret":
            negated = true
            pos = pos + 1
    var chars = ""
    var done = false
    while not done and pos < tokens.len():
        val token = tokens[pos]
        val ttype = token_type(token)
        if ttype == "rbracket":
            done = true
            pos = pos + 1
        else:
            val tvalue = token_value(token)
            chars = chars + tvalue
            pos = pos + 1
    if not done:
        return (false, nil, pos, "Unclosed character class")
    val ast = ast_char_class(chars, negated)
    (true, ast, pos, "")

fn parse_brace_quantifier(tokens: [any], start_pos: i64) -> any:
    """Parse {n}, {n,}, {n,m} quantifier. Returns (success, min, max, next_pos)."""
    var pos = start_pos + 1
    var min_str = ""
    var max_str = ""
    var in_max = false
    var done = false
    while not done and pos < tokens.len():
        val token = tokens[pos]
        val ttype = token_type(token)
        val tvalue = token_value(token)
        if ttype == "rbrace":
            done = true
            pos = pos + 1
        else:
            if tvalue == ",":
                in_max = true
                pos = pos + 1
            else:
                if is_digit_char(tvalue):
                    if in_max:
                        max_str = max_str + tvalue
                    else:
                        min_str = min_str + tvalue
                    pos = pos + 1
                else:
                    return (false, 0, 0, pos)
    if not done:
        return (false, 0, 0, pos)
    val min_count = parse_int(min_str)
    var max_count = min_count
    if in_max:
        if max_str == "":
            max_count = -1
        else:
            max_count = parse_int(max_str)
    (true, min_count, max_count, pos)

fn parse_int(s: text) -> i64:
    """Parse integer from string."""
    if s == "": return 0
    var result = 0
    var i = 0
    while i < s.len():
        val ch = s[i:i + 1]
        val digit = char_code(ch) - 48
        result = result * 10 + digit
        i = i + 1
    result

# ============================================================================
# NFA CONSTRUCTION
# ============================================================================

fn nfa_create() -> any:
    """Create empty NFA."""
    NFA(states: [], transitions: [], start_state: 0, accept_state: 0, next_state_id: 0, group_count: 0)

fn nfa_add_state(nfa: any, is_accept: bool) -> any:
    """Add state to NFA. Returns (nfa, state_id)."""
    val state_id = nfa.next_state_id
    val state = NFAState(state_id: state_id, is_accept: is_accept, group_start: -1, group_end: -1)
    var states = nfa.states
    states.push(state)
    val new_nfa = NFA(states: states, transitions: nfa.transitions, start_state: nfa.start_state, accept_state: nfa.accept_state, next_state_id: state_id + 1, group_count: nfa.group_count)
    (new_nfa, state_id)

fn nfa_add_transition(nfa: any, from_state: i64, to_state: i64, symbol: text) -> any:
    """Add transition to NFA."""
    val trans = NFATransition(from_state: from_state, to_state: to_state, symbol: symbol, char_class: "")
    var transitions = nfa.transitions
    transitions.push(trans)
    NFA(states: nfa.states, transitions: transitions, start_state: nfa.start_state, accept_state: nfa.accept_state, next_state_id: nfa.next_state_id, group_count: nfa.group_count)

fn nfa_add_epsilon(nfa: any, from_state: i64, to_state: i64) -> any:
    """Add epsilon transition to NFA."""
    nfa_add_transition(nfa, from_state, to_state, "")

fn nfa_set_start(nfa: any, state_id: i64) -> any:
    """Set start state of NFA."""
    NFA(states: nfa.states, transitions: nfa.transitions, start_state: state_id, accept_state: nfa.accept_state, next_state_id: nfa.next_state_id, group_count: nfa.group_count)

fn nfa_set_accept(nfa: any, state_id: i64) -> any:
    """Set accept state of NFA."""
    NFA(states: nfa.states, transitions: nfa.transitions, start_state: nfa.start_state, accept_state: state_id, next_state_id: nfa.next_state_id, group_count: nfa.group_count)

# ============================================================================
# THOMPSON'S CONSTRUCTION
# ============================================================================

fn thompson_from_ast(ast: any, nfa: any) -> any:
    """Build NFA from AST using Thompson's construction. Returns (nfa, start, accept)."""
    val node_type = ast.node_type
    if node_type == "literal":
        return thompson_literal(ast.value, nfa)
    if node_type == "dot":
        return thompson_dot(nfa)
    if node_type == "char_class":
        return thompson_char_class(ast.value, ast.negated, nfa)
    if node_type == "concat":
        return thompson_concat(ast.children, nfa)
    if node_type == "alternation":
        return thompson_alternation(ast.children, nfa)
    if node_type == "quantifier":
        val child = ast.children[0]
        return thompson_quantifier(child, ast.min_count, ast.max_count, ast.lazy, nfa)
    if node_type == "group":
        val child = ast.children[0]
        return thompson_from_ast(child, nfa)
    if node_type == "anchor":
        return thompson_anchor(ast.value, nfa)
    (nfa, 0, 0)

fn thompson_literal(ch: text, nfa: any) -> any:
    """Create NFA fragment for literal character. Returns (nfa, start, accept)."""
    val add_start = nfa_add_state(nfa, false)
    val nfa1 = add_start.0
    val start_id = add_start.1
    val add_accept = nfa_add_state(nfa1, false)
    val nfa2 = add_accept.0
    val accept_id = add_accept.1
    val nfa3 = nfa_add_transition(nfa2, start_id, accept_id, ch)
    (nfa3, start_id, accept_id)

fn thompson_dot(nfa: any) -> any:
    """Create NFA fragment for dot (any character). Returns (nfa, start, accept)."""
    val add_start = nfa_add_state(nfa, false)
    val nfa1 = add_start.0
    val start_id = add_start.1
    val add_accept = nfa_add_state(nfa1, false)
    val nfa2 = add_accept.0
    val accept_id = add_accept.1
    val nfa3 = nfa_add_transition(nfa2, start_id, accept_id, ".")
    (nfa3, start_id, accept_id)

fn thompson_char_class(definition: text, negated: bool, nfa: any) -> any:
    """Create NFA fragment for character class. Returns (nfa, start, accept)."""
    val add_start = nfa_add_state(nfa, false)
    val nfa1 = add_start.0
    val start_id = add_start.1
    val add_accept = nfa_add_state(nfa1, false)
    val nfa2 = add_accept.0
    val accept_id = add_accept.1
    val char_class = char_class_create(definition, negated)
    val chars = char_class_parse(definition)
    var nfa_curr = nfa2
    var i = 0
    while i < chars.len():
        nfa_curr = nfa_add_transition(nfa_curr, start_id, accept_id, chars[i])
        i = i + 1
    (nfa_curr, start_id, accept_id)

fn thompson_concat(children: [any], nfa: any) -> any:
    """Create NFA fragment for concatenation. Returns (nfa, start, accept)."""
    if children.len() == 0:
        val add_state = nfa_add_state(nfa, false)
        val nfa1 = add_state.0
        val state_id = add_state.1
        return (nfa1, state_id, state_id)
    var nfa_curr = nfa
    var overall_start = 0
    var prev_accept = 0
    var i = 0
    while i < children.len():
        val child = children[i]
        val fragment = thompson_from_ast(child, nfa_curr)
        nfa_curr = fragment.0
        val frag_start = fragment.1
        val frag_accept = fragment.2
        if i == 0:
            overall_start = frag_start
        else:
            nfa_curr = nfa_add_epsilon(nfa_curr, prev_accept, frag_start)
        prev_accept = frag_accept
        i = i + 1
    (nfa_curr, overall_start, prev_accept)

fn thompson_alternation(children: [any], nfa: any) -> any:
    """Create NFA fragment for alternation. Returns (nfa, start, accept)."""
    val add_start = nfa_add_state(nfa, false)
    val nfa1 = add_start.0
    val start_id = add_start.1
    val add_accept = nfa_add_state(nfa1, false)
    val nfa2 = add_accept.0
    val accept_id = add_accept.1
    var nfa_curr = nfa2
    var i = 0
    while i < children.len():
        val child = children[i]
        val fragment = thompson_from_ast(child, nfa_curr)
        nfa_curr = fragment.0
        val frag_start = fragment.1
        val frag_accept = fragment.2
        nfa_curr = nfa_add_epsilon(nfa_curr, start_id, frag_start)
        nfa_curr = nfa_add_epsilon(nfa_curr, frag_accept, accept_id)
        i = i + 1
    (nfa_curr, start_id, accept_id)

fn thompson_quantifier(child: any, min_count: i64, max_count: i64, lazy: bool, nfa: any) -> any:
    """Create NFA fragment for quantifier. Returns (nfa, start, accept)."""
    if min_count == 0 and max_count == 1:
        return thompson_optional(child, nfa)
    if min_count == 0 and max_count == -1:
        return thompson_star(child, nfa)
    if min_count == 1 and max_count == -1:
        return thompson_plus(child, nfa)
    thompson_star(child, nfa)

fn thompson_star(child: any, nfa: any) -> any:
    """Create NFA fragment for star (*). Returns (nfa, start, accept)."""
    val fragment = thompson_from_ast(child, nfa)
    val nfa1 = fragment.0
    val frag_start = fragment.1
    val frag_accept = fragment.2
    val add_start = nfa_add_state(nfa1, false)
    val nfa2 = add_start.0
    val start_id = add_start.1
    val add_accept = nfa_add_state(nfa2, false)
    val nfa3 = add_accept.0
    val accept_id = add_accept.1
    var nfa4 = nfa_add_epsilon(nfa3, start_id, frag_start)
    nfa4 = nfa_add_epsilon(nfa4, frag_accept, accept_id)
    nfa4 = nfa_add_epsilon(nfa4, frag_accept, frag_start)
    nfa4 = nfa_add_epsilon(nfa4, start_id, accept_id)
    (nfa4, start_id, accept_id)

fn thompson_plus(child: any, nfa: any) -> any:
    """Create NFA fragment for plus (+). Returns (nfa, start, accept)."""
    val fragment = thompson_from_ast(child, nfa)
    val nfa1 = fragment.0
    val frag_start = fragment.1
    val frag_accept = fragment.2
    val add_accept = nfa_add_state(nfa1, false)
    val nfa2 = add_accept.0
    val accept_id = add_accept.1
    var nfa3 = nfa_add_epsilon(nfa2, frag_accept, accept_id)
    nfa3 = nfa_add_epsilon(nfa3, frag_accept, frag_start)
    (nfa3, frag_start, accept_id)

fn thompson_optional(child: any, nfa: any) -> any:
    """Create NFA fragment for optional (?). Returns (nfa, start, accept)."""
    val fragment = thompson_from_ast(child, nfa)
    val nfa1 = fragment.0
    val frag_start = fragment.1
    val frag_accept = fragment.2
    val add_start = nfa_add_state(nfa1, false)
    val nfa2 = add_start.0
    val start_id = add_start.1
    val add_accept = nfa_add_state(nfa2, false)
    val nfa3 = add_accept.0
    val accept_id = add_accept.1
    var nfa4 = nfa_add_epsilon(nfa3, start_id, frag_start)
    nfa4 = nfa_add_epsilon(nfa4, frag_accept, accept_id)
    nfa4 = nfa_add_epsilon(nfa4, start_id, accept_id)
    (nfa4, start_id, accept_id)

fn thompson_anchor(anchor_type: text, nfa: any) -> any:
    """Create NFA fragment for anchor. Returns (nfa, start, accept)."""
    val add_start = nfa_add_state(nfa, false)
    val nfa1 = add_start.0
    val start_id = add_start.1
    val add_accept = nfa_add_state(nfa1, false)
    val nfa2 = add_accept.0
    val accept_id = add_accept.1
    val nfa3 = nfa_add_epsilon(nfa2, start_id, accept_id)
    (nfa3, start_id, accept_id)

# ============================================================================
# NFA SIMULATION
# ============================================================================

fn nfa_epsilon_closure(nfa: any, states: [i64]) -> [i64]:
    """Compute epsilon closure of a set of NFA states."""
    var closure = []
    var stack = []
    var i = 0
    while i < states.len():
        stack.push(states[i])
        closure.push(states[i])
        i = i + 1
    while stack.len() > 0:
        val curr_idx = stack.len() - 1
        val curr = stack[curr_idx]
        stack = stack[0:curr_idx]
        var j = 0
        while j < nfa.transitions.len():
            val trans = nfa.transitions[j]
            if trans.from_state == curr and trans.symbol == "":
                val target = trans.to_state
                var already_in = false
                var k = 0
                while k < closure.len():
                    if closure[k] == target:
                        already_in = true
                    k = k + 1
                if not already_in:
                    closure.push(target)
                    stack.push(target)
            j = j + 1
    closure

fn nfa_move(nfa: any, states: [i64], symbol: text) -> [i64]:
    """Compute states reachable from given states by consuming symbol."""
    var result = []
    var i = 0
    while i < states.len():
        val state = states[i]
        var j = 0
        while j < nfa.transitions.len():
            val trans = nfa.transitions[j]
            if trans.from_state == state:
                val trans_sym = trans.symbol
                if trans_sym == symbol:
                    result.push(trans.to_state)
                else:
                    if trans_sym == ".":
                        result.push(trans.to_state)
            j = j + 1
        i = i + 1
    result

fn nfa_simulate(nfa: any, input: text) -> bool:
    """Simulate NFA on input string. Returns true if accepted."""
    val start_states = [nfa.start_state]
    var current_states = nfa_epsilon_closure(nfa, start_states)
    var pos = 0
    while pos < input.len():
        val ch = input[pos:pos + 1]
        val next_states = nfa_move(nfa, current_states, ch)
        current_states = nfa_epsilon_closure(nfa, next_states)
        if current_states.len() == 0:
            return false
        pos = pos + 1
    var i = 0
    while i < current_states.len():
        if current_states[i] == nfa.accept_state:
            return true
        i = i + 1
    false

# ============================================================================
# DFA CONSTRUCTION
# ============================================================================

fn dfa_create() -> any:
    """Create empty DFA."""
    DFA(states: [], transitions: [], start_state: 0, accept_states: [])

fn dfa_add_state(dfa: any, state_id: i64, is_accept: bool, nfa_states: [i64]) -> any:
    """Add state to DFA."""
    val state = DFAState(state_id: state_id, is_accept: is_accept, nfa_states: nfa_states)
    var states = dfa.states
    states.push(state)
    var accept_states = dfa.accept_states
    if is_accept:
        accept_states.push(state_id)
    DFA(states: states, transitions: dfa.transitions, start_state: dfa.start_state, accept_states: accept_states)

fn dfa_add_transition(dfa: any, from_state: i64, to_state: i64, symbol: text) -> any:
    """Add transition to DFA."""
    val trans = DFATransition(from_state: from_state, to_state: to_state, symbol: symbol)
    var transitions = dfa.transitions
    transitions.push(trans)
    DFA(states: dfa.states, transitions: transitions, start_state: dfa.start_state, accept_states: dfa.accept_states)

fn subset_construction(nfa: any) -> any:
    """Convert NFA to DFA using subset construction."""
    val start_states = [nfa.start_state]
    val start_closure = nfa_epsilon_closure(nfa, start_states)
    var dfa = dfa_create()
    var state_map = []
    var next_id = 0
    val start_is_accept = contains_accept(start_closure, nfa.accept_state)
    dfa = dfa_add_state(dfa, next_id, start_is_accept, start_closure)
    state_map.push((start_closure, next_id))
    next_id = next_id + 1
    var worklist = [start_closure]
    while worklist.len() > 0:
        val curr_idx = worklist.len() - 1
        val curr_states = worklist[curr_idx]
        worklist = worklist[0:curr_idx]
        val curr_id = find_state_id(state_map, curr_states)
        val alphabet = get_alphabet(nfa)
        var sym_idx = 0
        while sym_idx < alphabet.len():
            val symbol = alphabet[sym_idx]
            val next_states = nfa_move(nfa, curr_states, symbol)
            val next_closure = nfa_epsilon_closure(nfa, next_states)
            if next_closure.len() > 0:
                var next_id_val = find_state_id(state_map, next_closure)
                if next_id_val == -1:
                    val next_is_accept = contains_accept(next_closure, nfa.accept_state)
                    dfa = dfa_add_state(dfa, next_id, next_is_accept, next_closure)
                    state_map.push((next_closure, next_id))
                    next_id_val = next_id
                    next_id = next_id + 1
                    worklist.push(next_closure)
                dfa = dfa_add_transition(dfa, curr_id, next_id_val, symbol)
            sym_idx = sym_idx + 1
    dfa

fn contains_accept(states: [i64], accept_state: i64) -> bool:
    """Check if state set contains accept state."""
    var i = 0
    while i < states.len():
        if states[i] == accept_state:
            return true
        i = i + 1
    false

fn find_state_id(state_map: [any], states: [i64]) -> i64:
    """Find state ID for given NFA state set. Returns -1 if not found."""
    var i = 0
    while i < state_map.len():
        val entry = state_map[i]
        val entry_states = entry.0
        if states_equal(entry_states, states):
            return entry.1
        i = i + 1
    -1

fn states_equal(s1: [i64], s2: [i64]) -> bool:
    """Check if two state sets are equal."""
    if s1.len() != s2.len():
        return false
    var i = 0
    while i < s1.len():
        var found = false
        var j = 0
        while j < s2.len():
            if s1[i] == s2[j]:
                found = true
            j = j + 1
        if not found:
            return false
        i = i + 1
    true

fn get_alphabet(nfa: any) -> [text]:
    """Get alphabet (set of symbols) from NFA."""
    var symbols = []
    var i = 0
    while i < nfa.transitions.len():
        val trans = nfa.transitions[i]
        val symbol = trans.symbol
        if symbol != "":
            var already_in = false
            var j = 0
            while j < symbols.len():
                if symbols[j] == symbol:
                    already_in = true
                j = j + 1
            if not already_in:
                symbols.push(symbol)
        i = i + 1
    symbols

fn dfa_minimize(dfa: any) -> any:
    """Minimize DFA using Hopcroft's algorithm (simplified)."""
    dfa

# ============================================================================
# MATCHING API
# ============================================================================

fn regex_compile(pattern: text) -> any:
    """Compile regex pattern to NFA. Returns (success, nfa, error_msg)."""
    val parse_result = parse_regex(pattern)
    val parse_success = parse_result.0
    if not parse_success:
        val error = parse_result.3
        return (false, nil, error)
    val ast = parse_result.1
    var nfa = nfa_create()
    val thompson_result = thompson_from_ast(ast, nfa)
    nfa = thompson_result.0
    val start = thompson_result.1
    val accept = thompson_result.2
    nfa = nfa_set_start(nfa, start)
    nfa = nfa_set_accept(nfa, accept)
    (true, nfa, "")

fn regex_match(pattern: text, input: text) -> bool:
    """Test if entire input matches pattern."""
    val compile_result = regex_compile(pattern)
    val success = compile_result.0
    if not success:
        return false
    val nfa = compile_result.1
    nfa_simulate(nfa, input)

fn regex_test(pattern: text, input: text) -> bool:
    """Test if pattern matches anywhere in input."""
    val compile_result = regex_compile(pattern)
    val success = compile_result.0
    if not success:
        return false
    val nfa = compile_result.1
    var pos = 0
    while pos <= input.len():
        val substring = input[pos:input.len()]
        if nfa_simulate(nfa, substring):
            return true
        pos = pos + 1
    false

fn regex_find(pattern: text, input: text) -> any:
    """Find first match of pattern in input. Returns (found, start, end, matched_text)."""
    val compile_result = regex_compile(pattern)
    val success = compile_result.0
    if not success:
        return (false, -1, -1, "")
    val nfa = compile_result.1
    var pos = 0
    while pos <= input.len():
        var end = pos
        while end <= input.len():
            val substring = input[pos:end]
            if nfa_simulate(nfa, substring):
                return (true, pos, end, substring)
            end = end + 1
        pos = pos + 1
    (false, -1, -1, "")

fn regex_find_all(pattern: text, input: text) -> [any]:
    """Find all matches of pattern in input. Returns array of (start, end, matched_text)."""
    var matches = []
    val compile_result = regex_compile(pattern)
    val success = compile_result.0
    if not success:
        return matches
    val nfa = compile_result.1
    var pos = 0
    while pos < input.len():
        var found = false
        var end = pos + 1
        while end <= input.len() and not found:
            val substring = input[pos:end]
            if nfa_simulate(nfa, substring):
                matches.push((pos, end, substring))
                found = true
                pos = end
            end = end + 1
        if not found:
            pos = pos + 1
    matches

fn regex_exec(pattern: text, input: text) -> any:
    """Execute regex and return match result with groups."""
    val find_result = regex_find(pattern, input)
    val found = find_result.0
    if not found:
        return MatchResult(matched: false, start_pos: -1, end_pos: -1, groups: [], group_names: {})
    val start = find_result.1
    val end = find_result.2
    val text_match = find_result.3
    val groups = [(start, end, text_match)]
    MatchResult(matched: true, start_pos: start, end_pos: end, groups: groups, group_names: {})

# ============================================================================
# REPLACEMENT
# ============================================================================

fn regex_replace(pattern: text, input: text, replacement: text) -> text:
    """Replace first match of pattern with replacement."""
    val find_result = regex_find(pattern, input)
    val found = find_result.0
    if not found:
        return input
    val start = find_result.1
    val end = find_result.2
    val before = input[0:start]
    val after = input[end:input.len()]
    before + replacement + after

fn regex_replace_all(pattern: text, input: text, replacement: text) -> text:
    """Replace all matches of pattern with replacement."""
    val matches = regex_find_all(pattern, input)
    if matches.len() == 0:
        return input
    var result = ""
    var pos = 0
    var i = 0
    while i < matches.len():
        val match_tuple = matches[i]
        val start = match_tuple.0
        val end = match_tuple.1
        result = result + input[pos:start] + replacement
        pos = end
        i = i + 1
    result = result + input[pos:input.len()]
    result

fn regex_replace_fn(pattern: text, input: text, replacer_fn: fn(text) -> text) -> text:
    """Replace matches using replacer function."""
    val matches = regex_find_all(pattern, input)
    if matches.len() == 0:
        return input
    var result = ""
    var pos = 0
    var i = 0
    while i < matches.len():
        val match_tuple = matches[i]
        val start = match_tuple.0
        val end = match_tuple.1
        val matched_text = match_tuple.2
        val replacement = replacer_fn(matched_text)
        result = result + input[pos:start] + replacement
        pos = end
        i = i + 1
    result = result + input[pos:input.len()]
    result

# ============================================================================
# VALIDATION
# ============================================================================

fn validate_regex(pattern: text) -> any:
    """Validate regex pattern syntax. Returns (valid, error_msg)."""
    val compile_result = regex_compile(pattern)
    val success = compile_result.0
    if success:
        return (true, "")
    val error = compile_result.2
    (false, error)

fn check_balanced_parens(pattern: text) -> bool:
    """Check if parentheses are balanced in pattern."""
    var depth = 0
    var i = 0
    var escaped = false
    while i < pattern.len():
        val ch = pattern[i:i + 1]
        if escaped:
            escaped = false
        else:
            if ch == "\\":
                escaped = true
            else:
                if ch == "(":
                    depth = depth + 1
                if ch == ")":
                    depth = depth - 1
                    if depth < 0:
                        return false
        i = i + 1
    depth == 0

fn check_valid_quantifier(pattern: text) -> bool:
    """Check if quantifiers are valid (not at start, not doubled)."""
    if pattern.len() == 0:
        return true
    val first = pattern[0:1]
    if first == "*" or first == "+" or first == "?":
        return false
    var i = 1
    var prev_was_quant = false
    while i < pattern.len():
        val ch = pattern[i:i + 1]
        val is_quant = ch == "*" or ch == "+" or ch == "?"
        if is_quant and prev_was_quant:
            return false
        prev_was_quant = is_quant
        i = i + 1
    true

# ============================================================================
# UTILITIES
# ============================================================================

fn optimize_nfa(nfa: any) -> any:
    """Optimize NFA by removing unreachable states."""
    nfa

fn print_nfa(nfa: any) -> text:
    """Print NFA in human-readable format."""
    var result = "NFA:\n"
    result = result + "  Start: " + nfa.start_state.to_text() + "\n"
    result = result + "  Accept: " + nfa.accept_state.to_text() + "\n"
    result = result + "  States: " + nfa.states.len().to_text() + "\n"
    result = result + "  Transitions: " + nfa.transitions.len().to_text() + "\n"
    result

fn print_dfa(dfa: any) -> text:
    """Print DFA in human-readable format."""
    var result = "DFA:\n"
    result = result + "  Start: " + dfa.start_state.to_text() + "\n"
    result = result + "  Accept states: " + dfa.accept_states.len().to_text() + "\n"
    result = result + "  States: " + dfa.states.len().to_text() + "\n"
    result = result + "  Transitions: " + dfa.transitions.len().to_text() + "\n"
    result

fn regex_stats(pattern: text) -> any:
    """Get statistics about compiled regex. Returns (states, transitions, groups)."""
    val compile_result = regex_compile(pattern)
    val success = compile_result.0
    if not success:
        return (0, 0, 0)
    val nfa = compile_result.1
    (nfa.states.len(), nfa.transitions.len(), nfa.group_count)

# ============================================================================
# GROUP EXTRACTION
# ============================================================================

fn extract_groups(match_result: any) -> [any]:
    """Extract captured groups from match result."""
    match_result.groups

fn group_at(match_result: any, index: i64) -> text:
    """Get text of captured group at index."""
    val groups = match_result.groups
    if index >= 0 and index < groups.len():
        val group = groups[index]
        return group.2
    ""

fn group_count(match_result: any) -> i64:
    """Get number of captured groups."""
    match_result.groups.len()

fn group_names(match_result: any) -> [text]:
    """Get names of all named groups."""
    var names = []
    val name_map = match_result.group_names
    names

# ============================================================================
# SPLITTING
# ============================================================================

fn regex_split(pattern: text, input: text) -> [text]:
    """Split input string by regex pattern."""
    val matches = regex_find_all(pattern, input)
    if matches.len() == 0:
        return [input]
    var parts = []
    var pos = 0
    var i = 0
    while i < matches.len():
        val match_tuple = matches[i]
        val start = match_tuple.0
        val end = match_tuple.1
        val part = input[pos:start]
        parts.push(part)
        pos = end
        i = i + 1
    val last_part = input[pos:input.len()]
    parts.push(last_part)
    parts

fn regex_split_n(pattern: text, input: text, max_splits: i64) -> [text]:
    """Split input string by regex pattern with maximum number of splits."""
    val matches = regex_find_all(pattern, input)
    if matches.len() == 0:
        return [input]
    var parts = []
    var pos = 0
    var i = 0
    var splits = 0
    while i < matches.len() and splits < max_splits:
        val match_tuple = matches[i]
        val start = match_tuple.0
        val end = match_tuple.1
        val part = input[pos:start]
        parts.push(part)
        pos = end
        splits = splits + 1
        i = i + 1
    val last_part = input[pos:input.len()]
    parts.push(last_part)
    parts

# ============================================================================
# ADVANCED MATCHING
# ============================================================================

fn regex_count_matches(pattern: text, input: text) -> i64:
    """Count number of matches in input."""
    val matches = regex_find_all(pattern, input)
    matches.len()

fn regex_extract_all(pattern: text, input: text) -> [text]:
    """Extract all matched texts."""
    val matches = regex_find_all(pattern, input)
    var texts = []
    var i = 0
    while i < matches.len():
        val match_tuple = matches[i]
        val text_match = match_tuple.2
        texts.push(text_match)
        i = i + 1
    texts

fn regex_match_length(pattern: text, input: text) -> i64:
    """Get length of first match. Returns -1 if no match."""
    val find_result = regex_find(pattern, input)
    val found = find_result.0
    if not found:
        return -1
    val start = find_result.1
    val end = find_result.2
    end - start

fn regex_starts_with(pattern: text, input: text) -> bool:
    """Check if input starts with pattern match."""
    val anchored = "^" + pattern
    regex_match(anchored, input)

fn regex_ends_with(pattern: text, input: text) -> bool:
    """Check if input ends with pattern match."""
    val anchored = pattern + "$"
    regex_match(anchored, input)

# ============================================================================
# EXPORT ALL PUBLIC FUNCTIONS
# ============================================================================

export char_code, is_digit_char, is_alpha_char, is_alnum_char, is_word_char
export is_whitespace_char, is_hex_char, is_special_regex_char
export escape_regex, unescape_regex, expand_escape, is_escape_char
export char_class_create, char_class_parse, char_class_matches
export char_class_empty, char_class_any, char_class_digit, char_class_word, char_class_space
export tokenize_regex, get_token_type, token_type, token_value, token_pos
export ast_literal, ast_dot, ast_char_class, ast_concat, ast_alternation
export ast_quantifier, ast_group, ast_anchor
export parse_regex, parse_alternation, parse_concatenation, parse_quantifier
export parse_atom, parse_group, parse_char_class_bracket, parse_brace_quantifier
export nfa_create, nfa_add_state, nfa_add_transition, nfa_add_epsilon
export nfa_set_start, nfa_set_accept
export thompson_from_ast, thompson_literal, thompson_dot, thompson_char_class
export thompson_concat, thompson_alternation, thompson_quantifier
export thompson_star, thompson_plus, thompson_optional, thompson_anchor
export nfa_epsilon_closure, nfa_move, nfa_simulate
export dfa_create, dfa_add_state, dfa_add_transition, subset_construction, dfa_minimize
export regex_compile, regex_match, regex_test, regex_find, regex_find_all, regex_exec
export regex_replace, regex_replace_all, regex_replace_fn
export validate_regex, check_balanced_parens, check_valid_quantifier
export optimize_nfa, print_nfa, print_dfa, regex_stats
export extract_groups, group_at, group_count, group_names
export regex_split, regex_split_n
export regex_count_matches, regex_extract_all, regex_match_length
export regex_starts_with, regex_ends_with
export string_from_code, parse_int, contains_accept, find_state_id
export states_equal, get_alphabet
