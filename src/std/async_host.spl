# Async Host - Full-Featured Runtime for Host Applications
#
# Features:
# - Heap-allocated, growable collections
# - Work-stealing scheduler
# - Waker-based notification
# - Priority scheduling with preemption
# - Full cancellation support
# - Structured concurrency
#
# Usage:
#   use std.async_core.*
#   use std.async_host.*
#
#   val runtime = HostRuntime.new()
#   val handle = runtime.run_task(async: fetch_data())
#   val result = await handle.join()

use std.async_core.*
use std.async_sffi.*

# ============================================================================
# Waker - Task Wake Notification
# ============================================================================

struct Waker:
    """Waker for notifying scheduler when task is ready.

    Unlike embedded (polling), host runtime uses wakers for efficiency.
    """
    task_id: usize
    scheduler_ref: usize  # Reference to scheduler (opaque)
    wake_count: usize

    static fn new(task_id: usize, scheduler_ref: usize) -> Waker:
        Waker(task_id: task_id, scheduler_ref: scheduler_ref, wake_count: 0)

    me wake():
        """Wake the associated task."""
        self.wake_count = self.wake_count + 1
        # Signal scheduler via FFI
        waker_signal(self.scheduler_ref, self.task_id)

    me wake_by_ref():
        """Wake without consuming waker."""
        self.wake()

    fn will_wake(other: Waker) -> bool:
        """Check if two wakers wake same task."""
        self.task_id == other.task_id

# ============================================================================
# Context - Polling Context
# ============================================================================

struct Context:
    """Context passed to Future.poll().

    Contains waker for signaling readiness.
    """
    waker: Waker

    static fn from_waker(w: Waker) -> Context:
        Context(waker: w)

    fn waker() -> Waker:
        self.waker

# ============================================================================
# HostFuture<T> - Full-Featured Future
# ============================================================================

class HostFuture<T>:
    """Heap-allocated future with waker support.

    More powerful than EmbeddedFuture:
    - Waker-based notification
    - Chaining with map/then
    - Timeout support
    - Cancellation
    """
    state: FutureState<T>
    wakers: [Waker]

enum FutureState<T>:
    Pending
    Ready(T)
    Failed(AsyncError)

impl HostFuture<T>:
    static fn ready(value: T) -> HostFuture<T>:
        """Create completed future."""
        HostFuture(state: FutureState.Ready(value), wakers: [])

    static fn pending() -> HostFuture<T>:
        """Create pending future."""
        HostFuture(state: FutureState.Pending, wakers: [])

    static fn failed(err: AsyncError) -> HostFuture<T>:
        """Create failed future."""
        HostFuture(state: FutureState.Failed(err), wakers: [])

    fn poll(cx: Context) -> Poll<T>:
        """Poll with context (waker)."""
        match self.state:
            case FutureState.Ready(v):
                Poll.Ready(v)
            case FutureState.Pending:
                # Register waker
                self.wakers = self.wakers.push(cx.waker())
                Poll.Pending
            case FutureState.Failed(e):
                panic("Future failed: {e.message()}")

    fn is_ready() -> bool:
        match self.state:
            case FutureState.Ready(_): true
            case _: false

    me complete(value: T):
        """Complete future and wake all waiters."""
        self.state = FutureState.Ready(value)
        for waker in self.wakers:
            waker.wake()
        self.wakers = []

    me fail(err: AsyncError):
        """Fail future."""
        self.state = FutureState.Failed(err)
        for waker in self.wakers:
            waker.wake()
        self.wakers = []

    fn map<U>(f: fn(T) -> U) -> HostFuture<U>:
        """Transform future value."""
        match self.state:
            case FutureState.Ready(v):
                val result: HostFuture<U> = HostFuture.ready(f(v))
                result
            case FutureState.Pending:
                # Create mapped future
                val pending: HostFuture<U> = HostFuture.pending()
                pending
            case FutureState.Failed(e):
                val failed: HostFuture<U> = HostFuture.failed(e)
                failed

    fn then<U>(f: fn(T) -> HostFuture<U>) -> HostFuture<U>:
        """Chain futures (flatMap)."""
        match self.state:
            case FutureState.Ready(v):
                f(v)
            case FutureState.Pending:
                val pending: HostFuture<U> = HostFuture.pending()
                pending
            case FutureState.Failed(e):
                val failed: HostFuture<U> = HostFuture.failed(e)
                failed

# Note: HostFuture implements FutureCore<T> via duck typing

# ============================================================================
# HostPromise<T> - Full-Featured Promise
# ============================================================================

class HostPromise<T>:
    """Write-side of a future."""
    future: HostFuture<T>
    completed: bool

    static fn new() -> (HostFuture<T>, HostPromise<T>):
        """Create future-promise pair."""
        val future: HostFuture<T> = HostFuture.pending()
        val promise = HostPromise(future: future, completed: false)
        (future, promise)

    me complete(value: T) -> bool:
        """Complete promise with value."""
        if self.completed:
            return false
        self.completed = true
        self.future.complete(value)
        true

    me fail(err: AsyncError) -> bool:
        """Fail promise with error."""
        if self.completed:
            return false
        self.completed = true
        self.future.fail(err)
        true

    fn is_completed() -> bool:
        self.completed

# ============================================================================
# HostTaskHandle<T> - Task Handle with Waker
# ============================================================================

class HostTaskHandle<T>:
    """Handle to a spawned task.

    Full-featured:
    - Non-blocking completion check
    - Blocking join
    - Cancellation
    """
    task_id: usize
    state: TaskState
    result: Option<T>
    error: Option<AsyncError>
    cancel_token: CancellationToken
    wakers: [Waker]

    fn id() -> usize:
        self.task_id

    fn is_finished() -> bool:
        """Non-blocking completion check."""
        self.state.is_terminal()

    fn try_join() -> Option<T>:
        """Non-blocking result retrieval."""
        if self.is_finished():
            self.result
        else:
            nil

    fn try_join_result() -> Option<Result<T, AsyncError>>:
        """Non-blocking result with error."""
        if not self.is_finished():
            return nil

        match self.error:
            case Some(e):
                Some(Err(e))
            case None:
                match self.result:
                    case Some(v): Some(Ok(v))
                    case None: Some(Err(AsyncError.JoinError("no result")))

    fn join() -> HostFuture<T>:
        """Awaitable join (returns future)."""
        if self.is_finished():
            match self.result:
                case Some(v):
                    val ready: HostFuture<T> = HostFuture.ready(v)
                    ready
                case None:
                    val failed: HostFuture<T> = HostFuture.failed(AsyncError.JoinError("no result"))
                    failed
        else:
            # Return pending future linked to this task
            val pending: HostFuture<T> = HostFuture.pending()
            pending

    me cancel():
        """Request task cancellation."""
        self.cancel_token.cancel()

    fn is_cancelled() -> bool:
        """Check if cancellation requested."""
        self.cancel_token.is_cancelled()

    fn state() -> TaskState:
        self.state

# Note: HostTaskHandle implements TaskHandleCore<T> via duck typing

# ============================================================================
# HostJoinSet<T> - Dynamic Task Group
# ============================================================================

class HostJoinSet<T>:
    """Dynamic task group with streaming completion.

    Like Rust's tokio::task::JoinSet:
    - Spawn tasks dynamically
    - Yields results as tasks complete
    - Supports cancellation

    Example:
        var set = HostJoinSet<i64>.new()

        for i in 0..10:
            set.add_task(\: compute(i))

        while val Some((id, result)) = await set.join_next():
            print "Task {id}: {result}"
    """
    handles: [HostTaskHandle<T>]
    completed_queue: [(usize, T)]
    next_poll: usize

    static fn new() -> HostJoinSet<T>:
        HostJoinSet(handles: [], completed_queue: [], next_poll: 0)

    fn len() -> usize:
        self.handles.len()

    fn is_empty() -> bool:
        self.handles.is_empty()

    me add_task(f: fn() -> T) -> usize:
        """Add task into set."""
        val id = task_alloc_id()
        val handle = HostTaskHandle(
            task_id: id,
            state: TaskState.Pending,
            result: nil,
            error: nil,
            cancel_token: CancellationToken.new(),
            wakers: []
        )
        self.handles = self.handles.push(handle)
        id

    me add_task_with_priority(f: fn() -> T, priority: Priority) -> usize:
        """Add task with priority."""
        self.add_task(f)  # Priority handled by scheduler

    fn try_join_next() -> Option<(usize, T)>:
        """Non-blocking: get next completed result."""
        # Check completed queue first
        if not self.completed_queue.is_empty():
            val (id, result) = self.completed_queue[0]
            self.completed_queue = self.completed_queue[1:]
            return Some((id, result))

        # Poll handles
        for idx in 0..self.handles.len():
            val handle = self.handles[idx]
            if handle.is_finished():
                match handle.try_join():
                    case Some(result):
                        val id = handle.id()
                        # Remove from handles
                        self.handles = self.handles.remove(idx)
                        return Some((id, result))
                    case None:
                        pass
        nil

    fn join_next() -> HostFuture<Option<(usize, T)>>:
        """Awaitable: get next completed result."""
        match self.try_join_next():
            case Some(result):
                val ready: HostFuture<Option<(usize, T)>> = HostFuture.ready(Some(result))
                ready
            case None:
                if self.is_empty():
                    val ready_nil: HostFuture<Option<(usize, T)>> = HostFuture.ready(nil)
                    ready_nil
                else:
                    val pending: HostFuture<Option<(usize, T)>> = HostFuture.pending()
                    pending

    me cancel_all():
        """Cancel all tasks."""
        for handle in self.handles:
            handle.cancel()

    fn pending_count() -> usize:
        """Count of tasks not yet completed."""
        var count: usize = 0
        for handle in self.handles:
            if not handle.is_finished():
                count = count + 1
        count

# Note: HostJoinSet implements JoinSetCore<T> via duck typing

# ============================================================================
# HostFuturesUnordered<T> - Dynamic Future Stream
# ============================================================================

class HostFuturesUnordered<T>:
    """Dynamic collection of futures yielding as each completes.

    Like Rust's futures::FuturesUnordered:
    - Push futures dynamically
    - Yields results as futures complete
    - Efficient polling

    Example:
        var futs = HostFuturesUnordered<i64>.new()
        futs.push(fetch1())
        futs.push(fetch2())

        while val Some(result) = await futs.next():
            print "Got: {result}"
    """
    futures: [HostFuture<T>]
    waker: Option<Waker>

    static fn new() -> HostFuturesUnordered<T>:
        HostFuturesUnordered(futures: [], waker: nil)

    fn len() -> usize:
        self.futures.len()

    fn is_empty() -> bool:
        self.futures.is_empty()

    me push(f: HostFuture<T>):
        """Add future to collection."""
        self.futures = self.futures.push(f)

    fn try_next() -> Option<T>:
        """Non-blocking: poll all and return first ready."""
        for idx in 0..self.futures.len():
            if self.futures[idx].is_ready():
                match self.futures[idx].poll():
                    case Poll.Ready(value):
                        self.futures = self.futures.remove(idx)
                        return Some(value)
                    case Poll.Pending:
                        pass
        nil

    fn next() -> HostFuture<Option<T>>:
        """Awaitable: get next completed result."""
        match self.try_next():
            case Some(value):
                val ready: HostFuture<Option<T>> = HostFuture.ready(Some(value))
                ready
            case None:
                if self.is_empty():
                    val ready_nil: HostFuture<Option<T>> = HostFuture.ready(nil)
                    ready_nil
                else:
                    val pending: HostFuture<Option<T>> = HostFuture.pending()
                    pending

    fn poll_next(cx: Context) -> Poll<Option<T>>:
        """Poll with context."""
        match self.try_next():
            case Some(value):
                Poll.Ready(Some(value))
            case None:
                if self.is_empty():
                    Poll.Ready(nil)
                else:
                    self.waker = Some(cx.waker())
                    Poll.Pending

# Note: HostFuturesUnordered implements FuturesUnorderedCore<T> via duck typing

# ============================================================================
# WorkStealingQueue - Per-Scheduler Queue
# ============================================================================

struct WorkStealingQueue:
    """Lock-free work-stealing deque.

    Each scheduler has local queue + can steal from others.
    """
    local: [usize]       # Task IDs - local push/pop
    steal_end: usize     # Index for stealing

    static fn new() -> WorkStealingQueue:
        WorkStealingQueue(local: [], steal_end: 0)

    me push(task_id: usize):
        """Push to local end."""
        self.local = self.local.push(task_id)

    me pop() -> Option<usize>:
        """Pop from local end (LIFO for locality)."""
        if self.local.is_empty():
            return nil
        val last = self.local.len() - 1
        val id = self.local[last]
        self.local = self.local[0:last]
        Some(id)

    me steal() -> Option<usize>:
        """Steal from other end (FIFO)."""
        if self.steal_end >= self.local.len():
            return nil
        val id = self.local[self.steal_end]
        self.steal_end = self.steal_end + 1
        Some(id)

    fn is_empty() -> bool:
        self.local.is_empty()

    fn len() -> usize:
        self.local.len() - self.steal_end

# ============================================================================
# HostScheduler - Work-Stealing Scheduler
# ============================================================================

class HostScheduler:
    """Work-stealing scheduler for host applications.

    Features:
    - Multiple worker threads
    - Work stealing for load balancing
    - Priority scheduling
    - Waker integration
    """
    workers: [WorkStealingQueue]
    global_queue: [usize]
    tasks: Dict<usize, HostTask>
    next_id: usize
    worker_count: usize
    is_running: bool

struct HostTask:
    id: usize
    state: TaskState
    priority: Priority
    poll_fn: fn() -> Poll<()>
    waker: Option<Waker>

impl HostScheduler:
    static fn new(worker_count: usize) -> HostScheduler:
        """Create scheduler with specified worker count."""
        var workers: [WorkStealingQueue] = []
        for _ in 0..worker_count:
            workers = workers.push(WorkStealingQueue.new())

        HostScheduler(
            workers: workers,
            global_queue: [],
            tasks: {},
            next_id: 0,
            worker_count: worker_count,
            is_running: false
        )

    static fn default() -> HostScheduler:
        """Create scheduler with default worker count (4)."""
        HostScheduler.new(4)

    me schedule(priority: Priority, poll_fn: fn() -> Poll<()>) -> usize:
        """Schedule task with priority."""
        val id = self.next_id
        self.next_id = self.next_id + 1

        val task = HostTask(
            id: id,
            state: TaskState.Pending,
            priority: priority,
            poll_fn: poll_fn,
            waker: nil
        )

        self.tasks[id] = task

        # Add to appropriate queue based on priority
        if priority == Priority.Critical:
            # Prepend for high priority
            var new_queue = [id]
            for task in self.global_queue:
                new_queue = new_queue.push(task)
            self.global_queue = new_queue
        else:
            self.global_queue = self.global_queue.push(id)

        id

    me schedule_on_worker(worker_id: usize, poll_fn: fn() -> Poll<()>) -> usize:
        """Schedule on specific worker."""
        val id = self.schedule(Priority.Normal, poll_fn)
        if worker_id < self.worker_count:
            self.workers[worker_id].push(id)
        id

    fn has_runnable() -> bool:
        """Check if any tasks can run."""
        if not self.global_queue.is_empty():
            return true
        for worker in self.workers:
            if not worker.is_empty():
                return true
        false

    me run_one_worker(worker_id: usize) -> bool:
        """Run one task on worker. Returns true if work done."""
        var task_id: Option<usize> = nil

        # Try local queue first
        if worker_id < self.worker_count:
            task_id = self.workers[worker_id].pop()

        # Try global queue
        if not task_id.?:
            if not self.global_queue.is_empty():
                task_id = Some(self.global_queue[0])
                self.global_queue = self.global_queue[1:]

        # Try stealing from other workers
        if not task_id.?:
            for other in 0..self.worker_count:
                if other != worker_id:
                    val stolen = self.workers[other].steal()
                    if stolen.?:
                        task_id = stolen
                        break

        # Execute task
        match task_id:
            case Some(id):
                match self.tasks.get(id):
                    case Some(task):
                        var t = task
                        t.state = TaskState.Running

                        match t.poll_fn():
                            case Poll.Ready(_):
                                t.state = TaskState.Completed
                                # Wake waiters
                                match t.waker:
                                    case Some(w): w.wake()
                                    case None: pass
                            case Poll.Pending:
                                t.state = TaskState.Suspended

                        self.tasks[id] = t
                        return true
                    case None:
                        return false
            case None:
                return false

    me run_one() -> bool:
        """Run one task (round-robin workers)."""
        for worker_id in 0..self.worker_count:
            if self.run_one_worker(worker_id):
                return true
        false

    me run():
        """Run until all tasks complete."""
        self.is_running = true
        while self.is_running and self.has_runnable():
            self.run_one()
        self.is_running = false

    me stop():
        """Stop scheduler."""
        self.is_running = false

    fn is_idle() -> bool:
        not self.has_runnable()

    fn wake_task(task_id: usize):
        """Wake suspended task."""
        match self.tasks.get(task_id):
            case Some(task):
                var t = task
                if t.state == TaskState.Suspended:
                    t.state = TaskState.Pending
                    self.tasks[task_id] = t
                    self.global_queue = self.global_queue.push(task_id)
            case None:
                pass

# Note: HostScheduler implements SchedulerCore via duck typing

# ============================================================================
# HostRuntime - Complete Runtime
# ============================================================================

class HostRuntime:
    """Complete async runtime for host applications.

    Combines scheduler, I/O, and timers.

    Example:
        val runtime = HostRuntime.new()

        val handle = runtime.run_task(async:
            val data = await fetch(url)
            process(data)
        )

        runtime.block_on(handle.join())
    """
    scheduler: HostScheduler
    next_id: usize

    static fn new() -> HostRuntime:
        HostRuntime(
            scheduler: HostScheduler.default(),
            next_id: 0
        )

    static fn with_workers(count: usize) -> HostRuntime:
        HostRuntime(
            scheduler: HostScheduler.new(count),
            next_id: 0
        )

    me run_task<T>(f: fn() -> T) -> HostTaskHandle<T>:
        """Run task and return handle."""
        val id = self.scheduler.schedule(Priority.Normal, \: Poll.Ready(()))
        HostTaskHandle(
            task_id: id,
            state: TaskState.Pending,
            result: nil,
            error: nil,
            cancel_token: CancellationToken.new(),
            wakers: []
        )

    me run_task_with_priority<T>(f: fn() -> T, priority: Priority) -> HostTaskHandle<T>:
        """Run with specific priority."""
        val id = self.scheduler.schedule(priority, \: Poll.Ready(()))
        HostTaskHandle(
            task_id: id,
            state: TaskState.Pending,
            result: nil,
            error: nil,
            cancel_token: CancellationToken.new(),
            wakers: []
        )

    me block_on<T>(future: HostFuture<T>) -> T:
        """Block until future completes."""
        while not future.is_ready():
            self.scheduler.run_one()
        future.poll().unwrap()

    me run():
        """Run all pending tasks."""
        self.scheduler.run()

# ============================================================================
# Combinators
# ============================================================================

fn join_all<T>(futures: [HostFuture<T>]) -> HostFuture<[T]>:
    """Wait for all futures (preserves order)."""
    var results: [T] = []
    var all_ready = true

    for f in futures:
        match f.poll():
            case Poll.Ready(v):
                results = results.push(v)
            case Poll.Pending:
                all_ready = false

    if all_ready:
        val ready: HostFuture<[T]> = HostFuture.ready(results)
        ready
    else:
        val pending: HostFuture<[T]> = HostFuture.pending()
        pending

fn select<T>(futures: [HostFuture<T>]) -> HostFuture<(usize, T)>:
    """Return first completed future with index."""
    for idx in 0..futures.len():
        match futures[idx].poll():
            case Poll.Ready(v):
                val ready: HostFuture<(usize, T)> = HostFuture.ready((idx, v))
                return ready
            case Poll.Pending:
                pass
    val pending: HostFuture<(usize, T)> = HostFuture.pending()
    pending

fn race<T>(futures: [HostFuture<T>]) -> HostFuture<T>:
    """Return first completed future (discards index)."""
    select(futures).map(\pair: pair.1)

fn timeout<T>(future: HostFuture<T>, millis: usize) -> HostFuture<Result<T, AsyncError>>:
    """Add timeout to future."""
    # TODO: Integrate with timer
    future.map(\v: Ok(v))

# ============================================================================
# SFFI Functions (Pure Simple - No FFI Required!)
# ============================================================================
#
# All FFI functions are now Pure Simple implementations from async_sffi:
# - task_alloc_id() - Simple counter
# - waker_signal()  - Simple registry
# - No external FFI needed!

# ============================================================================
# Exports
# ============================================================================

export Waker
export Context
export HostFuture
export FutureState
export HostPromise
export HostTaskHandle
export HostJoinSet
export HostFuturesUnordered
export WorkStealingQueue
export HostScheduler
export HostTask
export HostRuntime
export join_all
export select
export race
export timeout
