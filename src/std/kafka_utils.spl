# Apache Kafka Wire Protocol Module
# Comprehensive implementation of Kafka protocol primitives
# No generics, no exceptions - pure Simple implementation

# ============================================================================
# Constants and Type Definitions
# ============================================================================

# Kafka API Keys
fn API_KEY_PRODUCE() -> i64: 0
fn API_KEY_FETCH() -> i64: 1
fn API_KEY_LIST_OFFSETS() -> i64: 2
fn API_KEY_METADATA() -> i64: 3
fn API_KEY_LEADER_AND_ISR() -> i64: 4
fn API_KEY_STOP_REPLICA() -> i64: 5
fn API_KEY_UPDATE_METADATA() -> i64: 6
fn API_KEY_CONTROLLED_SHUTDOWN() -> i64: 7
fn API_KEY_OFFSET_COMMIT() -> i64: 8
fn API_KEY_OFFSET_FETCH() -> i64: 9
fn API_KEY_FIND_COORDINATOR() -> i64: 10
fn API_KEY_JOIN_GROUP() -> i64: 11
fn API_KEY_HEARTBEAT() -> i64: 12
fn API_KEY_LEAVE_GROUP() -> i64: 13
fn API_KEY_SYNC_GROUP() -> i64: 14
fn API_KEY_DESCRIBE_GROUPS() -> i64: 15
fn API_KEY_LIST_GROUPS() -> i64: 16
fn API_KEY_SASL_HANDSHAKE() -> i64: 17
fn API_KEY_API_VERSIONS() -> i64: 18
fn API_KEY_CREATE_TOPICS() -> i64: 19
fn API_KEY_DELETE_TOPICS() -> i64: 20
fn API_KEY_DELETE_RECORDS() -> i64: 21
fn API_KEY_INIT_PRODUCER_ID() -> i64: 22
fn API_KEY_OFFSET_FOR_LEADER_EPOCH() -> i64: 23
fn API_KEY_ADD_PARTITIONS_TO_TXN() -> i64: 24
fn API_KEY_ADD_OFFSETS_TO_TXN() -> i64: 25
fn API_KEY_END_TXN() -> i64: 26
fn API_KEY_WRITE_TXN_MARKERS() -> i64: 27
fn API_KEY_TXN_OFFSET_COMMIT() -> i64: 28
fn API_KEY_DESCRIBE_ACLS() -> i64: 29
fn API_KEY_CREATE_ACLS() -> i64: 30
fn API_KEY_DELETE_ACLS() -> i64: 31
fn API_KEY_DESCRIBE_CONFIGS() -> i64: 32
fn API_KEY_ALTER_CONFIGS() -> i64: 33

# Kafka Error Codes
fn ERROR_NONE() -> i64: 0
fn ERROR_OFFSET_OUT_OF_RANGE() -> i64: 1
fn ERROR_CORRUPT_MESSAGE() -> i64: 2
fn ERROR_UNKNOWN_TOPIC_OR_PARTITION() -> i64: 3
fn ERROR_INVALID_FETCH_SIZE() -> i64: 4
fn ERROR_LEADER_NOT_AVAILABLE() -> i64: 5
fn ERROR_NOT_LEADER_FOR_PARTITION() -> i64: 6
fn ERROR_REQUEST_TIMED_OUT() -> i64: 7
fn ERROR_BROKER_NOT_AVAILABLE() -> i64: 8
fn ERROR_REPLICA_NOT_AVAILABLE() -> i64: 9
fn ERROR_MESSAGE_TOO_LARGE() -> i64: 10
fn ERROR_STALE_CONTROLLER_EPOCH() -> i64: 11
fn ERROR_OFFSET_METADATA_TOO_LARGE() -> i64: 12
fn ERROR_NETWORK_EXCEPTION() -> i64: 13
fn ERROR_COORDINATOR_LOAD_IN_PROGRESS() -> i64: 14
fn ERROR_COORDINATOR_NOT_AVAILABLE() -> i64: 15
fn ERROR_NOT_COORDINATOR() -> i64: 16
fn ERROR_INVALID_TOPIC_EXCEPTION() -> i64: 17
fn ERROR_RECORD_LIST_TOO_LARGE() -> i64: 18
fn ERROR_NOT_ENOUGH_REPLICAS() -> i64: 19
fn ERROR_NOT_ENOUGH_REPLICAS_AFTER_APPEND() -> i64: 20
fn ERROR_INVALID_REQUIRED_ACKS() -> i64: 21
fn ERROR_ILLEGAL_GENERATION() -> i64: 22
fn ERROR_INCONSISTENT_GROUP_PROTOCOL() -> i64: 23
fn ERROR_INVALID_GROUP_ID() -> i64: 24
fn ERROR_UNKNOWN_MEMBER_ID() -> i64: 25
fn ERROR_INVALID_SESSION_TIMEOUT() -> i64: 26
fn ERROR_REBALANCE_IN_PROGRESS() -> i64: 27
fn ERROR_INVALID_COMMIT_OFFSET_SIZE() -> i64: 28
fn ERROR_TOPIC_AUTHORIZATION_FAILED() -> i64: 29
fn ERROR_GROUP_AUTHORIZATION_FAILED() -> i64: 30
fn ERROR_CLUSTER_AUTHORIZATION_FAILED() -> i64: 31
fn ERROR_INVALID_TIMESTAMP() -> i64: 32
fn ERROR_UNSUPPORTED_SASL_MECHANISM() -> i64: 33
fn ERROR_ILLEGAL_SASL_STATE() -> i64: 34
fn ERROR_UNSUPPORTED_VERSION() -> i64: 35
fn ERROR_TOPIC_ALREADY_EXISTS() -> i64: 36
fn ERROR_INVALID_PARTITIONS() -> i64: 37
fn ERROR_INVALID_REPLICATION_FACTOR() -> i64: 38
fn ERROR_INVALID_REPLICA_ASSIGNMENT() -> i64: 39
fn ERROR_INVALID_CONFIG() -> i64: 40
fn ERROR_NOT_CONTROLLER() -> i64: 41
fn ERROR_INVALID_REQUEST() -> i64: 42
fn ERROR_UNSUPPORTED_FOR_MESSAGE_FORMAT() -> i64: 43
fn ERROR_POLICY_VIOLATION() -> i64: 44
fn ERROR_OUT_OF_ORDER_SEQUENCE_NUMBER() -> i64: 45
fn ERROR_DUPLICATE_SEQUENCE_NUMBER() -> i64: 46
fn ERROR_INVALID_PRODUCER_EPOCH() -> i64: 47
fn ERROR_INVALID_TXN_STATE() -> i64: 48
fn ERROR_INVALID_PRODUCER_ID_MAPPING() -> i64: 49
fn ERROR_INVALID_TRANSACTION_TIMEOUT() -> i64: 50

# Compression Codec Types
fn COMPRESSION_NONE() -> i64: 0
fn COMPRESSION_GZIP() -> i64: 1
fn COMPRESSION_SNAPPY() -> i64: 2
fn COMPRESSION_LZ4() -> i64: 3
fn COMPRESSION_ZSTD() -> i64: 4

# ============================================================================
# Error Handling
# ============================================================================

fn error_code_to_string(code: i64) -> text:
    if code == 0:
        return "NONE"
    if code == 1:
        return "OFFSET_OUT_OF_RANGE"
    if code == 2:
        return "CORRUPT_MESSAGE"
    if code == 3:
        return "UNKNOWN_TOPIC_OR_PARTITION"
    if code == 4:
        return "INVALID_FETCH_SIZE"
    if code == 5:
        return "LEADER_NOT_AVAILABLE"
    if code == 6:
        return "NOT_LEADER_FOR_PARTITION"
    if code == 7:
        return "REQUEST_TIMED_OUT"
    if code == 8:
        return "BROKER_NOT_AVAILABLE"
    if code == 9:
        return "REPLICA_NOT_AVAILABLE"
    if code == 10:
        return "MESSAGE_TOO_LARGE"
    if code == 11:
        return "STALE_CONTROLLER_EPOCH"
    if code == 12:
        return "OFFSET_METADATA_TOO_LARGE"
    if code == 13:
        return "NETWORK_EXCEPTION"
    if code == 14:
        return "COORDINATOR_LOAD_IN_PROGRESS"
    if code == 15:
        return "COORDINATOR_NOT_AVAILABLE"
    if code == 16:
        return "NOT_COORDINATOR"
    if code == 17:
        return "INVALID_TOPIC_EXCEPTION"
    if code == 18:
        return "RECORD_LIST_TOO_LARGE"
    if code == 19:
        return "NOT_ENOUGH_REPLICAS"
    if code == 20:
        return "NOT_ENOUGH_REPLICAS_AFTER_APPEND"
    if code == 21:
        return "INVALID_REQUIRED_ACKS"
    if code == 22:
        return "ILLEGAL_GENERATION"
    if code == 23:
        return "INCONSISTENT_GROUP_PROTOCOL"
    if code == 24:
        return "INVALID_GROUP_ID"
    if code == 25:
        return "UNKNOWN_MEMBER_ID"
    if code == 26:
        return "INVALID_SESSION_TIMEOUT"
    if code == 27:
        return "REBALANCE_IN_PROGRESS"
    if code == 28:
        return "INVALID_COMMIT_OFFSET_SIZE"
    if code == 29:
        return "TOPIC_AUTHORIZATION_FAILED"
    if code == 30:
        return "GROUP_AUTHORIZATION_FAILED"
    if code == 31:
        return "CLUSTER_AUTHORIZATION_FAILED"
    if code == 32:
        return "INVALID_TIMESTAMP"
    if code == 33:
        return "UNSUPPORTED_SASL_MECHANISM"
    if code == 34:
        return "ILLEGAL_SASL_STATE"
    if code == 35:
        return "UNSUPPORTED_VERSION"
    if code == 36:
        return "TOPIC_ALREADY_EXISTS"
    if code == 37:
        return "INVALID_PARTITIONS"
    if code == 38:
        return "INVALID_REPLICATION_FACTOR"
    if code == 39:
        return "INVALID_REPLICA_ASSIGNMENT"
    if code == 40:
        return "INVALID_CONFIG"
    if code == 41:
        return "NOT_CONTROLLER"
    if code == 42:
        return "INVALID_REQUEST"
    if code == 43:
        return "UNSUPPORTED_FOR_MESSAGE_FORMAT"
    if code == 44:
        return "POLICY_VIOLATION"
    if code == 45:
        return "OUT_OF_ORDER_SEQUENCE_NUMBER"
    if code == 46:
        return "DUPLICATE_SEQUENCE_NUMBER"
    if code == 47:
        return "INVALID_PRODUCER_EPOCH"
    if code == 48:
        return "INVALID_TXN_STATE"
    if code == 49:
        return "INVALID_PRODUCER_ID_MAPPING"
    if code == 50:
        return "INVALID_TRANSACTION_TIMEOUT"
    "UNKNOWN_ERROR"

fn is_error(code: i64) -> bool:
    code != 0

fn is_retriable_error(code: i64) -> bool:
    var retriable = code == 5
    if code == 6:
        retriable = true
    if code == 7:
        retriable = true
    if code == 14:
        retriable = true
    if code == 15:
        retriable = true
    retriable

# ============================================================================
# Request/Response Structure
# ============================================================================

# Request header: (api_key, version, correlation_id, client_id)
fn create_request_header(api_key: i64, version: i64, correlation_id: i64, client_id: text) -> list:
    [api_key, version, correlation_id, client_id]

fn get_request_api_key(header: list) -> i64:
    header[0]

fn get_request_version(header: list) -> i64:
    header[1]

fn get_request_correlation_id(header: list) -> i64:
    header[2]

fn get_request_client_id(header: list) -> text:
    header[3]

# Response header: (correlation_id)
fn create_response_header(correlation_id: i64) -> list:
    [correlation_id]

fn get_response_correlation_id(header: list) -> i64:
    header[0]

# Full request: (header, body)
fn create_request(header: list, body: list) -> list:
    [header, body]

fn get_request_header(request: list) -> list:
    request[0]

fn get_request_body(request: list) -> list:
    request[1]

# Full response: (header, body)
fn create_response(header: list, body: list) -> list:
    [header, body]

fn get_response_header(response: list) -> list:
    response[0]

fn get_response_body(response: list) -> list:
    response[1]

# ============================================================================
# Topic and Partition Structures
# ============================================================================

# Topic: (name, partitions)
fn create_topic(name: text, partitions: list) -> list:
    [name, partitions]

fn get_topic_name(topic: list) -> text:
    topic[0]

fn get_topic_partitions(topic: list) -> list:
    topic[1]

# Partition: (partition_id, leader, replicas, isr)
fn create_partition(partition_id: i64, leader: i64, replicas: list, isr: list) -> list:
    [partition_id, leader, replicas, isr]

fn get_partition_id(partition: list) -> i64:
    partition[0]

fn get_partition_leader(partition: list) -> i64:
    partition[1]

fn get_partition_replicas(partition: list) -> list:
    partition[2]

fn get_partition_isr(partition: list) -> list:
    partition[3]

# Partition metadata: (partition_id, error_code, leader, replicas, isr)
fn create_partition_metadata(partition_id: i64, error_code: i64, leader: i64, replicas: list, isr: list) -> list:
    [partition_id, error_code, leader, replicas, isr]

fn get_partition_metadata_id(metadata: list) -> i64:
    metadata[0]

fn get_partition_metadata_error(metadata: list) -> i64:
    metadata[1]

fn get_partition_metadata_leader(metadata: list) -> i64:
    metadata[2]

fn get_partition_metadata_replicas(metadata: list) -> list:
    metadata[3]

fn get_partition_metadata_isr(metadata: list) -> list:
    metadata[4]

# Broker: (node_id, host, port)
fn create_broker(node_id: i64, host: text, port: i64) -> list:
    [node_id, host, port]

fn get_broker_node_id(broker: list) -> i64:
    broker[0]

fn get_broker_host(broker: list) -> text:
    broker[1]

fn get_broker_port(broker: list) -> i64:
    broker[2]

# ============================================================================
# Record Format
# ============================================================================

# Record: (key, value, headers, timestamp, offset)
fn create_record(key: text, value: text, headers: list, timestamp: i64, offset: i64) -> list:
    [key, value, headers, timestamp, offset]

fn get_record_key(record: list) -> text:
    record[0]

fn get_record_value(record: list) -> text:
    record[1]

fn get_record_headers(record: list) -> list:
    record[2]

fn get_record_timestamp(record: list) -> i64:
    record[3]

fn get_record_offset(record: list) -> i64:
    record[4]

# Record header: (key, value)
fn create_record_header(key: text, value: text) -> list:
    [key, value]

fn get_record_header_key(header: list) -> text:
    header[0]

fn get_record_header_value(header: list) -> text:
    header[1]

# Record batch: (base_offset, partition_leader_epoch, attributes, records, last_offset_delta, compression)
fn create_record_batch(base_offset: i64, partition_leader_epoch: i64, attributes: i64, records: list, last_offset_delta: i64, compression: i64) -> list:
    [base_offset, partition_leader_epoch, attributes, records, last_offset_delta, compression]

fn get_record_batch_base_offset(batch: list) -> i64:
    batch[0]

fn get_record_batch_partition_leader_epoch(batch: list) -> i64:
    batch[1]

fn get_record_batch_attributes(batch: list) -> i64:
    batch[2]

fn get_record_batch_records(batch: list) -> list:
    batch[3]

fn get_record_batch_last_offset_delta(batch: list) -> i64:
    batch[4]

fn get_record_batch_compression(batch: list) -> i64:
    batch[5]

# ============================================================================
# Producer API
# ============================================================================

# Produce request body: (acks, timeout_ms, topic_data)
# topic_data: [(topic_name, partition_data)]
# partition_data: [(partition_id, record_batch)]
fn create_produce_request_body(acks: i64, timeout_ms: i64, topic_data: list) -> list:
    [acks, timeout_ms, topic_data]

fn get_produce_request_acks(body: list) -> i64:
    body[0]

fn get_produce_request_timeout(body: list) -> i64:
    body[1]

fn get_produce_request_topic_data(body: list) -> list:
    body[2]

# Produce response body: (throttle_time_ms, topic_data)
# topic_data: [(topic_name, partition_data)]
# partition_data: [(partition_id, error_code, base_offset, log_append_time, log_start_offset)]
fn create_produce_response_body(throttle_time_ms: i64, topic_data: list) -> list:
    [throttle_time_ms, topic_data]

fn get_produce_response_throttle_time(body: list) -> i64:
    body[0]

fn get_produce_response_topic_data(body: list) -> list:
    body[1]

# Produce partition response: (partition_id, error_code, base_offset, log_append_time, log_start_offset)
fn create_produce_partition_response(partition_id: i64, error_code: i64, base_offset: i64, log_append_time: i64, log_start_offset: i64) -> list:
    [partition_id, error_code, base_offset, log_append_time, log_start_offset]

fn get_produce_partition_response_id(response: list) -> i64:
    response[0]

fn get_produce_partition_response_error(response: list) -> i64:
    response[1]

fn get_produce_partition_response_base_offset(response: list) -> i64:
    response[2]

fn get_produce_partition_response_log_append_time(response: list) -> i64:
    response[3]

fn get_produce_partition_response_log_start_offset(response: list) -> i64:
    response[4]

# ============================================================================
# Consumer API - Fetch
# ============================================================================

# Fetch request body: (replica_id, max_wait_ms, min_bytes, max_bytes, isolation_level, topic_data)
# topic_data: [(topic_name, partition_data)]
# partition_data: [(partition_id, fetch_offset, log_start_offset, max_bytes)]
fn create_fetch_request_body(replica_id: i64, max_wait_ms: i64, min_bytes: i64, max_bytes: i64, isolation_level: i64, topic_data: list) -> list:
    [replica_id, max_wait_ms, min_bytes, max_bytes, isolation_level, topic_data]

fn get_fetch_request_replica_id(body: list) -> i64:
    body[0]

fn get_fetch_request_max_wait_ms(body: list) -> i64:
    body[1]

fn get_fetch_request_min_bytes(body: list) -> i64:
    body[2]

fn get_fetch_request_max_bytes(body: list) -> i64:
    body[3]

fn get_fetch_request_isolation_level(body: list) -> i64:
    body[4]

fn get_fetch_request_topic_data(body: list) -> list:
    body[5]

# Fetch partition request: (partition_id, fetch_offset, log_start_offset, max_bytes)
fn create_fetch_partition_request(partition_id: i64, fetch_offset: i64, log_start_offset: i64, max_bytes: i64) -> list:
    [partition_id, fetch_offset, log_start_offset, max_bytes]

fn get_fetch_partition_request_id(request: list) -> i64:
    request[0]

fn get_fetch_partition_request_offset(request: list) -> i64:
    request[1]

fn get_fetch_partition_request_log_start_offset(request: list) -> i64:
    request[2]

fn get_fetch_partition_request_max_bytes(request: list) -> i64:
    request[3]

# Fetch response body: (throttle_time_ms, error_code, session_id, topic_data)
# topic_data: [(topic_name, partition_data)]
# partition_data: [(partition_id, error_code, high_watermark, last_stable_offset, log_start_offset, record_batch)]
fn create_fetch_response_body(throttle_time_ms: i64, error_code: i64, session_id: i64, topic_data: list) -> list:
    [throttle_time_ms, error_code, session_id, topic_data]

fn get_fetch_response_throttle_time(body: list) -> i64:
    body[0]

fn get_fetch_response_error_code(body: list) -> i64:
    body[1]

fn get_fetch_response_session_id(body: list) -> i64:
    body[2]

fn get_fetch_response_topic_data(body: list) -> list:
    body[3]

# Fetch partition response: (partition_id, error_code, high_watermark, last_stable_offset, log_start_offset, record_batch)
fn create_fetch_partition_response(partition_id: i64, error_code: i64, high_watermark: i64, last_stable_offset: i64, log_start_offset: i64, record_batch: list) -> list:
    [partition_id, error_code, high_watermark, last_stable_offset, log_start_offset, record_batch]

fn get_fetch_partition_response_id(response: list) -> i64:
    response[0]

fn get_fetch_partition_response_error(response: list) -> i64:
    response[1]

fn get_fetch_partition_response_high_watermark(response: list) -> i64:
    response[2]

fn get_fetch_partition_response_last_stable_offset(response: list) -> i64:
    response[3]

fn get_fetch_partition_response_log_start_offset(response: list) -> i64:
    response[4]

fn get_fetch_partition_response_record_batch(response: list) -> list:
    response[5]

# ============================================================================
# Consumer API - Offset Management
# ============================================================================

# Offset commit request body: (group_id, generation_id, member_id, retention_time_ms, topic_data)
# topic_data: [(topic_name, partition_data)]
# partition_data: [(partition_id, offset, metadata)]
fn create_offset_commit_request_body(group_id: text, generation_id: i64, member_id: text, retention_time_ms: i64, topic_data: list) -> list:
    [group_id, generation_id, member_id, retention_time_ms, topic_data]

fn get_offset_commit_request_group_id(body: list) -> text:
    body[0]

fn get_offset_commit_request_generation_id(body: list) -> i64:
    body[1]

fn get_offset_commit_request_member_id(body: list) -> text:
    body[2]

fn get_offset_commit_request_retention_time(body: list) -> i64:
    body[3]

fn get_offset_commit_request_topic_data(body: list) -> list:
    body[4]

# Offset commit partition request: (partition_id, offset, metadata)
fn create_offset_commit_partition_request(partition_id: i64, offset: i64, metadata: text) -> list:
    [partition_id, offset, metadata]

fn get_offset_commit_partition_request_id(request: list) -> i64:
    request[0]

fn get_offset_commit_partition_request_offset(request: list) -> i64:
    request[1]

fn get_offset_commit_partition_request_metadata(request: list) -> text:
    request[2]

# Offset commit response body: (throttle_time_ms, topic_data)
# topic_data: [(topic_name, partition_data)]
# partition_data: [(partition_id, error_code)]
fn create_offset_commit_response_body(throttle_time_ms: i64, topic_data: list) -> list:
    [throttle_time_ms, topic_data]

fn get_offset_commit_response_throttle_time(body: list) -> i64:
    body[0]

fn get_offset_commit_response_topic_data(body: list) -> list:
    body[1]

# Offset fetch request body: (group_id, topic_data)
# topic_data: [(topic_name, partition_ids)]
fn create_offset_fetch_request_body(group_id: text, topic_data: list) -> list:
    [group_id, topic_data]

fn get_offset_fetch_request_group_id(body: list) -> text:
    body[0]

fn get_offset_fetch_request_topic_data(body: list) -> list:
    body[1]

# Offset fetch response body: (throttle_time_ms, topic_data, error_code)
# topic_data: [(topic_name, partition_data)]
# partition_data: [(partition_id, offset, metadata, error_code)]
fn create_offset_fetch_response_body(throttle_time_ms: i64, topic_data: list, error_code: i64) -> list:
    [throttle_time_ms, topic_data, error_code]

fn get_offset_fetch_response_throttle_time(body: list) -> i64:
    body[0]

fn get_offset_fetch_response_topic_data(body: list) -> list:
    body[1]

fn get_offset_fetch_response_error_code(body: list) -> i64:
    body[2]

# Offset fetch partition response: (partition_id, offset, metadata, error_code)
fn create_offset_fetch_partition_response(partition_id: i64, offset: i64, metadata: text, error_code: i64) -> list:
    [partition_id, offset, metadata, error_code]

fn get_offset_fetch_partition_response_id(response: list) -> i64:
    response[0]

fn get_offset_fetch_partition_response_offset(response: list) -> i64:
    response[1]

fn get_offset_fetch_partition_response_metadata(response: list) -> text:
    response[2]

fn get_offset_fetch_partition_response_error(response: list) -> i64:
    response[3]

# ============================================================================
# Metadata API
# ============================================================================

# Metadata request body: (topics, allow_auto_topic_creation)
# topics: [topic_name]
fn create_metadata_request_body(topics: list, allow_auto_topic_creation: bool) -> list:
    [topics, allow_auto_topic_creation]

fn get_metadata_request_topics(body: list) -> list:
    body[0]

fn get_metadata_request_allow_auto_topic_creation(body: list) -> bool:
    body[1]

# Metadata response body: (throttle_time_ms, brokers, cluster_id, controller_id, topic_metadata)
# brokers: [(node_id, host, port, rack)]
# topic_metadata: [(error_code, topic_name, is_internal, partition_metadata)]
fn create_metadata_response_body(throttle_time_ms: i64, brokers: list, cluster_id: text, controller_id: i64, topic_metadata: list) -> list:
    [throttle_time_ms, brokers, cluster_id, controller_id, topic_metadata]

fn get_metadata_response_throttle_time(body: list) -> i64:
    body[0]

fn get_metadata_response_brokers(body: list) -> list:
    body[1]

fn get_metadata_response_cluster_id(body: list) -> text:
    body[2]

fn get_metadata_response_controller_id(body: list) -> i64:
    body[3]

fn get_metadata_response_topic_metadata(body: list) -> list:
    body[4]

# Topic metadata: (error_code, topic_name, is_internal, partition_metadata)
fn create_topic_metadata(error_code: i64, topic_name: text, is_internal: bool, partition_metadata: list) -> list:
    [error_code, topic_name, is_internal, partition_metadata]

fn get_topic_metadata_error_code(metadata: list) -> i64:
    metadata[0]

fn get_topic_metadata_name(metadata: list) -> text:
    metadata[1]

fn get_topic_metadata_is_internal(metadata: list) -> bool:
    metadata[2]

fn get_topic_metadata_partition_metadata(metadata: list) -> list:
    metadata[3]

# ============================================================================
# Group Coordination API
# ============================================================================

# Join group request body: (group_id, session_timeout_ms, rebalance_timeout_ms, member_id, protocol_type, group_protocols)
# group_protocols: [(protocol_name, protocol_metadata)]
fn create_join_group_request_body(group_id: text, session_timeout_ms: i64, rebalance_timeout_ms: i64, member_id: text, protocol_type: text, group_protocols: list) -> list:
    [group_id, session_timeout_ms, rebalance_timeout_ms, member_id, protocol_type, group_protocols]

fn get_join_group_request_group_id(body: list) -> text:
    body[0]

fn get_join_group_request_session_timeout(body: list) -> i64:
    body[1]

fn get_join_group_request_rebalance_timeout(body: list) -> i64:
    body[2]

fn get_join_group_request_member_id(body: list) -> text:
    body[3]

fn get_join_group_request_protocol_type(body: list) -> text:
    body[4]

fn get_join_group_request_group_protocols(body: list) -> list:
    body[5]

# Join group response body: (throttle_time_ms, error_code, generation_id, protocol_name, leader, member_id, members)
# members: [(member_id, metadata)]
fn create_join_group_response_body(throttle_time_ms: i64, error_code: i64, generation_id: i64, protocol_name: text, leader: text, member_id: text, members: list) -> list:
    [throttle_time_ms, error_code, generation_id, protocol_name, leader, member_id, members]

fn get_join_group_response_throttle_time(body: list) -> i64:
    body[0]

fn get_join_group_response_error_code(body: list) -> i64:
    body[1]

fn get_join_group_response_generation_id(body: list) -> i64:
    body[2]

fn get_join_group_response_protocol_name(body: list) -> text:
    body[3]

fn get_join_group_response_leader(body: list) -> text:
    body[4]

fn get_join_group_response_member_id(body: list) -> text:
    body[5]

fn get_join_group_response_members(body: list) -> list:
    body[6]

# Sync group request body: (group_id, generation_id, member_id, group_assignment)
# group_assignment: [(member_id, member_assignment)]
fn create_sync_group_request_body(group_id: text, generation_id: i64, member_id: text, group_assignment: list) -> list:
    [group_id, generation_id, member_id, group_assignment]

fn get_sync_group_request_group_id(body: list) -> text:
    body[0]

fn get_sync_group_request_generation_id(body: list) -> i64:
    body[1]

fn get_sync_group_request_member_id(body: list) -> text:
    body[2]

fn get_sync_group_request_group_assignment(body: list) -> list:
    body[3]

# Sync group response body: (throttle_time_ms, error_code, member_assignment)
fn create_sync_group_response_body(throttle_time_ms: i64, error_code: i64, member_assignment: list) -> list:
    [throttle_time_ms, error_code, member_assignment]

fn get_sync_group_response_throttle_time(body: list) -> i64:
    body[0]

fn get_sync_group_response_error_code(body: list) -> i64:
    body[1]

fn get_sync_group_response_member_assignment(body: list) -> list:
    body[2]

# Heartbeat request body: (group_id, generation_id, member_id)
fn create_heartbeat_request_body(group_id: text, generation_id: i64, member_id: text) -> list:
    [group_id, generation_id, member_id]

fn get_heartbeat_request_group_id(body: list) -> text:
    body[0]

fn get_heartbeat_request_generation_id(body: list) -> i64:
    body[1]

fn get_heartbeat_request_member_id(body: list) -> text:
    body[2]

# Heartbeat response body: (throttle_time_ms, error_code)
fn create_heartbeat_response_body(throttle_time_ms: i64, error_code: i64) -> list:
    [throttle_time_ms, error_code]

fn get_heartbeat_response_throttle_time(body: list) -> i64:
    body[0]

fn get_heartbeat_response_error_code(body: list) -> i64:
    body[1]

# Leave group request body: (group_id, member_id)
fn create_leave_group_request_body(group_id: text, member_id: text) -> list:
    [group_id, member_id]

fn get_leave_group_request_group_id(body: list) -> text:
    body[0]

fn get_leave_group_request_member_id(body: list) -> text:
    body[1]

# Leave group response body: (throttle_time_ms, error_code)
fn create_leave_group_response_body(throttle_time_ms: i64, error_code: i64) -> list:
    [throttle_time_ms, error_code]

fn get_leave_group_response_throttle_time(body: list) -> i64:
    body[0]

fn get_leave_group_response_error_code(body: list) -> i64:
    body[1]

# ============================================================================
# Compression Utilities
# ============================================================================

fn compression_codec_to_string(codec: i64) -> text:
    if codec == 0:
        return "none"
    if codec == 1:
        return "gzip"
    if codec == 2:
        return "snappy"
    if codec == 3:
        return "lz4"
    if codec == 4:
        return "zstd"
    "unknown"

fn compression_codec_from_string(codec_name: text) -> i64:
    if codec_name == "none":
        return 0
    if codec_name == "gzip":
        return 1
    if codec_name == "snappy":
        return 2
    if codec_name == "lz4":
        return 3
    if codec_name == "zstd":
        return 4
    0

fn is_valid_compression_codec(codec: i64) -> bool:
    var valid = codec == 0
    if codec == 1:
        valid = true
    if codec == 2:
        valid = true
    if codec == 3:
        valid = true
    if codec == 4:
        valid = true
    valid

# ============================================================================
# Varint Encoding Utilities
# ============================================================================

# Encode unsigned varint (used in Kafka protocol)
fn encode_varint_unsigned(value: i64) -> list:
    var result = []
    var remaining = value
    var continue_encoding = true

    if remaining == 0:
        return [0]

    # Encode 7 bits at a time
    while continue_encoding:
        var byte_val = remaining % 128
        remaining = remaining / 128

        if remaining > 0:
            byte_val = byte_val + 128

        var temp = result
        result = temp + [byte_val]

        if remaining == 0:
            continue_encoding = false

    result

# Decode unsigned varint
fn decode_varint_unsigned(bytes: list) -> i64:
    var result = 0
    var shift = 0
    var idx = 0
    var byte_count = 0

    # Safety: limit to 10 bytes maximum
    while byte_count < 10:
        if idx >= bytes.len():
            return result

        var byte_val = bytes[idx]
        var value_bits = byte_val % 128
        result = result + (value_bits * (2 ** shift))

        idx = idx + 1
        byte_count = byte_count + 1
        shift = shift + 7

        # Check if this is the last byte
        if byte_val < 128:
            return result

    result

# Encode signed varint using zigzag encoding
fn encode_varint_signed(value: i64) -> list:
    var zigzag = 0
    if value >= 0:
        zigzag = value * 2
    if value < 0:
        zigzag = (value * -2) - 1
    encode_varint_unsigned(zigzag)

# Decode signed varint using zigzag encoding
fn decode_varint_signed(bytes: list) -> i64:
    var zigzag = decode_varint_unsigned(bytes)
    var is_negative = (zigzag % 2) == 1

    if is_negative:
        return (zigzag + 1) / -2

    zigzag / 2

# ============================================================================
# CRC32 Calculation
# ============================================================================

# Simple CRC32 implementation for Kafka message integrity
# Using standard CRC32 polynomial: 0xEDB88320
fn crc32_table() -> list:
    [
        0x00000000, 0x77073096, 0xEE0E612C, 0x990951BA, 0x076DC419, 0x706AF48F,
        0xE963A535, 0x9E6495A3, 0x0EDB8832, 0x79DCB8A4, 0xE0D5E91E, 0x97D2D988,
        0x09B64C2B, 0x7EB17CBD, 0xE7B82D07, 0x90BF1D91, 0x1DB71064, 0x6AB020F2,
        0xF3B97148, 0x84BE41DE, 0x1ADAD47D, 0x6DDDE4EB, 0xF4D4B551, 0x83D385C7,
        0x136C9856, 0x646BA8C0, 0xFD62F97A, 0x8A65C9EC, 0x14015C4F, 0x63066CD9,
        0xFA0F3D63, 0x8D080DF5, 0x3B6E20C8, 0x4C69105E, 0xD56041E4, 0xA2677172,
        0x3C03E4D1, 0x4B04D447, 0xD20D85FD, 0xA50AB56B, 0x35B5A8FA, 0x42B2986C,
        0xDBBBC9D6, 0xACBCF940, 0x32D86CE3, 0x45DF5C75, 0xDCD60DCF, 0xABD13D59,
        0x26D930AC, 0x51DE003A, 0xC8D75180, 0xBFD06116, 0x21B4F4B5, 0x56B3C423,
        0xCFBA9599, 0xB8BDA50F, 0x2802B89E, 0x5F058808, 0xC60CD9B2, 0xB10BE924,
        0x2F6F7C87, 0x58684C11, 0xC1611DAB, 0xB6662D3D
    ]

fn crc32_calculate(data: text) -> i64:
    var table = crc32_table()
    var crc = 0xFFFFFFFF
    var idx = 0
    var data_len = data.len()

    while idx < data_len:
        var byte_val = data[idx].ord()
        var table_idx = (crc ^ byte_val) % 256
        crc = (crc / 256) ^ table[table_idx]
        idx = idx + 1

    crc ^ 0xFFFFFFFF

fn crc32_verify(data: text, expected_crc: i64) -> bool:
    var calculated = crc32_calculate(data)
    calculated == expected_crc

# ============================================================================
# Serialization Utilities
# ============================================================================

# Convert i64 to 4-byte representation (big-endian)
fn int32_to_bytes(value: i64) -> list:
    var byte0 = (value / 16777216) % 256
    var byte1 = (value / 65536) % 256
    var byte2 = (value / 256) % 256
    var byte3 = value % 256
    [byte0, byte1, byte2, byte3]

# Convert i64 to 8-byte representation (big-endian)
fn int64_to_bytes(value: i64) -> list:
    var upper = value / 4294967296
    var lower = value % 4294967296
    var bytes_upper = int32_to_bytes(upper)
    var bytes_lower = int32_to_bytes(lower)
    bytes_upper + bytes_lower

# Convert 4 bytes to i64 (big-endian)
fn bytes_to_int32(bytes: list) -> i64:
    if bytes.len() < 4:
        return 0
    var result = bytes[0] * 16777216
    result = result + (bytes[1] * 65536)
    result = result + (bytes[2] * 256)
    result = result + bytes[3]
    result

# Convert 8 bytes to i64 (big-endian)
fn bytes_to_int64(bytes: list) -> i64:
    if bytes.len() < 8:
        return 0
    var upper_bytes = [bytes[0], bytes[1], bytes[2], bytes[3]]
    var lower_bytes = [bytes[4], bytes[5], bytes[6], bytes[7]]
    var upper = bytes_to_int32(upper_bytes)
    var lower = bytes_to_int32(lower_bytes)
    (upper * 4294967296) + lower

# Serialize text with length prefix
fn serialize_string(value: text) -> list:
    var length = value.len()
    var length_bytes = int32_to_bytes(length)
    var result = length_bytes
    var idx = 0

    while idx < length:
        var char_code = value[idx].ord()
        var temp = result
        result = temp + [char_code]
        idx = idx + 1

    result

# Deserialize text with length prefix
fn deserialize_string(bytes: list, offset: i64) -> text:
    if offset + 4 > bytes.len():
        return ""

    var length_bytes = [bytes[offset], bytes[offset + 1], bytes[offset + 2], bytes[offset + 3]]
    var length = bytes_to_int32(length_bytes)

    if length <= 0:
        return ""

    if offset + 4 + length > bytes.len():
        return ""

    var result = ""
    var idx = 0

    while idx < length:
        var byte_val = bytes[offset + 4 + idx]
        var char = byte_val.chr()
        result = result + char
        idx = idx + 1

    result

# ============================================================================
# Utility Functions
# ============================================================================

# Get current timestamp in milliseconds (mock implementation)
fn get_current_timestamp_ms() -> i64:
    # In real implementation, this would call external time function
    1234567890000

# Generate correlation ID (mock implementation)
fn generate_correlation_id() -> i64:
    # In real implementation, this would be a counter or random number
    42

# Validate topic name
fn is_valid_topic_name(topic: text) -> bool:
    var length = topic.len()
    if length == 0:
        return false
    if length > 249:
        return false

    # Must not be "." or ".."
    if topic == ".":
        return false
    if topic == "..":
        return false

    # Must contain only alphanumeric, dots, underscores, hyphens
    var idx = 0
    while idx < length:
        var char = topic[idx]
        var is_valid_char = false

        if char >= "a":
            if char <= "z":
                is_valid_char = true
        if char >= "A":
            if char <= "Z":
                is_valid_char = true
        if char >= "0":
            if char <= "9":
                is_valid_char = true
        if char == ".":
            is_valid_char = true
        if char == "_":
            is_valid_char = true
        if char == "-":
            is_valid_char = true

        if is_valid_char == false:
            return false

        idx = idx + 1

    true

# Validate group ID
fn is_valid_group_id(group_id: text) -> bool:
    var length = group_id.len()
    if length == 0:
        return false
    if length > 255:
        return false
    true

# Calculate record batch size
fn calculate_record_batch_size(batch: list) -> i64:
    var records = get_record_batch_records(batch)
    var record_count = records.len()
    var base_size = 61
    var total_size = base_size
    var idx = 0

    while idx < record_count:
        var record = records[idx]
        var key = get_record_key(record)
        var value = get_record_value(record)
        var headers = get_record_headers(record)

        var record_size = 10
        record_size = record_size + key.len()
        record_size = record_size + value.len()
        record_size = record_size + (headers.len() * 20)

        total_size = total_size + record_size
        idx = idx + 1

    total_size

# Find broker by node ID
fn find_broker_by_node_id(brokers: list, node_id: i64) -> list:
    var idx = 0
    var broker_count = brokers.len()

    while idx < broker_count:
        var broker = brokers[idx]
        var broker_node_id = get_broker_node_id(broker)

        if broker_node_id == node_id:
            return broker

        idx = idx + 1

    []

# Find partition leader
fn find_partition_leader(partition_metadata: list, partition_id: i64) -> i64:
    var idx = 0
    var partition_count = partition_metadata.len()

    while idx < partition_count:
        var metadata = partition_metadata[idx]
        var metadata_id = get_partition_metadata_id(metadata)

        if metadata_id == partition_id:
            return get_partition_metadata_leader(metadata)

        idx = idx + 1

    -1

# Check if partition is in-sync
fn is_partition_in_sync(partition_metadata: list, replica_id: i64) -> bool:
    var isr = get_partition_metadata_isr(partition_metadata)
    var idx = 0
    var isr_count = isr.len()

    while idx < isr_count:
        var isr_replica = isr[idx]

        if isr_replica == replica_id:
            return true

        idx = idx + 1

    false
