# Semantic doc similarity report formatter

use app.duplicate_check.config.{DuplicationConfig}
use app.duplicate_check.doc_extractor.{DocEntry}
use app.duplicate_check.semantic.{SemanticMatch, SemanticReport}

# JSON helpers (avoid }} escape bug)
fn _LB() -> text:
    (123 as char).to_text()

fn _RB() -> text:
    (125 as char).to_text()

fn _Q() -> text:
    "\""

fn _escape_json(s: text) -> text:
    var result = ""
    var i = 0
    while i < s.len():
        val ch = s[i]
        if ch == "\\":
            result = result + "\\\\"
        elif ch == "\"":
            result = result + "\\\""
        elif ch == "\n":
            result = result + "\\n"
        elif ch == "\r":
            result = result + "\\r"
        elif ch == "\t":
            result = result + "\\t"
        else:
            result = result + ch
        i = i + 1
    result

fn print_semantic_text_report(report: SemanticReport, config: DuplicationConfig):
    print "Semantic Doc Similarity Report"
    print "=============================="
    print ""

    val fallback_note = if report.used_fallback: " [text-based fallback]" else: ""
    print "Source: {report.total_items} items, {report.items_with_docs} documented{fallback_note}"

    if not report.used_fallback:
        print "Model: {config.semantic_model} via Ollama"
        print "Cache: {report.cache_hits} cached / {report.cache_misses} new"

    print ""

    # Copy-paste docs
    var copy_paste_matches: [SemanticMatch] = []
    var similar_matches: [SemanticMatch] = []
    var drift_matches: [SemanticMatch] = []

    for m in report.matches:
        if m.match_kind == "copy_paste" or m.match_kind.starts_with("copy_paste"):
            copy_paste_matches = copy_paste_matches + [m]
        elif m.match_kind == "drift":
            drift_matches = drift_matches + [m]
        else:
            similar_matches = similar_matches + [m]

    val all_similar = copy_paste_matches + similar_matches

    if all_similar.len() > 0:
        print "Similar Docs (>{format_threshold(config.semantic_threshold)}): {all_similar.len()} pairs"
        for m in all_similar:
            val line = format_match_line(m)
            print line
        print ""

    if drift_matches.len() > 0:
        print "Drift Warnings (<{format_threshold(config.semantic_drift_threshold)}): {drift_matches.len()} items"
        for m in drift_matches:
            val line = format_match_line(m)
            print line
        print ""

    # Missing docs
    if report.missing_docs.len() > 0:
        # Group by file
        var file_counts: {text: i64} = {}
        for entry in report.missing_docs:
            val current = file_counts[entry.file_path] ?? 0
            file_counts[entry.file_path] = current + 1

        val pct = if report.total_items > 0:
            val missing_f = report.missing_docs.len() * 1000 / report.total_items
            missing_f / 10.0
        else:
            0.0

        print "Missing Docs: {report.missing_docs.len()} items ({pct}%)"
        val file_keys = file_counts.keys()
        for fk in file_keys:
            val count = file_counts[fk]
            print "  {fk}: {count} items"
        print ""

    # Summary
    val doc_pct = if report.total_items > 0:
        val doc_f = report.items_with_docs * 1000 / report.total_items
        doc_f / 10.0
    else:
        0.0

    print "Summary: {report.total_items} total, {report.items_with_docs} documented ({doc_pct}%), {all_similar.len()} similar, {drift_matches.len()} drift"

fn print_semantic_json_report(report: SemanticReport):
    val lb = _LB()
    val rb = _RB()
    val q = _Q()

    print lb
    print "  " + q + "summary" + q + ": " + lb
    print "    " + q + "total_items" + q + ": {report.total_items},"
    print "    " + q + "items_with_docs" + q + ": {report.items_with_docs},"
    print "    " + q + "missing_docs" + q + ": {report.missing_docs.len()},"
    print "    " + q + "similar_pairs" + q + ": {report.matches.len()},"
    print "    " + q + "cache_hits" + q + ": {report.cache_hits},"
    print "    " + q + "cache_misses" + q + ": {report.cache_misses},"
    print "    " + q + "used_fallback" + q + ": {report.used_fallback}"
    print "  " + rb + ","

    # Matches
    print "  " + q + "matches" + q + ": ["
    var m_idx = 0
    for m in report.matches:
        val entry_a_json = format_entry_json(m.entry_a)
        val entry_b_json = format_entry_json(m.entry_b)
        val comma = if m_idx < report.matches.len() - 1: "," else: ""
        print "    " + lb
        print "      " + q + "similarity" + q + ": {m.similarity},"
        print "      " + q + "kind" + q + ": " + q + _escape_json(m.match_kind) + q + ","
        print "      " + q + "entry_a" + q + ": " + entry_a_json + ","
        print "      " + q + "entry_b" + q + ": " + entry_b_json
        print "    " + rb + comma
        m_idx = m_idx + 1
    print "  ],"

    # Missing docs
    print "  " + q + "missing_docs" + q + ": ["
    var md_idx = 0
    for entry in report.missing_docs:
        val entry_json = format_entry_json(entry)
        val comma = if md_idx < report.missing_docs.len() - 1: "," else: ""
        print "    " + entry_json + comma
        md_idx = md_idx + 1
    print "  ]"

    print rb

fn format_entry_json(entry: DocEntry) -> text:
    val lb = _LB()
    val rb = _RB()
    val q = _Q()
    lb + q + "file" + q + ": " + q + _escape_json(entry.file_path) + q + ", " + q + "line" + q + ": {entry.line_number}, " + q + "name" + q + ": " + q + _escape_json(entry.item_name) + q + ", " + q + "kind" + q + ": " + q + entry.item_kind + q + rb

fn format_match_line(m: SemanticMatch) -> text:
    val sim_str = format_sim(m.similarity)
    val kind = severity_label(m.similarity, m.match_kind)
    "  [{sim_str}] {m.entry_a.file_path}:{m.entry_a.item_name} (L{m.entry_a.line_number}) <-> {m.entry_b.file_path}:{m.entry_b.item_name} (L{m.entry_b.line_number}) {kind}"

fn severity_label(score: f64, kind: text) -> text:
    if kind.starts_with("copy_paste"):
        return "[COPY-PASTE]"
    if kind == "drift":
        return "[DRIFT]"
    if score >= 0.95:
        return "[NEAR-IDENTICAL]"
    "[SIMILAR]"

fn format_sim(sim: f64) -> text:
    # Format as 0.XX
    val pct = (sim * 100.0) as i64
    val whole = pct / 100
    val frac = pct % 100
    if frac < 10:
        "{whole}.0{frac}"
    else:
        "{whole}.{frac}"

fn format_threshold(t: f64) -> text:
    format_sim(t)

export print_semantic_text_report, print_semantic_json_report
export format_match_line, severity_label
