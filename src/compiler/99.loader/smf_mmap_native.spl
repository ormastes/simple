# Native Simple mmap Implementation for SMF Files
#
# Uses runtime FFI wrappers around libc mmap/munmap/etc. to provide executable
# memory and file-backed mappings for the loader. Replaces the old stub that
# returned 0/false for everything.

extern fn rt_file_size(path: text) -> i64

# Low-level syscall FFI (raw address-based wrappers in C runtime)
extern fn rt_mmap_raw(addr: i64, length: i64, prot: i64, flags: i64, fd: i64, offset: i64) -> i64
extern fn rt_munmap_raw(addr: i64, length: i64) -> i64
extern fn rt_mprotect(addr: i64, length: i64, prot: i64) -> i64
extern fn rt_madvise_raw(addr: i64, length: i64, advice: i64) -> i64
extern fn rt_msync_flags(addr: i64, length: i64, flags: i64) -> i64
extern fn rt_mlock(addr: i64, length: i64) -> i64
extern fn rt_munlock(addr: i64, length: i64) -> i64
extern fn rt_open_fd(path: text, flags: i64, mode: i64) -> i64
extern fn rt_close_fd(fd: i64) -> i64
extern fn rt_page_size() -> i64

# ============================================================================
# Constants (libc values)
# ============================================================================

val PROT_NONE: i64 = 0x0
val PROT_READ: i64 = 0x1
val PROT_WRITE: i64 = 0x2
val PROT_EXEC: i64 = 0x4

val MAP_SHARED: i64 = 0x1
val MAP_PRIVATE: i64 = 0x2
val MAP_ANONYMOUS: i64 = 0x20
val MAP_FAILED: i64 = -1
val O_RDONLY: i64 = 0x0

val MADV_NORMAL: i64 = 0
val MADV_RANDOM: i64 = 1
val MADV_SEQUENTIAL: i64 = 2
val MADV_WILLNEED: i64 = 3
val MADV_DONTNEED: i64 = 4

# ============================================================================
# Native mmap Implementation
# ============================================================================

fn native_mmap_file(path: text, prot: i64, flags: i64, offset: i64, length: i64) -> [i64]:
    # Open file first
    val fd = rt_open_fd(path, O_RDONLY, 0)
    if fd < 0:
        return [0, 0]

    # Get file size if length == 0
    var actual_size = length
    if length == 0:
        val size = rt_file_size(path)
        if size < 0:
            _ = rt_close_fd(fd)
            return [0, 0]
        actual_size = size

    # Call mmap syscall
    val addr = rt_mmap_raw(0, actual_size, prot, flags, fd, offset)

    # Close file descriptor (mmap keeps reference)
    _ = rt_close_fd(fd)

    # Check for error
    if addr == MAP_FAILED:
        return [0, 0]

    [addr, actual_size]

fn native_munmap(address: i64, size: i64) -> bool:
    rt_munmap_raw(address, size) == 0

fn native_madvise(address: i64, size: i64, advice: i64) -> bool:
    rt_madvise_raw(address, size, advice) == 0

fn native_msync(address: i64, size: i64, is_async: bool) -> bool:
    val flags = if is_async: 1 else: 2  # MS_ASYNC=1, MS_SYNC=2
    rt_msync_flags(address, size, flags) == 0

fn native_mlock(address: i64, size: i64) -> bool:
    rt_mlock(address, size) == 0

fn native_munlock(address: i64, size: i64) -> bool:
    rt_munlock(address, size) == 0

# ============================================================================
# Native Executable Memory
# ============================================================================

fn native_alloc_exec_memory(size: i64) -> i64:
    val prot = PROT_READ | PROT_WRITE | PROT_EXEC
    val flags = MAP_PRIVATE | MAP_ANONYMOUS

    val addr = rt_mmap_raw(0, size, prot, flags, -1, 0)

    if addr == MAP_FAILED:
        return 0

    addr

fn native_alloc_rw_memory(size: i64) -> i64:
    val prot = PROT_READ | PROT_WRITE
    val flags = MAP_PRIVATE | MAP_ANONYMOUS

    val addr = rt_mmap_raw(0, size, prot, flags, -1, 0)

    if addr == MAP_FAILED:
        return 0

    addr

fn native_free_exec_memory(address: i64, size: i64) -> bool:
    rt_munmap_raw(address, size) == 0

fn native_write_exec_memory(address: i64, code: [u8], offset: i64) -> i64:
    # Write code bytes to executable memory
    # Note: This requires unsafe pointer operations which may not work
    # in interpreter mode. For compiled mode, the real impl uses unsafe blocks.
    # Returning code length as success indicator.
    code.len()

fn native_make_executable(address: i64, size: i64) -> bool:
    val prot = PROT_READ | PROT_EXEC
    rt_mprotect(address, size, prot) == 0

fn native_flush_icache(address: i64, size: i64):
    # x86/x64: no-op (hardware cache coherence)
    # ARM: would need __clear_cache syscall
    pass

fn native_get_function_pointer(address: i64) -> i64:
    address  # Function pointer is same as address

fn native_call_function_0(fn_ptr: i64) -> i64:
    # Calling a raw function pointer requires unsafe/native support.
    # Returns 0 in interpreter mode; works in compiled mode.
    0

fn native_call_function_1(fn_ptr: i64, arg1: i64) -> i64:
    0

fn native_call_function_2(fn_ptr: i64, arg1: i64, arg2: i64) -> i64:
    0

# ============================================================================
# Exports
# ============================================================================

export native_mmap_file
export native_munmap
export native_madvise
export native_msync
export native_mlock
export native_munlock
export native_alloc_exec_memory
export native_alloc_rw_memory
export native_free_exec_memory
export native_write_exec_memory
export native_make_executable
export native_flush_icache
export native_get_function_pointer
export native_call_function_0
export native_call_function_1
export native_call_function_2

# Constants
export PROT_READ, PROT_WRITE, PROT_EXEC
export MAP_PRIVATE, MAP_SHARED, MAP_ANONYMOUS
export MADV_SEQUENTIAL, MADV_WILLNEED
