# x86_64 Instruction Selection
#
# Translates MIR instructions to x86_64 MachInst sequences.
# Pattern-matches on MirInstKind to produce low-level machine instructions.
# Follows System V AMD64 ABI for function calls.
#
# Pipeline: MIR -> ISel (this module) -> RegAlloc -> Encode -> ELF

use compiler.mir_data.{MirModule, MirFunction, MirBlock, MirInst, MirInstKind, MirBinOp, MirUnaryOp, MirOperand, MirOperandKind, MirConstValue, MirTerminator, MirType, MirTypeKind, LocalId, LocalKind, BlockId, SwitchCase}
use compiler.backend.native.mach_inst.{MachReg, virtual_reg, physical_reg, reg_id, Operand, OperandKind, op_reg, op_phys, op_virt, op_imm, op_mem, op_label, op_sym, operand_get_reg, MachInst, new_mach_inst, MachBlock, new_mach_block, mach_block_add_inst, MachFunction, new_mach_function, mach_func_add_block, mach_func_set_frame_size, MachModule, DataEntry, new_mach_module, mach_module_add_func, mach_module_add_data, mach_module_add_extern}
use compiler.backend.common.isel_common.{LoweredOperand, ISelFuncResult, ISelBlockResult, ISelInstResult, local_to_vreg, local_vreg_op}
use compiler.backend.native.mach_inst.{X86_RAX, X86_RCX, X86_RDX, X86_RBX, X86_RSP, X86_RBP, X86_RSI, X86_RDI, X86_R8, X86_R9, X86_R10, X86_R11, X86_R12, X86_R13, X86_R14, X86_R15}
use compiler.backend.native.mach_inst.{X86_ARG_REGS, X86_ARG_REG_COUNT, X86_CALLEE_SAVED}
use compiler.backend.native.mach_inst.{X86_OP_MOV_REG_REG, X86_OP_MOV_REG_IMM, X86_OP_MOV_REG_MEM, X86_OP_MOV_MEM_REG, X86_OP_ADD, X86_OP_SUB, X86_OP_IMUL, X86_OP_IDIV, X86_OP_AND, X86_OP_OR, X86_OP_XOR, X86_OP_SHL, X86_OP_SAR, X86_OP_SHR, X86_OP_NEG, X86_OP_NOT, X86_OP_CMP, X86_OP_TEST, X86_OP_SETE, X86_OP_SETNE, X86_OP_SETL, X86_OP_SETLE, X86_OP_SETG, X86_OP_SETGE, X86_OP_JMP, X86_OP_JE, X86_OP_JNE, X86_OP_JNZ, X86_OP_JZ, X86_OP_CALL, X86_OP_RET, X86_OP_PUSH, X86_OP_POP, X86_OP_LEA, X86_OP_MOVZX, X86_OP_CQO, X86_OP_NOP, X86_OP_ADD_IMM, X86_OP_SUB_IMM, X86_OP_CMP_IMM, X86_OP_MOV_REG_IMM32, X86_OP_CALL_INDIRECT}
use compiler.backend.common.isel_context.{ISelContext, new_isel_context, isel_alloc_vreg, isel_get_vreg, isel_alloc_frame_slot, isel_frame_offset, isel_add_extern, isel_add_string_data, isel_last_string_label}
use compiler.backend.common.ascii_utils.{char_to_ascii}

# ============================================================================
# Operand Lowering
# ============================================================================

fn lower_operand(ctx: ISelContext, operand: MirOperand) -> LoweredOperand:
    match operand.kind:
        case Copy(local):
            LoweredOperand(insts: [], result: local_vreg_op(local.id), ctx: ctx)
        case Move(local):
            LoweredOperand(insts: [], result: local_vreg_op(local.id), ctx: ctx)
        case Const(value, type_):
            lower_const(ctx, value, type_)

fn lower_const(ctx: ISelContext, value: MirConstValue, type_: MirType) -> LoweredOperand:
    match value:
        case Int(v):
            var new_ctx = isel_alloc_vreg(ctx)
            val vreg = isel_get_vreg(new_ctx)
            val dest = op_reg(virtual_reg(vreg))
            val inst = new_mach_inst(X86_OP_MOV_REG_IMM, [dest, op_imm(v)])
            LoweredOperand(insts: [inst], result: dest, ctx: new_ctx)
        case Bool(v):
            var new_ctx = isel_alloc_vreg(ctx)
            val vreg = isel_get_vreg(new_ctx)
            val dest = op_reg(virtual_reg(vreg))
            val imm_val = if v: 1 else: 0
            val inst = new_mach_inst(X86_OP_MOV_REG_IMM, [dest, op_imm(imm_val)])
            LoweredOperand(insts: [inst], result: dest, ctx: new_ctx)
        case Str(s):
            var new_ctx = isel_add_string_data(ctx, s, char_to_ascii)
            val label = isel_last_string_label(new_ctx)
            new_ctx = isel_alloc_vreg(new_ctx)
            val vreg = isel_get_vreg(new_ctx)
            val dest = op_reg(virtual_reg(vreg))
            val inst = new_mach_inst(X86_OP_LEA, [dest, op_sym(label)])
            LoweredOperand(insts: [inst], result: dest, ctx: new_ctx)
        case Zero:
            var new_ctx = isel_alloc_vreg(ctx)
            val vreg = isel_get_vreg(new_ctx)
            val dest = op_reg(virtual_reg(vreg))
            val inst = new_mach_inst(X86_OP_XOR, [dest, dest])
            LoweredOperand(insts: [inst], result: dest, ctx: new_ctx)
        case _:
            var new_ctx = isel_alloc_vreg(ctx)
            val vreg = isel_get_vreg(new_ctx)
            val dest = op_reg(virtual_reg(vreg))
            val inst = new_mach_inst(X86_OP_MOV_REG_IMM, [dest, op_imm(0)])
            LoweredOperand(insts: [inst], result: dest, ctx: new_ctx)

# ============================================================================
# Instruction Selection - Core
# ============================================================================

fn isel_module(module: MirModule) -> MachModule:
    var mach_module = new_mach_module(module.name)
    var ctx = new_isel_context()

    val func_keys = module.functions_keys(functions)
    for key in func_keys:
        val func = module.functions[key]
        var result = isel_function(ctx, func)
        ctx = result.ctx
        mach_module = mach_module_add_func(mach_module, result.func)

    # Add data entries from string constants
    for entry in ctx.data_entries:
        mach_module = mach_module_add_data(mach_module, entry)

    # Add extern symbols
    for sym in ctx.extern_symbols:
        mach_module = mach_module_add_extern(mach_module, sym)

    mach_module

fn isel_function(ctx: ISelContext, func: MirFunction) -> ISelFuncResult:
    var mach_func = new_mach_function(func.name)

    # Reset vreg counter - use local IDs directly, start high for temps
    var local_ctx = ISelContext(
        next_vreg: func.locals_len(locals) + 100,
        frame_slots: ctx.frame_slots,
        next_frame_offset: 0,
        extern_symbols: ctx.extern_symbols,
        data_entries: ctx.data_entries,
        string_counter: ctx.string_counter
    )

    # Allocate frame slots for locals that need stack space
    for local in func.locals:
        val size = local.type__size_bytes(type_)
        local_ctx = isel_alloc_frame_slot(local_ctx, local.id.id, size)

    # Generate prologue block
    var prologue_block = new_mach_block("prologue", -1)
    prologue_block = mach_block_add_inst(prologue_block, new_mach_inst(X86_OP_PUSH, [op_phys(X86_RBP)]))
    prologue_block = mach_block_add_inst(prologue_block, new_mach_inst(X86_OP_MOV_REG_REG, [op_phys(X86_RBP), op_phys(X86_RSP)]))
    # Frame size placeholder - will be patched after we know total frame size
    prologue_block = mach_block_add_inst(prologue_block, new_mach_inst(X86_OP_SUB_IMM, [op_phys(X86_RSP), op_imm(0)]))

    # Move arguments from ABI registers to virtual registers
    var arg_idx = 0
    for local in func.locals:
        match local.kind:
            case Arg(index):
                if index < X86_ARG_REG_COUNT:
                    val arg_reg = X86_ARG_REGS[index]
                    prologue_block = mach_block_add_inst(prologue_block, new_mach_inst(X86_OP_MOV_REG_REG, [local_vreg_op(local.id.id), op_phys(arg_reg)]))
                arg_idx = arg_idx + 1
            case _: ()

    mach_func = mach_func_add_block(mach_func, prologue_block)

    # Translate each MIR block
    for block in func.blocks:
        var result = isel_block(local_ctx, block)
        local_ctx = result.ctx
        mach_func = mach_func_add_block(mach_func, result.block)

    # Set frame size (aligned to 16)
    var frame_size = local_ctx.next_frame_offset
    if frame_size % 16 != 0:
        frame_size = frame_size + (16 - (frame_size % 16))
    mach_func = mach_func_set_frame_size(mach_func, frame_size)

    # Propagate context back
    val out_ctx = ISelContext(
        next_vreg: ctx.next_vreg,
        frame_slots: ctx.frame_slots,
        next_frame_offset: ctx.next_frame_offset,
        extern_symbols: local_ctx.extern_symbols,
        data_entries: local_ctx.data_entries,
        string_counter: local_ctx.string_counter
    )

    ISelFuncResult(func: mach_func, ctx: out_ctx)

fn isel_block(ctx: ISelContext, block: MirBlock) -> ISelBlockResult:
    val label = if block.has_label: block.label_value else: "bb{block.id.id}"
    var mach_block = new_mach_block(label, block.id.id)
    var current_ctx = ctx

    # Lower instructions
    for inst in block.instructions:
        var result = isel_inst(current_ctx, inst)
        current_ctx = result.ctx
        for mi in result.insts:
            mach_block = mach_block_add_inst(mach_block, mi)

    # Lower terminator
    var term_result = isel_terminator(current_ctx, block.terminator)
    current_ctx = term_result.ctx
    for mi in term_result.insts:
        mach_block = mach_block_add_inst(mach_block, mi)

    ISelBlockResult(block: mach_block, ctx: current_ctx)

# ============================================================================
# Instruction Selection - Instructions
# ============================================================================

fn isel_inst(ctx: ISelContext, inst: MirInst) -> ISelInstResult:
    match inst.kind:
        case Const(dest, value, type_):
            isel_const(ctx, dest, value, type_)
        case Copy(dest, src):
            isel_copy(ctx, dest, src)
        case Move(dest, src):
            isel_copy(ctx, dest, src)
        case BinOp(dest, op, left, right):
            isel_binop(ctx, dest, op, left, right)
        case UnaryOp(dest, op, operand):
            isel_unaryop(ctx, dest, op, operand)
        case Load(dest, ptr):
            isel_load(ctx, dest, ptr)
        case Store(ptr, value):
            isel_store(ctx, ptr, value)
        case Call(dest, func_op, args):
            isel_call(ctx, dest, func_op, args)
        case GetField(dest, base, field):
            isel_get_field(ctx, dest, base, field)
        case SetField(base, field, value):
            isel_set_field(ctx, base, field, value)
        case Alloc(dest, type_):
            isel_alloc(ctx, dest, type_)
        case Aggregate(dest, kind, operands):
            isel_aggregate(ctx, dest, operands)
        case Cast(dest, operand, target):
            isel_cast(ctx, dest, operand, target)
        case GetElementPtr(dest, base, indices):
            isel_get_element_ptr(ctx, dest, base, indices)
        case Nop:
            ISelInstResult(insts: [new_mach_inst(X86_OP_NOP, [])], ctx: ctx)
        case _:
            # Unsupported instruction - emit NOP
            ISelInstResult(insts: [new_mach_inst(X86_OP_NOP, [])], ctx: ctx)

fn isel_const(ctx: ISelContext, dest: LocalId, value: MirConstValue, type_: MirType) -> ISelInstResult:
    val lowered = lower_const(ctx, value, type_)
    val dest_op = local_vreg_op(dest.id)
    # Move the const result to the destination vreg
    var insts = lowered.insts
    insts = insts + [new_mach_inst(X86_OP_MOV_REG_REG, [dest_op, lowered.result])]
    ISelInstResult(insts: insts, ctx: lowered.ctx)

fn isel_copy(ctx: ISelContext, dest: LocalId, src: LocalId) -> ISelInstResult:
    val inst = new_mach_inst(X86_OP_MOV_REG_REG, [local_vreg_op(dest.id), local_vreg_op(src.id)])
    ISelInstResult(insts: [inst], ctx: ctx)

fn isel_binop(ctx: ISelContext, dest: LocalId, op: MirBinOp, left: MirOperand, right: MirOperand) -> ISelInstResult:
    val left_low = lower_operand(ctx, left)
    val right_low = lower_operand(left_low.ctx, right)
    var current_ctx = right_low.ctx
    val dest_op = local_vreg_op(dest.id)
    var insts: [MachInst] = []
    insts = insts + left_low.insts
    insts = insts + right_low.insts

    match op:
        case Add:
            insts = insts + [new_mach_inst(X86_OP_MOV_REG_REG, [dest_op, left_low.result])]
            insts = insts + [new_mach_inst(X86_OP_ADD, [dest_op, right_low.result])]
        case Sub:
            insts = insts + [new_mach_inst(X86_OP_MOV_REG_REG, [dest_op, left_low.result])]
            insts = insts + [new_mach_inst(X86_OP_SUB, [dest_op, right_low.result])]
        case Mul:
            insts = insts + [new_mach_inst(X86_OP_MOV_REG_REG, [dest_op, left_low.result])]
            insts = insts + [new_mach_inst(X86_OP_IMUL, [dest_op, right_low.result])]
        case Div:
            # idiv uses rax:rdx / operand -> quotient in rax
            insts = insts + [new_mach_inst(X86_OP_MOV_REG_REG, [op_phys(X86_RAX), left_low.result])]
            insts = insts + [new_mach_inst(X86_OP_CQO, [])]
            insts = insts + [new_mach_inst(X86_OP_IDIV, [right_low.result])]
            insts = insts + [new_mach_inst(X86_OP_MOV_REG_REG, [dest_op, op_phys(X86_RAX)])]
        case Rem:
            # idiv uses rax:rdx / operand -> remainder in rdx
            insts = insts + [new_mach_inst(X86_OP_MOV_REG_REG, [op_phys(X86_RAX), left_low.result])]
            insts = insts + [new_mach_inst(X86_OP_CQO, [])]
            insts = insts + [new_mach_inst(X86_OP_IDIV, [right_low.result])]
            insts = insts + [new_mach_inst(X86_OP_MOV_REG_REG, [dest_op, op_phys(X86_RDX)])]
        case BitAnd:
            insts = insts + [new_mach_inst(X86_OP_MOV_REG_REG, [dest_op, left_low.result])]
            insts = insts + [new_mach_inst(X86_OP_AND, [dest_op, right_low.result])]
        case BitOr:
            insts = insts + [new_mach_inst(X86_OP_MOV_REG_REG, [dest_op, left_low.result])]
            insts = insts + [new_mach_inst(X86_OP_OR, [dest_op, right_low.result])]
        case BitXor:
            insts = insts + [new_mach_inst(X86_OP_MOV_REG_REG, [dest_op, left_low.result])]
            insts = insts + [new_mach_inst(X86_OP_XOR, [dest_op, right_low.result])]
        case Shl:
            insts = insts + [new_mach_inst(X86_OP_MOV_REG_REG, [dest_op, left_low.result])]
            insts = insts + [new_mach_inst(X86_OP_MOV_REG_REG, [op_phys(X86_RCX), right_low.result])]
            insts = insts + [new_mach_inst(X86_OP_SHL, [dest_op])]
        case Shr:
            insts = insts + [new_mach_inst(X86_OP_MOV_REG_REG, [dest_op, left_low.result])]
            insts = insts + [new_mach_inst(X86_OP_MOV_REG_REG, [op_phys(X86_RCX), right_low.result])]
            insts = insts + [new_mach_inst(X86_OP_SHR, [dest_op])]
        case Eq:
            insts = insts + isel_comparison(dest_op, left_low.result, right_low.result, X86_OP_SETE)
        case Ne:
            insts = insts + isel_comparison(dest_op, left_low.result, right_low.result, X86_OP_SETNE)
        case Lt:
            insts = insts + isel_comparison(dest_op, left_low.result, right_low.result, X86_OP_SETL)
        case Le:
            insts = insts + isel_comparison(dest_op, left_low.result, right_low.result, X86_OP_SETLE)
        case Gt:
            insts = insts + isel_comparison(dest_op, left_low.result, right_low.result, X86_OP_SETG)
        case Ge:
            insts = insts + isel_comparison(dest_op, left_low.result, right_low.result, X86_OP_SETGE)
        case _:
            # Unsupported binop - zero result
            insts = insts + [new_mach_inst(X86_OP_XOR, [dest_op, dest_op])]

    ISelInstResult(insts: insts, ctx: current_ctx)

fn isel_comparison(dest: Operand, left: Operand, right: Operand, setcc_op: i64) -> [MachInst]:
    var insts: [MachInst] = []
    insts = insts + [new_mach_inst(X86_OP_CMP, [left, right])]
    insts = insts + [new_mach_inst(setcc_op, [dest])]
    insts = insts + [new_mach_inst(X86_OP_MOVZX, [dest, dest])]
    insts

fn isel_unaryop(ctx: ISelContext, dest: LocalId, op: MirUnaryOp, operand: MirOperand) -> ISelInstResult:
    val low = lower_operand(ctx, operand)
    val dest_op = local_vreg_op(dest.id)
    var insts = low.insts

    match op:
        case Neg:
            insts = insts + [new_mach_inst(X86_OP_MOV_REG_REG, [dest_op, low.result])]
            insts = insts + [new_mach_inst(X86_OP_NEG, [dest_op])]
        case Not:
            insts = insts + [new_mach_inst(X86_OP_MOV_REG_REG, [dest_op, low.result])]
            insts = insts + [new_mach_inst(X86_OP_NOT, [dest_op])]
        case BitNot:
            insts = insts + [new_mach_inst(X86_OP_MOV_REG_REG, [dest_op, low.result])]
            insts = insts + [new_mach_inst(X86_OP_NOT, [dest_op])]
        case _:
            insts = insts + [new_mach_inst(X86_OP_MOV_REG_REG, [dest_op, low.result])]

    ISelInstResult(insts: insts, ctx: low.ctx)

fn isel_load(ctx: ISelContext, dest: LocalId, ptr: MirOperand) -> ISelInstResult:
    val low = lower_operand(ctx, ptr)
    val dest_op = local_vreg_op(dest.id)
    var insts = low.insts
    insts = insts + [new_mach_inst(X86_OP_MOV_REG_MEM, [dest_op, op_mem(operand_get_reg(low.result), 0)])]
    ISelInstResult(insts: insts, ctx: low.ctx)

fn isel_store(ctx: ISelContext, ptr: MirOperand, value: MirOperand) -> ISelInstResult:
    val ptr_low = lower_operand(ctx, ptr)
    val val_low = lower_operand(ptr_low.ctx, value)
    var insts = ptr_low.insts
    insts = insts + val_low.insts
    insts = insts + [new_mach_inst(X86_OP_MOV_MEM_REG, [op_mem(operand_get_reg(ptr_low.result), 0), val_low.result])]
    ISelInstResult(insts: insts, ctx: val_low.ctx)

fn isel_call(ctx: ISelContext, dest: LocalId, func_op: MirOperand, args: [MirOperand]) -> ISelInstResult:
    var insts: [MachInst] = []
    var current_ctx = ctx

    # Lower arguments into ABI registers
    for i in 0..args_len(args):
        val arg_low = lower_operand(current_ctx, args[i])
        current_ctx = arg_low.ctx
        insts = insts + arg_low.insts
        if i < X86_ARG_REG_COUNT:
            val arg_reg = X86_ARG_REGS[i]
            insts = insts + [new_mach_inst(X86_OP_MOV_REG_REG, [op_phys(arg_reg), arg_low.result])]
        else:
            # Stack argument
            insts = insts + [new_mach_inst(X86_OP_PUSH, [arg_low.result])]

    # Emit call
    match func_op.kind:
        case Const(mirconstvalue_Str(name), _):
            # Direct call to named function
            current_ctx = isel_add_extern(current_ctx, name)
            insts = insts + [new_mach_inst(X86_OP_CALL, [op_sym(name)])]
        case Copy(local):
            # Indirect call through register
            insts = insts + [new_mach_inst(X86_OP_CALL_INDIRECT, [local_vreg_op(local.id)])]
        case Move(local):
            insts = insts + [new_mach_inst(X86_OP_CALL_INDIRECT, [local_vreg_op(local.id)])]
        case _:
            insts = insts + [new_mach_inst(X86_OP_NOP, [])]

    # Move return value from rax
    if has_dest:
        val d = dest_value
        insts = insts + [new_mach_inst(X86_OP_MOV_REG_REG, [local_vreg_op(d.id), op_phys(X86_RAX)])]

    # Clean up stack args
    val stack_args = if args_len(args) > X86_ARG_REG_COUNT: args_len(args) - X86_ARG_REG_COUNT else: 0
    if stack_args > 0:
        insts = insts + [new_mach_inst(X86_OP_ADD_IMM, [op_phys(X86_RSP), op_imm(stack_args * 8)])]

    ISelInstResult(insts: insts, ctx: current_ctx)

fn isel_get_field(ctx: ISelContext, dest: LocalId, base: MirOperand, field: i64) -> ISelInstResult:
    val base_low = lower_operand(ctx, base)
    val dest_op = local_vreg_op(dest.id)
    val offset = field * 8
    var insts = base_low.insts
    insts = insts + [new_mach_inst(X86_OP_MOV_REG_MEM, [dest_op, op_mem(operand_get_reg(base_low.result), offset)])]
    ISelInstResult(insts: insts, ctx: base_low.ctx)

fn isel_set_field(ctx: ISelContext, base: MirOperand, field: i64, value: MirOperand) -> ISelInstResult:
    val base_low = lower_operand(ctx, base)
    val val_low = lower_operand(base_low.ctx, value)
    val offset = field * 8
    var insts = base_low.insts
    insts = insts + val_low.insts
    insts = insts + [new_mach_inst(X86_OP_MOV_MEM_REG, [op_mem(operand_get_reg(base_low.result), offset), val_low.result])]
    ISelInstResult(insts: insts, ctx: val_low.ctx)

fn isel_alloc(ctx: ISelContext, dest: LocalId, type_: MirType) -> ISelInstResult:
    val size = type__size_bytes(type_)
    val aligned = if size < 8: 8 else: size
    val dest_op = local_vreg_op(dest.id)
    var insts: [MachInst] = []
    insts = insts + [new_mach_inst(X86_OP_SUB_IMM, [op_phys(X86_RSP), op_imm(aligned)])]
    insts = insts + [new_mach_inst(X86_OP_LEA, [dest_op, op_mem(physical_reg(X86_RSP), 0)])]
    ISelInstResult(insts: insts, ctx: ctx)

fn isel_aggregate(ctx: ISelContext, dest: LocalId, operands: [MirOperand]) -> ISelInstResult:
    var insts: [MachInst] = []
    var current_ctx = ctx

    # Calculate total size (each field is 8 bytes)
    val num_fields = operands_len(operands)
    var total_size = num_fields * 8
    if total_size < 8:
        total_size = 8
    # Align to 16 bytes for stack alignment
    if total_size % 16 != 0:
        total_size = total_size + (16 - (total_size % 16))

    # Allocate stack space
    insts = insts + [new_mach_inst(X86_OP_SUB_IMM, [op_phys(X86_RSP), op_imm(total_size)])]

    # Get base address into destination vreg
    val dest_op = local_vreg_op(dest.id)
    val base_reg = virtual_reg(dest.id)
    insts = insts + [new_mach_inst(X86_OP_LEA, [dest_op, op_mem(physical_reg(X86_RSP), 0)])]

    # Store each operand at its field offset
    for i in 0..num_fields:
        val op_low = lower_operand(current_ctx, operands[i])
        current_ctx = op_low.ctx
        insts = insts + op_low.insts
        val offset = i * 8
        insts = insts + [new_mach_inst(X86_OP_MOV_MEM_REG, [op_mem(base_reg, offset), op_low.result])]

    ISelInstResult(insts: insts, ctx: current_ctx)

fn isel_get_element_ptr(ctx: ISelContext, dest: LocalId, base: MirOperand, indices: [MirOperand]) -> ISelInstResult:
    """Compute element address: dest = base + indices[0] * 8."""
    var insts: [MachInst] = []
    var current_ctx = ctx

    # Lower base operand
    val base_low = lower_operand(current_ctx, base)
    current_ctx = base_low.ctx
    insts = insts + base_low.insts

    val dest_op = local_vreg_op(dest.id)

    if indices_len(indices) > 0:
        # Lower index operand
        val idx_low = lower_operand(current_ctx, indices[0])
        current_ctx = idx_low.ctx
        insts = insts + idx_low.insts

        # Allocate temp vreg for scaled index
        current_ctx = isel_alloc_vreg(current_ctx)
        val tmp_vreg = isel_get_vreg(current_ctx)
        val tmp_op = op_reg(virtual_reg(tmp_vreg))

        # tmp = 8 (element size)
        insts = insts + [new_mach_inst(X86_OP_MOV_REG_IMM, [tmp_op, op_imm(8)])]
        # tmp = tmp * index = 8 * index
        insts = insts + [new_mach_inst(X86_OP_IMUL, [tmp_op, idx_low.result])]
        # dest = base
        insts = insts + [new_mach_inst(X86_OP_MOV_REG_REG, [dest_op, base_low.result])]
        # dest = dest + tmp = base + index * 8
        insts = insts + [new_mach_inst(X86_OP_ADD, [dest_op, tmp_op])]
    else:
        # No indices - just copy base
        insts = insts + [new_mach_inst(X86_OP_MOV_REG_REG, [dest_op, base_low.result])]

    ISelInstResult(insts: insts, ctx: current_ctx)

fn isel_cast(ctx: ISelContext, dest: LocalId, operand: MirOperand, target: MirType) -> ISelInstResult:
    val low = lower_operand(ctx, operand)
    val dest_op = local_vreg_op(dest.id)
    var insts = low.insts
    # Simple move - truncation/extension handled by encoder based on type
    insts = insts + [new_mach_inst(X86_OP_MOV_REG_REG, [dest_op, low.result])]
    ISelInstResult(insts: insts, ctx: low.ctx)

# ============================================================================
# Instruction Selection - Terminators
# ============================================================================

fn isel_terminator(ctx: ISelContext, term: MirTerminator) -> ISelInstResult:
    match term:
        case Goto(target):
            val inst = new_mach_inst(X86_OP_JMP, [op_label(target.id)])
            ISelInstResult(insts: [inst], ctx: ctx)
        case Return(value):
            var insts: [MachInst] = []
            if has_value:
                val v = value_value
                val low = lower_operand(ctx, v)
                insts = insts + low.insts
                insts = insts + [new_mach_inst(X86_OP_MOV_REG_REG, [op_phys(X86_RAX), low.result])]
            # Epilogue
            insts = insts + [new_mach_inst(X86_OP_MOV_REG_REG, [op_phys(X86_RSP), op_phys(X86_RBP)])]
            insts = insts + [new_mach_inst(X86_OP_POP, [op_phys(X86_RBP)])]
            insts = insts + [new_mach_inst(X86_OP_RET, [])]
            ISelInstResult(insts: insts, ctx: ctx)
        case If(cond, then_, else_):
            val cond_low = lower_operand(ctx, cond)
            var insts = cond_low.insts
            insts = insts + [new_mach_inst(X86_OP_TEST, [cond_low.result, cond_low.result])]
            insts = insts + [new_mach_inst(X86_OP_JNZ, [op_label(then_.id)])]
            insts = insts + [new_mach_inst(X86_OP_JMP, [op_label(else_.id)])]
            ISelInstResult(insts: insts, ctx: cond_low.ctx)
        case Switch(value, targets, default_target):
            val val_low = lower_operand(ctx, value)
            var insts = val_low.insts
            for target in targets:
                insts = insts + [new_mach_inst(X86_OP_CMP_IMM, [val_low.result, op_imm(target.value)])]
                insts = insts + [new_mach_inst(X86_OP_JE, [op_label(target.target.id)])]
            insts = insts + [new_mach_inst(X86_OP_JMP, [op_label(default_target.id)])]
            ISelInstResult(insts: insts, ctx: val_low.ctx)
        case Unreachable:
            ISelInstResult(insts: [new_mach_inst(X86_OP_NOP, [])], ctx: ctx)
        case _:
            ISelInstResult(insts: [new_mach_inst(X86_OP_NOP, [])], ctx: ctx)

# ============================================================================
# Exports
# ============================================================================

export ISelContext, new_isel_context
export isel_module
