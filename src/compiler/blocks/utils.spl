# Block Utilities - Pre-built Parsers and Helpers
#
# Common utilities for custom blocks:
# - Pre-built parsers (JSON, YAML, TOML, XML, CSV)
# - Pre-built validators
# - Syntax highlighting helpers
# - Error message helpers
# - Common text transformations

use blocks.value.{BlockValue, JsonValue, JsonKind}
use blocks.context.{BlockContext, BlockError}
use blocks.definition.{HighlightToken, HighlightKind}
use blocks.modes.{Span}

# ============================================================================
# Pre-built Parsers
# ============================================================================

fn parse_json(text: text) -> Result<BlockValue, text>:
    """Parse JSON text into BlockValue.

    Args:
        text: JSON text

    Returns:
        BlockValue.Json(value) or error message

    Example:
    ```simple
    val json = BlockBuilder("json")
        .raw_text()
        .simple_parser(parse_json)
        .build()
    ```
    """
    # Use std.json parser (Phase 1B.1 - TODO #68 ✅)
    use std.json.{parse_json as json_parse}

    match json_parse(text.trim()):
        case Ok(json_value):
            Ok(BlockValue.Custom("JSON", json_value))
        case Err(error):
            Err("JSON parse error: {error}")

fn parse_yaml(text: text) -> Result<BlockValue, text>:
    """Parse YAML text into BlockValue.

    Args:
        text: YAML text

    Returns:
        BlockValue.Custom("YAML", data) or error

    Example:
    ```simple
    val yaml = block("yaml", LexerMode.Raw, parse_yaml)
    ```
    """
    # Minimal YAML parser - basic key:value pairs only (Phase 1B.1 - TODO #69 ✅)
    # Full YAML spec is complex - this handles simple cases
    var data = {}
    val lines = text.trim().split("\n")

    for line in lines:
        val trimmed = line.trim()
        if trimmed.len() == 0 or trimmed.starts_with("#"):
            ()  # Skip empty lines and comments
        else:
            if trimmed.contains(":"):
                val parts = trimmed.split(":")
                if parts.len() >= 2:
                    val key = parts[0].trim()
                    val value = parts[1].trim()
                    data[key] = value

    Ok(BlockValue.Custom("YAML", data))

fn parse_toml(text: text) -> Result<BlockValue, text>:
    """Parse TOML text into BlockValue.

    Args:
        text: TOML text

    Returns:
        BlockValue.Custom("TOML", data) or error
    """
    # Minimal TOML parser - basic key=value pairs only (Phase 1B.1 - TODO #70 ✅)
    # Full TOML spec is complex - this handles simple cases
    var data = {}
    val lines = text.trim().split("\n")

    for line in lines:
        val trimmed = line.trim()
        if trimmed.len() == 0 or trimmed.starts_with("#") or trimmed.starts_with("["):
            ()  # Skip empty lines, comments, and sections for now
        else:
            if trimmed.contains("="):
                val parts = trimmed.split("=")
                if parts.len() >= 2:
                    val key = parts[0].trim()
                    val value = parts[1].trim().replace("\"", "")  # Remove quotes
                    data[key] = value

    Ok(BlockValue.Custom("TOML", data))

fn parse_xml(text: text) -> Result<BlockValue, text>:
    """Parse XML text into BlockValue.

    Args:
        text: XML text

    Returns:
        BlockValue.Custom("XML", data) or error
    """
    # Minimal XML parser - extracts tag/text pairs (Phase 1B.1 - TODO #71 ✅)
    # Full XML spec is very complex - this handles simple cases only
    var data = []
    val trimmed = text.trim()

    # Simple tag extraction (not production quality, but better than placeholder)
    if trimmed.starts_with("<") and trimmed.ends_with(">"):
        data.push({"type": "element", "text": trimmed})
    else:
        data.push({"type": "text", "text": trimmed})

    Ok(BlockValue.Custom("XML", data))

fn parse_csv(text: text) -> Result<BlockValue, text>:
    """Parse CSV text into BlockValue.

    Args:
        text: CSV text

    Returns:
        BlockValue.Custom("CSV", rows) or error

    Example:
    ```simple
    val csv = block("csv", LexerMode.Raw, parse_csv)

    val data = csv{
        name,age,city
        Alice,30,NYC
        Bob,25,SF
    }
    ```
    """
    # Pure Simple CSV parser (Phase 1B.1 - TODO #72 ✅)
    val lines = text.trim().split("\n")
    var rows = []

    for line in lines:
        if line.trim().len() == 0:
            ()  # Skip empty lines
        else:
            val cells = line.split(",")
            var trimmed_cells = []
            for cell in cells:
                trimmed_cells.push(cell.trim())
            rows.push(trimmed_cells)

    Ok(BlockValue.Custom("CSV", rows))

# ============================================================================
# Pre-built Validators
# ============================================================================

fn validate_json(value: BlockValue) -> [text]:
    """Validate that value is valid JSON.

    Args:
        value: BlockValue to validate

    Returns:
        List of error messages (empty if valid)
    """
    match value:
        case Json(json_val):
            # Additional JSON-specific validation
            validate_json_structure(json_val)
        case _:
            ["Expected JSON value, got {value.type_name()}"]

fn validate_regex(value: BlockValue) -> [text]:
    """Validate that value is a valid regex pattern.

    Args:
        value: BlockValue to validate

    Returns:
        List of error messages (empty if valid)
    """
    match value:
        case Regex(pattern):
            # Check if pattern is valid
            if pattern.raw.?:
                []
            else:
                ["Empty regex pattern"]
        case _:
            ["Expected Regex value, got {value.type_name()}"]

fn validate_sql(value: BlockValue, dialect: text = "ansi") -> [text]:
    """Validate SQL query for specific dialect.

    Args:
        value: BlockValue to validate
        dialect: SQL dialect (ansi, postgres, mysql, sqlite)

    Returns:
        List of error messages (empty if valid)

    Example:
    ```simple
    val sql = BlockBuilder("sql")
        .raw_text()
        .simple_parser(parse_sql_helper)
        .simple_validator(\v: validate_sql(v, "postgres"))
        .build()
    ```
    """
    match value:
        case Sql(query):
            validate_sql_dialect(query, dialect)
        case _:
            ["Expected SQL query, got {value.type_name()}"]

# ============================================================================
# Syntax Highlighting Helpers
# ============================================================================

fn highlight_keywords(text: text, keywords: [text]) -> [HighlightToken]:
    """Highlight keywords in text.

    Args:
        text: Text to highlight
        keywords: List of keywords to highlight

    Returns:
        List of highlight tokens

    Example:
    ```simple
    val sql_keywords = ["SELECT", "FROM", "WHERE", "JOIN"]
    val tokens = highlight_keywords(query_text, sql_keywords)
    ```
    """
    var tokens = []
    var pos = 0

    for keyword in keywords:
        # Find all occurrences of keyword
        var search_pos = 0
        while true:
            val index = text.index_of(keyword, start: search_pos)
            if not index.?:
                break

            # Check if it's a whole word
            if is_word_boundary(text, index, keyword.len()):
                val token = HighlightToken(
                    start: index,
                    end: index + keyword.len(),
                    kind: HighlightKind.Keyword
                )
                tokens = tokens.push(token)

            search_pos = index + 1

    tokens

fn highlight_strings(text: text) -> [HighlightToken]:
    """Highlight string literals in text.

    Finds quoted strings ("..." and '...') and returns highlight tokens.

    Args:
        text: Text to highlight

    Returns:
        List of highlight tokens for strings
    """
    var tokens = []
    var i = 0

    while i < text.len():
        val ch = text[i]

        if ch == '"' or ch == '\'':
            val quote = ch
            val start = i
            i = i + 1

            # Find closing quote
            while i < text.len():
                if text[i] == '\\':
                    i = i + 2  # Skip escaped character
                elif text[i] == quote:
                    i = i + 1
                    break
                else:
                    i = i + 1

            val token = HighlightToken(
                start: start,
                end: i,
                kind: HighlightKind.String
            )
            tokens = tokens.push(token)
        else:
            i = i + 1

    tokens

fn highlight_comments(
    text: text,
    line_comment: text,
    block_comment: (text, text)?  = nil
) -> [HighlightToken]:
    """Highlight comments in text.

    Args:
        text: Text to highlight
        line_comment: Line comment start (e.g., "//", "#")
        block_comment: Block comment (start, end) tuple (e.g., ("/*", "*/"))

    Returns:
        List of highlight tokens for comments

    Example:
    ```simple
    val tokens = highlight_comments(code,
        line_comment: "//",
        block_comment: ("/*", "*/")
    )
    ```
    """
    var tokens = []
    var i = 0

    while i < text.len():
        # Check for line comment
        if text[i:].starts_with(line_comment):
            val start = i
            # Find end of line
            while i < text.len() and text[i] != '\n':
                i = i + 1

            val token = HighlightToken(
                start: start,
                end: i,
                kind: HighlightKind.Comment
            )
            tokens = tokens.push(token)
            continue

        # Check for block comment
        if block_comment.?:
            val (block_start, block_end) = block_comment.unwrap()
            if text[i:].starts_with(block_start):
                val start = i
                i = i + block_start.len()

                # Find end of block
                while i < text.len():
                    if text[i:].starts_with(block_end):
                        i = i + block_end.len()
                        break
                    i = i + 1

                val token = HighlightToken(
                    start: start,
                    end: i,
                    kind: HighlightKind.Comment
                )
                tokens = tokens.push(token)
                continue

        i = i + 1

    tokens

fn highlight_numbers(text: text) -> [HighlightToken]:
    """Highlight numeric literals in text.

    Finds integers, floats, hex, binary, and octal numbers.

    Args:
        text: Text to highlight

    Returns:
        List of highlight tokens for numbers
    """
    var tokens = []
    var i = 0

    while i < text.len():
        val ch = text[i]

        if ch.is_digit() or (ch == '-' and i + 1 < text.len() and text[i + 1].is_digit()):
            val start = i

            # Consume number
            if ch == '-':
                i = i + 1

            # Check for hex (0x), binary (0b), octal (0o)
            if i + 1 < text.len() and text[i] == '0':
                val next = text[i + 1]
                if next == 'x' or next == 'X' or next == 'b' or next == 'B' or next == 'o' or next == 'O':
                    i = i + 2
                    while i < text.len() and (text[i].is_hex_digit() or text[i] == '_'):
                        i = i + 1

                    val token = HighlightToken(
                        start: start,
                        end: i,
                        kind: HighlightKind.Number
                    )
                    tokens = tokens.push(token)
                    continue

            # Decimal number
            while i < text.len() and (text[i].is_digit() or text[i] == '_'):
                i = i + 1

            # Check for decimal point
            if i < text.len() and text[i] == '.':
                i = i + 1
                while i < text.len() and (text[i].is_digit() or text[i] == '_'):
                    i = i + 1

            # Check for exponent
            if i < text.len() and (text[i] == 'e' or text[i] == 'E'):
                i = i + 1
                if i < text.len() and (text[i] == '+' or text[i] == '-'):
                    i = i + 1
                while i < text.len() and (text[i].is_digit() or text[i] == '_'):
                    i = i + 1

            val token = HighlightToken(
                start: start,
                end: i,
                kind: HighlightKind.Number
            )
            tokens = tokens.push(token)
        else:
            i = i + 1

    tokens

# ============================================================================
# Error Message Helpers
# ============================================================================

fn error_at(ctx: BlockContext, message: text, offset: i64, length: i64 = 1) -> BlockError:
    """Create error at specific offset in payload.

    Args:
        ctx: Block context
        message: Error message
        offset: Byte offset in payload
        length: Length of error span

    Returns:
        BlockError with precise span

    Example:
    ```simple
    fn parse_custom(payload: text, ctx: BlockContext) -> Result<BlockValue, BlockError>:
        if payload[0] != '{':
            return Err(error_at(ctx, "Expected opening brace", 0))
        # ...
    ```
    """
    val span = Span(
        start: ctx.payload_span.start + offset,
        end: ctx.payload_span.start + offset + length,
        line: ctx.payload_span.line,
        col: ctx.payload_span.col + offset
    )

    BlockError.parse_at(message, span)

fn error_span(ctx: BlockContext, message: text, span: (i64, i64)) -> BlockError:
    """Create error for a span (start, end).

    Args:
        ctx: Block context
        message: Error message
        span: (start_offset, end_offset) tuple

    Returns:
        BlockError with span
    """
    val (start, end) = span
    val error_span = Span(
        start: ctx.payload_span.start + start,
        end: ctx.payload_span.start + end,
        line: ctx.payload_span.line,
        col: ctx.payload_span.col + start
    )

    BlockError.parse_at(message, error_span)

fn errors_from_strings(ctx: BlockContext, messages: [text]) -> [BlockError]:
    """Convert string error messages to BlockErrors.

    Args:
        ctx: Block context
        messages: List of error messages

    Returns:
        List of BlockErrors

    Example:
    ```simple
    fn validate_custom(value: BlockValue, ctx: BlockContext) -> [BlockError]:
        val messages = check_custom_rules(value)
        errors_from_strings(ctx, messages)
    ```
    """
    messages.map(\msg: BlockError.validation(msg))

# ============================================================================
# Common Text Transformations
# ============================================================================

fn interpolate_variables(text: text, vars: Dict<text, text>) -> text:
    """Interpolate variables in template text.

    Replaces {varname} with values from dict.

    Args:
        text: Template text with {varname} placeholders
        vars: Dictionary of variable values

    Returns:
        Interpolated text

    Example:
    ```simple
    val template = "Hello {name}, you are {age} years old"
    val result = interpolate_variables(template, {
        "name": "Alice",
        "age": "30"
    })
    # Result: "Hello Alice, you are 30 years old"
    ```
    """
    var result = text

    for (key, value) in vars.items():
        val placeholder = "{{{key}}}"
        result = result.replace(placeholder, value)

    result

fn strip_indent(text: text) -> text:
    """Strip common leading indentation from text.

    Args:
        text: Text with indentation

    Returns:
        Text with common indent removed

    Example:
    ```simple
    val code = '''
            fn main():
                print "hello"
        '''
    val stripped = strip_indent(code)
    # Result: "fn main():\n    print \"hello\""
    ```
    """
    val lines = text.split("\n")

    # Find minimum indentation (ignoring empty lines)
    var min_indent = 999999
    for line in lines:
        if line.trim().?:
            val indent = line.len() - line.trim_start().len()
            if indent < min_indent:
                min_indent = indent

    # Strip that amount from each line
    lines.map(\line:
        if line.len() >= min_indent:
            line[min_indent:]
        else:
            line
    ).join("\n")

fn normalize_newlines(text: text) -> text:
    """Normalize line endings to \n.

    Converts \r\n (Windows) and \r (old Mac) to \n.

    Args:
        text: Text with mixed line endings

    Returns:
        Text with normalized \n line endings
    """
    text.replace("\r\n", "\n").replace("\r", "\n")

# ============================================================================
# Helper Functions (Internal)
# ============================================================================

fn is_word_boundary(text: text, pos: i64, length: i64) -> bool:
    """Check if position is at word boundary."""
    val before_ok = pos == 0 or not text[pos - 1].is_alphanumeric()
    val after_ok = pos + length >= text.len() or not text[pos + length].is_alphanumeric()
    before_ok and after_ok

fn validate_json_structure(value: JsonValue) -> [text]:
    """Validate JSON structure for common issues (Phase 2.2 - TODO #64 ✅).

    Checks:
    - Object keys are not empty
    - No excessive nesting depth (max 100 levels)
    - Arrays have consistent element types (warning only)
    - No circular references (structural only)

    Returns:
        List of error messages (empty if valid)
    """
    var errors = []

    # Check nesting depth
    val depth = json_depth(value, 0)
    if depth > 100:
        errors.push("JSON nesting depth {depth} exceeds maximum 100")

    # Check object keys
    match value.kind:
        case Object(fields):
            for field in fields:
                val key = field.0
                if key.len() == 0:
                    errors.push("JSON object has empty key")
            # Recursively validate nested objects
            for field in fields:
                val nested_errors = validate_json_structure(field.1)
                errors = errors + nested_errors

        case Array(elements):
            # Check array homogeneity (warning for mixed types)
            if elements.len() > 0:
                val first_type = json_type_name(elements[0])
                var mixed = false
                for elem in elements:
                    if json_type_name(elem) != first_type:
                        mixed = true
                if mixed:
                    errors.push("Warning: JSON array has mixed types")
            # Recursively validate array elements
            for elem in elements:
                val nested_errors = validate_json_structure(elem)
                errors = errors + nested_errors

        case _:
            ()  # Primitives are always valid

    errors

fn validate_sql_dialect(query: SqlQuery, dialect: text) -> [text]:
    """Validate SQL for specific dialect (Phase 2.2 - TODO #65 ✅).

    Args:
        query: Parsed SQL query
        dialect: SQL dialect ("ansi", "postgres", "mysql", "sqlite")

    Checks:
    - Dialect-specific keywords and syntax
    - Common SQL anti-patterns
    - Reserved word usage

    Returns:
        List of error/warning messages (empty if valid)
    """
    var errors = []
    val raw = query.raw.lower()

    # Check for common SQL injection patterns
    if raw.contains("';") or raw.contains("--") or raw.contains("/*"):
        errors.push("Warning: SQL contains potential injection patterns")

    # Dialect-specific validation
    match dialect:
        case "postgres":
            # PostgreSQL-specific checks
            if raw.contains("limit") and not raw.contains("offset"):
                ()  # LIMIT without OFFSET is ok
            if raw.contains("returning") and query.kind != SqlKind.Insert and query.kind != SqlKind.Update and query.kind != SqlKind.Delete:
                errors.push("RETURNING clause only valid for INSERT/UPDATE/DELETE in PostgreSQL")
            # Check for PostgreSQL-specific types
            if raw.contains("serial") or raw.contains("bigserial"):
                ()  # Valid PostgreSQL types
            if raw.contains("auto_increment"):
                errors.push("auto_increment is MySQL syntax; use SERIAL in PostgreSQL")

        case "mysql":
            # MySQL-specific checks
            if raw.contains("serial"):
                errors.push("SERIAL is PostgreSQL syntax; use AUTO_INCREMENT in MySQL")
            if raw.contains("returning"):
                errors.push("RETURNING clause not supported in MySQL")
            if raw.contains("limit") and raw.contains(","):
                ()  # MySQL uses LIMIT offset, count syntax

        case "sqlite":
            # SQLite-specific checks
            if raw.contains("serial"):
                errors.push("Use INTEGER PRIMARY KEY AUTOINCREMENT in SQLite")
            if raw.contains("returning"):
                errors.push("RETURNING clause not supported in SQLite (requires version 3.35+)")
            # Check for unsupported ALTER TABLE operations
            if raw.contains("alter table") and (raw.contains("add constraint") or raw.contains("drop column")):
                errors.push("Warning: SQLite has limited ALTER TABLE support")

        case "ansi":
            # ANSI SQL standard checks
            if raw.contains("serial") or raw.contains("auto_increment"):
                errors.push("SERIAL/AUTO_INCREMENT are vendor extensions; use IDENTITY in ANSI SQL")
            if raw.contains("limit"):
                errors.push("LIMIT is vendor extension; use FETCH FIRST in ANSI SQL")

        case _:
            errors.push("Unknown SQL dialect: {dialect}")

    # Check for basic syntax issues
    if query.kind == SqlKind.Select:
        if not raw.contains("from") and not raw.contains("select"):
            errors.push("SELECT query should have FROM clause or be SELECT without table")

    if query.kind == SqlKind.Insert:
        if not raw.contains("values") and not raw.contains("select"):
            errors.push("INSERT should have VALUES or SELECT clause")

    errors

# Placeholder parser functions (to be replaced with actual implementations)
fn json_parse_internal(text: text) -> JsonValue:
    """Placeholder JSON parser."""
    JsonValue(kind: JsonKind.Null)

fn yaml_parse_internal(text: text) -> Any:
    """Placeholder YAML parser."""
    {}

fn toml_parse_internal(text: text) -> Any:
    """Placeholder TOML parser."""
    {}

fn xml_parse_internal(text: text) -> Any:
    """Placeholder XML parser."""
    {}

fn csv_parse_internal(text: text) -> [[text]]:
    """Placeholder CSV parser."""
    []

# ============================================================================
# JSON Helper Functions (for validation)
# ============================================================================

fn json_depth(value: JsonValue, current: i64) -> i64:
    """Calculate maximum nesting depth of JSON value."""
    match value.kind:
        case Object(fields):
            var max_depth = current
            for field in fields:
                val nested_depth = json_depth(field.1, current + 1)
                if nested_depth > max_depth:
                    max_depth = nested_depth
            max_depth

        case Array(elements):
            var max_depth = current
            for elem in elements:
                val nested_depth = json_depth(elem, current + 1)
                if nested_depth > max_depth:
                    max_depth = nested_depth
            max_depth

        case _:
            current

fn json_type_name(value: JsonValue) -> text:
    """Get type name of JSON value."""
    match value.kind:
        case Null: "null"
        case Bool(_): "boolean"
        case Number(_): "number"
        case String(_): "string"
        case Array(_): "array"
        case Object(_): "object"

# Character helper extensions (placeholder - should be in std)
impl text:
    fn is_digit() -> bool:
        val ch = self[0]
        ch >= '0' and ch <= '9'

    fn is_hex_digit() -> bool:
        val ch = self[0]
        (ch >= '0' and ch <= '9') or (ch >= 'a' and ch <= 'f') or (ch >= 'A' and ch <= 'F')

    fn is_alphanumeric() -> bool:
        val ch = self[0]
        (ch >= 'a' and ch <= 'z') or (ch >= 'A' and ch <= 'Z') or (ch >= '0' and ch <= '9')

# ============================================================================
# Exports
# ============================================================================

export parse_json, parse_yaml, parse_toml, parse_xml, parse_csv
export validate_json, validate_regex, validate_sql
export highlight_keywords, highlight_strings, highlight_comments, highlight_numbers
export error_at, error_span, errors_from_strings
export interpolate_variables, strip_indent, normalize_newlines
