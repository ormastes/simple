# Block Lexer Modes and Syntax Features
#
# Defines how block content should be tokenized and parsed.

# ============================================================================
# Lexer Modes
# ============================================================================

"""Lexer mode determines tokenization behavior inside block."""
enum LexerMode:
    Normal          # Standard Simple tokenization
    Math            # ^ for power, ' for transpose, implicit mul
    Raw             # Capture as raw text (no tokenization)
    Custom(config: LexerConfig)  # Custom configuration


# ============================================================================
# LexerMode Methods (was: impl LexerMode:)
# ============================================================================

# ============================================================================
# Lexer Configuration
# ============================================================================

struct LexerConfig:
    """Custom lexer configuration for blocks.

    Allows fine-grained control over tokenization behavior.
    """

    # Operator overrides
    caret_is_power: bool        # ^ as power operator (instead of error)
    quote_is_transpose: bool    # ' as postfix transpose
    implicit_mul: bool          # 2x -> 2*x, (a)(b) -> (a)*(b)

    # String handling
    interpolation: bool         # Allow ${...} interpolation
    raw_strings: bool           # Disable escape sequences

    # Delimiter handling
    preserve_braces: bool       # Include {} in payload
    preserve_newlines: bool     # Include newlines in payload

    # Block-specific
    allow_nested_blocks: bool   # Allow block{} inside this block


# ============================================================================
# LexerConfig Methods (was: impl LexerConfig:)
# ============================================================================

fn lexerconfig_default() -> LexerConfig:
        """Default configuration: standard Simple tokenization."""
        LexerConfig(
            caret_is_power: false,
            quote_is_transpose: false,
            implicit_mul: false,
            interpolation: true,
            raw_strings: false,
            preserve_braces: false,
            preserve_newlines: true,
            allow_nested_blocks: true
        )


fn lexerconfig_math() -> LexerConfig:
        """Math mode configuration."""
        LexerConfig(
            caret_is_power: true,
            quote_is_transpose: true,
            implicit_mul: true,
            interpolation: true,
            raw_strings: false,
            preserve_braces: false,
            preserve_newlines: true,
            allow_nested_blocks: true
        )


fn lexerconfig_raw() -> LexerConfig:
        """Raw mode configuration: no tokenization."""
        LexerConfig(
            caret_is_power: false,
            quote_is_transpose: false,
            implicit_mul: false,
            interpolation: false,
            raw_strings: true,
            preserve_braces: false,
            preserve_newlines: true,
            allow_nested_blocks: false
        )


# ============================================================================
# Syntax Features
# ============================================================================

struct SyntaxFeatures:
    """Syntax features enabled for a block.

    Controls which special syntax elements are available.
    """

    # Math-like features
    power_caret: bool           # ^ is power (not XOR/error)
    transpose_quote: bool       # ' is transpose (postfix)
    implicit_multiplication: bool  # 2x means 2*x

    # Tensor features
    broadcast_ops: bool         # .+ .- .* ./ .^
    matrix_mul: bool            # @ operator

    # ML features
    auto_backward: bool         # Call .backward() on result
    disable_grad: bool          # Disable gradient tracking

    # Pipeline features
    pipe_forward: bool          # |> operator
    composition: bool           # >> << operators

    # DSL features
    custom_keywords: [text]     # Additional keywords to recognize


# ============================================================================
# SyntaxFeatures Methods (was: impl SyntaxFeatures:)
# ============================================================================

fn syntaxfeatures_default() -> SyntaxFeatures:
        """Default: no special features."""
        SyntaxFeatures(
            power_caret: false,
            transpose_quote: false,
            implicit_multiplication: false,
            broadcast_ops: false,
            matrix_mul: false,
            auto_backward: false,
            disable_grad: false,
            pipe_forward: false,
            composition: false,
            custom_keywords: []
        )


fn syntaxfeatures_math() -> SyntaxFeatures:
        """Math block features: power, transpose, implicit mul, tensors."""
        SyntaxFeatures(
            power_caret: true,
            transpose_quote: true,
            implicit_multiplication: true,
            broadcast_ops: true,
            matrix_mul: true,
            auto_backward: false,
            disable_grad: false,
            pipe_forward: false,
            composition: false,
            custom_keywords: []
        )


fn syntaxfeatures_loss() -> SyntaxFeatures:
        """Loss block: math features + auto-backward."""
        var f = syntaxfeatures_math()
        f.auto_backward = true
        f


fn syntaxfeatures_nograd() -> SyntaxFeatures:
        """Nograd block: math features + disabled gradients."""
        var f = syntaxfeatures_math()
        f.disable_grad = true
        f


fn syntaxfeatures_pipeline() -> SyntaxFeatures:
        """Pipeline features for functional composition."""
        SyntaxFeatures(
            power_caret: false,
            transpose_quote: false,
            implicit_multiplication: false,
            broadcast_ops: false,
            matrix_mul: false,
            auto_backward: false,
            disable_grad: false,
            pipe_forward: true,
            composition: true,
            custom_keywords: []
        )


fn syntaxfeatures_with_power_caret(self: SyntaxFeatures) -> SyntaxFeatures:
        self.power_caret = true
        self


fn syntaxfeatures_with_transpose(self: SyntaxFeatures) -> SyntaxFeatures:
        self.transpose_quote = true
        self


fn syntaxfeatures_with_implicit_mul(self: SyntaxFeatures) -> SyntaxFeatures:
        self.implicit_multiplication = true
        self


fn syntaxfeatures_with_broadcast(self: SyntaxFeatures) -> SyntaxFeatures:
        self.broadcast_ops = true
        self


fn syntaxfeatures_with_matrix_mul(self: SyntaxFeatures) -> SyntaxFeatures:
        self.matrix_mul = true
        self


fn syntaxfeatures_with_auto_backward(self: SyntaxFeatures) -> SyntaxFeatures:
        self.auto_backward = true
        self


fn syntaxfeatures_with_disable_grad(self: SyntaxFeatures) -> SyntaxFeatures:
        self.disable_grad = true
        self


fn syntaxfeatures_with_pipeline(self: SyntaxFeatures) -> SyntaxFeatures:
        self.pipe_forward = true
        self.composition = true
        self


fn syntaxfeatures_with_keywords(self: SyntaxFeatures, keywords: [text]) -> SyntaxFeatures:
        self.custom_keywords = keywords
        self


# ============================================================================
# Span (Source Location)
# ============================================================================

struct Span:
    """Source location for error reporting.

    Defined here (in modes.spl) to avoid circular imports.
    The lexer module defines a compatible Span type.
    """
    start: i64
    end: i64
    line: i64
    col: i64


# ============================================================================
# Span Methods (was: impl Span:)
# ============================================================================

fn span_new(start: i64, end: i64, line: i64, col: i64) -> Span:
        Span(start: start, end: end, line: line, col: col)


fn span_empty() -> Span:
        span_new(0, 0, 0, 0)


# ============================================================================
# Exports
# ============================================================================

# ============================================================================
# Pre-Lex Info (Tier 1+2 scanning data)
# ============================================================================

struct TextSpan:
    """Byte range within a payload."""
    start: i64
    end: i64


# ============================================================================
# TextSpan Methods (was: impl TextSpan:)
# ============================================================================

fn textspan_new(start: i64, end: i64) -> TextSpan:
        TextSpan(start: start, end: end)


struct PreLexInfo:
    """Pre-lexing info collected during Tier 1/2 brace tracking.

    The main lexer collects this while scanning block payloads,
    so block handlers don't need to re-discover strings/comments/escapes.
    """
    string_spans: [TextSpan]       # "..." and '...' regions
    comment_spans: [TextSpan]      # Line/block comment regions
    escape_positions: [i64]        # Backslash positions
    brace_pairs: [(i64, i64)]      # Matched { } positions with depth


# ============================================================================
# PreLexInfo Methods (was: impl PreLexInfo:)
# ============================================================================

fn prelexinfo_empty() -> PreLexInfo:
        PreLexInfo(
            string_spans: [],
            comment_spans: [],
            escape_positions: [],
            brace_pairs: []
        )


# ============================================================================
# Block Skip Policy
# ============================================================================

enum BlockSkipPolicy:
    """Controls whether TreeSitter can skip a block in fast mode."""
    Skippable          # TreeSitter can skip in fast mode
    OutlineRequired    # Must run treesitter_outline even in fast mode
    AlwaysFull         # Always fully parse


# ============================================================================
# BlockSkipPolicy Methods (was: impl BlockSkipPolicy:)
# ============================================================================

# ============================================================================
# Block Outline Info
# ============================================================================

struct BlockOutlineInfo:
    """Structural summary extracted by treesitter_outline.

    Provides enough info for IDE features without full parsing.
    """
    kind: text
    identifiers: [text]       # Variables/symbols referenced
    external_refs: [text]     # Table names, commands, file paths
    # # DESUGARED: structure_kind: text
    has_structure_kind: bool
    structure_kind: text
    is_opaque: bool


# ============================================================================
# BlockOutlineInfo Methods (was: impl BlockOutlineInfo:)
# ============================================================================

fn blockoutlineinfo_opaque(kind: text) -> BlockOutlineInfo:
        """Create an opaque outline (no structural info)."""
        BlockOutlineInfo(
            kind: kind,
            identifiers: [],
            external_refs: [],
            #  # DESUGARED: structure_kind: nil
            is_opaque: true
        )


# ============================================================================
# Block Tokens (sub-lexer output)
# ============================================================================

enum BlockTokenKind:
    """Token kinds produced by block sub-lexers."""
    Keyword
    Identifier
    Number
    StringLit
    Operator
    Punctuation
    Comment
    Whitespace
    Error

struct BlockToken:
    """Token produced by a block's sub-lexer."""
    kind: BlockTokenKind
    span: TextSpan
    value: text


# ============================================================================
# BlockToken Methods (was: impl BlockToken:)
# ============================================================================

fn blocktoken_new(kind: BlockTokenKind, start: i64, end: i64, value: text) -> BlockToken:
        BlockToken(kind: kind, span: TextSpan(start: start, end: end), value: value)


# ============================================================================
# Exports
# ============================================================================

export LexerMode, LexerConfig, SyntaxFeatures, Span
export TextSpan, PreLexInfo
export BlockSkipPolicy, BlockOutlineInfo
export BlockToken, BlockTokenKind
