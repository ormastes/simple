# Performance Profiler - Pure Simple Implementation
# Analyzes Simple code performance and suggests optimizations

import io
import json

# Performance counters
class PerfCounter:
    name: text
    count: i64
    total_time_ns: i64
    min_time_ns: i64
    max_time_ns: i64

    fn avg_time_ns() -> i64:
        if self.count == 0:
            return 0
        self.total_time_ns / self.count

    fn to_dict() -> Dict:
        {
            "name": self.name,
            "count": self.count,
            "total_time_ns": self.total_time_ns,
            "avg_time_ns": self.avg_time_ns(),
            "min_time_ns": self.min_time_ns,
            "max_time_ns": self.max_time_ns
        }

# Performance profiler state
class Profiler:
    counters: Dict<text, PerfCounter>
    start_time: i64
    enabled: bool

    static fn create() -> Profiler:
        Profiler(
            counters: {},
            start_time: rt_time_monotonic_ns(),
            enabled: true
        )

    me enable():
        self.enabled = true

    me disable():
        self.enabled = false

    me start_region(name: text) -> i64:
        if not self.enabled:
            return 0
        rt_time_monotonic_ns()

    me end_region(name: text, start_ns: i64):
        if not self.enabled:
            return

        val elapsed = rt_time_monotonic_ns() - start_ns

        # Get or create counter
        if not self.counters.contains_key(name):
            self.counters[name] = PerfCounter(
                name: name,
                count: 0,
                total_time_ns: 0,
                min_time_ns: elapsed,
                max_time_ns: elapsed
            )

        # Update counter
        var counter = self.counters[name]
        counter.count = counter.count + 1
        counter.total_time_ns = counter.total_time_ns + elapsed
        if elapsed < counter.min_time_ns:
            counter.min_time_ns = elapsed
        if elapsed > counter.max_time_ns:
            counter.max_time_ns = elapsed
        self.counters[name] = counter

    fn get_stats() -> List<PerfCounter>:
        var result = []
        for (name, counter) in self.counters:
            result.push(counter)
        result

    fn report() -> text:
        var lines = ["Performance Profile Report", "=" * 60, ""]

        val total_time = rt_time_monotonic_ns() - self.start_time
        lines.push("Total time: {total_time / 1000000} ms")
        lines.push("")

        # Sort by total time
        var stats = self.get_stats()
        stats.sort_by(\a, b: b.total_time_ns - a.total_time_ns)

        lines.push("Region".pad_right(30) + "Count".pad_right(10) + "Avg(µs)".pad_right(12) + "Total(ms)".pad_right(12) + "% Time")
        lines.push("-" * 80)

        for counter in stats:
            val pct = (counter.total_time_ns * 100) / total_time
            val avg_us = counter.avg_time_ns() / 1000
            val total_ms = counter.total_time_ns / 1000000

            val line = counter.name.pad_right(30) +
                       counter.count.to_string().pad_right(10) +
                       avg_us.to_string().pad_right(12) +
                       total_ms.to_string().pad_right(12) +
                       "{pct}%"
            lines.push(line)

        lines.join("\n")

    fn to_json() -> text:
        var stats_list = []
        for counter in self.get_stats():
            stats_list.push(counter.to_dict())

        json.stringify({
            "total_time_ns": rt_time_monotonic_ns() - self.start_time,
            "regions": stats_list
        })

# Global profiler instance
var GLOBAL_PROFILER: Profiler? = nil

fn init_profiler():
    GLOBAL_PROFILER = Some(Profiler.create())

fn get_profiler() -> Profiler:
    if val Some(prof) = GLOBAL_PROFILER:
        return prof
    init_profiler()
    get_profiler()

fn profile_region<T>(name: text, f: fn() -> T) -> T:
    var prof = get_profiler()
    val start = prof.start_region(name)
    val result = f()
    prof.end_region(name, start)
    result

fn print_profile():
    val prof = get_profiler()
    print prof.report()

fn save_profile(path: text):
    val prof = get_profiler()
    io.write_file(path, prof.to_json())
    print "Profile saved to {path}"

# Optimization analysis
fn analyze_hotspots() -> List<text>:
    val prof = get_profiler()
    val stats = prof.get_stats()
    stats.sort_by(\a, b: b.total_time_ns - a.total_time_ns)

    var suggestions = []

    for counter in stats:
        val avg_us = counter.avg_time_ns() / 1000

        # Suggest optimizations for slow regions
        if avg_us > 1000:
            suggestions.push("⚠ '{counter.name}' is slow (avg {avg_us}µs) - consider optimization")
        elif avg_us > 100 and counter.count > 100:
            suggestions.push("⚡ '{counter.name}' called {counter.count} times - consider caching")

    suggestions

# Benchmark helper
fn benchmark(name: text, iterations: i64, f: fn() -> ()):
    print "Benchmarking: {name}"
    var prof = get_profiler()
    prof.enable()

    val warmup = iterations / 10
    for i in 0..warmup:
        f()

    val start = rt_time_monotonic_ns()
    for i in 0..iterations:
        f()
    val elapsed = rt_time_monotonic_ns() - start

    val avg_ns = elapsed / iterations
    val avg_us = avg_ns / 1000

    print "  Iterations: {iterations}"
    print "  Total time: {elapsed / 1000000} ms"
    print "  Average:    {avg_us} µs"
    print "  Throughput: {1000000000 / avg_ns} ops/sec"

# Export SFFI hooks
extern fn rt_time_monotonic_ns() -> i64
