# Simple Language - Unified CLI (Written in Simple)
#
# This is the main entry point for the Simple CLI, written in Simple itself.
# Most functionality is implemented in Simple; FFI is only used for runtime operations.
#
# Usage like Python:
#   simple              - Start interactive REPL
#   simple file.spl     - Run source file
#   simple file.smf     - Run compiled binary
#   simple -c "code"    - Run code string
#   simple compile src.spl [-o out.smf]  - Compile to SMF
#   simple watch file.spl  - Watch and auto-recompile

# =========================================================================
# Version and Help - implemented in Simple
# =========================================================================
fn get_version() -> str:
    "0.1.0"

fn print_version():
    val v = get_version()
    print "Simple v{v}"

fn print_help():
    val v = get_version()
    print "Simple Language v{v}"
    print ""
    print "Usage:"
    print "  simple                      Start interactive TUI REPL (default)"
    print "  simple --notui              Start Normal REPL (rustyline-based)"
    print "  simple <file.spl>           Run source file"
    print "  simple <file.smf>           Run compiled binary"
    print "  simple -c \"code\"            Run code string"
    print "  simple compile <src> [-o <out>] [options]  Compile source file"
    print "  simple watch <file.spl>     Watch and auto-recompile"
    print "  simple targets              List available target architectures"
    print "  simple linkers              List available native linkers"
    print ""
    print "Testing:"
    print "  simple test [path]          Run tests (default: test/)"
    print "  simple test --unit          Run unit tests only"
    print "  simple test --integration   Run integration tests only"
    print "  simple test --system        Run system tests only"
    print "  simple test --tag <name>    Filter by tag"
    print "  simple test --fail-fast     Stop on first failure"
    print "  simple test --format <fmt>  Output format: text, json, doc"
    print "  simple test --list-skip-features  List features from .skip files"
    print "  simple test --planned-only  Filter to planned features only"
    print ""
    print "Code Quality:"
    print "  simple lex <file.spl>       Tokenize file (Simple lexer)"
    print "  simple lint [path]          Run linter on file or directory"
    print "  simple lint --fix           Apply auto-fixes"
    print "  simple fmt [path]           Format file or directory"
    print "  simple fmt --check          Check formatting without changes"
    print "  simple check [path]         Type check without running"
    print ""
    print "LLM-Friendly Tools:"
    print "  simple mcp <file.spl>       Generate minimal code preview"
    print "  simple diff <old> <new>     Semantic diff"
    print "  simple brief <path>         Brief view for LLM context"
    print "  simple query --generated    Find LLM-generated code"
    print ""
    print "Verification:"
    print "  simple verify <file.spl>    Run formal verification"
    print "  simple gen-lean generate    Generate Lean verification files"
    print ""
    print "Package Management:"
    print "  simple init [name]          Create a new project"
    print "  simple add <pkg> [options]  Add a dependency"
    print "  simple remove <pkg>         Remove a dependency"
    print "  simple install              Install all dependencies"
    print "  simple update [pkg]         Update dependencies"
    print "  simple list                 List installed dependencies"
    print "  simple tree                 Show dependency tree"
    print ""
    print "Options:"
    print "  -h, --help     Show this help"
    print "  -v, --version  Show version"
    print "  -c <code>      Run code string"
    print "  --notui        Use Normal REPL instead of TUI"
    print "  --gc-log       Enable verbose GC logging"
    print "  --gc-off       Disable garbage collection"
    print ""
    print "Examples:"
    print "  simple                      # Start REPL"
    print "  simple hello.spl            # Run source"
    print "  simple -c \"print 42\"        # Run expression"
    print "  simple compile app.spl      # Compile to native"
    print "  simple test                 # Run all tests"

# =========================================================================
# Target architectures - implemented in Simple
# =========================================================================
fn print_targets():
    print "Available target architectures:"
    print ""
    print "  x86_64    64-bit x86 (default on most systems)"
    print "  aarch64   64-bit ARM (Apple Silicon, ARM servers)"
    print "  i686      32-bit x86"
    print "  armv7     32-bit ARM"
    print "  riscv64   64-bit RISC-V"
    print "  riscv32   32-bit RISC-V"
    print ""
    print "Usage:"
    print "  simple compile app.spl --target aarch64"

# =========================================================================
# Native linkers - implemented in Simple
# =========================================================================
fn print_linkers():
    print "Available native linkers:"
    print ""
    print "  mold      Modern linker (fastest, recommended)"
    print "  lld       LLVM linker (fast, widely available)"
    print "  ld        GNU linker (default, always available)"
    print ""
    print "The linker is auto-detected if not specified."
    print "Preference order: mold > lld > ld"
    print ""
    print "Usage:"
    print "  simple compile app.spl --linker mold"

# =========================================================================
# Error messages - implemented in Simple
# =========================================================================
fn print_error(msg: str):
    print "error: {msg}"

fn print_error_with_help(msg: str):
    print "error: {msg}"
    print ""
    print_help()

# =========================================================================
# Simple Lexer - implemented entirely in Simple
# =========================================================================
enum TokenKind:
    # Keywords
    Fn
    Val
    Var
    Return
    If
    Else
    Elif
    Match
    Case
    For
    While
    Loop
    Break
    Continue
    Struct
    Class
    Enum
    Trait
    Impl
    Extern
    Use
    Pub
    TrueKw
    FalseKw
    NilKw
    And
    Or
    Not
    In
    As
    Is
    # Operators
    Plus
    Minus
    Star
    Slash
    Percent
    Eq
    NotEq
    Lt
    Gt
    LtEq
    GtEq
    Assign
    Arrow
    Colon
    Dot
    Comma
    # Delimiters
    LParen
    RParen
    LBrace
    RBrace
    LBracket
    RBracket
    # Literals
    Integer(i64)
    Float(f64)
    String(str)
    Identifier(str)
    # Special
    Newline
    Indent
    Dedent
    Comment
    Eof
    Error(str)

struct Token:
    kind: TokenKind
    text: str
    line: i64
    column: i64

# Helper functions for character classification
fn is_alpha(ch: str) -> bool:
    if ch.len() == 0:
        return false
    val c = ch.char_at(0)
    (c >= "a" and c <= "z") or (c >= "A" and c <= "Z") or c == "_"

fn is_digit(ch: str) -> bool:
    if ch.len() == 0:
        return false
    val c = ch.char_at(0)
    c >= "0" and c <= "9"

fn is_whitespace(ch: str) -> bool:
    ch == " " or ch == "\t" or ch == "\r"

fn keyword_or_identifier(text: str) -> TokenKind:
    match text:
        case "fn": TokenKind.Fn
        case "val": TokenKind.Val
        case "var": TokenKind.Var
        case "return": TokenKind.Return
        case "if": TokenKind.If
        case "else": TokenKind.Else
        case "elif": TokenKind.Elif
        case "match": TokenKind.Match
        case "case": TokenKind.Case
        case "for": TokenKind.For
        case "while": TokenKind.While
        case "loop": TokenKind.Loop
        case "break": TokenKind.Break
        case "continue": TokenKind.Continue
        case "struct": TokenKind.Struct
        case "class": TokenKind.Class
        case "enum": TokenKind.Enum
        case "trait": TokenKind.Trait
        case "impl": TokenKind.Impl
        case "extern": TokenKind.Extern
        case "use": TokenKind.Use
        case "pub": TokenKind.Pub
        case "true": TokenKind.TrueKw
        case "false": TokenKind.FalseKw
        case "nil": TokenKind.NilKw
        case "and": TokenKind.And
        case "or": TokenKind.Or
        case "not": TokenKind.Not
        case "in": TokenKind.In
        case "as": TokenKind.As
        case "is": TokenKind.Is
        case _: TokenKind.Identifier(text)

# SimpleLexer class with methods defined in body
class SimpleLexer:
    source: str
    pos: i64
    line: i64
    column: i64

    # Read-only methods
    fn current() -> str:
        val p = self.pos
        val e = p + 1
        if p < self.source.len():
            self.source[p:e]
        else:
            ""

    fn peek() -> str:
        val p = self.pos + 1
        val e = p + 1
        if p < self.source.len():
            self.source[p:e]
        else:
            ""

    # Mutable methods
    me advance():
        val p = self.pos
        val e = p + 1
        if p < self.source.len():
            if self.source[p:e] == "\n":
                self.line = self.line + 1
                self.column = 1
            else:
                self.column = self.column + 1
            self.pos = e

    me skip_whitespace():
        while self.pos < self.source.len() and is_whitespace(self.current()):
            self.advance()

    me skip_comment():
        # Skip # comment to end of line
        while self.pos < self.source.len() and self.current() != "\n":
            self.advance()

    me read_identifier() -> str:
        val start = self.pos
        while self.pos < self.source.len():
            val ch = self.current()
            if is_alpha(ch) or is_digit(ch):
                self.advance()
            else:
                break
        val end = self.pos
        self.source[start:end]

    me read_number() -> Token:
        val start = self.pos
        val start_line = self.line
        val start_col = self.column
        var has_dot = false

        while self.pos < self.source.len():
            val ch = self.current()
            if is_digit(ch):
                self.advance()
            elif ch == "." and not has_dot:
                has_dot = true
                self.advance()
            else:
                break

        val end = self.pos
        val text = self.source[start:end]
        if has_dot:
            Token(kind: TokenKind.Float(0.0), text: text, line: start_line, column: start_col)
        else:
            Token(kind: TokenKind.Integer(0), text: text, line: start_line, column: start_col)

    me read_string() -> Token:
        val start_line = self.line
        val start_col = self.column
        val quote = self.current()
        self.advance()  # skip opening quote
        val start = self.pos

        while self.pos < self.source.len() and self.current() != quote:
            if self.current() == "\\":
                self.advance()  # skip escape
            self.advance()

        val end = self.pos
        val text = self.source[start:end]
        self.advance()  # skip closing quote
        Token(kind: TokenKind.String(text), text: text, line: start_line, column: start_col)

    me next_token() -> Token:
        self.skip_whitespace()

        if self.pos >= self.source.len():
            return Token(kind: TokenKind.Eof, text: "", line: self.line, column: self.column)

        val ch = self.current()
        val start_line = self.line
        val start_col = self.column

        # Comments
        if ch == "#":
            self.skip_comment()
            return Token(kind: TokenKind.Comment, text: "#", line: start_line, column: start_col)

        # Newline
        if ch == "\n":
            self.advance()
            return Token(kind: TokenKind.Newline, text: "\\n", line: start_line, column: start_col)

        # Identifiers and keywords
        if is_alpha(ch):
            val text = self.read_identifier()
            return Token(kind: keyword_or_identifier(text), text: text, line: start_line, column: start_col)

        # Numbers
        if is_digit(ch):
            return self.read_number()

        # Strings
        if ch == "\"" or ch == "'":
            return self.read_string()

        # Two-character operators
        val next = self.peek()
        if ch == "-" and next == ">":
            self.advance()
            self.advance()
            return Token(kind: TokenKind.Arrow, text: "->", line: start_line, column: start_col)
        if ch == "=" and next == "=":
            self.advance()
            self.advance()
            return Token(kind: TokenKind.Eq, text: "==", line: start_line, column: start_col)
        if ch == "!" and next == "=":
            self.advance()
            self.advance()
            return Token(kind: TokenKind.NotEq, text: "!=", line: start_line, column: start_col)
        if ch == "<" and next == "=":
            self.advance()
            self.advance()
            return Token(kind: TokenKind.LtEq, text: "<=", line: start_line, column: start_col)
        if ch == ">" and next == "=":
            self.advance()
            self.advance()
            return Token(kind: TokenKind.GtEq, text: ">=", line: start_line, column: start_col)

        # Single-character tokens - use if-else for braces (f-string conflict)
        self.advance()
        val lbrace = r"{".char_at(0)
        val rbrace = r"}".char_at(0)
        if ch == "+":
            Token(kind: TokenKind.Plus, text: "+", line: start_line, column: start_col)
        elif ch == "-":
            Token(kind: TokenKind.Minus, text: "-", line: start_line, column: start_col)
        elif ch == "*":
            Token(kind: TokenKind.Star, text: "*", line: start_line, column: start_col)
        elif ch == "/":
            Token(kind: TokenKind.Slash, text: "/", line: start_line, column: start_col)
        elif ch == "%":
            Token(kind: TokenKind.Percent, text: "%", line: start_line, column: start_col)
        elif ch == "=":
            Token(kind: TokenKind.Assign, text: "=", line: start_line, column: start_col)
        elif ch == "<":
            Token(kind: TokenKind.Lt, text: "<", line: start_line, column: start_col)
        elif ch == ">":
            Token(kind: TokenKind.Gt, text: ">", line: start_line, column: start_col)
        elif ch == ":":
            Token(kind: TokenKind.Colon, text: ":", line: start_line, column: start_col)
        elif ch == ".":
            Token(kind: TokenKind.Dot, text: ".", line: start_line, column: start_col)
        elif ch == ",":
            Token(kind: TokenKind.Comma, text: ",", line: start_line, column: start_col)
        elif ch == "(":
            Token(kind: TokenKind.LParen, text: "(", line: start_line, column: start_col)
        elif ch == ")":
            Token(kind: TokenKind.RParen, text: ")", line: start_line, column: start_col)
        elif ch == lbrace:
            Token(kind: TokenKind.LBrace, text: ch, line: start_line, column: start_col)
        elif ch == rbrace:
            Token(kind: TokenKind.RBrace, text: ch, line: start_line, column: start_col)
        elif ch == "[":
            Token(kind: TokenKind.LBracket, text: "[", line: start_line, column: start_col)
        elif ch == "]":
            Token(kind: TokenKind.RBracket, text: "]", line: start_line, column: start_col)
        else:
            Token(kind: TokenKind.Error("Unknown character"), text: ch, line: start_line, column: start_col)

fn tokenize(source: str) -> [Token]:
    var lex: SimpleLexer = SimpleLexer(source: source, pos: 0, line: 1, column: 1)
    var tokens: [Token] = []

    loop:
        val tok: Token = lex.next_token()
        tokens.push(tok)
        match tok.kind:
            case TokenKind.Eof:
                break
            case _:
                ()

    tokens

fn token_kind_name(kind: TokenKind) -> str:
    match kind:
        case TokenKind.Fn: "FN"
        case TokenKind.Val: "VAL"
        case TokenKind.Var: "VAR"
        case TokenKind.Return: "RETURN"
        case TokenKind.If: "IF"
        case TokenKind.Else: "ELSE"
        case TokenKind.Elif: "ELIF"
        case TokenKind.Match: "MATCH"
        case TokenKind.Case: "CASE"
        case TokenKind.For: "FOR"
        case TokenKind.While: "WHILE"
        case TokenKind.Loop: "LOOP"
        case TokenKind.Break: "BREAK"
        case TokenKind.Continue: "CONTINUE"
        case TokenKind.Struct: "STRUCT"
        case TokenKind.Class: "CLASS"
        case TokenKind.Enum: "ENUM"
        case TokenKind.Trait: "TRAIT"
        case TokenKind.Impl: "IMPL"
        case TokenKind.Extern: "EXTERN"
        case TokenKind.Use: "USE"
        case TokenKind.Pub: "PUB"
        case TokenKind.TrueKw: "TRUE"
        case TokenKind.FalseKw: "FALSE"
        case TokenKind.NilKw: "NIL"
        case TokenKind.And: "AND"
        case TokenKind.Or: "OR"
        case TokenKind.Not: "NOT"
        case TokenKind.In: "IN"
        case TokenKind.As: "AS"
        case TokenKind.Is: "IS"
        case TokenKind.Plus: "PLUS"
        case TokenKind.Minus: "MINUS"
        case TokenKind.Star: "STAR"
        case TokenKind.Slash: "SLASH"
        case TokenKind.Percent: "PERCENT"
        case TokenKind.Eq: "EQ"
        case TokenKind.NotEq: "NOTEQ"
        case TokenKind.Lt: "LT"
        case TokenKind.Gt: "GT"
        case TokenKind.LtEq: "LTEQ"
        case TokenKind.GtEq: "GTEQ"
        case TokenKind.Assign: "ASSIGN"
        case TokenKind.Arrow: "ARROW"
        case TokenKind.Colon: "COLON"
        case TokenKind.Dot: "DOT"
        case TokenKind.Comma: "COMMA"
        case TokenKind.LParen: "LPAREN"
        case TokenKind.RParen: "RPAREN"
        case TokenKind.LBrace: "LBRACE"
        case TokenKind.RBrace: "RBRACE"
        case TokenKind.LBracket: "LBRACKET"
        case TokenKind.RBracket: "RBRACKET"
        case TokenKind.Integer(_): "INTEGER"
        case TokenKind.Float(_): "FLOAT"
        case TokenKind.String(_): "STRING"
        case TokenKind.Identifier(_): "IDENT"
        case TokenKind.Newline: "NEWLINE"
        case TokenKind.Indent: "INDENT"
        case TokenKind.Dedent: "DEDENT"
        case TokenKind.Comment: "COMMENT"
        case TokenKind.Eof: "EOF"
        case TokenKind.Error(_): "ERROR"

fn print_tokens(tokens: [Token]):
    for tok in tokens:
        val kind_name = token_kind_name(tok.kind)
        match tok.kind:
            case TokenKind.Newline:
                print "{tok.line}:{tok.column}  {kind_name}"
            case TokenKind.Comment:
                ()  # skip comment output
            case TokenKind.Eof:
                print "{tok.line}:{tok.column}  {kind_name}"
            case _:
                print "{tok.line}:{tok.column}  {kind_name}  '{tok.text}'"

fn run_lex_command(path: str) -> i64:
    val source = rt_cli_read_file(path)
    if source == "":
        print_error("Failed to read file: {path}")
        return 1

    print "Tokenizing: {path}"
    print "============================================"
    val tokens = tokenize(source)
    print_tokens(tokens)
    print "============================================"
    print "Total tokens: {tokens.len()}"
    0

# =========================================================================
# FFI - only for operations requiring Rust runtime
# =========================================================================
extern fn rt_cli_get_args() -> [str]
extern fn rt_cli_file_exists(path: str) -> bool
extern fn rt_cli_read_file(path: str) -> str

# Code execution
extern fn rt_cli_run_code(code: str, gc_log: bool, gc_off: bool) -> i64
extern fn rt_cli_run_file(path: str, args: [str], gc_log: bool, gc_off: bool) -> i64
extern fn rt_cli_watch_file(path: str) -> i64
extern fn rt_cli_run_repl(gc_log: bool, gc_off: bool) -> i64

# Testing
extern fn rt_cli_run_tests(args: [str], gc_log: bool, gc_off: bool) -> i64

# Code quality
extern fn rt_cli_run_lint(args: [str]) -> i64
extern fn rt_cli_run_fmt(args: [str]) -> i64
extern fn rt_cli_run_check(args: [str]) -> i64

# Verification
extern fn rt_cli_run_verify(args: [str], gc_log: bool, gc_off: bool) -> i64

# Migration and tooling
extern fn rt_cli_run_migrate(args: [str]) -> i64
extern fn rt_cli_run_mcp(args: [str]) -> i64
extern fn rt_cli_run_diff(args: [str]) -> i64
extern fn rt_cli_run_constr(args: [str]) -> i64

# Analysis
extern fn rt_cli_run_query(args: [str]) -> i64
extern fn rt_cli_run_info(args: [str]) -> i64

# Auditing
extern fn rt_cli_run_spec_coverage(args: [str]) -> i64
extern fn rt_cli_run_replay(args: [str]) -> i64

# Code generation
extern fn rt_cli_run_gen_lean(args: [str]) -> i64
extern fn rt_cli_run_feature_gen(args: [str]) -> i64
extern fn rt_cli_run_task_gen(args: [str]) -> i64
extern fn rt_cli_run_spec_gen(args: [str]) -> i64
extern fn rt_cli_run_sspec_docgen(args: [str]) -> i64
extern fn rt_cli_run_todo_scan(args: [str]) -> i64
extern fn rt_cli_run_todo_gen(args: [str]) -> i64

# Brief view
extern fn rt_cli_run_brief(args: [str]) -> i64

# i18n
extern fn rt_cli_run_i18n(args: [str]) -> i64

# Compilation
extern fn rt_cli_handle_compile(args: [str]) -> i64

# Web framework
extern fn rt_cli_handle_web(args: [str]) -> i64

# Diagram generation
extern fn rt_cli_handle_diagram(args: [str]) -> i64

# Package management
extern fn rt_cli_handle_init(args: [str]) -> i64
extern fn rt_cli_handle_add(args: [str]) -> i64
extern fn rt_cli_handle_remove(args: [str]) -> i64
extern fn rt_cli_handle_install() -> i64
extern fn rt_cli_handle_update(args: [str]) -> i64
extern fn rt_cli_handle_list() -> i64
extern fn rt_cli_handle_tree() -> i64
extern fn rt_cli_handle_cache(args: [str]) -> i64

# Environment management
extern fn rt_cli_handle_env(args: [str]) -> i64

# Lock file management
extern fn rt_cli_handle_lock(args: [str]) -> i64

# Explicit run command
extern fn rt_cli_handle_run(args: [str], gc_log: bool, gc_off: bool) -> i64

# Global flags struct
struct GlobalFlags:
    gc_log: bool
    gc_off: bool
    use_notui: bool

fn parse_global_flags(args: [str]) -> GlobalFlags:
    var gc_log = false
    var gc_off = false
    var use_notui = false

    for arg in args:
        if arg == "--gc-log":
            gc_log = true
        elif arg == "--gc-off":
            gc_off = true
        elif arg == "--notui":
            use_notui = true

    GlobalFlags(gc_log: gc_log, gc_off: gc_off, use_notui: use_notui)

fn filter_internal_flags(args: [str]) -> [str]:
    var result = []
    for arg in args:
        if not arg.starts_with("--gc") and arg != "--notui" and arg != "--lang":
            if not arg.starts_with("--lang="):
                result.push(arg)
    result

fn main() -> i64:
    val all_args = rt_cli_get_args()

    var args = []
    var start_idx = 1
    if all_args.len() > 1 and all_args[1].ends_with("main.spl"):
        start_idx = 2
    var i = start_idx
    while i < all_args.len():
        args.push(all_args[i])
        i = i + 1

    val flags = parse_global_flags(args)
    val filtered_args = filter_internal_flags(args)

    if filtered_args.len() == 0:
        return rt_cli_run_repl(flags.gc_log, flags.gc_off)

    val first = filtered_args[0]

    match first:
        case "-h" | "--help":
            print_help()
            return 0

        case "-v" | "--version":
            print_version()
            return 0

        case "-c":
            if filtered_args.len() < 2:
                print_error("-c requires a code argument")
                return 1
            return rt_cli_run_code(filtered_args[1], flags.gc_log, flags.gc_off)

        case "compile":
            return rt_cli_handle_compile(filtered_args)

        case "targets":
            print_targets()
            return 0

        case "linkers":
            print_linkers()
            return 0

        case "web":
            return rt_cli_handle_web(filtered_args)

        case "watch":
            if filtered_args.len() < 2:
                print_error("watch requires a source file")
                return 1
            return rt_cli_watch_file(filtered_args[1])

        case "test":
            val test_args = filtered_args[1:]
            return rt_cli_run_tests(test_args, flags.gc_log, flags.gc_off)

        case "lex":
            if filtered_args.len() < 2:
                print_error("lex requires a source file")
                return 1
            return run_lex_command(filtered_args[1])

        case "lint":
            return rt_cli_run_lint(filtered_args)

        case "fmt":
            return rt_cli_run_fmt(filtered_args)

        case "check":
            val check_args = filtered_args[1:]
            return rt_cli_run_check(check_args)

        case "i18n":
            return rt_cli_run_i18n(filtered_args)

        case "migrate":
            return rt_cli_run_migrate(filtered_args)

        case "mcp":
            return rt_cli_run_mcp(filtered_args)

        case "diff":
            return rt_cli_run_diff(filtered_args)

        case "constr":
            return rt_cli_run_constr(filtered_args)

        case "query":
            return rt_cli_run_query(filtered_args)

        case "info":
            return rt_cli_run_info(filtered_args)

        case "spec-coverage":
            return rt_cli_run_spec_coverage(filtered_args)

        case "replay":
            return rt_cli_run_replay(filtered_args)

        case "gen-lean":
            return rt_cli_run_gen_lean(filtered_args)

        case "feature-gen":
            return rt_cli_run_feature_gen(filtered_args)

        case "task-gen":
            return rt_cli_run_task_gen(filtered_args)

        case "spec-gen":
            return rt_cli_run_spec_gen(filtered_args)

        case "sspec-docgen":
            return rt_cli_run_sspec_docgen(filtered_args)

        case "todo-scan":
            return rt_cli_run_todo_scan(filtered_args)

        case "todo-gen":
            return rt_cli_run_todo_gen(filtered_args)

        case "brief":
            return rt_cli_run_brief(filtered_args)

        case "dashboard":
            print "Dashboard command - implementation in progress"
            return 0

        case "verify":
            return rt_cli_run_verify(filtered_args, flags.gc_log, flags.gc_off)

        case "diagram":
            return rt_cli_handle_diagram(filtered_args)

        case "init":
            return rt_cli_handle_init(filtered_args)

        case "add":
            return rt_cli_handle_add(filtered_args)

        case "remove":
            return rt_cli_handle_remove(filtered_args)

        case "install":
            return rt_cli_handle_install()

        case "update":
            return rt_cli_handle_update(filtered_args)

        case "list":
            return rt_cli_handle_list()

        case "tree":
            return rt_cli_handle_tree()

        case "cache":
            return rt_cli_handle_cache(filtered_args)

        case "env":
            return rt_cli_handle_env(filtered_args)

        case "lock":
            return rt_cli_handle_lock(filtered_args)

        case "run":
            return rt_cli_handle_run(filtered_args, flags.gc_log, flags.gc_off)

        case _:
            if rt_cli_file_exists(first):
                var program_args = [first]
                var j = 1
                while j < filtered_args.len():
                    program_args.push(filtered_args[j])
                    j = j + 1
                return rt_cli_run_file(first, program_args, flags.gc_log, flags.gc_off)
            else:
                print_error_with_help("file not found: {first}")
                return 1
