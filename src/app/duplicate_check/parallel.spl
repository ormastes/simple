# Parallel file processing for duplicate detection
#
# Processes multiple files concurrently while respecting shared state (cache, interner).
# Simplified from BuildGraph pattern since files have no inter-dependencies.

use app.duplicate_check.config.{DuplicationConfig}
use app.duplicate_check.tokenizer.{SimpleToken}
use app.duplicate_check.cache.{TokenCacheManager}
use app.duplicate_check.detector.{DuplicateBlock, find_duplicates_in_file}
use app.io.mod.{shell}

# Parallel processing configuration
struct ParallelConfig:
    num_workers: i64        # Number of parallel workers (0 = auto-detect)
    batch_size: i64         # Files per batch
    enabled: bool           # Enable parallel processing

fn default_parallel_config() -> ParallelConfig:
    ParallelConfig(
        num_workers: 0,      # Auto-detect CPU count
        batch_size: 10,       # Process 10 files per batch
        enabled: true
    )

fn single_threaded_config() -> ParallelConfig:
    ParallelConfig(
        num_workers: 1,
        batch_size: 1,
        enabled: false
    )

# Detect CPU count
fn detect_cpu_count() -> i64:
    val result = shell("nproc 2>/dev/null || echo 4")
    val output = result.stdout.trim()
    val count = int(output)
    if count > 0:
        count
    else:
        4  # Default to 4 if detection fails

# Process a batch of files (sequential within batch)
fn process_file_batch(
    files: [text],
    config: DuplicationConfig,
    cache_manager: TokenCacheManager,
    interner: TokenInterner
) -> [DuplicateBlock]:
    var all_blocks = []
    for file in files:
        val blocks = find_duplicates_in_file(file, config, cache_manager, interner)
        all_blocks = all_blocks + blocks
    all_blocks

# Process files in parallel batches
fn process_files_parallel(
    files: [text],
    config: DuplicationConfig,
    cache_manager: TokenCacheManager,
    interner: TokenInterner,
    parallel_config: ParallelConfig
) -> [DuplicateBlock]:
    # Determine worker count
    val num_workers = if parallel_config.num_workers == 0:
        detect_cpu_count()
    else:
        parallel_config.num_workers

    # If single-threaded or too few files, process sequentially
    if not parallel_config.enabled or files.len() < parallel_config.batch_size:
        return process_file_batch(files, config, cache_manager, interner)

    # Split files into batches
    var batches = []
    var current_batch = []
    var i = 0
    while i < files.len():
        current_batch = current_batch + [files[i]]
        if current_batch.len() >= parallel_config.batch_size:
            batches = batches + [current_batch]
            current_batch = []
        i = i + 1
    if current_batch.len() > 0:
        batches = batches + [current_batch]

    # Process batches (sequential for now, parallel via FFI in future)
    # TODO: Use rayon FFI for true parallelism
    var all_blocks = []
    var batch_idx = 0
    while batch_idx < batches.len():
        val batch = batches[batch_idx]
        val blocks = process_file_batch(batch, config, cache_manager, interner)
        all_blocks = all_blocks + blocks
        batch_idx = batch_idx + 1

    all_blocks

# Stub for future TokenInterner import (avoid circular dependency)
struct TokenInterner:
    strings: {text: i64}
    reverse: {i64: text}
    next_id: i64

export ParallelConfig, default_parallel_config, single_threaded_config
export detect_cpu_count, process_files_parallel
