# Documentation Generator
#
# Generates markdown reports from test results and feature database.
# Output files:
#   - doc/test/test_result.md    (test results summary)
#   - doc/feature/feature.md     (feature index)
#   - doc/feature/pending_feature.md (incomplete features)
#   - doc/feature/category/*.md  (per-category details)

use app.io.mod (file_atomic_write, dir_create_all, time_now_unix_micros)
use test_db_types.*
use test_db_core.TestDatabase
use test_stats.{detect_flaky_test, has_significant_change}
use test_db_validation.{needs_qualification, count_unqualified_ignores}
use feature_db.{FeatureDatabase, FeatureRecord}

# =========================================================================
# Test Result Report
# =========================================================================

fn generate_test_result_md(db: TestDatabase) -> text:
    var lines: [text] = []
    lines.push("# Test Results")
    lines.push("")
    lines.push("*Auto-generated by Simple test runner*")
    lines.push("")

    # Summary
    var total_tests = db.tests.len()
    var passed = 0
    var failed = 0
    var skipped = 0

    for t in db.tests:
        val status = db.interner.get(t.status_str)
        if status == "passed":
            passed = passed + 1
        elif status == "failed":
            failed = failed + 1
        elif status == "skipped" or status == "ignored":
            skipped = skipped + 1

    lines.push("## Summary")
    lines.push("")
    lines.push("| Metric | Count |")
    lines.push("|--------|-------|")
    lines.push("| Total | {total_tests} |")
    lines.push("| Passed | {passed} |")
    lines.push("| Failed | {failed} |")
    lines.push("| Skipped | {skipped} |")
    lines.push("")

    # D2: Flaky tests section (improved algorithm)
    var flaky_tests: [text] = []
    for c in db.counters:
        val is_flaky = detect_flaky_test(c.total_runs, c.last_10_runs, c.failure_rate_pct)
        if is_flaky or c.flaky_count > 0:
            val name = db.interner.get(c.test_id)
            val rate_str = "{c.failure_rate_pct}"
            flaky_tests.push("| {name} | {c.flaky_count} | {rate_str}% | {c.last_10_runs} |")

    if flaky_tests.len() > 0:
        lines.push("## Flaky Tests")
        lines.push("")
        lines.push("| Test | Flips | Failure Rate | Recent Runs |")
        lines.push("|------|-------|--------------|-------------|")
        for entry in flaky_tests:
            lines.push(entry)
        lines.push("")

    # Recent runs
    if db.test_runs.len() > 0:
        lines.push("## Recent Runs")
        lines.push("")
        lines.push("| Run ID | Status | Tests | Passed | Failed | Timed Out |")
        lines.push("|--------|--------|-------|--------|--------|-----------|")
        var count = 0
        var i = db.test_runs.len() - 1
        while i >= 0 and count < 10:
            val r = db.test_runs[i]
            lines.push("| {r.run_id} | {r.status} | {r.test_count} | {r.passed} | {r.failed} | {r.timed_out} |")
            count = count + 1
            i = i - 1
        lines.push("")

    # Timing summary (show tests with percentile data)
    var timing_entries: [text] = []
    for t in db.timing:
        if t.p50 > 0.0:
            val name = db.interner.get(t.test_id)
            timing_entries.push("| {name} | {t.last_ms} | {t.p50} | {t.p90} | {t.p95} | {t.baseline_median} |")

    if timing_entries.len() > 0:
        lines.push("## Timing Percentiles")
        lines.push("")
        lines.push("| Test | Last (ms) | p50 | p90 | p95 | Baseline |")
        lines.push("|------|-----------|-----|-----|-----|----------|")
        for entry in timing_entries:
            lines.push(entry)
        lines.push("")

    # F1: Slowest tests (p95 > 1000ms)
    var slow_entries: [text] = []
    for t in db.timing:
        if t.p95 > 1000.0:
            val name = db.interner.get(t.test_id)
            slow_entries.push("| {name} | {t.p95} | {t.p50} | {t.mean} |")

    if slow_entries.len() > 0:
        lines.push("## Slowest Tests (p95 > 1s)")
        lines.push("")
        lines.push("| Test | p95 (ms) | p50 (ms) | Mean (ms) |")
        lines.push("|------|----------|----------|-----------|")
        var slow_count = 0
        for entry in slow_entries:
            if slow_count >= 20:
                break
            lines.push(entry)
            slow_count = slow_count + 1
        lines.push("")

    # F2: Recent changes (last 20)
    if db.changes.len() > 0:
        lines.push("## Recent Changes")
        lines.push("")
        lines.push("| Test | Change | Run ID |")
        lines.push("|------|--------|--------|")
        var change_count = 0
        var ci = db.changes.len() - 1
        while ci >= 0 and change_count < 20:
            val ch = db.changes[ci]
            val name = db.interner.get(ch.test_id)
            lines.push("| {name} | {ch.change_type} | {ch.run_id} |")
            change_count = change_count + 1
            ci = ci - 1
        lines.push("")

    # F3: Qualified ignores
    var qualified_entries: [text] = []
    for t in db.tests:
        if t.qualified_by != "":
            val name = db.interner.get(t.name_str)
            qualified_entries.push("| {name} | {t.qualified_by} | {t.qualified_at} | {t.qualified_reason} |")

    if qualified_entries.len() > 0:
        lines.push("## Qualified Ignores")
        lines.push("")
        lines.push("| Test | Qualified By | Date | Reason |")
        lines.push("|------|-------------|------|--------|")
        for entry in qualified_entries:
            lines.push(entry)
        lines.push("")

    # F4: Regression warnings (> 20% above baseline)
    var regression_entries: [text] = []
    for t in db.timing:
        if t.baseline_median > 0.001:
            if has_significant_change(t.last_ms, t.baseline_median, 20.0):
                val name = db.interner.get(t.test_id)
                val pct_change = (t.last_ms - t.baseline_median) / t.baseline_median * 100.0
                regression_entries.push("| {name} | {t.last_ms} | {t.baseline_median} | {pct_change}% |")

    if regression_entries.len() > 0:
        lines.push("## Regression Warnings")
        lines.push("")
        lines.push("| Test | Last (ms) | Baseline (ms) | Change |")
        lines.push("|------|-----------|---------------|--------|")
        for entry in regression_entries:
            lines.push(entry)
        lines.push("")

    # Failed tests
    var failed_tests: [text] = []
    var idx = 0
    for t in db.tests:
        val status = db.interner.get(t.status_str)
        if status == "failed":
            val name = db.interner.get(t.name_str)
            failed_tests.push(name)
        idx = idx + 1

    if failed_tests.len() > 0:
        lines.push("## Failed Tests")
        lines.push("")
        for name in failed_tests:
            lines.push("- {name}")
        lines.push("")

    lines.join("\n")

# =========================================================================
# Feature Index Report
# =========================================================================

fn generate_feature_md(fdb: FeatureDatabase) -> text:
    var lines: [text] = []
    lines.push("# Feature Index")
    lines.push("")
    lines.push("*Auto-generated by Simple test runner*")
    lines.push("")

    val categories = fdb.categories()
    lines.push("| Category | Total | Complete | Failed | Planned | Ignored |")
    lines.push("|----------|-------|----------|--------|---------|---------|")

    for cat in categories:
        val features = fdb.features_by_category(cat)
        var complete = 0
        var failed = 0
        var planned = 0
        var ignored = 0
        for f in features:
            match f.status:
                case "complete": complete = complete + 1
                case "failed": failed = failed + 1
                case "planned": planned = planned + 1
                case "in_progress": planned = planned + 1
                case "ignored": ignored = ignored + 1
                case _: ()
        val total = features.len()
        val safe_name = cat.replace(" ", "_")
        lines.push("| [{cat}](category/{safe_name}.md) | {total} | {complete} | {failed} | {planned} | {ignored} |")

    lines.push("")
    lines.join("\n")

# =========================================================================
# H9: Pending Feature Report (category grouping + priority emoji)
# =========================================================================

fn generate_pending_feature_md(fdb: FeatureDatabase) -> text:
    var lines: [text] = []
    lines.push("# Pending Features")
    lines.push("")
    lines.push("*Auto-generated by Simple test runner*")
    lines.push("")

    val total = fdb.features.len()
    val complete = fdb.count_by_status("complete")
    val failed = fdb.count_by_status("failed")
    val in_progress = fdb.count_by_status("in_progress")
    val planned = fdb.count_by_status("planned")
    val ignored = fdb.count_by_status("ignored")

    # Overall completion percentage
    val pending_total = total - complete - ignored
    val completion_pct = if total > 0: (complete * 100) / total else: 0

    lines.push("## Summary")
    lines.push("")
    lines.push("**Completion: {completion_pct}%** ({complete}/{total} features)")
    lines.push("")
    lines.push("| Status | Count | Priority |")
    lines.push("|--------|-------|----------|")
    lines.push("| Failed | {failed} | Critical |")
    lines.push("| In Progress | {in_progress} | High |")
    lines.push("| Planned | {planned} | Medium |")
    lines.push("| Ignored | {ignored} | Low |")
    lines.push("| **Total Pending** | **{pending_total}** | |")
    lines.push("")

    # Progress by category table
    val categories = fdb.categories()
    lines.push("## Progress by Category")
    lines.push("")
    lines.push("| Category | Complete | Failed | In Progress | Planned | Total | % |")
    lines.push("|----------|----------|--------|-------------|---------|-------|---|")
    for cat in categories:
        val features = fdb.features_by_category(cat)
        var cat_complete = 0
        var cat_failed = 0
        var cat_in_progress = 0
        var cat_planned = 0
        for f in features:
            match f.status:
                case "complete": cat_complete = cat_complete + 1
                case "failed": cat_failed = cat_failed + 1
                case "in_progress": cat_in_progress = cat_in_progress + 1
                case "planned": cat_planned = cat_planned + 1
                case _: ()
        val cat_total = features.len()
        val cat_pct = if cat_total > 0: (cat_complete * 100) / cat_total else: 0
        lines.push("| {cat} | {cat_complete} | {cat_failed} | {cat_in_progress} | {cat_planned} | {cat_total} | {cat_pct}% |")
    lines.push("")

    # Failed features (critical) with priority emoji
    if failed > 0:
        lines.push("## Failed Features")
        lines.push("")
        for cat in categories:
            var cat_failed_features: [FeatureRecord] = []
            for f in fdb.features_by_category(cat):
                if f.status == "failed":
                    cat_failed_features.push(f)
            if cat_failed_features.len() > 0:
                lines.push("### {cat}")
                lines.push("")
                for f in cat_failed_features:
                    val spec_link = if f.spec != "": " ([spec]({f.spec}))" else: ""
                    lines.push("- **{f.id}** {f.name}{spec_link}")
                lines.push("")

    # In progress features
    if in_progress > 0:
        lines.push("## In Progress Features")
        lines.push("")
        for cat in categories:
            var cat_ip_features: [FeatureRecord] = []
            for f in fdb.features_by_category(cat):
                if f.status == "in_progress":
                    cat_ip_features.push(f)
            if cat_ip_features.len() > 0:
                lines.push("### {cat}")
                lines.push("")
                for f in cat_ip_features:
                    val spec_link = if f.spec != "": " ([spec]({f.spec}))" else: ""
                    lines.push("- **{f.id}** {f.name}{spec_link}")
                lines.push("")

    # Planned features
    if planned > 0:
        lines.push("## Planned Features")
        lines.push("")
        for cat in categories:
            var cat_planned_features: [FeatureRecord] = []
            for f in fdb.features_by_category(cat):
                if f.status == "planned":
                    cat_planned_features.push(f)
            if cat_planned_features.len() > 0:
                lines.push("### {cat}")
                lines.push("")
                for f in cat_planned_features:
                    val spec_link = if f.spec != "": " ([spec]({f.spec}))" else: ""
                    lines.push("- **{f.id}** {f.name}{spec_link}")
                lines.push("")

    lines.join("\n")

# =========================================================================
# H10: Category Reports (with subcategory hierarchy)
# =========================================================================

fn generate_category_md(fdb: FeatureDatabase, category: text) -> text:
    var lines: [text] = []
    lines.push("# {category}")
    lines.push("")

    val features = fdb.features_by_category(category)

    # H10: Detect subcategories (dot-separated)
    var subcategories: Dict<text, bool> = {}
    for f in features:
        val parts = f.id.split(".")
        if parts.len() >= 2:
            subcategories[parts[0]] = true

    # Generate subcategory links if present
    if subcategories.len() > 1:
        lines.push("## Subcategories")
        lines.push("")
        for subcat in subcategories.keys():
            lines.push("- [{subcat}](#{subcat})")
        lines.push("")

    lines.push("| ID | Feature | Description | Interp | JIT | SMF-CL | SMF-LLVM | Status | Spec |")
    lines.push("|----|---------|-------------|--------|-----|--------|----------|--------|------|")

    for f in features:
        if f.status != "ignored":
            val interp = mode_badge(f.mode_interpreter)
            val jit = mode_badge(f.mode_jit)
            val smf_cl = mode_badge(f.mode_smf_cranelift)
            val smf_llvm = mode_badge(f.mode_smf_llvm)
            val sb = status_badge(f.status)
            # M5: Spec links with relative path
            val spec_link = if f.spec != "": "[spec](../../{f.spec})" else: ""
            lines.push("| <a id=\"feature-{f.id}\"></a>{f.id} | {f.name} | {f.description} | {interp} | {jit} | {smf_cl} | {smf_llvm} | {sb} | {spec_link} |")

    lines.push("")
    lines.join("\n")

fn mode_badge(mode: text) -> text:
    if mode == "supported":
        return "supported"
    "not_supported"

fn status_badge(status: text) -> text:
    match status:
        case "complete": "complete"
        case "failed": "**FAILED**"
        case "in_progress": "in_progress"
        case "planned": "planned"
        case _: status

# =========================================================================
# Generate All Docs
# =========================================================================

fn generate_all_docs(db: TestDatabase, fdb: FeatureDatabase):
    # Test result
    val test_result = generate_test_result_md(db)
    file_atomic_write("doc/test/test_result.md", test_result)

    # Feature index
    val feature_md = generate_feature_md(fdb)
    file_atomic_write("doc/feature/feature.md", feature_md)

    # Pending features
    val pending_md = generate_pending_feature_md(fdb)
    file_atomic_write("doc/feature/pending_feature.md", pending_md)

    # Per-category docs
    dir_create_all("doc/feature/category")
    val categories = fdb.categories()
    for cat in categories:
        val cat_md = generate_category_md(fdb, cat)
        val safe_name = cat.replace(" ", "_")
        file_atomic_write("doc/feature/category/{safe_name}.md", cat_md)

export generate_test_result_md, generate_feature_md
export generate_pending_feature_md, generate_category_md
export generate_all_docs
