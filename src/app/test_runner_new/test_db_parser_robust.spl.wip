# Test Database V3 SDN Parser - Robust Version
#
# Enhanced parser with error recovery, validation, and performance optimizations.
# Handles malformed rows gracefully without failing the entire parse.

use string_interner.{StringInterner, unescape_sdn_string}
use test_db_types.*
use app.io.mod (eprintln)

# =========================================================================
# Parse Statistics
# =========================================================================

struct ParseStats:
    total_rows: i64
    skipped_rows: i64
    errors: List<text>

impl ParseStats:
    static fn empty() -> ParseStats:
        ParseStats(total_rows: 0, skipped_rows: 0, errors: [])

    me record_error(table: text, line_num: i64, reason: text):
        self.errors.push("Line {line_num} in {table}: {reason}")
        self.skipped_rows = self.skipped_rows + 1

    fn has_errors() -> bool:
        self.errors.len() > 0

    fn summary() -> text:
        if not self.has_errors():
            return "Parsed {self.total_rows} rows successfully"
        "Parsed {self.total_rows} rows, skipped {self.skipped_rows} malformed rows"

# =========================================================================
# Parsed Database with Stats
# =========================================================================

struct ParsedStableDbRobust:
    interner: StringInterner
    files: List<FileRecord>
    suites: List<SuiteRecord>
    tests: List<TestRecord>
    stats: ParseStats

struct ParsedVolatileDbRobust:
    counters: List<CounterRecord>
    timing: List<TimingSummary>
    timing_runs: List<TimingRun>
    changes: List<ChangeEvent>
    test_runs: List<RunRecord>
    stats: ParseStats

# =========================================================================
# Table Detection
# =========================================================================

fn detect_table(line: text) -> text:
    val trimmed = line.trim()
    if trimmed.starts_with("strings |"):
        return "strings"
    if trimmed.starts_with("files |"):
        return "files"
    if trimmed.starts_with("suites |"):
        return "suites"
    if trimmed.starts_with("tests |"):
        return "tests"
    if trimmed.starts_with("counters |"):
        return "counters"
    if trimmed.starts_with("timing_runs |"):
        return "timing_runs"
    if trimmed.starts_with("timing |"):
        return "timing"
    if trimmed.starts_with("changes |"):
        return "changes"
    if trimmed.starts_with("test_runs |"):
        return "test_runs"
    ""

# =========================================================================
# Robust CSV-like Field Parsing
# =========================================================================

fn parse_fields(line: text) -> List<text>:
    """Parse CSV-like fields, handling quoted strings with embedded commas."""
    var fields: List<text> = []
    val trimmed = line.trim()
    var i = 0
    var current = ""
    var in_quote = false

    while i < trimmed.len():
        val ch = trimmed[i]
        if in_quote:
            if ch == "\\" and i + 1 < trimmed.len():
                # Handle escape sequences
                current = current + trimmed[i + 1]
                i = i + 2
                continue
            if ch == "\"":
                in_quote = false
                i = i + 1
                continue
            current = current + ch
        else:
            if ch == "\"":
                in_quote = true
                i = i + 1
                continue
            if ch == ",":
                fields.push(current.trim())
                current = ""
                i = i + 1
                continue
            current = current + ch
        i = i + 1

    fields.push(current.trim())
    fields

# =========================================================================
# Validation Helpers
# =========================================================================

fn validate_row_columns(table: text, fields: List<text>, expected: i64, line_num: i64, stats: ParseStats) -> bool:
    """Validate that a row has the expected number of columns."""
    if fields.len() < expected:
        stats.record_error(table, line_num, "expected {expected} columns, found {fields.len()}")
        return false
    true

fn safe_to_int(s: text, default: i64) -> i64:
    """Safely convert string to int, returning default on error."""
    val result = s.parse_int()
    result ?? default

fn safe_to_float(s: text, default: f64) -> f64:
    """Safely convert string to float, returning default on error."""
    val result = s.parse_float()
    result ?? default

# =========================================================================
# Parse Stable DB (test_db.sdn) - Robust Version
# =========================================================================

fn parse_stable_db_robust(content: text) -> ParsedStableDbRobust:
    val interner = StringInterner.empty()
    var files: List<FileRecord> = []
    var suites: List<SuiteRecord> = []
    var tests: List<TestRecord> = []
    var stats = ParseStats.empty()

    var current_table = ""
    var line_num = 0

    val lines = content.split("\n")
    for line in lines:
        line_num = line_num + 1

        val table = detect_table(line)
        if table != "":
            current_table = table
            continue

        val trimmed = line.trim()
        if trimmed == "" or trimmed.starts_with("#"):
            continue

        stats.total_rows = stats.total_rows + 1

        if current_table == "strings":
            # Parse: id, value
            val fields = parse_fields(trimmed)
            if validate_row_columns("strings", fields, 2, line_num, stats):
                interner.intern(fields[1])

        elif current_table == "files":
            val fields = parse_fields(trimmed)
            if validate_row_columns("files", fields, 2, line_num, stats):
                files.push(FileRecord(
                    file_id: safe_to_int(fields[0], 0),
                    path_str: safe_to_int(fields[1], 0)
                ))

        elif current_table == "suites":
            val fields = parse_fields(trimmed)
            if validate_row_columns("suites", fields, 3, line_num, stats):
                suites.push(SuiteRecord(
                    suite_id: safe_to_int(fields[0], 0),
                    file_id: safe_to_int(fields[1], 0),
                    name_str: safe_to_int(fields[2], 0)
                ))

        elif current_table == "tests":
            val fields = parse_fields(trimmed)
            if validate_row_columns("tests", fields, 11, line_num, stats):
                tests.push(TestRecord(
                    suite_id: safe_to_int(fields[1], 0),
                    name_str: safe_to_int(fields[2], 0),
                    category_str: safe_to_int(fields[3], 0),
                    status_str: safe_to_int(fields[4], 0),
                    tags_str: fields[5],
                    description_str: fields[6],
                    valid: fields[7] != "false",
                    qualified_by: fields[8],
                    qualified_at: fields[9],
                    qualified_reason: fields[10]
                ))

    ParsedStableDbRobust(
        interner: interner,
        files: files,
        suites: suites,
        tests: tests,
        stats: stats
    )

# =========================================================================
# Parse Volatile DB (test_db_runs.sdn) - Robust Version
# =========================================================================

fn parse_volatile_db_robust(content: text) -> ParsedVolatileDbRobust:
    var counters: List<CounterRecord> = []
    var timing: List<TimingSummary> = []
    var timing_runs: List<TimingRun> = []
    var changes: List<ChangeEvent> = []
    var test_runs: List<RunRecord> = []
    var stats = ParseStats.empty()

    var current_table = ""
    var line_num = 0

    val lines = content.split("\n")
    for line in lines:
        line_num = line_num + 1

        val table = detect_table(line)
        if table != "":
            current_table = table
            continue

        val trimmed = line.trim()
        if trimmed == "" or trimmed.starts_with("#"):
            continue

        stats.total_rows = stats.total_rows + 1
        val fields = parse_fields(trimmed)

        if current_table == "counters" and validate_row_columns("counters", fields, 6, line_num, stats):
            val last_10 = if fields.len() >= 7: fields[6] else: ""
            val fail_rate = if fields.len() >= 8: safe_to_float(fields[7], 0.0) else: 0.0
            counters.push(CounterRecord(
                test_id: safe_to_int(fields[0], 0),
                total_runs: safe_to_int(fields[1], 0),
                passed: safe_to_int(fields[2], 0),
                failed: safe_to_int(fields[3], 0),
                flaky_count: safe_to_int(fields[4], 0),
                last_change: fields[5],
                last_10_runs: last_10,
                failure_rate_pct: fail_rate
            ))

        elif current_table == "timing" and validate_row_columns("timing", fields, 6, line_num, stats):
            timing.push(TimingSummary(
                test_id: safe_to_int(fields[0], 0),
                last_ms: safe_to_float(fields[1], 0.0),
                p50: safe_to_float(fields[2], 0.0),
                p90: safe_to_float(fields[3], 0.0),
                p95: safe_to_float(fields[4], 0.0),
                baseline_median: safe_to_float(fields[5], 0.0),
                p99: if fields.len() >= 7: safe_to_float(fields[6], 0.0) else: 0.0,
                min_time: if fields.len() >= 8: safe_to_float(fields[7], 0.0) else: 0.0,
                max_time: if fields.len() >= 9: safe_to_float(fields[8], 0.0) else: 0.0,
                iqr: if fields.len() >= 10: safe_to_float(fields[9], 0.0) else: 0.0,
                mean: if fields.len() >= 11: safe_to_float(fields[10], 0.0) else: 0.0,
                std_dev: if fields.len() >= 12: safe_to_float(fields[11], 0.0) else: 0.0,
                cv_pct: if fields.len() >= 13: safe_to_float(fields[12], 0.0) else: 0.0,
                baseline_mean: if fields.len() >= 14: safe_to_float(fields[13], 0.0) else: 0.0,
                baseline_std_dev: if fields.len() >= 15: safe_to_float(fields[14], 0.0) else: 0.0,
                baseline_cv_pct: if fields.len() >= 16: safe_to_float(fields[15], 0.0) else: 0.0,
                baseline_last_updated: if fields.len() >= 17: fields[16] else: "",
                baseline_run_count: if fields.len() >= 18: safe_to_int(fields[17], 0) else: 0,
                baseline_update_reason: if fields.len() >= 19: fields[18] else: ""
            ))

        elif current_table == "timing_runs" and validate_row_columns("timing_runs", fields, 4, line_num, stats):
            timing_runs.push(TimingRun(
                test_id: safe_to_int(fields[0], 0),
                timestamp: fields[1],
                duration_ms: safe_to_float(fields[2], 0.0),
                outlier: fields[3] == "true"
            ))

        elif current_table == "changes" and validate_row_columns("changes", fields, 3, line_num, stats):
            changes.push(ChangeEvent(
                test_id: safe_to_int(fields[0], 0),
                change_type: fields[1],
                run_id: fields[2]
            ))

        elif current_table == "test_runs" and validate_row_columns("test_runs", fields, 11, line_num, stats):
            test_runs.push(RunRecord(
                run_id: fields[0],
                start_time: fields[1],
                end_time: fields[2],
                pid: safe_to_int(fields[3], 0),
                hostname: fields[4],
                status: fields[5],
                test_count: safe_to_int(fields[6], 0),
                passed: safe_to_int(fields[7], 0),
                failed: safe_to_int(fields[8], 0),
                crashed: safe_to_int(fields[9], 0),
                timed_out: safe_to_int(fields[10], 0)
            ))

    ParsedVolatileDbRobust(
        counters: counters,
        timing: timing,
        timing_runs: timing_runs,
        changes: changes,
        test_runs: test_runs,
        stats: stats
    )

# =========================================================================
# Exports
# =========================================================================

export parse_stable_db_robust, parse_volatile_db_robust
export ParsedStableDbRobust, ParsedVolatileDbRobust
export ParseStats
