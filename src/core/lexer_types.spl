# Core Simple â€” Lexer Types (struct-based)
#
# Struct-based types for the lexer: Span, Token, Lexer.
# Used by core lexer and extended by compiler lexer.
#
# Compiled by seed (Core Simple subset).

use core.tokens.{tok_kind_name}

export span_new, span_empty, span_merge, span_len
export token_new, token_eof, token_error
export token_is_keyword, token_is_operator, token_is_literal

# ===== Span â€” source location range =====
struct Span:
    start: i64    # Byte offset (inclusive)
    end_pos: i64  # Byte offset (exclusive) - named end_pos to avoid C++ keyword
    line: i64     # 1-based line number
    col: i64      # 1-based column number

fn span_new(start: i64, end_pos: i64, line: i64, col: i64) -> Span:
    return Span(start: start, end_pos: end_pos, line: line, col: col)

fn span_empty() -> Span:
    return Span(start: 0, end_pos: 0, line: 0, col: 0)

fn span_merge(a: Span, b: Span) -> Span:
    var s = a.start
    if b.start < s: s = b.start
    var e = a.end_pos
    if b.end_pos > e: e = b.end_pos
    return Span(start: s, end_pos: e, line: a.line, col: a.col)

fn span_len(s: Span) -> i64:
    return s.end_pos - s.start

# ===== Token â€” lexed token with kind + span + text =====
struct Token:
    kind: i64     # TokenKind (integer constant from tokens.spl)
    span: Span
    text: text    # Literal text of the token

fn token_new(kind: i64, text: text, line: i64, col: i64) -> Token:
    val s = Span(start: 0, end_pos: 0, line: line, col: col)
    return Token(kind: kind, span: s, text: text)

fn token_eof(line: i64) -> Token:
    return token_new(190, "", line, 0)

fn token_error(msg: text, line: i64, col: i64) -> Token:
    return token_new(191, msg, line, col)

fn token_is_keyword(t: Token) -> bool:
    return t.kind >= 20 and t.kind <= 59

fn token_is_operator(t: Token) -> bool:
    return t.kind >= 60 and t.kind <= 139

fn token_is_literal(t: Token) -> bool:
    return t.kind >= 1 and t.kind <= 6
