# Fail-Safe Rate Limiter
# Token bucket rate limiting with per-client and global limits
# Prevents DoS attacks and ensures fair resource usage

use core.*
use std.failsafe.core.*

# ============================================================================
# RATE LIMIT CONFIGURATION
# ============================================================================

# Rate limit configuration
pub class RateLimitConfig:
    pub requests_per_second: f64
    pub burst_size: i64
    pub client_limit: Option<f64>      # Per-client requests/sec
    pub client_burst: Option<i64>
    pub penalty_duration_ms: i64       # Penalty for exceeding limits

    static fn default() -> RateLimitConfig:
        return RateLimitConfig(
            requests_per_second: 100.0,
            burst_size: 50,
            client_limit: Some(10.0),
            client_burst: Some(20),
            penalty_duration_ms: 1000
        )

    static fn strict() -> RateLimitConfig:
        return RateLimitConfig(
            requests_per_second: 50.0,
            burst_size: 20,
            client_limit: Some(5.0),
            client_burst: Some(10),
            penalty_duration_ms: 5000
        )

    static fn permissive() -> RateLimitConfig:
        return RateLimitConfig(
            requests_per_second: 1000.0,
            burst_size: 500,
            client_limit: nil,
            client_burst: nil,
            penalty_duration_ms: 100
        )

# ============================================================================
# TOKEN BUCKET
# ============================================================================

# Token bucket algorithm implementation
pub class TokenBucket:
    pub capacity: f64          # Maximum tokens
    pub tokens: f64            # Current tokens
    pub refill_rate: f64       # Tokens per second
    pub last_refill: i64       # Last refill timestamp

    static fn new(capacity: f64, refill_rate: f64) -> TokenBucket:
        return TokenBucket(
            capacity: capacity,
            tokens: capacity,
            refill_rate: refill_rate,
            last_refill: current_time_ms()
        )

    # Refill tokens based on elapsed time
    me refill():
        val now = current_time_ms()
        val elapsed_sec = (now - self.last_refill) as f64 / 1000.0
        val new_tokens = elapsed_sec * self.refill_rate

        self.tokens = min_f64(self.capacity, self.tokens + new_tokens)
        self.last_refill = now

    # Try to consume tokens, returns true if successful
    pub me try_consume(count: f64) -> bool:
        self.refill()

        if self.tokens >= count:
            self.tokens = self.tokens - count
            return true
        return false

    # Check if tokens available without consuming
    pub fn available() -> f64:
        self.refill()
        return self.tokens

    # Time until tokens are available (in ms)
    pub fn wait_time(count: f64) -> i64:
        self.refill()

        if self.tokens >= count:
            return 0

        val needed = count - self.tokens
        val wait_sec = needed / self.refill_rate
        return (wait_sec * 1000.0) as i64

    # Reset bucket to full
    pub me reset():
        self.tokens = self.capacity
        self.last_refill = current_time_ms()

# ============================================================================
# RATE LIMITER
# ============================================================================

# Rate limit decision
pub enum RateLimitDecision:
    Allow
    Deny(i64)       # Deny with retry-after in ms
    Penalize(i64)   # Allowed but with penalty warning

    pub fn is_allowed() -> bool:
        match self:
            case Allow: true
            case Penalize(_): true
            case Deny(_): false

    pub fn retry_after_ms() -> Option<i64>:
        match self:
            case Allow: nil
            case Deny(ms): Some(ms)
            case Penalize(_): nil

# Rate limiter
pub class RateLimiter:
    pub config: RateLimitConfig
    pub global_bucket: TokenBucket
    pub client_buckets: Dict<text, TokenBucket>
    pub penalties: Dict<text, i64>      # client_id -> penalty_expires_at
    pub stats: RateLimitStats
    pub enabled: bool

    static fn new(config: RateLimitConfig) -> RateLimiter:
        val global_bucket = TokenBucket.new(
            config.burst_size as f64,
            config.requests_per_second
        )

        return RateLimiter(
            config: config,
            global_bucket: global_bucket,
            client_buckets: {},
            penalties: {},
            stats: RateLimitStats.new(),
            enabled: true
        )

    static fn default() -> RateLimiter:
        return RateLimiter.new(RateLimitConfig.default())

    # Check if request should be allowed
    pub me check(client_id: text) -> RateLimitDecision:
        if not self.enabled:
            return RateLimitDecision.Allow

        # Check if client is penalized
        match self.penalties.get(client_id):
            case Some(expires_at):
                val now = current_time_ms()
                if now < expires_at:
                    self.stats.record_denied()
                    return RateLimitDecision.Deny(expires_at - now)
                else:
                    # Penalty expired
                    self.penalties.remove(client_id)
            case nil:
                pass

        # Check global limit
        if not self.global_bucket.try_consume(1.0):
            val wait = self.global_bucket.wait_time(1.0)
            self.stats.record_denied()
            return RateLimitDecision.Deny(wait)

        # Check per-client limit if configured
        match self.config.client_limit:
            case Some(client_rate):
                val bucket = self.get_or_create_client_bucket(client_id, client_rate)
                if not bucket.try_consume(1.0):
                    val wait = bucket.wait_time(1.0)
                    self.stats.record_denied()
                    # Apply penalty for client
                    self.apply_penalty(client_id)
                    return RateLimitDecision.Deny(wait)
            case nil:
                pass

        self.stats.record_allowed()
        return RateLimitDecision.Allow

    # Get or create client bucket
    fn get_or_create_client_bucket(client_id: text, rate: f64) -> TokenBucket:
        match self.client_buckets.get(client_id):
            case Some(bucket):
                return bucket
            case nil:
                val burst = self.config.client_burst.unwrap_or(self.config.burst_size)
                val bucket = TokenBucket.new(burst as f64, rate)
                self.client_buckets.set(client_id, bucket)
                return bucket

    # Apply penalty to client
    me apply_penalty(client_id: text):
        val expires_at = current_time_ms() + self.config.penalty_duration_ms
        self.penalties.set(client_id, expires_at)
        self.stats.penalties_applied = self.stats.penalties_applied + 1

    # Remove client penalty
    pub me remove_penalty(client_id: text):
        self.penalties.remove(client_id)

    # Clear all client state (useful for testing)
    pub me reset():
        self.global_bucket.reset()
        self.client_buckets = {}
        self.penalties = {}
        self.stats = RateLimitStats.new()

    # Cleanup expired client buckets and penalties
    pub me cleanup():
        val now = current_time_ms()

        # Remove expired penalties
        var expired_penalties: List<text> = []
        for client_id in self.penalties.keys():
            match self.penalties.get(client_id):
                case Some(expires_at):
                    if now >= expires_at:
                        expired_penalties.append(client_id)
                case nil:
                    pass

        for client_id in expired_penalties:
            self.penalties.remove(client_id)

    # Disable rate limiting
    pub me disable():
        self.enabled = false

    # Enable rate limiting
    pub me enable():
        self.enabled = true

    # Get current stats
    pub fn get_stats() -> RateLimitStats:
        return self.stats

# Rate limit statistics
pub class RateLimitStats:
    pub allowed_requests: i64
    pub denied_requests: i64
    pub penalties_applied: i64
    pub started_at: i64

    static fn new() -> RateLimitStats:
        return RateLimitStats(
            allowed_requests: 0,
            denied_requests: 0,
            penalties_applied: 0,
            started_at: current_time_ms()
        )

    me record_allowed():
        self.allowed_requests = self.allowed_requests + 1

    me record_denied():
        self.denied_requests = self.denied_requests + 1

    pub fn total_requests() -> i64:
        return self.allowed_requests + self.denied_requests

    pub fn denial_rate() -> f64:
        val total = self.total_requests()
        if total == 0:
            return 0.0
        return self.denied_requests as f64 / total as f64

    pub fn requests_per_second() -> f64:
        val elapsed_sec = (current_time_ms() - self.started_at) as f64 / 1000.0
        if elapsed_sec <= 0.0:
            return 0.0
        return self.total_requests() as f64 / elapsed_sec

# ============================================================================
# RATE LIMIT MIDDLEWARE
# ============================================================================

# Rate limit result with error handling
pub fn rate_limit_check(limiter: RateLimiter, client_id: text) -> FailSafeResult<()>:
    match limiter.check(client_id):
        case RateLimitDecision.Allow:
            return FailSafeResult.Ok(())

        case RateLimitDecision.Deny(retry_after):
            return FailSafeResult.Err(
                FailSafeError.new(ErrorCategory.TooManyRequests, "Rate limit exceeded")
                    .with_retry(retry_after)
                    .with_detail("client_id", client_id)
            )

        case RateLimitDecision.Penalize(warning):
            # Allow but log warning
            return FailSafeResult.Ok(())

# Wrapper that rate limits an operation
pub fn with_rate_limit<T>(
    limiter: RateLimiter,
    client_id: text,
    operation: fn() -> FailSafeResult<T>
) -> FailSafeResult<T>:
    match rate_limit_check(limiter, client_id):
        case FailSafeResult.Ok(_):
            return operation()
        case FailSafeResult.Err(e):
            return FailSafeResult.Err(e)

# ============================================================================
# SLIDING WINDOW RATE LIMITER
# ============================================================================

# Sliding window entry
pub class WindowEntry:
    pub timestamp: i64
    pub count: i64

# Sliding window rate limiter for more accurate rate limiting
pub class SlidingWindowLimiter:
    pub window_size_ms: i64
    pub max_requests: i64
    pub entries: Dict<text, List<WindowEntry>>  # client_id -> entries

    static fn new(window_size_ms: i64, max_requests: i64) -> SlidingWindowLimiter:
        return SlidingWindowLimiter(
            window_size_ms: window_size_ms,
            max_requests: max_requests,
            entries: {}
        )

    # Check if request should be allowed
    pub me check(client_id: text) -> bool:
        val now = current_time_ms()
        val window_start = now - self.window_size_ms

        # Get or create entry list
        var client_entries = match self.entries.get(client_id):
            case Some(e): e
            case nil: []

        # Remove old entries outside window
        var valid_entries: List<WindowEntry> = []
        var total_count: i64 = 0

        for entry in client_entries:
            if entry.timestamp >= window_start:
                valid_entries.append(entry)
                total_count = total_count + entry.count

        # Check if under limit
        if total_count >= self.max_requests:
            self.entries.set(client_id, valid_entries)
            return false

        # Add new entry
        valid_entries.append(WindowEntry(timestamp: now, count: 1))
        self.entries.set(client_id, valid_entries)
        return true

    # Get current count for client
    pub fn get_count(client_id: text) -> i64:
        val now = current_time_ms()
        val window_start = now - self.window_size_ms

        match self.entries.get(client_id):
            case Some(entries):
                var count: i64 = 0
                for entry in entries:
                    if entry.timestamp >= window_start:
                        count = count + entry.count
                return count
            case nil:
                return 0

# ============================================================================
# ADAPTIVE RATE LIMITER
# ============================================================================

# Adaptive rate limiter that adjusts based on system load
pub class AdaptiveRateLimiter:
    pub base_limiter: RateLimiter
    pub load_threshold: f64
    pub scale_factor: f64
    pub min_rate: f64
    pub current_load: f64

    static fn new(config: RateLimitConfig) -> AdaptiveRateLimiter:
        return AdaptiveRateLimiter(
            base_limiter: RateLimiter.new(config),
            load_threshold: 0.8,
            scale_factor: 0.5,
            min_rate: 10.0,
            current_load: 0.0
        )

    # Update current system load (0.0 - 1.0)
    pub me update_load(load: f64):
        self.current_load = load

        # Adjust rate based on load
        if load > self.load_threshold:
            val reduction = (load - self.load_threshold) * self.scale_factor
            val new_rate = max_f64(
                self.min_rate,
                self.base_limiter.config.requests_per_second * (1.0 - reduction)
            )
            self.base_limiter.global_bucket.refill_rate = new_rate

    # Check if request should be allowed
    pub me check(client_id: text) -> RateLimitDecision:
        return self.base_limiter.check(client_id)

# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

fn current_time_ms() -> i64:
    return time_now_ms()

fn min_f64(a: f64, b: f64) -> f64:
    if a < b: a else: b

fn max_f64(a: f64, b: f64) -> f64:
    if a > b: a else: b

extern fn time_now_ms() -> i64
