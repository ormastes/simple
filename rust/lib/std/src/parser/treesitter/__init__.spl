# Tree-sitter Lexer Module for Simple Language
# Provides Lexer, Token, TokenKind, Span

mod treesitter
mod edits

pub struct Span:
    start_byte: i64
    end_byte: i64
    start_line: i64
    end_line: i64
    start_column: i64
    end_column: i64

pub enum TokenKind:
    # Keywords
    Fn
    Val
    Var
    Let
    If
    Else
    Elif
    While
    For
    Return
    Match
    Case
    Struct
    Class
    Enum
    Trait
    Impl
    Pub
    Import
    Use
    Mod
    True
    False
    Nil
    In
    Not
    And
    Or
    Pass
    Break
    Continue
    # Literals
    Integer
    Float
    StringLit
    Identifier
    # Operators
    Plus
    Minus
    Star
    Slash
    Percent
    Eq
    NotEq
    Lt
    Gt
    LtEq
    GtEq
    Assign
    Arrow
    FatArrow
    Dot
    DoubleDot
    # Delimiters
    LParen
    RParen
    LBrace
    RBrace
    LBracket
    RBracket
    Colon
    Comma
    Semicolon
    Hash
    At
    Backslash
    # Special
    Newline
    Indent
    Dedent
    Eof
    Unknown

pub struct Token:
    kind: TokenKind
    text: text
    span: Span

pub struct Lexer:
    source: text
    pos: i64
    line: i64
    column: i64
    tokens: Vec<Token>

impl Lexer:
    pub static fn new(source: text) -> Lexer:
        return Lexer(source: source, pos: 0, line: 1, column: 1, tokens: [])

    pub me tokenize() -> Result<Vec<Token>, text>:
        while self.pos < self.source.len():
            self.skip_whitespace_except_newline()
            if self.pos >= self.source.len():
                break
            val start_pos = self.pos
            val start_line = self.line
            val start_col = self.column
            val ch = self.source[self.pos]

            var kind = TokenKind.Unknown
            var matched = false

            # Newline
            if ch == '\n':
                kind = TokenKind.Newline
                self.pos = self.pos + 1
                self.line = self.line + 1
                self.column = 1
                matched = true
            # Comment - skip to end of line
            elif ch == '#':
                while self.pos < self.source.len() and self.source[self.pos] != '\n':
                    self.pos = self.pos + 1
                    self.column = self.column + 1
                matched = true
                kind = TokenKind.Hash
            # String literals
            elif ch == '"':
                self.pos = self.pos + 1
                self.column = self.column + 1
                while self.pos < self.source.len() and self.source[self.pos] != '"':
                    if self.source[self.pos] == '\\':
                        self.pos = self.pos + 1
                        self.column = self.column + 1
                    self.pos = self.pos + 1
                    self.column = self.column + 1
                if self.pos < self.source.len():
                    self.pos = self.pos + 1
                    self.column = self.column + 1
                kind = TokenKind.StringLit
                matched = true
            # Numbers
            elif ch >= '0' and ch <= '9':
                var is_float = false
                while self.pos < self.source.len() and self.source[self.pos] >= '0' and self.source[self.pos] <= '9':
                    self.pos = self.pos + 1
                    self.column = self.column + 1
                if self.pos < self.source.len() and self.source[self.pos] == '.':
                    is_float = true
                    self.pos = self.pos + 1
                    self.column = self.column + 1
                    while self.pos < self.source.len() and self.source[self.pos] >= '0' and self.source[self.pos] <= '9':
                        self.pos = self.pos + 1
                        self.column = self.column + 1
                kind = if is_float { TokenKind.Float } else { TokenKind.Integer }
                matched = true
            # Identifiers and keywords
            elif (ch >= 'a' and ch <= 'z') or (ch >= 'A' and ch <= 'Z') or ch == '_':
                while self.pos < self.source.len():
                    val c = self.source[self.pos]
                    if (c >= 'a' and c <= 'z') or (c >= 'A' and c <= 'Z') or (c >= '0' and c <= '9') or c == '_':
                        self.pos = self.pos + 1
                        self.column = self.column + 1
                    else:
                        break
                val word = self.source[start_pos:self.pos]
                kind = self.keyword_or_ident(word)
                matched = true
            # Two-char operators
            elif self.pos + 1 < self.source.len():
                val two = self.source[self.pos:self.pos + 2]
                if two == "==":
                    kind = TokenKind.Eq
                    self.pos = self.pos + 2
                    self.column = self.column + 2
                    matched = true
                elif two == "!=":
                    kind = TokenKind.NotEq
                    self.pos = self.pos + 2
                    self.column = self.column + 2
                    matched = true
                elif two == "<=":
                    kind = TokenKind.LtEq
                    self.pos = self.pos + 2
                    self.column = self.column + 2
                    matched = true
                elif two == ">=":
                    kind = TokenKind.GtEq
                    self.pos = self.pos + 2
                    self.column = self.column + 2
                    matched = true
                elif two == "->":
                    kind = TokenKind.Arrow
                    self.pos = self.pos + 2
                    self.column = self.column + 2
                    matched = true
                elif two == "=>":
                    kind = TokenKind.FatArrow
                    self.pos = self.pos + 2
                    self.column = self.column + 2
                    matched = true
                elif two == "..":
                    kind = TokenKind.DoubleDot
                    self.pos = self.pos + 2
                    self.column = self.column + 2
                    matched = true

            if not matched:
                # Single char operators/delimiters
                match ch:
                    case '+': kind = TokenKind.Plus
                    case '-': kind = TokenKind.Minus
                    case '*': kind = TokenKind.Star
                    case '/': kind = TokenKind.Slash
                    case '%': kind = TokenKind.Percent
                    case '<': kind = TokenKind.Lt
                    case '>': kind = TokenKind.Gt
                    case '=': kind = TokenKind.Assign
                    case '(': kind = TokenKind.LParen
                    case ')': kind = TokenKind.RParen
                    case '{': kind = TokenKind.LBrace
                    case '}': kind = TokenKind.RBrace
                    case '[': kind = TokenKind.LBracket
                    case ']': kind = TokenKind.RBracket
                    case ':': kind = TokenKind.Colon
                    case ',': kind = TokenKind.Comma
                    case ';': kind = TokenKind.Semicolon
                    case '.': kind = TokenKind.Dot
                    case '@': kind = TokenKind.At
                    case '\\': kind = TokenKind.Backslash
                    case _: kind = TokenKind.Unknown
                self.pos = self.pos + 1
                self.column = self.column + 1

            val token_text = self.source[start_pos:self.pos]
            val span = Span(
                start_byte: start_pos,
                end_byte: self.pos,
                start_line: start_line,
                end_line: self.line,
                start_column: start_col,
                end_column: self.column,
            )
            self.tokens.push(Token(kind: kind, text: token_text, span: span))

        # Add EOF
        val eof_span = Span(
            start_byte: self.pos,
            end_byte: self.pos,
            start_line: self.line,
            end_line: self.line,
            start_column: self.column,
            end_column: self.column,
        )
        self.tokens.push(Token(kind: TokenKind.Eof, text: "", span: eof_span))
        return Ok(self.tokens)

    fn keyword_or_ident(self, word: text) -> TokenKind:
        match word:
            case "fn": TokenKind.Fn
            case "val": TokenKind.Val
            case "var": TokenKind.Var
            case "let": TokenKind.Let
            case "if": TokenKind.If
            case "else": TokenKind.Else
            case "elif": TokenKind.Elif
            case "while": TokenKind.While
            case "for": TokenKind.For
            case "return": TokenKind.Return
            case "match": TokenKind.Match
            case "case": TokenKind.Case
            case "struct": TokenKind.Struct
            case "class": TokenKind.Class
            case "enum": TokenKind.Enum
            case "trait": TokenKind.Trait
            case "impl": TokenKind.Impl
            case "pub": TokenKind.Pub
            case "import": TokenKind.Import
            case "use": TokenKind.Use
            case "mod": TokenKind.Mod
            case "true": TokenKind.True
            case "false": TokenKind.False
            case "nil": TokenKind.Nil
            case "in": TokenKind.In
            case "not": TokenKind.Not
            case "and": TokenKind.And
            case "or": TokenKind.Or
            case "pass": TokenKind.Pass
            case "break": TokenKind.Break
            case "continue": TokenKind.Continue
            case _: TokenKind.Identifier

    me skip_whitespace_except_newline():
        while self.pos < self.source.len():
            val ch = self.source[self.pos]
            if ch == ' ' or ch == '\t' or ch == '\r':
                self.pos = self.pos + 1
                self.column = self.column + 1
            else:
                break

# Tree node
pub struct Node:
    kind_: text
    text_: text
    span_: Span

impl Node:
    pub fn kind(self) -> text:
        return self.kind_

# Parse tree
pub struct Tree:
    root_node: Node
    source: text

impl Tree:
    pub fn root(self) -> Option<Node>:
        return Some(self.root_node)

# Tree-sitter parser
pub struct TreeSitterParser:
    language: text

impl TreeSitterParser:
    pub static fn new(language: text) -> Result<TreeSitterParser, text>:
        return Ok(TreeSitterParser(language: language))

    pub me parse(self, source: text) -> Result<Tree, text>:
        val root = Node(
            kind_: "source_file",
            text_: source,
            span_: Span(start_byte: 0, end_byte: source.len(), start_line: 1, end_line: 1, start_column: 1, end_column: source.len() + 1),
        )
        return Ok(Tree(root_node: root, source: source))

export edits
