# Grammar rules for Simple language
# Minimal subset for Phase 1: functions, expressions, basic statements

use core.{Option, Result}
use tree.{Span}

# Token kinds (simplified subset from src/parser/src/token.rs)
enum TokenKind:
    # Keywords
    Fn
    Let
    Mut
    Return
    If
    Else
    Elif
    Struct
    Class
    Enum
    Trait
    Impl
    Match
    Case
    For
    While
    Loop
    Break
    Continue
    # Additional keywords for error recovery
    Union
    Mixin
    Actor
    Type
    Unit
    Mod
    Val
    Var
    Const
    Static

    # Literals
    Integer(i64)
    f32(f64)
    text(str)
    bool(bool)
    Nil

    # Identifiers
    Identifier(str)
    TypeIdentifier(str)

    # Operators
    Plus
    Minus
    Star
    Slash
    Percent
    Eq
    NotEq
    Lt
    Gt
    LtEq
    GtEq
    And
    Or
    Not
    Assign
    Arrow
    ChannelArrow

    # Delimiters
    LParen
    RParen
    LBrace
    RBrace
    LBracket
    RBracket
    Comma
    Colon
    Semicolon
    Dot

    # Special (indentation-based blocks)
    Indent
    Dedent
    Newline

    # Meta
    Eof
    Error(str)

impl TokenKind:
    # =========================================================================
    # Helper Methods
    # =========================================================================

    fn is_keyword() -> bool:
        """Check if this is a keyword token."""
        match self:
            case Fn | Let | Mut | Return | If | Else | Elif: true
            case Struct | Class | Enum | Trait | Impl: true
            case Match | Case | For | While | Loop | Break | Continue: true
            case Union | Mixin | Actor | Type | Unit | Mod: true
            case Val | Var | Const | Static: true
            case _: false

    fn is_literal() -> bool:
        """Check if this is a literal value."""
        match self:
            case Integer(_) | f32(_) | text(_) | bool(_) | Nil: true
            case _: false

    fn is_identifier() -> bool:
        """Check if this is an identifier."""
        match self:
            case Identifier(_) | TypeIdentifier(_): true
            case _: false

    fn is_operator() -> bool:
        """Check if this is an operator."""
        match self:
            case Plus | Minus | Star | Slash | Percent: true
            case Eq | NotEq | Lt | Gt | LtEq | GtEq: true
            case And | Or | Not | Assign | Arrow | ChannelArrow: true
            case _: false

    fn is_delimiter() -> bool:
        """Check if this is a delimiter."""
        match self:
            case LParen | RParen | LBrace | RBrace | LBracket | RBracket: true
            case Comma | Colon | Semicolon | Dot: true
            case _: false

    fn is_special() -> bool:
        """Check if this is special whitespace token."""
        match self:
            case Indent | Dedent | Newline: true
            case _: false

    fn to_string() -> text:
        """Convert token kind to string."""
        match self:
            case Fn: "fn"
            case Let: "val"
            case Integer(n): n.to_string()
            case Identifier(s): s
            case Plus: "+"
            case Eof: "EOF"
            case _: "token"

    fn summary() -> text:
        """Get summary of token kind."""
        val category = if self.is_keyword():
            "keyword"
        else:
            if self.is_literal():
                "literal"
            else:
                if self.is_identifier():
                    "identifier"
                else:
                    if self.is_operator():
                        "operator"
                    else:
                        if self.is_delimiter():
                            "delimiter"
                        else:
                            "special"
        return "TokenKind: {category}"

struct Token:
    kind: TokenKind
    text: str
    span: Span

# Grammar rule representation (PEG-style)
enum GrammarRule:
    # Terminals
    TokenRule(TokenKind)          # Match specific token

    # Combinators
    Seq([GrammarRule])            # Sequence: A B C
    Choice([GrammarRule])         # Ordered choice: A / B / C
    Optional(GrammarRule)         # Zero or one: Option<A>
    ZeroOrMore(GrammarRule)       # Repetition: A*
    OneOrMore(GrammarRule)        # Non-empty: A+

    # Named rules (for CST nodes)
    Named(str, GrammarRule)       # Create node with name
    Field(str, GrammarRule)       # Named field for node

    # Rule reference (for recursive grammars)
    RuleRef(str)                  # Reference to named rule in grammar

impl GrammarRule:
    # =========================================================================
    # Helper Methods
    # =========================================================================

    fn is_terminal() -> bool:
        """Check if this is a terminal rule (TokenRule)."""
        match self:
            case TokenRule(_): true
            case _: false

    fn is_combinator() -> bool:
        """Check if this is a combinator rule."""
        match self:
            case Seq(_) | Choice(_) | Optional(_): true
            case ZeroOrMore(_) | OneOrMore(_): true
            case _: false

    fn is_repetition() -> bool:
        """Check if this is a repetition rule (*/+)."""
        match self:
            case ZeroOrMore(_) | OneOrMore(_): true
            case _: false

    fn is_named() -> bool:
        """Check if this rule creates a named node."""
        match self:
            case Named(_, _) | Field(_, _): true
            case _: false

    fn is_sequence() -> bool:
        """Check if this is a sequence rule."""
        match self:
            case Seq(_): true
            case _: false

    fn is_choice() -> bool:
        """Check if this is a choice rule."""
        match self:
            case Choice(_): true
            case _: false

    fn is_optional() -> bool:
        """Check if this is an optional rule."""
        match self:
            case Optional(_): true
            case _: false

    fn has_children() -> bool:
        """Check if rule contains sub-rules."""
        match self:
            case TokenRule(_): false
            case RuleRef(_): false  # RuleRef is a reference, not containing sub-rules directly
            case _: true

    fn to_string() -> text:
        """Convert rule to string."""
        match self:
            case TokenRule(_): "token_rule"
            case Seq(_): "sequence"
            case Choice(_): "choice"
            case Optional(_): "optional"
            case ZeroOrMore(_): "zero_or_more"
            case OneOrMore(_): "one_or_more"
            case Named(_, _): "named"
            case Field(_, _): "field"
            case RuleRef(name): "rule_ref({name})"

    fn summary() -> text:
        """Get summary of grammar rule."""
        val name = self.to_string()
        var kind = "combinator"
        if self.is_terminal():
            kind = "terminal"
        elif self.is_repetition():
            kind = "repetition"
        elif self.is_named():
            kind = "named"
        return "GrammarRule: {name} ({kind})"

# Grammar definition
struct Grammar:
    rules: {str: GrammarRule}
    entry_point: str

# Build Simple language grammar (minimal subset)
# Uses RuleRef for recursive rules to avoid infinite recursion
fn build_simple_grammar() -> Grammar:
    return Grammar(
        entry_point: "module",
        rules: {
            # Entry point - uses RuleRef for statement
            "module": GrammarRule.ZeroOrMore(
                GrammarRule.RuleRef("statement")
            ),

            # Statements - uses RuleRef to break cycles
            "statement": GrammarRule.Choice([
                GrammarRule.Named("function_def", GrammarRule.RuleRef("function_def")),
                GrammarRule.Named("let_stmt", GrammarRule.RuleRef("let_stmt")),
                GrammarRule.Named("return_stmt", GrammarRule.RuleRef("return_stmt")),
                GrammarRule.Named("expression_stmt", GrammarRule.RuleRef("expression")),
            ]),

            "function_def": function_def_rule_safe(),
            "let_stmt": let_stmt_rule_safe(),
            "return_stmt": return_stmt_rule_safe(),
            "expression_stmt": GrammarRule.RuleRef("expression"),

            # Block - uses RuleRef for statement
            "block": GrammarRule.Named("block", GrammarRule.Seq([
                GrammarRule.TokenRule(TokenKind.Newline),
                GrammarRule.TokenRule(TokenKind.Indent),
                GrammarRule.OneOrMore(GrammarRule.RuleRef("statement")),
                GrammarRule.TokenRule(TokenKind.Dedent)
            ])),

            # Expressions - uses RuleRef to break cycles
            "expression": GrammarRule.RuleRef("binary_expr"),
            "binary_expr": binary_expr_rule_safe(),
            "unary_expr": unary_expr_rule_safe(),
            "primary_expr": primary_expr_rule(),

            # Types
            "type_expr": type_expr_rule(),
        }
    )

# Old versions kept for reference but not used (cause infinite recursion)
fn statement_rule() -> GrammarRule:
    return GrammarRule.RuleRef("statement")

# Safe version that uses RuleRef for block
fn function_def_rule_safe() -> GrammarRule:
    # fn name(params) -> return_type: body
    return GrammarRule.Seq([
        GrammarRule.TokenRule(TokenKind.Fn),
        GrammarRule.Field("name",
            GrammarRule.Named("identifier", identifier_rule())),
        GrammarRule.TokenRule(TokenKind.LParen),
        GrammarRule.Field("params",
            GrammarRule.Optional(parameter_list_rule_safe())),
        GrammarRule.TokenRule(TokenKind.RParen),
        GrammarRule.Optional(GrammarRule.Seq([
            GrammarRule.TokenRule(TokenKind.Arrow),
            GrammarRule.Field("return_type", type_expr_rule())
        ])),
        GrammarRule.TokenRule(TokenKind.Colon),
        GrammarRule.Field("body", GrammarRule.RuleRef("block"))
    ])

fn function_def_rule() -> GrammarRule:
    return function_def_rule_safe()

fn parameter_list_rule_safe() -> GrammarRule:
    return GrammarRule.Seq([
        parameter_rule(),
        GrammarRule.ZeroOrMore(GrammarRule.Seq([
            GrammarRule.TokenRule(TokenKind.Comma),
            parameter_rule()
        ]))
    ])

fn parameter_list_rule() -> GrammarRule:
    return parameter_list_rule_safe()

fn parameter_rule() -> GrammarRule:
    # name: type
    return GrammarRule.Named("parameter", GrammarRule.Seq([
        GrammarRule.Field("name", identifier_rule()),
        GrammarRule.TokenRule(TokenKind.Colon),
        GrammarRule.Field("type", type_expr_rule())
    ]))

fn block_rule() -> GrammarRule:
    # Use RuleRef to avoid infinite recursion
    return GrammarRule.RuleRef("block")

fn let_stmt_rule_safe() -> GrammarRule:
    # val name: type = value - uses RuleRef for expression
    return GrammarRule.Seq([
        GrammarRule.TokenRule(TokenKind.Let),
        GrammarRule.Optional(GrammarRule.TokenRule(TokenKind.Mut)),
        GrammarRule.Field("name", identifier_rule()),
        GrammarRule.Optional(GrammarRule.Seq([
            GrammarRule.TokenRule(TokenKind.Colon),
            GrammarRule.Field("type", type_expr_rule())
        ])),
        GrammarRule.TokenRule(TokenKind.Assign),
        GrammarRule.Field("value", GrammarRule.RuleRef("expression"))
    ])

fn let_stmt_rule() -> GrammarRule:
    return let_stmt_rule_safe()

fn return_stmt_rule_safe() -> GrammarRule:
    return GrammarRule.Seq([
        GrammarRule.TokenRule(TokenKind.Return),
        GrammarRule.Optional(GrammarRule.Field("value", GrammarRule.RuleRef("expression")))
    ])

fn return_stmt_rule() -> GrammarRule:
    return return_stmt_rule_safe()

fn expression_stmt_rule() -> GrammarRule:
    return GrammarRule.RuleRef("expression")

fn expression_rule() -> GrammarRule:
    # For Phase 1: simple precedence (just binary expressions)
    return GrammarRule.RuleRef("binary_expr")

fn binary_expr_rule_safe() -> GrammarRule:
    # Simplified: unary (op unary)* - uses RuleRef for unary
    return GrammarRule.Named("binary_expr", GrammarRule.Seq([
        GrammarRule.RuleRef("unary_expr"),
        GrammarRule.ZeroOrMore(GrammarRule.Seq([
            GrammarRule.Field("op", binary_op_rule()),
            GrammarRule.RuleRef("unary_expr")
        ]))
    ]))

fn binary_expr_rule() -> GrammarRule:
    return binary_expr_rule_safe()

fn binary_op_rule() -> GrammarRule:
    return GrammarRule.Choice([
        GrammarRule.TokenRule(TokenKind.Plus),
        GrammarRule.TokenRule(TokenKind.Minus),
        GrammarRule.TokenRule(TokenKind.Star),
        GrammarRule.TokenRule(TokenKind.Slash),
        GrammarRule.TokenRule(TokenKind.Eq),
        GrammarRule.TokenRule(TokenKind.NotEq),
        GrammarRule.TokenRule(TokenKind.Lt),
        GrammarRule.TokenRule(TokenKind.Gt),
    ])

fn unary_expr_rule_safe() -> GrammarRule:
    # Prefix operators: -, not, <-, etc. OR primary expression
    # Uses RuleRef for recursion to avoid stack overflow
    return GrammarRule.Choice([
        GrammarRule.Named("unary_expr", GrammarRule.Seq([
            GrammarRule.Field("op", unary_op_rule()),
            GrammarRule.RuleRef("unary_expr")  # Use RuleRef for recursive call
        ])),
        GrammarRule.RuleRef("primary_expr")
    ])

fn unary_expr_rule() -> GrammarRule:
    return unary_expr_rule_safe()

fn unary_op_rule() -> GrammarRule:
    return GrammarRule.Choice([
        GrammarRule.TokenRule(TokenKind.Minus),
        GrammarRule.TokenRule(TokenKind.Not),
        GrammarRule.TokenRule(TokenKind.ChannelArrow),
    ])

fn primary_expr_rule() -> GrammarRule:
    return GrammarRule.Choice([
        integer_literal_rule(),
        identifier_rule(),
        paren_expr_rule(),
    ])

fn integer_literal_rule() -> GrammarRule:
    return GrammarRule.Named("integer",
        GrammarRule.TokenRule(TokenKind.Integer(0)))

fn identifier_rule() -> GrammarRule:
    return GrammarRule.TokenRule(TokenKind.Identifier(""))

fn paren_expr_rule() -> GrammarRule:
    return GrammarRule.Seq([
        GrammarRule.TokenRule(TokenKind.LParen),
        GrammarRule.RuleRef("expression"),
        GrammarRule.TokenRule(TokenKind.RParen)
    ])

fn type_expr_rule() -> GrammarRule:
    # For Phase 1: just identifiers
    return GrammarRule.Named("type_identifier",
        GrammarRule.TokenRule(TokenKind.TypeIdentifier("")))
