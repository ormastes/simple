# PyTorch-compatible tensor module
mod torch
mod device
mod dtype
mod tensor_ffi

use device.{Device}
use dtype.{DType}

export device
export dtype
export tensor_ffi

pub struct Tensor:
    data_: Vec<f64>
    shape_: Vec<i64>
    dtype_: DType
    device_: Device

impl Tensor:
    pub fn shape(self) -> Vec<i64>:
        return self.shape_

    pub fn ndim(self) -> i64:
        return self.shape_.len()

    pub fn numel(self) -> i64:
        var count = 1
        for d in self.shape_:
            count = count * d
        return count

    pub fn dtype(self) -> DType:
        return self.dtype_

    pub fn device(self) -> Device:
        return self.device_

    pub fn reshape(self, new_shape: Vec<i64>) -> Tensor:
        return Tensor(data_: self.data_, shape_: new_shape, dtype_: self.dtype_, device_: self.device_)

    pub fn flatten(self) -> Tensor:
        return Tensor(data_: self.data_, shape_: [self.numel()], dtype_: self.dtype_, device_: self.device_)

    pub fn t(self) -> Tensor:
        # Transpose 2D tensor
        if self.shape_.len() == 2:
            val new_shape = [self.shape_[1], self.shape_[0]]
            return Tensor(data_: self.data_, shape_: new_shape, dtype_: self.dtype_, device_: self.device_)
        return self

    pub fn __getitem__(self, index: i64) -> f64:
        var idx = index
        if idx < 0:
            idx = self.data_.len() + idx
        return self.data_[idx]

    pub fn __getslice__(self, start: i64, end: i64) -> Tensor:
        var s = start
        var e = end
        if s < 0:
            s = self.data_.len() + s
        if e < 0:
            e = self.data_.len() + e
        val sliced = self.data_[s:e]
        return Tensor(data_: sliced, shape_: [sliced.len()], dtype_: self.dtype_, device_: self.device_)

    pub fn __add__(self, other: Tensor) -> Tensor:
        var result = []
        for i in 0..self.data_.len():
            result.push(self.data_[i] + other.data_[i])
        return Tensor(data_: result, shape_: self.shape_, dtype_: self.dtype_, device_: self.device_)

    pub fn __mul__(self, other: Tensor) -> Tensor:
        var result = []
        for i in 0..self.data_.len():
            result.push(self.data_[i] * other.data_[i])
        return Tensor(data_: result, shape_: self.shape_, dtype_: self.dtype_, device_: self.device_)

    pub fn __matmul__(self, other: Tensor) -> Tensor:
        # Simple 2D matmul
        if self.shape_.len() == 2 and other.shape_.len() == 2:
            val m = self.shape_[0]
            val k = self.shape_[1]
            val n = other.shape_[1]
            var result = []
            for i in 0..m:
                for j in 0..n:
                    var sum = 0.0
                    for p in 0..k:
                        sum = sum + self.data_[i * k + p] * other.data_[p * n + j]
                    result.push(sum)
            return Tensor(data_: result, shape_: [m, n], dtype_: self.dtype_, device_: self.device_)
        return self

# Factory functions
pub fn tensor(data: Vec<f64>) -> Tensor:
    return Tensor(data_: data, shape_: [data.len()], dtype_: DType.Float32, device_: Device.CPU)

pub fn zeros(shape: Vec<i64>) -> Tensor:
    var count = 1
    for d in shape:
        count = count * d
    var data = []
    for i in 0..count:
        data.push(0.0)
    return Tensor(data_: data, shape_: shape, dtype_: DType.Float32, device_: Device.CPU)

pub fn ones(shape: Vec<i64>) -> Tensor:
    var count = 1
    for d in shape:
        count = count * d
    var data = []
    for i in 0..count:
        data.push(1.0)
    return Tensor(data_: data, shape_: shape, dtype_: DType.Float32, device_: Device.CPU)
