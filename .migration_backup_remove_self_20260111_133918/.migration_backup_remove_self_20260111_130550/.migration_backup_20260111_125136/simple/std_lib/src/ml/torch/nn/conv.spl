# Convolutional Layers
#
# Provides 2D and 3D convolutional layers for neural networks.
#
# ## Classes
# - `Conv2d`: 2D convolutional layer for images and 2D feature maps
# - `Conv3d`: 3D convolutional layer for video and 3D data
#
# ## Example
# ```simple
# import ml.torch as torch
# import ml.torch.nn as nn
#
# # 2D convolution for images
# let conv2d = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)
# let img = torch.randn([1, 3, 32, 32])  # [batch, channels, height, width]
# let features = conv2d(img)  # [1, 16, 32, 32]
#
# # 3D convolution for video
# let conv3d = nn.Conv3d(in_channels=3, out_channels=16, kernel_size=3, padding=1)
# let video = torch.randn([1, 3, 16, 32, 32])  # [batch, channels, depth, height, width]
# let features = conv3d(video)  # [1, 16, 16, 32, 32]
# ```

export Conv2d, Conv3d

import base.{Module}


# ============================================================================
# Conv2d Layer
# ============================================================================

class Conv2d(Module):
    """2D convolutional layer.

    Applies 2D convolution over input tensor.

    Example:
        ```simple
        # Input: [batch, 3, 32, 32] (RGB images)
        # Output: [batch, 16, 32, 32] (16 feature maps)
        let conv = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)
        let output = conv(input)
        ```
    """
    module_handle: u64
    in_channels: i32
    out_channels: i32
    kernel_size: i32

    fn __init__(in_channels: i32, out_channels: i32, kernel_size: i32, stride: i32 = 1, padding: i32 = 0):
        """Initialize 2D convolution layer.

        Args:
            in_channels: Number of input channels
            out_channels: Number of output channels (filters)
            kernel_size: Size of convolution kernel
            stride: Stride for convolution (default: 1)
            padding: Zero-padding added to both sides (default: 0)
        """
        super().__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.kernel_size = kernel_size

        # Create module via FFI
        self.module_handle = @rt_torch_conv2d_new(
            in_channels,
            out_channels,
            kernel_size,
            stride,
            padding
        )
        if self.module_handle == 0:
            panic("Failed to create Conv2d layer")

    fn __del__():
        """Free module resources."""
        if self.module_handle != 0:
            @rt_torch_module_free(self.module_handle)

    fn forward(x: Tensor) -> Tensor:
        """Apply 2D convolution.

        Args:
            x: Input tensor [batch, in_channels, height, width]

        Returns:
            Output tensor [batch, out_channels, out_height, out_width]
        """
        let handle = @rt_torch_conv2d_forward(self.module_handle, x.handle)
        if handle == 0:
            panic("Conv2d forward pass failed")
        return Tensor(handle)


# ============================================================================
# Conv3d Layer
# ============================================================================

class Conv3d(Module):
    """3D convolutional layer.

    Applies 3D convolution over input tensor (video, 3D medical imaging).

    Example:
        ```simple
        # Input: [batch, 3, depth, height, width] (video frames)
        # Output: [batch, 16, depth, height, width] (16 feature maps)
        let conv = nn.Conv3d(in_channels=3, out_channels=16, kernel_size=3, padding=1)
        let output = conv(input)
        ```
    """
    module_handle: u64
    in_channels: i32
    out_channels: i32
    kernel_size: i32

    fn __init__(in_channels: i32, out_channels: i32, kernel_size: i32, stride: i32 = 1, padding: i32 = 0):
        """Initialize 3D convolution layer.

        Args:
            in_channels: Number of input channels
            out_channels: Number of output channels (filters)
            kernel_size: Size of convolution kernel
            stride: Stride for convolution (default: 1)
            padding: Zero-padding added to both sides (default: 0)
        """
        super().__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.kernel_size = kernel_size

        # Create module via FFI
        self.module_handle = @rt_torch_conv3d_new(
            in_channels,
            out_channels,
            kernel_size,
            stride,
            padding
        )
        if self.module_handle == 0:
            panic("Failed to create Conv3d layer")

    fn __del__():
        """Free module resources."""
        if self.module_handle != 0:
            @rt_torch_module_free(self.module_handle)

    fn forward(x: Tensor) -> Tensor:
        """Apply 3D convolution.

        Args:
            x: Input tensor [batch, in_channels, depth, height, width]

        Returns:
            Output tensor [batch, out_channels, out_depth, out_height, out_width]
        """
        let handle = @rt_torch_conv3d_forward(self.module_handle, x.handle)
        if handle == 0:
            panic("Conv3d forward pass failed")
        return Tensor(handle)


# ============================================================================
# External FFI Functions
# ============================================================================

extern fn rt_torch_conv2d_new(in_ch: i32, out_ch: i32, kernel: i32, stride: i32, padding: i32) -> u64
extern fn rt_torch_conv2d_forward(module: u64, input: u64) -> u64

extern fn rt_torch_conv3d_new(in_ch: i32, out_ch: i32, kernel: i32, stride: i32, padding: i32) -> u64
extern fn rt_torch_conv3d_forward(module: u64, input: u64) -> u64

extern fn rt_torch_module_free(module: u64) -> i32
