"""
# Execution Context Types - User Enum Pattern Demo

Demonstrates Gpu<UserEnum, idx> pattern where:
- Custom types wrap primitives (no bare Int, Float allowed)
- User enum embeds custom types
- Implicit conversion from custom type → enum
- GpuIndex for device selection
- Type-safe device placement and transfers

**Pattern**: CustomType → UserEnum → Gpu<UserEnum, idx>
"""

# ============================================================================
# Step 1: Custom Types (Prevent Bare Primitives)
# ============================================================================

struct GpuInt:
    """Integer value for GPU computation."""
    value: Int

    fn new(val: Int) -> GpuInt:
        GpuInt(value: val)

    fn get() -> Int:
        self.value

    fn add(other: GpuInt) -> GpuInt:
        GpuInt(value: self.value + other.value)

    fn multiply(other: GpuInt) -> GpuInt:
        GpuInt(value: self.value * other.value)

struct HostInt:
    """Integer value for host/CPU computation."""
    value: Int

    fn new(val: Int) -> HostInt:
        HostInt(value: val)

    fn get() -> Int:
        self.value

    fn process() -> HostInt:
        HostInt(value: self.value * 2)

# ============================================================================
# Step 2: User Enum (Embeds Custom Types)
# ============================================================================

enum DeviceInt:
    """User-defined enum wrapping GPU and Host integers."""
    Gpu(GpuInt)
    Host(HostInt)

    fn get() -> Int:
        match self:
            case DeviceInt::Gpu(v):
                v.get()
            case DeviceInt::Host(v):
                v.get()

    fn device_name() -> String:
        match self:
            case DeviceInt::Gpu(_):
                "GPU"
            case DeviceInt::Host(_):
                "Host"

# Note: In full implementation, implicit From conversions would be automatic
# For now, we demonstrate the pattern explicitly

fn gpu_int_to_enum(val: GpuInt) -> DeviceInt:
    DeviceInt::Gpu(val)

fn host_int_to_enum(val: HostInt) -> DeviceInt:
    DeviceInt::Host(val)

# ============================================================================
# Step 3: GpuIndex Type
# ============================================================================

enum GpuIndex:
    Gpu0
    Gpu1
    Gpu2
    Gpu3

    fn to_int() -> Int:
        match self:
            case GpuIndex::Gpu0: 0
            case GpuIndex::Gpu1: 1
            case GpuIndex::Gpu2: 2
            case GpuIndex::Gpu3: 3

    fn name() -> String:
        match self:
            case GpuIndex::Gpu0: "GPU 0"
            case GpuIndex::Gpu1: "GPU 1"
            case GpuIndex::Gpu2: "GPU 2"
            case GpuIndex::Gpu3: "GPU 3"

# ============================================================================
# Step 4: Device Placement Types
# ============================================================================

# Note: In full implementation, these would be generic Gpu<T, const idx>
# For prototype, we use concrete types for each device

struct Gpu0Value:
    """Value placed on GPU 0."""
    value: DeviceInt
    device_id: GpuIndex

    fn new(val: DeviceInt) -> Gpu0Value:
        Gpu0Value(value: val, device_id: GpuIndex::Gpu0)

    fn get() -> DeviceInt:
        self.value

struct Gpu1Value:
    """Value placed on GPU 1."""
    value: DeviceInt
    device_id: GpuIndex

    fn new(val: DeviceInt) -> Gpu1Value:
        Gpu1Value(value: val, device_id: GpuIndex::Gpu1)

    fn get() -> DeviceInt:
        self.value

struct HostValue:
    """Value placed on host/CPU."""
    value: DeviceInt

    fn new(val: DeviceInt) -> HostValue:
        HostValue(value: val)

    fn get() -> DeviceInt:
        self.value

# ============================================================================
# Step 5: Device Transfer Operations
# ============================================================================

fn host_to_gpu0(host: HostValue) -> Gpu0Value:
    print("Transfer: Host → GPU 0")
    Gpu0Value.new(host.get())

fn host_to_gpu1(host: HostValue) -> Gpu1Value:
    print("Transfer: Host → GPU 1")
    Gpu1Value.new(host.get())

fn gpu0_to_gpu1(gpu0: Gpu0Value) -> Gpu1Value:
    print("Transfer: GPU 0 → GPU 1")
    Gpu1Value.new(gpu0.get())

fn gpu1_to_gpu0(gpu1: Gpu1Value) -> Gpu0Value:
    print("Transfer: GPU 1 → GPU 0")
    Gpu0Value.new(gpu1.get())

fn gpu0_to_host(gpu0: Gpu0Value) -> HostValue:
    print("Transfer: GPU 0 → Host")
    HostValue.new(gpu0.get())

fn gpu1_to_host(gpu1: Gpu1Value) -> HostValue:
    print("Transfer: GPU 1 → Host")
    HostValue.new(gpu1.get())

# ============================================================================
# Step 6: Device-Specific Operations
# ============================================================================

fn compute_on_gpu0(val: Gpu0Value) -> Gpu0Value:
    print("Computing on GPU 0...")
    let device_val = val.get()

    let result = match device_val:
        case DeviceInt::Gpu(gv):
            DeviceInt::Gpu(gv.add(GpuInt.new(10)))
        case _:
            device_val

    Gpu0Value.new(result)

fn compute_on_gpu1(val: Gpu1Value) -> Gpu1Value:
    print("Computing on GPU 1...")
    let device_val = val.get()

    let result = match device_val:
        case DeviceInt::Gpu(gv):
            DeviceInt::Gpu(gv.multiply(GpuInt.new(2)))
        case _:
            device_val

    Gpu1Value.new(result)

fn compute_on_host(val: HostValue) -> HostValue:
    print("Computing on host...")
    let device_val = val.get()

    let result = match device_val:
        case DeviceInt::Host(hv):
            DeviceInt::Host(hv.process())
        case _:
            device_val

    HostValue.new(result)

# ============================================================================
# Example 1: Basic Device Operations
# ============================================================================

fn example1_basic_operations():
    print("\n=== Example 1: Basic Device Operations ===\n")

    # Step 1: Create custom type (NOT bare primitive)
    let x: GpuInt = GpuInt.new(42)
    print(f"Created GpuInt: {x.get()}")

    # Step 2: Convert to user enum (implicit in real implementation)
    let x_enum: DeviceInt = gpu_int_to_enum(x)
    print(f"Converted to enum: {x_enum.get()} ({x_enum.device_name()})")

    # Step 3: Place on GPU 0
    let gpu0_val: Gpu0Value = Gpu0Value.new(x_enum)
    print(f"Placed on {gpu0_val.device_id.name()}: {gpu0_val.get().get()}")

    # Step 4: Compute on GPU 0
    let result: Gpu0Value = compute_on_gpu0(gpu0_val)
    print(f"Result: {result.get().get()}")

# ============================================================================
# Example 2: Multi-Device Pipeline
# ============================================================================

fn example2_multi_device_pipeline():
    print("\n=== Example 2: Multi-Device Pipeline ===\n")

    # Stage 1: Load on host
    let data: HostInt = HostInt.new(10)
    let data_enum: DeviceInt = host_int_to_enum(data)
    let host_val: HostValue = HostValue.new(data_enum)
    print(f"Loaded on host: {host_val.get().get()}")

    # Stage 2: Transfer to GPU 0
    let gpu0_val: Gpu0Value = host_to_gpu0(host_val)

    # Stage 3: Compute on GPU 0
    let gpu0_result: Gpu0Value = compute_on_gpu0(gpu0_val)
    print(f"GPU 0 result: {gpu0_result.get().get()}")

    # Stage 4: Transfer to GPU 1
    let gpu1_val: Gpu1Value = gpu0_to_gpu1(gpu0_result)

    # Stage 5: Compute on GPU 1
    let gpu1_result: Gpu1Value = compute_on_gpu1(gpu1_val)
    print(f"GPU 1 result: {gpu1_result.get().get()}")

    # Stage 6: Transfer back to host
    let final: HostValue = gpu1_to_host(gpu1_result)
    let final_result: HostValue = compute_on_host(final)
    print(f"Final result on host: {final_result.get().get()}")

# ============================================================================
# Example 3: Type Safety Demonstration
# ============================================================================

fn example3_type_safety():
    print("\n=== Example 3: Type Safety ===\n")

    # ❌ This would be an error (bare primitive)
    # let x: Int = 42
    print("❌ Bare primitives not allowed: let x: Int = 42")

    # ✅ Must wrap in custom type
    let x: GpuInt = GpuInt.new(42)
    print(f"✅ Custom type required: GpuInt.new(42) = {x.get()}")

    # Convert to enum
    let x_enum: DeviceInt = gpu_int_to_enum(x)

    # Place on GPU 0
    let gpu0: Gpu0Value = Gpu0Value.new(x_enum)
    print(f"✅ Placed on GPU 0: {gpu0.get().get()}")

    # ❌ Cannot directly assign to different GPU
    # let gpu1: Gpu1Value = gpu0  # Type error!
    print("❌ Cannot assign GPU0Value to Gpu1Value")

    # ✅ Must explicitly transfer
    let gpu1: Gpu1Value = gpu0_to_gpu1(gpu0)
    print(f"✅ Explicit transfer required: gpu0_to_gpu1()")
    print(f"   Result on GPU 1: {gpu1.get().get()}")

# ============================================================================
# Example 4: Pattern Matching on User Enum
# ============================================================================

fn process_device_value(val: DeviceInt) -> String:
    match val:
        case DeviceInt::Gpu(gpu_val):
            let result = gpu_val.add(GpuInt.new(100))
            f"GPU: {gpu_val.get()} + 100 = {result.get()}"

        case DeviceInt::Host(host_val):
            let result = host_val.process()
            f"Host: {host_val.get()} * 2 = {result.get()}"

fn example4_pattern_matching():
    print("\n=== Example 4: Pattern Matching ===\n")

    # Create different device values
    let gpu_val: GpuInt = GpuInt.new(50)
    let host_val: HostInt = HostInt.new(25)

    # Convert to enums
    let gpu_enum: DeviceInt = gpu_int_to_enum(gpu_val)
    let host_enum: DeviceInt = host_int_to_enum(host_val)

    # Process with pattern matching
    let gpu_result = process_device_value(gpu_enum)
    let host_result = process_device_value(host_enum)

    print(f"GPU processing: {gpu_result}")
    print(f"Host processing: {host_result}")

# ============================================================================
# Example 5: Data Parallel Simulation
# ============================================================================

fn example5_data_parallel():
    print("\n=== Example 5: Data Parallel Training ===\n")

    # Create 4 data batches
    let batch_values = [10, 20, 30, 40]
    print("Creating batches on 4 GPUs...")

    # Place each batch on a different GPU
    let batch0_int: GpuInt = GpuInt.new(batch_values[0])
    let batch0_enum: DeviceInt = gpu_int_to_enum(batch0_int)
    let batch0: Gpu0Value = Gpu0Value.new(batch0_enum)
    print(f"  Batch 0 on GPU 0: {batch0.get().get()}")

    let batch1_int: GpuInt = GpuInt.new(batch_values[1])
    let batch1_enum: DeviceInt = gpu_int_to_enum(batch1_int)
    let batch1: Gpu1Value = Gpu1Value.new(batch1_enum)
    print(f"  Batch 1 on GPU 1: {batch1.get().get()}")

    # Simulate parallel computation
    print("\nParallel computation:")
    let result0: Gpu0Value = compute_on_gpu0(batch0)
    let result1: Gpu1Value = compute_on_gpu1(batch1)

    print(f"  GPU 0 result: {result0.get().get()}")
    print(f"  GPU 1 result: {result1.get().get()}")

    # Gather to GPU 0
    print("\nGathering results to GPU 0...")
    let result1_on_gpu0: Gpu0Value = gpu1_to_gpu0(result1)

    print(f"  GPU 0 has: {result0.get().get()}")
    print(f"  GPU 1→0 has: {result1_on_gpu0.get().get()}")

    # Average on GPU 0
    let avg_val = match (result0.get(), result1_on_gpu0.get()):
        case (DeviceInt::Gpu(v1), DeviceInt::Gpu(v2)):
            let sum = v1.get() + v2.get()
            let avg = sum / 2
            GpuInt.new(avg)
        case _:
            GpuInt.new(0)

    print(f"\nAveraged result: {avg_val.get()}")

# ============================================================================
# Main Demo
# ============================================================================

fn main():
    print("=" * 60)
    print("  Execution Context Types - User Enum Pattern Demo")
    print("=" * 60)

    example1_basic_operations()
    example2_multi_device_pipeline()
    example3_type_safety()
    example4_pattern_matching()
    example5_data_parallel()

    print("\n" + "=" * 60)
    print("Demo complete!")
    print("\nKey features demonstrated:")
    print("✅ Custom types wrap primitives (no bare Int/Float)")
    print("✅ User enum embeds custom types")
    print("✅ Implicit conversion (custom type → enum)")
    print("✅ GpuIndex for device selection")
    print("✅ Type-safe device placement")
    print("✅ Explicit device transfers")
    print("✅ Pattern matching on user enum")
    print("✅ Multi-GPU data parallelism")
    print("=" * 60)
