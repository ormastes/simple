# ============================================================================
# Mock Library - Advanced Features
# ============================================================================
#
# Advanced mocking features including:
# - Task scheduling with priorities and execution tracking
# - Retry policies with backoff strategies
# - Rate limiting and throttling
# - Timeout controllers
# - Execution order tracking
# - Concurrency control
# - Debouncing and throttling utilities
#
# ============================================================================

# ============================================================================
# Phase 7: Advanced Scheduling
# ============================================================================

enum TaskPriority:
    Critical
    High
    Normal
    Low
    Background

struct ScheduledTask:
    id: i32
    name: text
    priority: TaskPriority
    delay_ms: i32
    executed: bool
    execution_time: i32
    result: Option<text>

class TaskScheduler:
    tasks: [ScheduledTask]
    next_id: i32
    current_time: i32
    executed_order: [i32]

    static fn new() -> TaskScheduler:
        TaskScheduler(
            tasks: [],
            next_id: 0,
            current_time: 0,
            executed_order: []
        )

    me schedule(name: text, priority: TaskPriority, delay_ms: i32) -> i32:
        val id = self.next_id
        self.next_id = self.next_id + 1
        self.tasks.append(ScheduledTask(
            id: id,
            name: name,
            priority: priority,
            delay_ms: delay_ms,
            executed: false,
            execution_time: 0,
            result: nil
        ))
        id

    me schedule_immediate(name: text) -> i32:
        self.schedule(name, TaskPriority.High, 0)

    me schedule_delayed(name: text, delay_ms: i32) -> i32:
        self.schedule(name, TaskPriority.Normal, delay_ms)

    me schedule_background(name: text, delay_ms: i32) -> i32:
        self.schedule(name, TaskPriority.Background, delay_ms)

    fn get_priority_value(priority: TaskPriority) -> i32:
        match priority:
            TaskPriority.Critical: 0
            TaskPriority.High: 1
            TaskPriority.Normal: 2
            TaskPriority.Low: 3
            TaskPriority.Background: 4

    me execute_next() -> Option<ScheduledTask>:
        var best_idx: Option<i32> = nil
        var best_priority = 999
        var idx = 0
        for task in self.tasks:
            if not task.executed:
                val priority_val = self.get_priority_value(task.priority)
                if priority_val < best_priority:
                    best_priority = priority_val
                    best_idx = Some(idx)
                else if priority_val == best_priority:
                    match best_idx:
                        Some(bi):
                            if task.delay_ms < self.tasks[bi as usize].delay_ms:
                                best_idx = Some(idx)
                        nil: best_idx = Some(idx)
            idx = idx + 1

        match best_idx:
            Some(i):
                val task = self.tasks[i as usize]
                val updated_task = ScheduledTask(
                    id: task.id,
                    name: task.name,
                    priority: task.priority,
                    delay_ms: task.delay_ms,
                    executed: true,
                    execution_time: self.current_time,
                    result: task.result
                )
                self.tasks[i as usize] = updated_task
                self.current_time = self.current_time + task.delay_ms
                self.executed_order.append(task.id)
                Some(updated_task)
            nil: nil

    me execute_all():
        var has_pending = true
        while has_pending:
            match self.execute_next():
                Some(_): true
                nil: has_pending = false

    fn get_executed_order() -> [i32]:
        self.executed_order

    fn get_pending_count() -> i32:
        var count = 0
        for task in self.tasks:
            if not task.executed:
                count = count + 1
        count

    fn get_task(id: i32) -> Option<ScheduledTask>:
        for task in self.tasks:
            if task.id == id:
                return Some(task)
        nil

    fn verify_execution_order(expected: [i32]) -> bool:
        if self.executed_order.len() != expected.len():
            return false
        for i in 0..expected.len():
            if self.executed_order[i] != expected[i]:
                return false
        true

    me reset():
        self.tasks = []
        self.next_id = 0
        self.current_time = 0
        self.executed_order = []

enum BackoffStrategy:
    NoBackoff
    Linear
    Exponential
    Fixed

struct RetryAttempt:
    attempt_number: i32
    delay_ms: i32
    success: bool
    error: Option<text>

class RetryPolicy:
    max_attempts: i32
    base_delay_ms: i32
    max_delay_ms: i32
    backoff: BackoffStrategy
    attempts: [RetryAttempt]

    static fn new(max_attempts: i32) -> RetryPolicy:
        RetryPolicy(
            max_attempts: max_attempts,
            base_delay_ms: 100,
            max_delay_ms: 5000,
            backoff: BackoffStrategy.Exponential,
            attempts: []
        )

    static fn no_retry() -> RetryPolicy:
        RetryPolicy(
            max_attempts: 1,
            base_delay_ms: 0,
            max_delay_ms: 0,
            backoff: BackoffStrategy.NoBackoff,
            attempts: []
        )

    static fn with_linear_backoff(max_attempts: i32, delay_ms: i32) -> RetryPolicy:
        RetryPolicy(
            max_attempts: max_attempts,
            base_delay_ms: delay_ms,
            max_delay_ms: delay_ms * max_attempts,
            backoff: BackoffStrategy.Linear,
            attempts: []
        )

    static fn with_exponential_backoff(max_attempts: i32, base_delay_ms: i32) -> RetryPolicy:
        RetryPolicy(
            max_attempts: max_attempts,
            base_delay_ms: base_delay_ms,
            max_delay_ms: base_delay_ms * 32,
            backoff: BackoffStrategy.Exponential,
            attempts: []
        )

    me set_max_delay(max_ms: i32):
        self.max_delay_ms = max_ms

    fn calculate_delay(attempt: i32) -> i32:
        val delay = match self.backoff:
            BackoffStrategy.NoBackoff: 0
            BackoffStrategy.Fixed: self.base_delay_ms
            BackoffStrategy.Linear: self.base_delay_ms * attempt
            BackoffStrategy.Exponential:
                var result = self.base_delay_ms
                for _ in 1..attempt:
                    result = result * 2
                result
        if delay > self.max_delay_ms:
            self.max_delay_ms
        else:
            delay

    me record_attempt(success: bool, error: Option<text>):
        val attempt_num = self.attempts.len() as i32 + 1
        val delay = self.calculate_delay(attempt_num)
        self.attempts.append(RetryAttempt(
            attempt_number: attempt_num,
            delay_ms: delay,
            success: success,
            error: error
        ))

    fn should_retry() -> bool:
        if self.attempts.len() == 0:
            return true
        if self.attempts.len() as i32 >= self.max_attempts:
            return false
        val last = self.attempts[self.attempts.len() - 1]
        not last.success

    fn get_attempt_count() -> i32:
        self.attempts.len() as i32

    fn get_total_delay() -> i32:
        var total = 0
        for attempt in self.attempts:
            total = total + attempt.delay_ms
        total

    fn was_successful() -> bool:
        if self.attempts.len() == 0:
            return false
        self.attempts[self.attempts.len() - 1].success

    me reset():
        self.attempts = []

class RateLimiter:
    max_requests: i32
    window_ms: i32
    requests: [i32]
    current_time: i32

    static fn new(max_requests: i32, window_ms: i32) -> RateLimiter:
        RateLimiter(
            max_requests: max_requests,
            window_ms: window_ms,
            requests: [],
            current_time: 0
        )

    static fn per_second(max_requests: i32) -> RateLimiter:
        RateLimiter.new(max_requests, 1000)

    static fn per_minute(max_requests: i32) -> RateLimiter:
        RateLimiter.new(max_requests, 60000)

    me advance_time(ms: i32):
        self.current_time = self.current_time + ms
        self.cleanup_old_requests()

    me cleanup_old_requests():
        var new_requests = []
        val window_start = self.current_time - self.window_ms
        for req_time in self.requests:
            if req_time >= window_start:
                new_requests.append(req_time)
        self.requests = new_requests

    fn can_proceed() -> bool:
        self.cleanup_old_requests()
        (self.requests.len() as i32) < self.max_requests

    me try_acquire() -> bool:
        if not self.can_proceed():
            return false
        self.requests.append(self.current_time)
        true

    fn get_wait_time() -> i32:
        if self.can_proceed():
            return 0
        if self.requests.len() == 0:
            return 0
        val oldest = self.requests[0]
        val wait = (oldest + self.window_ms) - self.current_time
        if wait > 0: wait else: 0

    fn get_remaining_requests() -> i32:
        self.cleanup_old_requests()
        self.max_requests - (self.requests.len() as i32)

    me reset():
        self.requests = []
        self.current_time = 0

struct TimeoutResult:
    completed: bool
    timed_out: bool
    duration_ms: i32
    result: Option<text>

class TimeoutController:
    timeout_ms: i32
    elapsed_ms: i32
    is_running: bool
    is_timed_out: bool

    static fn new(timeout_ms: i32) -> TimeoutController:
        TimeoutController(
            timeout_ms: timeout_ms,
            elapsed_ms: 0,
            is_running: false,
            is_timed_out: false
        )

    me start():
        self.is_running = true
        self.elapsed_ms = 0
        self.is_timed_out = false

    me advance(ms: i32):
        if self.is_running:
            self.elapsed_ms = self.elapsed_ms + ms
            if self.elapsed_ms >= self.timeout_ms:
                self.is_timed_out = true
                self.is_running = false

    me complete() -> TimeoutResult:
        self.is_running = false
        TimeoutResult(
            completed: not self.is_timed_out,
            timed_out: self.is_timed_out,
            duration_ms: self.elapsed_ms,
            result: if self.is_timed_out: nil else: Some("completed")
        )

    fn has_timed_out() -> bool:
        self.is_timed_out

    fn remaining_time() -> i32:
        val remaining = self.timeout_ms - self.elapsed_ms
        if remaining > 0: remaining else: 0

    me reset():
        self.elapsed_ms = 0
        self.is_running = false
        self.is_timed_out = false

struct ExecutionEvent:
    task_name: text
    timestamp: i32
    event_type: text

class ExecutionOrderTracker:
    events: [ExecutionEvent]
    current_time: i32

    static fn new() -> ExecutionOrderTracker:
        ExecutionOrderTracker(events: [], current_time: 0)

    me record_start(name: text):
        self.events.append(ExecutionEvent(
            task_name: name,
            timestamp: self.current_time,
            event_type: "start"
        ))

    me record_end(name: text):
        self.events.append(ExecutionEvent(
            task_name: name,
            timestamp: self.current_time,
            event_type: "end"
        ))

    me advance_time(ms: i32):
        self.current_time = self.current_time + ms

    fn get_start_order() -> [text]:
        var result = []
        for event in self.events:
            if event.event_type == "start":
                result.append(event.task_name)
        result

    fn get_end_order() -> [text]:
        var result = []
        for event in self.events:
            if event.event_type == "end":
                result.append(event.task_name)
        result

    fn verify_started_before(first: text, second: text) -> bool:
        var first_time: Option<i32> = nil
        var second_time: Option<i32> = nil
        for event in self.events:
            if event.event_type == "start":
                if event.task_name == first and first_time.is_none():
                    first_time = Some(event.timestamp)
                if event.task_name == second and second_time.is_none():
                    second_time = Some(event.timestamp)
        match first_time:
            Some(ft):
                match second_time:
                    Some(st): ft < st
                    nil: true
            nil: false

    fn verify_completed_before(first: text, second: text) -> bool:
        var first_time: Option<i32> = nil
        var second_time: Option<i32> = nil
        for event in self.events:
            if event.event_type == "end":
                if event.task_name == first and first_time.is_none():
                    first_time = Some(event.timestamp)
                if event.task_name == second and second_time.is_none():
                    second_time = Some(event.timestamp)
        match first_time:
            Some(ft):
                match second_time:
                    Some(st): ft < st
                    nil: true
            nil: false

    fn get_concurrent_at(time: i32) -> [text]:
        var running = []
        for event in self.events:
            if event.timestamp <= time:
                if event.event_type == "start":
                    running.append(event.task_name)
                else if event.event_type == "end":
                    var new_running = []
                    for name in running:
                        if name != event.task_name:
                            new_running.append(name)
                    running = new_running
        running

    me reset():
        self.events = []
        self.current_time = 0

class ConcurrencyController:
    max_concurrent: i32
    active_count: i32
    waiting_queue: [text]
    active_tasks: [text]
    completed_tasks: [text]

    static fn new(max_concurrent: i32) -> ConcurrencyController:
        ConcurrencyController(
            max_concurrent: max_concurrent,
            active_count: 0,
            waiting_queue: [],
            active_tasks: [],
            completed_tasks: []
        )

    fn can_start() -> bool:
        self.active_count < self.max_concurrent

    me try_start(name: text) -> bool:
        if not self.can_start():
            self.waiting_queue.append(name)
            return false
        self.active_count = self.active_count + 1
        self.active_tasks.append(name)
        true

    me complete(name: text):
        var new_active = []
        for task in self.active_tasks:
            if task != name:
                new_active.append(task)
        self.active_tasks = new_active
        self.active_count = self.active_count - 1
        self.completed_tasks.append(name)
        self.try_start_waiting()

    me try_start_waiting():
        if self.waiting_queue.len() > 0 and self.can_start():
            val next = self.waiting_queue[0]
            var new_queue = []
            for i in 1..self.waiting_queue.len():
                new_queue.append(self.waiting_queue[i])
            self.waiting_queue = new_queue
            self.active_count = self.active_count + 1
            self.active_tasks.append(next)

    fn get_active_count() -> i32:
        self.active_count

    fn get_waiting_count() -> i32:
        self.waiting_queue.len() as i32

    fn get_completed_count() -> i32:
        self.completed_tasks.len() as i32

    fn get_active_tasks() -> [text]:
        self.active_tasks

    me reset():
        self.active_count = 0
        self.waiting_queue = []
        self.active_tasks = []
        self.completed_tasks = []

class Debouncer:
    delay_ms: i32
    last_call_time: i32
    pending_value: Option<text>
    executed_values: [text]
    current_time: i32

    static fn new(delay_ms: i32) -> Debouncer:
        Debouncer(
            delay_ms: delay_ms,
            last_call_time: -999999,
            pending_value: nil,
            executed_values: [],
            current_time: 0
        )

    me call(value: text):
        self.pending_value = Some(value)
        self.last_call_time = self.current_time

    me advance_time(ms: i32):
        self.current_time = self.current_time + ms
        match self.pending_value:
            Some(v):
                if self.current_time - self.last_call_time >= self.delay_ms:
                    self.executed_values.append(v)
                    self.pending_value = nil
            nil: true

    fn get_executed_values() -> [text]:
        self.executed_values

    fn get_execution_count() -> i32:
        self.executed_values.len() as i32

    fn has_pending() -> bool:
        self.pending_value.is_some()

    me reset():
        self.last_call_time = -999999
        self.pending_value = nil
        self.executed_values = []
        self.current_time = 0

class Throttler:
    interval_ms: i32
    last_execution_time: i32
    dropped_count: i32
    executed_values: [text]
    current_time: i32

    static fn new(interval_ms: i32) -> Throttler:
        Throttler(
            interval_ms: interval_ms,
            last_execution_time: -999999,
            dropped_count: 0,
            executed_values: [],
            current_time: 0
        )

    me call(value: text) -> bool:
        if self.current_time - self.last_execution_time >= self.interval_ms:
            self.executed_values.append(value)
            self.last_execution_time = self.current_time
            true
        else:
            self.dropped_count = self.dropped_count + 1
            false

    me advance_time(ms: i32):
        self.current_time = self.current_time + ms

    fn get_executed_values() -> [text]:
        self.executed_values

    fn get_execution_count() -> i32:
        self.executed_values.len() as i32

    fn get_dropped_count() -> i32:
        self.dropped_count

    me reset():
        self.last_execution_time = -999999
        self.dropped_count = 0
        self.executed_values = []
        self.current_time = 0

# ============================================================================
# All Exports (Phases 1-7)
# ============================================================================

# Phase 1: Core Types
export CallRecord
export MockFunction
export MockBuilder
export RegistryEntry
export MockRegistry
export create_mock
export verify_called
export verify_called_with

# Phase 2: Verification System
export Expectation
export VerificationResult
export Matcher

# Phase 3: Advanced Features
export CallAnalyzer
export ReturnValue
export SequentialReturns
export Spy

# Policy System
export MockPolicy
export mock_policy_init
export mock_policy_is_enabled
export mock_policy_allow_in_layer
export mock_policy_disable
export mock_policy_reset

# Phase 4: Advanced Patterns
export ConditionalReturn
export ConditionalReturns
export CallChain
export CallChainTracker
export BehaviorState
export BehaviorSequence
export MockSnapshot
export MockComposition

# Phase 5: Trait-Based Mocking (Generics Workaround)
export MethodSignature
export FluentExpectation
export WhenBuilder
export MethodCall
export ProtocolMock
export AutoMock

# Phase 6: Async/Await Mocking
export AsyncCallRecord
export AsyncMock
export PromiseReturn
export PromiseSequence
export TimingStats
export AsyncSpy
export AsyncMethodMock
export AsyncProtocolMock
export AsyncMockEntry
export AsyncMockComposition
export AsyncTimingMatcher
export verify_async_timing
export verify_call_timing

# Phase 7: Advanced Scheduling
export TaskPriority
export ScheduledTask
export TaskScheduler
export BackoffStrategy
export RetryAttempt
export RetryPolicy
export RateLimiter
export TimeoutResult
export TimeoutController
export ExecutionEvent
export ExecutionOrderTracker
export ConcurrencyController
export Debouncer
export Throttler

# ============================================================================
# Exports
# ============================================================================

export TaskPriority, ScheduledTask, TaskScheduler
export BackoffStrategy, RetryAttempt, RetryPolicy
export RateLimiter
export TimeoutResult, TimeoutController
export ExecutionEvent, ExecutionOrderTracker
export ConcurrencyController
export Debouncer, Throttler
