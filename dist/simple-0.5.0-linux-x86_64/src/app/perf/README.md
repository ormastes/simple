# Performance Tools - Pure Simple Implementation

Complete performance analysis and optimization tools written entirely in Simple.

## Overview

This package provides:
- **Profiler** - Measure execution time of code regions
- **Benchmark** - Run performance tests and compare results
- **Optimizer** - Analyze code and suggest optimizations

All tools are implemented in Pure Simple (no Rust modifications needed).

## Quick Start

```bash
# Analyze code for optimization opportunities
simple perf optimize src/

# Profile a script
simple perf profile examples/fibonacci.spl

# Run benchmarks
simple perf benchmark benchmarks/my_bench.spl

# Compare benchmark results
simple perf compare current.json baseline.json
```

## Profiler

Measure execution time of specific code regions.

### Usage

```simple
import perf.profiler

fn main():
    profiler.init_profiler()

    # Profile a region
    profiler.profile_region("computation", \:
        expensive_calculation()
    )

    # Print report
    profiler.print_profile()

    # Save to JSON
    profiler.save_profile("profile.json")

    # Get optimization suggestions
    val suggestions = profiler.analyze_hotspots()
    for sugg in suggestions:
        print sugg
```

### Output Example

```
Performance Profile Report
============================================================

Total time: 1234 ms

Region                        Count     Avg(Âµs)     Total(ms)    % Time
--------------------------------------------------------------------------------
computation                   100       500         50           40%
database_query                50        300         15           12%
render                        200       100         20           16%
```

## Benchmark

Run performance tests and track improvements over time.

### Usage

```simple
import perf.benchmark

fn main():
    var suite = benchmark.BenchSuite.create("My Benchmarks")

    # Load baseline for comparison
    suite.load_baseline("baseline.json")

    # Run benchmarks
    val result = suite.run_bench("array_ops", 1000, \:
        var arr = []
        for i in 0..100:
            arr.push(i)
    )
    suite.add_result(result)

    # Print results (with comparison to baseline)
    print suite.report()

    # Save results
    suite.save("current.json")
```

### Output Example

```
Benchmark Results: My Benchmarks
================================================================================

Benchmark                               Avg(Âµs)     Min(Âµs)     Max(Âµs)     Change
------------------------------------------------------------------------------------------
array_ops                               125         120         145         âœ“ -15% faster
dict_lookup                             200         195         220         â‰ˆ +2%
string_concat                           450         440         480         âœ— +20% slower
```

## Optimizer

Static code analysis with optimization suggestions.

### Usage

```bash
# Analyze a file
simple perf optimize src/app/build/main.spl

# Analyze entire directory
simple perf optimize src/
```

### Output Example

```
Code Optimization Report
================================================================================

Summary:
  Critical: 2
  Warnings: 5
  Info:     8

Critical Issues:
--------------------------------------------------------------------------------
ğŸ”´ src/app/build/main.spl:45 - Triple-nested loop detected (O(nÂ³))
   â†’ Consider algorithm optimization or data structure change

Warnings:
--------------------------------------------------------------------------------
âš ï¸  src/app/build/compiler.spl:23 - Function call in loop condition
   â†’ Cache .len() result before loop: val n = items.len()

âš ï¸  src/app/build/formatter.spl:67 - String concatenation in loop
   â†’ Use list.join() or string builder for better performance

âš ï¸  src/app/build/utils.spl:120 - Recursive function without memoization
   â†’ Add @memoize decorator or manual caching for repeated inputs
```

## Optimization Patterns Detected

1. **Function calls in loop conditions** - Cache results
2. **String concatenation in loops** - Use join() or builder
3. **Nested loops** - O(nÂ²) or O(nÂ³) complexity warnings
4. **Multiple indexing in loops** - Extract to locals
5. **Recursive functions without memoization** - Add caching
6. **Large literals in hot paths** - Move to const

## Integration with Development Workflow

### 1. Development Phase

```bash
# Check code for optimization opportunities
simple perf optimize src/

# Run benchmarks
simple build test
```

### 2. Before Commit

```bash
# Save baseline
simple perf benchmark benchmarks/ > baseline.json

# After changes, compare
simple perf benchmark benchmarks/ > current.json
simple perf compare current.json baseline.json
```

### 3. CI/CD Integration

```yaml
# .github/workflows/performance.yml
- name: Run benchmarks
  run: simple perf benchmark benchmarks/ > results.json

- name: Compare with baseline
  run: simple perf compare results.json baseline.json
```

## Example: Complete Workflow

```simple
import perf.profiler
import perf.benchmark

fn optimize_my_code():
    # 1. Profile to find hotspots
    profiler.init_profiler()
    profiler.profile_region("main_loop", \:
        my_algorithm()
    )
    profiler.print_profile()

    # 2. Benchmark before optimization
    var suite = benchmark.BenchSuite.create("Algorithm")
    val before = suite.run_bench("original", 100, \: my_algorithm())
    suite.add_result(before)

    # 3. Make optimizations based on profiler output
    # ...

    # 4. Benchmark after optimization
    val after = suite.run_bench("optimized", 100, \: my_optimized_algorithm())
    suite.add_result(after)

    # 5. Compare results
    print suite.report()
```

## Performance Tips

### DO:
- âœ… Profile before optimizing
- âœ… Benchmark to verify improvements
- âœ… Cache expensive computations
- âœ… Use appropriate data structures
- âœ… Minimize allocations in hot paths

### DON'T:
- âŒ Optimize without measuring
- âŒ Concatenate strings in loops
- âŒ Repeat expensive calls
- âŒ Use O(nÂ²) when O(n) is possible
- âŒ Ignore the profiler's suggestions

## Architecture

All tools are pure Simple:
```
src/app/perf/
â”œâ”€â”€ profiler.spl     # Time measurement and analysis
â”œâ”€â”€ benchmark.spl    # Performance testing framework
â”œâ”€â”€ optimizer.spl    # Static code analysis
â”œâ”€â”€ main.spl         # CLI interface
â””â”€â”€ README.md        # This file
```

No Rust modifications required! Performance tools are self-contained.

## SFFI Requirements

These tools use standard SFFI hooks:
- `rt_time_monotonic_ns()` - High-resolution timer
- `rt_timestamp_iso8601()` - Timestamp generation
- `rt_get_args()` - Command-line arguments

All hooks are already available in the standard runtime.

## Future Enhancements

- [ ] Flame graph generation
- [ ] Memory profiling
- [ ] CPU cache analysis
- [ ] Auto-optimization suggestions
- [ ] JIT compilation hints
- [ ] Parallel execution profiling

## See Also

- `/examples/perf_demo.spl` - Complete usage examples
- `/doc/report/optimization_progress_2026-02-04.md` - Performance work
- `/script/profiling/` - Rust-level profiling tools (for runtime optimization)
