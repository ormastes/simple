# Pure Simple Tensor Operations
#
# All tensor operations implemented in pure Simple
# Zero external dependencies

use lib.pure.tensor (PureTensor)

# ============================================================================
# Element-wise Operations
# ============================================================================

fn add(a: PureTensor<f64>, b: PureTensor<f64>) -> PureTensor<f64>:
    """Element-wise addition."""
    var result_data: [f64] = []
    var i = 0
    while i < a.data.len():
        result_data.push(a.data[i] + b.data[i])
        i = i + 1
    PureTensor.from_data(result_data, a.shape)

fn sub(a: PureTensor<f64>, b: PureTensor<f64>) -> PureTensor<f64>:
    """Element-wise subtraction."""
    var result_data: [f64] = []
    var i = 0
    while i < a.data.len():
        result_data.push(a.data[i] - b.data[i])
        i = i + 1
    PureTensor.from_data(result_data, a.shape)

fn mul(a: PureTensor<f64>, b: PureTensor<f64>) -> PureTensor<f64>:
    """Element-wise multiplication."""
    var result_data: [f64] = []
    var i = 0
    while i < a.data.len():
        result_data.push(a.data[i] * b.data[i])
        i = i + 1
    PureTensor.from_data(result_data, a.shape)

fn div(a: PureTensor<f64>, b: PureTensor<f64>) -> PureTensor<f64>:
    """Element-wise division."""
    var result_data: [f64] = []
    var i = 0
    while i < a.data.len():
        result_data.push(a.data[i] / b.data[i])
        i = i + 1
    PureTensor.from_data(result_data, a.shape)

fn mul_scalar(t: PureTensor<f64>, scalar: f64) -> PureTensor<f64>:
    """Multiply tensor by scalar."""
    var result_data: [f64] = []
    for v in t.data:
        result_data.push(v * scalar)
    PureTensor.from_data(result_data, t.shape)

fn add_scalar(t: PureTensor<f64>, scalar: f64) -> PureTensor<f64>:
    """Add scalar to tensor."""
    var result_data: [f64] = []
    for v in t.data:
        result_data.push(v + scalar)
    PureTensor.from_data(result_data, t.shape)

# ============================================================================
# Matrix Operations
# ============================================================================

fn matmul(a: PureTensor<f64>, b: PureTensor<f64>) -> PureTensor<f64>:
    """Matrix multiplication: C = A @ B

    Assumes: A is [M, K], B is [K, N] -> C is [M, N]
    Algorithm: Naive triple loop (O(nÂ³))
    """
    val M = a.shape[0]
    val K = a.shape[1]
    val N = b.shape[1]

    var result_data: [f64] = []
    var i = 0
    while i < M:
        var j = 0
        while j < N:
            var sum = 0.0
            var k = 0
            while k < K:
                sum = sum + a.get([i, k]) * b.get([k, j])
                k = k + 1
            result_data.push(sum)
            j = j + 1
        i = i + 1

    PureTensor.from_data(result_data, [M, N])

fn transpose(t: PureTensor<f64>) -> PureTensor<f64>:
    """Transpose 2D tensor."""
    val rows = t.shape[0]
    val cols = t.shape[1]

    var result_data: [f64] = []
    var i = 0
    while i < cols:
        var j = 0
        while j < rows:
            result_data.push(t.get([j, i]))
            j = j + 1
        i = i + 1

    PureTensor.from_data(result_data, [cols, rows])

# ============================================================================
# Reductions
# ============================================================================

fn sum(t: PureTensor<f64>) -> f64:
    """Sum all elements."""
    var total = 0.0
    for v in t.data:
        total = total + v
    total

fn mean(t: PureTensor<f64>) -> f64:
    """Mean of all elements."""
    sum(t) / t.numel()

fn max(t: PureTensor<f64>) -> f64:
    """Maximum element."""
    var max_val = t.data[0]
    for v in t.data:
        if v > max_val:
            max_val = v
    max_val

fn min(t: PureTensor<f64>) -> f64:
    """Minimum element."""
    var min_val = t.data[0]
    for v in t.data:
        if v < min_val:
            min_val = v
    min_val

# ============================================================================
# Activation Functions
# ============================================================================

fn relu(x: PureTensor<f64>) -> PureTensor<f64>:
    """ReLU: max(0, x)."""
    var result_data: [f64] = []
    for v in x.data:
        result_data.push(if v > 0.0: v else: 0.0)
    PureTensor.from_data(result_data, x.shape)

fn sigmoid(x: PureTensor<f64>) -> PureTensor<f64>:
    """Sigmoid: 1 / (1 + exp(-x)).

    Uses linear approximation for simplicity.
    TODO: Implement proper exp() function.
    """
    var result_data: [f64] = []
    for v in x.data:
        val sigmoid_val = 0.5 + v * 0.25
        val clamped = if sigmoid_val < 0.0: 0.0 elif sigmoid_val > 1.0: 1.0 else: sigmoid_val
        result_data.push(clamped)
    PureTensor.from_data(result_data, x.shape)

fn tanh(x: PureTensor<f64>) -> PureTensor<f64>:
    """Tanh: (exp(x) - exp(-x)) / (exp(x) + exp(-x)).

    Uses linear approximation for simplicity.
    """
    var result_data: [f64] = []
    for v in x.data:
        val tanh_val = v * 0.5
        val clamped = if tanh_val < -1.0: -1.0 elif tanh_val > 1.0: 1.0 else: tanh_val
        result_data.push(clamped)
    PureTensor.from_data(result_data, x.shape)

# ============================================================================
# Exports
# ============================================================================

export add, sub, mul, div, mul_scalar, add_scalar
export matmul, transpose
export sum, mean, max, min
export relu, sigmoid, tanh
