# Pure Simple Tensor F64 - Concrete f64 tensor (interpreter-compatible)
#
# Non-generic version of PureTensor<f64> that works with current interpreter
# TODO: Merge back to generic PureTensor<T> once interpreter supports generics

class TensorF64:
    """Pure Simple f64 tensor with flat array storage."""
    data: [f64]      # Flat array storage
    shape: [i64]     # Dimension sizes
    strides: [i64]   # Memory layout strides

    fn numel() -> i64:
        """Get total number of elements."""
        var total = 1
        for dim in self.shape:
            total = total * dim
        total

    fn get(indices: [i64]) -> f64:
        """Get element at multi-dimensional index."""
        var offset = 0
        var i = 0
        while i < indices.len():
            offset = offset + indices[i] * self.strides[i]
            i = i + 1
        self.data[offset]

    fn set(indices: [i64], value: f64):
        """Set element at multi-dimensional index."""
        var offset = 0
        var i = 0
        while i < indices.len():
            offset = offset + indices[i] * self.strides[i]
            i = i + 1
        self.data[offset] = value

    fn to_string() -> text:
        """Convert tensor to string representation."""
        if self.shape.len() == 1:
            # 1D tensor: [1.0, 2.0, 3.0]
            var result = "["
            for i in 0..self.data.len():
                if i > 0:
                    result = result + ", "
                result = result + "{self.data[i]}"
            result + "]"
        elif self.shape.len() == 2:
            # 2D tensor: [[1.0, 2.0], [3.0, 4.0]]
            var result = "["
            for row in 0..self.shape[0]:
                if row > 0:
                    result = result + ",\n "
                result = result + "["
                for col in 0..self.shape[1]:
                    if col > 0:
                        result = result + ", "
                    val idx = row * self.strides[0] + col * self.strides[1]
                    result = result + "{self.data[idx]}"
                result = result + "]"
            result + "]"
        else:
            # Higher dimensions: just show shape
            "TensorF64(shape: {self.shape})"

fn compute_strides(shape: [i64]) -> [i64]:
    """Compute strides for C-contiguous layout."""
    var strides: [i64] = []
    var stride = 1
    var i = shape.len() - 1
    while i >= 0:
        strides.insert(0, stride)
        stride = stride * shape[i]
        i = i - 1
    strides

# Factory functions (non-generic, interpreter-compatible)

fn from_data(data: [f64], shape: [i64]) -> TensorF64:
    """Create f64 tensor from data array."""
    TensorF64(data: data, shape: shape, strides: compute_strides(shape))

fn zeros(shape: [i64]) -> TensorF64:
    """Create tensor filled with zeros."""
    var numel = 1
    for dim in shape:
        numel = numel * dim
    var data: [f64] = []
    var i = 0
    while i < numel:
        data.push(0.0)
        i = i + 1
    TensorF64(data: data, shape: shape, strides: compute_strides(shape))

fn ones(shape: [i64]) -> TensorF64:
    """Create tensor filled with ones."""
    var numel = 1
    for dim in shape:
        numel = numel * dim
    var data: [f64] = []
    var i = 0
    while i < numel:
        data.push(1.0)
        i = i + 1
    TensorF64(data: data, shape: shape, strides: compute_strides(shape))

fn randn(shape: [i64]) -> TensorF64:
    """Create tensor with random values."""
    var numel = 1
    for dim in shape:
        numel = numel * dim
    var data: [f64] = []
    var i = 0
    while i < numel:
        val rand = ((i * 2654435761) % 1000000) / 1000000.0
        data.push(rand - 0.5)
        i = i + 1
    TensorF64(data: data, shape: shape, strides: compute_strides(shape))

export TensorF64, compute_strides
export from_data, zeros, ones, randn
