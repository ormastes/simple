# Phase 1: Medical Dictionary Training
# Progressive LoRA: Merge LoRA_0, add LoRA_1

extends: "base.sdn"

training:
  epochs: 3
  max_samples: 5000
  learning_rate: 0.0002

data:
  type: "medical_dict"
  path: "example/medgemma_korean/data/medical_dict"
  format: "jsonl"

# Previous LoRAs to merge before training
previous_loras:
  - "example/medgemma_korean/models/phase0/lora_0"

output:
  lora_path: "example/medgemma_korean/models/phase1/lora_1"
  merged_path: "example/medgemma_korean/models/phase1/merged"

validation:
  test_plain_text: true  # Verify Phase 0 knowledge retained
  test_medical_dict: true

tags:
  - "phase1"
  - "medical_dict"
  - "progressive_lora"
