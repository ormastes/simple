# Experiment Storage - .exp/ directory and event log
#
# Directory structure:
#   .exp/
#     runs/
#       <run_id>/
#         meta.sdn        - Run metadata
#         events.sdnl     - Append-only event log (SDN-lines)
#         artifacts.sdn   - Artifact references
#         config.sdn      - Frozen config snapshot
#     blobs/
#       <sha256_prefix>/  - Content-addressed blob store
#         <sha256_full>
#     index.sdn           - Run index for fast queries

extern fn rt_file_read_text(path: str) -> str
extern fn rt_file_write_text(path: str, content: str) -> bool
extern fn rt_file_append_text(path: str, content: str) -> bool
extern fn rt_file_exists(path: str) -> bool
extern fn rt_dir_create(path: str) -> bool
extern fn rt_dir_list(path: str) -> [str]
extern fn rt_file_delete(path: str) -> bool
extern fn rt_package_sha256(path: str) -> str

# ============================================================================
# Directory Management
# ============================================================================

val EXP_DIR = ".exp"
val RUNS_DIR = ".exp/runs"
val BLOBS_DIR = ".exp/blobs"
val INDEX_FILE = ".exp/index.sdn"

pub fn init_exp_dir():
    """Initialize .exp/ directory structure."""
    ensure_dir(EXP_DIR)
    ensure_dir(RUNS_DIR)
    ensure_dir(BLOBS_DIR)
    if not file_exists(INDEX_FILE):
        file_write(INDEX_FILE, "# Experiment run index\nruns:\n")

pub fn ensure_run_dir(run_id: text):
    """Create directory for a specific run."""
    val run_dir = "{RUNS_DIR}/{run_id}"
    ensure_dir(run_dir)

pub fn run_dir_path(run_id: text) -> text:
    """Get path to a run's directory."""
    "{RUNS_DIR}/{run_id}"

pub fn run_exists(run_id: text) -> bool:
    """Check if a run directory exists."""
    file_exists("{RUNS_DIR}/{run_id}/meta.sdn")

# ============================================================================
# Event Log (Append-Only SDN-Lines)
# ============================================================================

struct Event:
    """A single event in the run log."""
    timestamp: text
    kind: text
    data: Dict<text, text>

impl Event:
    fn to_sdnl() -> text:
        """Serialize event to SDN-lines format (one line)."""
        var parts: [text] = ["timestamp: \"{self.timestamp}\"", "kind: \"{self.kind}\""]
        for key in self.data.keys():
            parts.push("data.{key}: \"{self.data[key]}\"")
        parts.join(", ")

pub fn append_event(run_id: text, event: Event):
    """Append an event to the run's event log."""
    val log_path = "{RUNS_DIR}/{run_id}/events.sdnl"
    val line = event.to_sdnl() + "\n"
    file_append(log_path, line)

pub fn read_events(run_id: text) -> [Event]:
    """Read all events from a run's event log."""
    val log_path = "{RUNS_DIR}/{run_id}/events.sdnl"
    if not file_exists(log_path):
        return []
    val content = file_read(log_path)
    val lines = content.split("\n")
    var events: [Event] = []
    for line in lines:
        if line.trim().?:
            val parsed = parse_event_line(line)
            if parsed.?:
                events.push(parsed.unwrap())
    events

fn parse_event_line(line: text) -> Event?:
    """Parse a single SDN-lines event."""
    # Simple key: "value" parser for event lines
    var timestamp = ""
    var kind = ""
    var data: Dict<text, text> = {}

    val parts = line.split(", ")
    for part in parts:
        var p: text = "{part}"
        if not p.contains(": "):
            continue
        val kv = p.split(": ")
        if kv.len() < 2:
            continue
        val key: text = "{kv[0]}".trim()
        # Rejoin value parts
        var vparts: [text] = []
        var vi = 1
        while vi < kv.len():
            vparts.push("{kv[vi]}")
            vi = vi + 1
        var value: text = vparts.join(": ").trim()
        # Strip quotes
        if value.starts_with("\"") and value.ends_with("\""):
            value = value[1:-1]

        if key == "timestamp":
            timestamp = value
        elif key == "kind":
            kind = value
        elif key.starts_with("data."):
            val data_key = key[5:]
            data[data_key] = value

    if timestamp.? and kind.?:
        Some(Event(timestamp: timestamp, kind: kind, data: data))
    else:
        nil

# ============================================================================
# Run Metadata
# ============================================================================

pub fn write_run_meta(run_id: text, meta: Dict<text, text>):
    """Write run metadata SDN file."""
    var lines: [text] = ["# Run metadata"]
    lines.push("run_id: \"{run_id}\"")
    for key in meta.keys():
        lines.push("{key}: \"{meta[key]}\"")

    val content = lines.join("\n") + "\n"
    file_write("{RUNS_DIR}/{run_id}/meta.sdn", content)

pub fn read_run_meta(run_id: text) -> Dict<text, text>:
    """Read run metadata."""
    val path = "{RUNS_DIR}/{run_id}/meta.sdn"
    if not file_exists(path):
        return {}
    parse_simple_sdn(file_read(path))

# ============================================================================
# Content-Addressed Blob Store
# ============================================================================

pub fn store_blob(data: text) -> text:
    """Store data as content-addressed blob, return SHA256 hash."""
    val hash = sha256_hex(data)
    val prefix = hash[:2]
    val blob_dir = "{BLOBS_DIR}/{prefix}"
    val blob_path = "{blob_dir}/{hash}"
    if not file_exists(blob_path):
        ensure_dir(blob_dir)
        file_write(blob_path, data)
    hash

pub fn store_blob_file(source_path: text) -> text:
    """Store a file as content-addressed blob, return SHA256 hash."""
    val data = file_read(source_path)
    store_blob(data)

pub fn read_blob(hash: text) -> text?:
    """Read a blob by its hash."""
    val prefix = hash[:2]
    val blob_path = "{BLOBS_DIR}/{prefix}/{hash}"
    if file_exists(blob_path):
        Some(file_read(blob_path))
    else:
        nil

pub fn blob_exists(hash: text) -> bool:
    """Check if a blob exists."""
    val prefix = hash[:2]
    file_exists("{BLOBS_DIR}/{prefix}/{hash}")

# ============================================================================
# Run Index
# ============================================================================

pub fn update_index(run_id: text, status: text, tags: [text]):
    """Update the run index with a run entry."""
    val tag_str = tags.join(", ")
    val line = "  {run_id}: status=\"{status}\", tags=[{tag_str}]\n"
    file_append(INDEX_FILE, line)

pub fn list_run_ids() -> [text]:
    """List all run IDs from the runs directory."""
    if not file_exists(RUNS_DIR):
        return []
    dir_list(RUNS_DIR)

# ============================================================================
# Garbage Collection Support
# ============================================================================

pub fn list_blob_hashes() -> [text]:
    """List all blob hashes in the store."""
    var hashes: [text] = []
    if not file_exists(BLOBS_DIR):
        return hashes
    val prefixes = dir_list(BLOBS_DIR)
    for prefix in prefixes:
        val blobs = dir_list("{BLOBS_DIR}/{prefix}")
        hashes = hashes.merge(blobs)
    hashes

pub fn delete_blob(hash: text) -> bool:
    """Delete a blob by hash."""
    val prefix = hash[:2]
    file_delete("{BLOBS_DIR}/{prefix}/{hash}")

# ============================================================================
# Helpers
# ============================================================================

fn parse_simple_sdn(content: text) -> Dict<text, text>:
    """Parse simple key: "value" SDN format."""
    var result: Dict<text, text> = {}
    val lines = content.split("\n")
    for line in lines:
        var trimmed: text = "{line}".trim()
        if trimmed.starts_with("#") or not trimmed.?:
            continue
        if not trimmed.contains(": "):
            continue
        # Split on first ": " to get key and value
        val parts = trimmed.split(": ")
        if parts.len() < 2:
            continue
        val key: text = "{parts[0]}".trim()
        # Rejoin remaining parts in case value contained ": "
        var value_parts: [text] = []
        var i = 1
        while i < parts.len():
            value_parts.push("{parts[i]}")
            i = i + 1
        var value: text = value_parts.join(": ").trim()
        if value.starts_with("\"") and value.ends_with("\""):
            value = value[1:-1]
        result[key] = value
    result

fn ensure_dir(path: text):
    # TODO: Replace direct FFI call with wrapper (dir_create) from app.io or compiler.ffi
    rt_dir_create(path)

fn file_exists(path: text) -> bool:
    # TODO: Replace direct FFI call with wrapper (file_exists) from app.io or compiler.ffi
    rt_file_exists(path)

fn file_read(path: text) -> text:
    # TODO: Replace direct FFI call with wrapper (file_read_text) from app.io or compiler.ffi
    val raw = rt_file_read_text(path)
    "{raw}"

fn file_write(path: text, content: text):
    # TODO: Replace direct FFI call with wrapper (file_write_text) from app.io or compiler.ffi
    rt_file_write_text(path, content)

fn file_append(path: text, content: text):
    # TODO: Replace direct FFI call with wrapper (file_append_text) from app.io or compiler.ffi
    rt_file_append_text(path, content)

fn file_delete(path: text) -> bool:
    # TODO: Replace direct FFI call with wrapper (file_delete) from app.io or compiler.ffi
    rt_file_delete(path)

fn dir_list(path: text) -> [text]:
    # TODO: Replace direct FFI call with wrapper (dir_list) from app.io or compiler.ffi
    val raw = rt_dir_list(path)
    if not raw.?:
        return []
    var items: [text] = []
    for item in raw.unwrap():
        items.push("{item}")
    items

fn sha256_hex(data: text) -> text:
    # rt_package_sha256 expects a file path, so write to temp file first
    val tmp_path = ".exp/.tmp_hash"
    # TODO: Replace direct FFI call with wrapper (file_write_text) from app.io or compiler.ffi
    rt_file_write_text(tmp_path, data)
    val hash = rt_package_sha256(tmp_path)
    # TODO: Replace direct FFI call with wrapper (file_delete) from app.io or compiler.ffi
    rt_file_delete(tmp_path)
    hash

# ============================================================================
# Exports
# ============================================================================

export Event
export init_exp_dir, ensure_run_dir, run_dir_path, run_exists
export append_event, read_events
export write_run_meta, read_run_meta
export store_blob, store_blob_file, read_blob, blob_exists
export update_index, list_run_ids
export list_blob_hashes, delete_blob
