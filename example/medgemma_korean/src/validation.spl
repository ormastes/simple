# Validation Utilities for Knowledge Retention Testing
#
# This module provides utilities to validate that progressive LoRA training
# does not cause catastrophic forgetting. Each phase's knowledge should be
# retained after training subsequent phases.
#
# Tests:
#   - test_plain_text: Validate Phase 0 knowledge (Korean fluency)
#   - test_medical_dict: Validate Phase 1 knowledge (terminology)
#   - test_mcq: Validate Phase 2 knowledge (medical reasoning)
#   - test_all_phases: Run all validation tests

export test_plain_text, test_medical_dict, test_mcq, test_all_phases
export ValidationResult, ValidationReport


# ============================================================================
# Validation Result Classes
# ============================================================================

class ValidationResult:
    """Result of a single validation test."""
    phase: i32
    test_name: str
    passed: bool
    score: f64
    details: str

    fn __init__(phase: i32, test_name: str, passed: bool, score: f64, details: str):
        self.phase = phase
        self.test_name = test_name
        self.passed = passed
        self.score = score
        self.details = details

    fn print_result():
        """Print validation result."""
        val status = "PASS" if self.passed else "FAIL"
        print(f"  [{status}] Phase {self.phase}: {self.test_name}")
        print(f"          Score: {self.score:.2%}")
        if self.details != "":
            print(f"          Details: {self.details}")


class ValidationReport:
    """Complete validation report for all phases."""
    results: [ValidationResult]
    total_tests: i32
    passed_tests: i32
    overall_score: f64

    fn __init__():
        self.results = []
        self.total_tests = 0
        self.passed_tests = 0
        self.overall_score = 0.0

    fn add_result(result: ValidationResult):
        """Add a validation result."""
        self.results.push(result)
        self.total_tests += 1
        if result.passed:
            self.passed_tests += 1

    fn compute_overall_score():
        """Compute overall score from all results."""
        if self.total_tests == 0:
            self.overall_score = 0.0
            return

        var total_score = 0.0
        for result in self.results:
            total_score += result.score

        self.overall_score = total_score / self.total_tests

    fn print_report():
        """Print validation report."""
        print("\n" + "=" * 70)
        print("VALIDATION REPORT")
        print("=" * 70)
        print()

        # Print individual results
        for result in self.results:
            result.print_result()

        print()
        print("=" * 70)
        print(f"Overall: {self.passed_tests}/{self.total_tests} tests passed")
        print(f"Overall Score: {self.overall_score:.2%}")

        if self.passed_tests == self.total_tests:
            print("Status: ALL TESTS PASSED - No catastrophic forgetting!")
        else:
            print("Status: SOME TESTS FAILED - Catastrophic forgetting detected!")

        print("=" * 70)

    fn has_catastrophic_forgetting() -> bool:
        """Check if catastrophic forgetting occurred."""
        return self.passed_tests < self.total_tests


# ============================================================================
# Phase 0 Validation: Korean Fluency
# ============================================================================

fn test_plain_text(model: any, tokenizer: any, device: str) -> ValidationResult:
    """Test Phase 0 knowledge: Korean language fluency.

    Tests that the model can generate fluent Korean text.
    """
    print("\n<Phase 0 Test> Plain Text Generation")
    print("  Testing Korean fluency...")

    # Test prompts
    val test_prompts = [
        "한국어로 설명하면",
        "의학적으로",
        "환자의 증상은"
    ]

    var total_score = 0.0
    var passed_count = 0

    for prompt in test_prompts:
        print(f"  Prompt: '{prompt}'")

        # Mock response for example (in production, use model.generate)
        val response = "한국어로 설명하면 다음과 같습니다. 의학적인 관점에서..."

        # Score: Check if response contains Korean characters
        val has_korean = "한" in response or "의" in response or "는" in response
        val score = 1.0 if has_korean else 0.0

        total_score += score
        if score >= 0.7:
            passed_count += 1

        print(f"    Response: {response}")
        print(f"    Score: {score:.2%}")

    val avg_score = total_score / test_prompts.len()
    val passed = avg_score >= 0.7

    return ValidationResult(
        phase=0,
        test_name="Korean Fluency",
        passed=passed,
        score=avg_score,
        details=f"{passed_count}/{test_prompts.len()} prompts passed"
    )


# ============================================================================
# Phase 1 Validation: Medical Dictionary
# ============================================================================

fn test_medical_dict(model: any, tokenizer: any, device: str) -> ValidationResult:
    """Test Phase 1 knowledge: Medical terminology.

    Tests that the model can define medical terms correctly.
    """
    print("\n<Phase 1 Test> Medical Dictionary")
    print("  Testing medical terminology...")

    # Test cases: term -> expected keywords
    val test_terms = ["고혈압", "당뇨병", "폐렴"]
    val expected_keywords = [
        ["Hypertension", "혈압", "blood pressure"],
        ["Diabetes", "인슐린", "insulin"],
        ["Pneumonia", "폐", "lung"]
    ]

    var total_score = 0.0
    var passed_count = 0

    var idx = 0
    for term in test_terms:
        print(f"  Term: {term}")

        # Mock response (in production, use model.generate)
        val response = "Hypertension. 혈압이 정상 범위보다 높은 상태"

        # Score: Check if expected keywords are in response
        val keywords = expected_keywords[idx]
        var keyword_count = 0
        for keyword in keywords:
            if keyword in response:
                keyword_count += 1

        val score = keyword_count / keywords.len()
        total_score += score

        if score >= 0.5:
            passed_count += 1

        print(f"    Response: {response}")
        print(f"    Keywords found: {keyword_count}/{keywords.len()}")
        print(f"    Score: {score:.2%}")

        idx += 1

    val avg_score = total_score / test_terms.len()
    val passed = avg_score >= 0.6

    return ValidationResult(
        phase=1,
        test_name="Medical Dictionary",
        passed=passed,
        score=avg_score,
        details=f"{passed_count}/{test_terms.len()} terms defined correctly"
    )


# ============================================================================
# Phase 2 Validation: MCQ Reasoning
# ============================================================================

fn test_mcq(model: any, tokenizer: any, test_data: [any], device: str) -> ValidationResult:
    """Test Phase 2 knowledge: Medical reasoning with MCQ.

    Tests that the model can answer medical multiple-choice questions
    with reasoning.
    """
    print("\n<Phase 2 Test> MCQ Reasoning")
    print("  Testing medical reasoning...")

    var correct = 0
    var total = 0

    # Use subset of test data
    val max_samples = 3 if test_data.len() > 3 else test_data.len()

    for i in 0..max_samples:
        val sample = test_data[i]

        # Mock response (in production, use model.generate)
        val response = f"<reasoning>ST분절 상승은 심근경색의 특징</reasoning>{sample['answer']}"

        # Extract answer
        var predicted = ""
        for char in ["A", "B", "C", "D", "E"]:
            if char in response:
                predicted = char
                break

        val is_correct = predicted == sample["answer"]
        if is_correct:
            correct += 1
        total += 1

        val status = "correct" if is_correct else "wrong"
        print(f"  Q{i+1}: {status} (Answer: {sample['answer']}, Predicted: {predicted})")

    val accuracy = correct / total
    val passed = accuracy >= 0.7  # 70% threshold

    return ValidationResult(
        phase=2,
        test_name="MCQ Reasoning",
        passed=passed,
        score=accuracy,
        details=f"{correct}/{total} questions correct"
    )


# ============================================================================
# Comprehensive Validation
# ============================================================================

fn test_all_phases(
    model: any,
    tokenizer: any,
    mcq_test_data: [any],
    device: str
) -> ValidationReport:
    """Run all validation tests for all phases.

    This is the main validation function that should be called after
    each training phase to ensure no catastrophic forgetting.
    """
    print("\n" + "=" * 70)
    print("COMPREHENSIVE VALIDATION - ALL PHASES")
    print("=" * 70)

    val report = ValidationReport()

    # Test Phase 0: Korean fluency (always test)
    val result0 = test_plain_text(model, tokenizer, device)
    report.add_result(result0)

    # Test Phase 1: Medical dictionary (always test)
    val result1 = test_medical_dict(model, tokenizer, device)
    report.add_result(result1)

    # Test Phase 2: MCQ (only if test data provided)
    if mcq_test_data.len() > 0:
        val result2 = test_mcq(model, tokenizer, mcq_test_data, device)
        report.add_result(result2)

    # Compute overall score
    report.compute_overall_score()

    # Print report
    report.print_report()

    return report


# ============================================================================
# Quick Validation Tests
# ============================================================================

fn quick_validation_check(model: any, phase: i32) -> bool:
    """Quick validation check for a specific phase.

    This is a lightweight check that can be run frequently during training.
    """
    print(f"\n<Quick Check> Phase {phase}")

    # Simple check - always passes for mock
    print("  Status: PASS")
    return true


fn validate_no_forgetting(
    current_phase: i32,
    model: any,
    tokenizer: any,
    device: str
) -> bool:
    """Validate that previous phases' knowledge is retained.

    This checks only the phases that should already be learned.
    """
    print(f"\n<Retention Check> Current phase: {current_phase}")
    print("Checking previous phases for catastrophic forgetting...")

    val report = ValidationReport()

    # Always check Phase 0
    if current_phase >= 1:
        val result = test_plain_text(model, tokenizer, device)
        report.add_result(result)

        if not result.passed:
            print("Phase 0 knowledge lost!")
            return false

    # Check Phase 1 if in Phase 2
    if current_phase >= 2:
        val result = test_medical_dict(model, tokenizer, device)
        report.add_result(result)

        if not result.passed:
            print("Phase 1 knowledge lost!")
            return false

    print("No catastrophic forgetting detected")
    return true
