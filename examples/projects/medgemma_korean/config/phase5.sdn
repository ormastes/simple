# Phase 5: Korean Translation (Note.md Phase 4)
# Front/back layer duplication + translation training

extends: "base.sdn"

training:
  epochs: 5
  learning_rate: 0.0003
  max_length: 1024

front_back_layers:
  enabled: true
  front_source: "layer1"
  back_source: "layer3"

subphases:
  a_epochs: 3
  b_epochs: 2

data:
  korean_text:
    path: "example/medgemma_korean/data/korean_text"
    format: "jsonl"
  translation:
    path: "example/medgemma_korean/data/korean_english_parallel"
    format: "jsonl"

previous_loras:
  - "example/medgemma_korean/models/phase4/lora_3"

output:
  lora_path: "example/medgemma_korean/models/phase5/lora_4"
  merged_path: "example/medgemma_korean/models/phase5/merged"

validation:
  test_korean_text: true
  test_translation: true
  test_english_retention: true
  retention_threshold: 0.97

tags:
  - "phase5"
  - "translation"
  - "front_back_layers"
  - "progressive_lora"
