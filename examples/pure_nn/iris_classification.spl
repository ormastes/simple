# Iris Classification - Complete Example
# Train a classifier on the Iris flower dataset

use lib.pure.autograd (Tensor, backward)
use lib.pure.nn (Linear, ReLU, Softmax, Sequential, count_parameters)
use lib.pure.training (Adam, Trainer, mse_loss)
use lib.pure.data (IrisDataset)

print "=== Iris Flower Classification ==="
print ""

# Load Iris dataset
print "Loading Iris dataset..."
val iris = IrisDataset.load_builtin()
print iris.to_string()
print ""

# Split into train/test
print "Splitting data (80/20 train/test)..."
val (train_data, test_data) = iris.split(0.8)
print "  Training samples: {train_data.len()}"
print "  Test samples: {test_data.len()}"
print ""

# Build classifier
print "Building neural network classifier..."
val model = Sequential.create([
    Linear.create(4, 8),      # 4 features -> 8 hidden
    ReLU.create(),
    Linear.create(8, 3),      # 8 hidden -> 3 classes
    Softmax.create()
])

print "Architecture:"
print model.to_string()
print "Parameters: {count_parameters(model)}"
print ""

# Create optimizer
print "Creating Adam optimizer (lr=0.01)..."
val optimizer = Adam.create(model.parameters(), lr: 0.01)
print ""

# Create trainer
print "Creating trainer with MSE loss..."
val trainer = Trainer.create(model, optimizer, mse_loss)
print ""

# Train
print "Training for 50 epochs..."
trainer.fit(train_data, epochs: 50, verbose: true)
print ""

# Evaluate on test set
print "=== Evaluation ==="
print ""

print "Test set predictions:"
for (i, (x, y_true)) in test_data.enumerate():
    val y_pred = model.forward(x)

    # Find predicted class (argmax)
    var max_idx = 0
    var max_val = y_pred.value.data[0]
    var j = 1
    while j < 3:
        if y_pred.value.data[j] > max_val:
            max_val = y_pred.value.data[j]
            max_idx = j
        j = j + 1

    # Find true class (argmax of one-hot)
    var true_idx = 0
    var k = 0
    while k < 3:
        if y_true.value.data[k] == 1.0:
            true_idx = k
        k = k + 1

    val class_names = ["Setosa", "Versicolor", "Virginica"]
    print "  Sample {i}:"
    print "    Predicted: {class_names[max_idx]} ({max_val:.2f})"
    print "    True:      {class_names[true_idx]}"
    print "    Correct:   {if max_idx == true_idx: 'Yes ✓' else: 'No ✗'}"
    print ""

# Compute accuracy
val test_acc = trainer.evaluate(test_data)
print "Test Accuracy: {test_acc * 100:.1f}%"
print ""

# Training history
val history = trainer.get_history()
print "Training History:"
print "  Total epochs: {history.epochs.len()}"
print "  Initial loss: {history.losses[0]:.4f}"
print "  Final loss:   {history.get_final_loss():.4f}"
val improvement = (1.0 - history.get_final_loss() / history.losses[0]) * 100
print "  Improvement:  {improvement:.1f}%"
print ""

# Summary
print "=== Summary ==="
print "✓ Iris dataset loaded (15 samples)"
print "✓ Neural network trained (4-8-3 architecture)"
print "✓ Adam optimizer used"
print "✓ Test accuracy: {test_acc * 100:.1f}%"
print ""
print "Iris classification is a classic 3-class problem:"
print "  - Setosa (class 0)"
print "  - Versicolor (class 1)"
print "  - Virginica (class 2)"
print ""
print "This demonstrates multi-class classification capability!"
