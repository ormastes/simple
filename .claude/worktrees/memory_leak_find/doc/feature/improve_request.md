# Improvement Requests

Track improvement ideas discovered while developing Simple standard library and applications.

## Summary (Updated 2026-01-05)

| Improvement | Status | Priority |
|-------------|--------|----------|
| Multi-Line Method Chaining | ‚úÖ Implemented | Medium |
| Triple-Quoted F-Strings | ‚úÖ Implemented | Low |
| String Multiplication | ‚úÖ Implemented | Low |
| Match Arrow Syntax | ‚úÖ Implemented | High |
| Function Return Type Annotations | ‚úÖ Implemented | High |
| Generic Type Syntax | ‚úÖ Implemented | High |
| Enum Variant Construction | ‚úÖ Implemented | Medium |
| Qualified Method Chains | ‚úÖ Implemented | Medium |
| Struct Literal Construction | ‚úÖ Implemented | Medium |
| Reserved Keyword Handling | ‚úÖ Implemented | High |
| Multi-line Dict Literals | ‚úÖ Implemented | Medium |
| Comprehensive File I/O API | ‚úÖ Partial (native funcs) | High |
| Enhanced String Methods | ‚úÖ Implemented | High |
| JSON Library | ‚úÖ Implemented | Medium |
| Error Handling (`?` operator) | ‚úÖ Implemented | Medium |
| Symbol Table Cross-Refs | ‚úÖ Implemented | Low |
| MCP Server Auto-Install for Claude Code | üîç PROPOSED | High |
| symbol_table_spec.spl timeout (>30s) | üîç PROPOSED | Medium |

**Summary:** 16 implemented, 1 partial, 0 blocked, 0 proposed

**BDD Spec Coverage:** 5 improvements now have dedicated BDD specs in `simple/std_lib/test/features/stdlib/`:
- JSON Library ‚Üí `json_spec.spl` (15 tests)
- File I/O API ‚Üí `file_io_spec.spl` (11 tests)
- Symbol Table ‚Üí `symbol_table_spec.spl` (18 tests)
- String Methods ‚Üí `string_methods_spec.spl` (20 tests)
- Try Operator ‚Üí `try_operator_spec.spl` (11 tests)

**What Remains:**
- **Comprehensive File I/O API** - Partial (native funcs work, full io.fs module needs variant support)

---

## Template

```markdown
### [Component] Brief description

**Type:** Improvement
**Category:** API Design | Performance | DX | Feature | Stdlib
**Priority:** High | Medium | Low
**Proposed:** YYYY-MM-DD
**Status:** Proposed | Accepted | Implemented | Rejected

**Problem:**
[What problem does this solve?]

**Proposed Solution:**
[How should we solve it?]

**Example:**
```simple
[Code example showing the improvement]
```

**Benefits:**
- [Benefit 1]
- [Benefit 2]

**Alternatives Considered:**
[Other approaches and why this is preferred]

**Impact:**
- Breaking changes: Yes/No
- Migration path: [if applicable]
```

---

## Active Requests

<!-- Add new improvement requests below this line -->

### [Parser] Multi-Line Method Chaining Support

**Type:** Improvement
**Category:** DX
**Priority:** Medium
**Proposed:** 2026-01-01
**Status:** ‚úÖ Partial (2026-01-05) - Same-level and trailing dot patterns implemented

**Problem:**
Method chaining across multiple lines originally failed to parse, forcing developers to use single-line chains or intermediate variables.

**What Works Now (2026-01-05):**

```simple
# Pattern 1: Trailing dot (dot at end of line)
let result = Builder.new().
    add(5).
    mul(2).
    build()

# Pattern 2: Dot at same indentation level (within module/function)
let r = obj.method1()
.method2()
.method3()

# Pattern 3: Single line (always worked)
let result = Builder.new().add(5).mul(2).build()
```

**What Does NOT Work (Limitation):**

```simple
# Indented dots are NOT supported due to lexer indentation tracking
# INDENT/DEDENT tokens signal block boundaries and cannot be consumed
# without breaking the parser's indentation state

let result = Builder.new()
    .add(5)      # ERROR: Indented dots break block structure
    .mul(2)
```

**Workaround for Indented Pattern:**
Use trailing dot style (dot at end of line) instead:

```simple
# Instead of indented dots, use trailing dots:
let result = Builder.new().
    add(5).
    mul(2).
    build()
```

**Technical Details:**

The limitation with indented dots is fundamental to how indentation-based parsing works:
- INDENT/DEDENT tokens are generated by the lexer based on indentation changes
- These tokens signal block structure (function bodies, if blocks, etc.)
- Consuming INDENT for method chaining corrupts the parser's indentation tracking
- This causes subsequent DEDENT tokens to be misinterpreted

**Implementation (2026-01-05):**
1. ‚úÖ `parse_postfix()` now handles `TokenKind::Newline` case
2. ‚úÖ Peeks through NEWLINE tokens to check for DOT
3. ‚úÖ Skips NEWLINE tokens when DOT follows
4. ‚úÖ Stops at INDENT/DEDENT to preserve block structure
5. ‚úÖ All existing tests pass (41 runner tests, 53 interpreter tests)

**Files Changed:**
- `src/parser/src/parser_helpers.rs` - `peek_through_newlines_and_indents_is()`, `skip_newlines_and_indents_for_method_chain()`
- `src/parser/src/expressions/mod.rs` - NEWLINE case in postfix loop (lines 869-878)

**Impact:**
- Breaking changes: No (only adds new capability)
- Existing code continues to work
- New code can use trailing-dot or same-level chaining patterns

---

### [Parser] Triple-Quoted F-String Support

**Type:** Improvement
**Category:** Feature
**Priority:** Low
**Proposed:** 2025-12-29
**Status:** Proposed

**Problem:**
F-strings with triple quotes (`f"""..."""`) cause "Unterminated f-string" parse errors.

**Current Spec Behavior:**
- `"..."` or `f"..."` - Interpolated strings (supports `{expr}`)
- `'...'` - Raw strings (NO interpolation, NO escapes)
- `"""..."""` - Doc comments only (not string values)

Triple-quoted strings are currently only for documentation comments, not multi-line string values with interpolation.

**Proposed Solution:**
Add parser support for `f"""..."""` (triple-quoted f-strings) to allow multi-line string templates with interpolation, without requiring `\n` escapes.

**Example:**
```simple
# Works: Single-line f-string
let msg = f"Hello, {name}!"

# Works: F-string with \n escapes
let markdown = f"# {name}\n\n**ID:** #{id}\n"

# Doesn't work: Triple-quoted f-string
let markdown = f"""# {name}

**ID:** #{id}
"""
# Error: Unterminated f-string

# Current workaround: Use \n escapes
let markdown = f"# {name}\n\n**ID:** #{id}\n"
```

**Benefits:**
- More readable multi-line templates
- Consistent with Python f-strings
- Natural formatting for markdown/HTML generation
- Reduces need for `\n` escapes

**Alternatives Considered:**
- Use `\n` escapes - current workaround, works but less readable
- Use string concatenation - more verbose
- Regular triple-quoted strings - no interpolation

**Impact:**
- Breaking changes: No (new feature addition)
- Files affected: Templates and documentation generators
- Related: BDD Feature Documentation (#SESSION-6)

**Note:** Single-line f-strings work perfectly. This is only about triple-quoted multi-line f-strings.

---

### [Core] String Multiplication Operator

**Type:** Improvement
**Category:** Feature
**Priority:** Low
**Proposed:** 2025-12-29
**Status:** ‚úÖ Implemented (verified 2026-01-04)

**Problem:**
String multiplication syntax (`"x" * n`) is not supported, forcing manual repetition for common patterns like separators and padding.

**Proposed Solution:**
Implement string multiplication operator to repeat strings:

**Example:**
```simple
# Desired syntax (doesn't work):
separator = "=" * 60
indent = " " * 4

# Current workaround (manual):
separator = "============================================================"
indent = "    "
```

**Benefits:**
- Cleaner code for repeated strings
- Common pattern in Python and other languages
- Useful for formatting and alignment
- Reduces magic constants

**Alternatives Considered:**
- Repeat function: `String.repeat("x", n)` - more verbose but could work
- Manual repetition - current approach, error-prone

**Impact:**
- Breaking changes: No (new feature)
- Migration path: Optional, manual strings still work
- Implementation: Operator overloading in interpreter/codegen

---

### [Parser] Match Expression Arrow Syntax Support

**Type:** Improvement
**Category:** Feature
**Priority:** High
**Proposed:** 2025-12-25
**Status:** ‚úÖ Implemented (verified 2026-01-04)

**Problem:**
Match expressions with arrow syntax (`->`) are specified in the language but not implemented in the parser. This blocks compilation of idiomatic Simple code including the LMS implementation.

**Proposed Solution:**
Implement parser support for match expressions with arrow syntax:

**Example:**
```simple
match value:
    Some(x) ->
        x + 1
    None ->
        0
```

Current parser expects `case Pattern:` but language spec requires `Pattern ->`.

**Benefits:**
- Enables functional pattern matching style
- Matches language specification
- Unblocks LMS server implementation (~930 lines)
- Consistent with Rust/ML-family language syntax

**Alternatives Considered:**
- Keep `case Pattern:` syntax - rejected (not in spec)
- Support both syntaxes - adds complexity

**Impact:**
- Breaking changes: No (feature addition)
- Files blocked: error.spl, protocol.spl, server.spl
- Related: #1200-1209 (LMS implementation)

---

### [Parser] Function Return Type Annotations

**Type:** Improvement
**Category:** Feature
**Priority:** High
**Proposed:** 2025-12-25
**Status:** ‚úÖ Implemented (verified 2026-01-04)

**Problem:**
Function return type annotations (`fn name() -> Type:`) are not parsed correctly. Parser fails with "expected identifier, found Result/Option/etc".

**Proposed Solution:**
Implement parser support for `-> Type` return type syntax in function signatures.

**Example:**
```simple
fn read_file(path: String) -> Result[String, Error]:
    # implementation
```

**Benefits:**
- Type safety and documentation
- Required for Result/Option return types
- Enables compiler type checking
- Matches language specification

**Alternatives Considered:**
- Type inference only - loses explicit documentation and early error detection

**Impact:**
- Breaking changes: No (feature addition)
- Files blocked: All LMS files (transport.spl, error.spl, protocol.spl, session.spl, server.spl, main.spl)
- Related: #1200-1209 (LMS implementation)

---

### [Parser] Generic Type Syntax in Type Positions

**Type:** Improvement
**Category:** Feature
**Priority:** High
**Proposed:** 2025-12-25
**Status:** ‚úÖ Implemented (verified 2026-01-04)

**Problem:**
Generic types like `Result[T, E]`, `Option[T]`, `Dict[K, V]` are not recognized by the parser in return type positions and field declarations.

**Proposed Solution:**
Implement parser support for square bracket generic syntax in all type positions.

**Example:**
```simple
class Server:
    cache: Dict[String, String]
    session: Option[Session]

fn process() -> Result[Int, Error]:
    Ok(42)
```

**Benefits:**
- Enables type-safe collections and error handling
- Required for Result/Option types
- Matches modern language conventions
- Unblocks stdlib development

**Alternatives Considered:**
- Use angle brackets `<>` - conflicts with comparison operators
- No generics - loses type safety

**Impact:**
- Breaking changes: No (feature addition)
- Files blocked: All LMS files
- Related: #1200-1209 (LMS implementation)

---

### [Parser] Enum Variant Construction Syntax ‚úÖ IMPLEMENTED

**Type:** Improvement
**Category:** Feature
**Priority:** Medium
**Proposed:** 2025-12-25
**Status:** ‚úÖ IMPLEMENTED (2026-01-04)

**Implementation:**
Enum variant construction with `EnumName.Variant(args)` syntax is now fully supported.

The implementation includes:
1. `Value::EnumType` - Represents an enum type (like `Color`)
2. `Value::EnumVariantConstructor` - Represents a variant constructor for variants with data
3. Enum types are registered in the environment during module evaluation
4. Identifier resolution checks enums and returns `EnumType`
5. Field access on `EnumType` returns the variant value (unit) or constructor
6. Method calls on `EnumType` construct variants with data

**Example:**
```simple
enum LmsError:
    MethodNotFound(String)
    InvalidParams(String)

let error = LmsError.MethodNotFound("initialize")  # Works!

enum Color:
    Red
    Green
    Blue

let c = Color.Red  # Works!
```

**Files Changed:**
- `src/compiler/src/value.rs` - Added `EnumType`, `EnumVariantConstructor` variants
- `src/compiler/src/interpreter_eval.rs` - Register enums in env
- `src/compiler/src/interpreter_expr.rs` - Enum lookup in identifier resolution, field access handling
- `src/compiler/src/interpreter_method/mod.rs` - Method call handling for variant construction
- `src/compiler/src/interpreter_module.rs` - Export enums as `EnumType`
- `src/compiler/src/interpreter_call/mod.rs` - Call handling for `EnumVariantConstructor`
- `src/compiler/src/value_*.rs` - Pattern matching updates

---

### [Parser] Qualified Method Call Chains ‚úÖ IMPLEMENTED

**Type:** Improvement
**Category:** Feature
**Priority:** Medium
**Proposed:** 2025-12-25
**Status:** ‚úÖ Implemented (2026-01-05)

**Implementation:**
Multi-level qualified method calls and field access work correctly. The previous issue was testing with non-existent modules.

**Example:**
```simple
class Time:
    fn now_ms() -> Int:
        return 1000

class Sys:
    time: Time

let sys = Sys { time: Time {} }
let timestamp = sys.time.now_ms()  # Works: 1000
let name = session.client_info.name  # Works if objects exist
```

**What Works:**
- `outer.middle.inner.method()` - Chained field access + method call
- `a.b.c.d()` - Any depth of nesting
- Method calls with arguments on nested objects

**Benefits:**
- Enables namespace organization
- Required for stdlib module structure
- Natural method chaining

**Note:** The original report of "expected Comma, found Dot" was likely due to testing with undefined modules.

---

### [Parser] Struct Literal Construction Syntax

**Type:** Improvement
**Category:** Feature
**Priority:** Medium
**Proposed:** 2025-12-25
**Status:** ‚úÖ Implemented (verified 2026-01-04)

**Problem:**
Struct/class construction with field names `ClassName { field: value }` is not parsed.

**Proposed Solution:**
Support struct literal syntax for class instantiation.

**Example:**
```simple
let info = protocol.ClientInfo {
    name: "claude",
    version: "1.0.0"
}
```

**Benefits:**
- Clear field initialization
- Self-documenting code
- Prevents field order mistakes

**Alternatives Considered:**
- Positional construction only - error-prone for many fields

**Impact:**
- Breaking changes: No (feature addition)
- Files blocked: server.spl, protocol.spl
- Related: #1200-1209 (LMS implementation)

---

### [Parser] Reserved Keyword Handling for Parameter Names

**Type:** Improvement
**Category:** Feature
**Priority:** High
**Proposed:** 2025-12-25
**Status:** ‚úÖ Implemented (2025-12-25)

**Problem:**
Using `result` as a parameter name causes "expected identifier, found Result" error because `Result` is a built-in type. The parser treats lowercase `result` as conflicting with the capitalized `Result` type.

**Proposed Solution:**
Allow lowercase identifiers that match type names (e.g., `result`, `option`, `string`) to be used as parameter/variable names. Only treat capitalized identifiers as type references in type positions.

**Example:**
```simple
# Should work:
pub fn success_response(id: Int, result: Dict) -> Dict:
    return {"jsonrpc": "2.0", "id": id, "result": result}

# Currently fails with "expected identifier, found Result"
```

**Benefits:**
- Natural parameter naming (e.g., `result` for Result types)
- Matches conventions in other languages (Rust allows `result` variable names)
- Less surprising behavior

**Alternatives Considered:**
- Rename all conflicting parameters (current workaround) - verbose and unnatural
- Make `Result` not a keyword - would break type system

**Impact:**
- Breaking changes: No (relaxing restrictions)
- Files affected: error.spl, transport.spl, protocol.spl (can now use original parameter names)
- Related: #1200-1209 (LMS implementation)

**Implementation:**
Modified `expect_identifier()` in `src/parser/src/parser_helpers.rs` to accept contextual keywords (`Result`, `Type`, `Out`, `OutErr`) as identifiers. These tokens are now treated as regular identifiers in parameter/variable contexts while remaining keywords only in their specific contract/type contexts.

---

### [Parser] Multi-line Dictionary Literal Support

**Type:** Improvement
**Category:** Feature
**Priority:** Medium
**Proposed:** 2025-12-25
**Status:** ‚úÖ Implemented (2025-12-25)

**Problem:**
Dict literals cannot span multiple lines. Opening brace on new line or nested structures fail with "expected expression, found Newline".

**Proposed Solution:**
Support multi-line Dict literals with proper indentation handling, similar to Python dicts or JSON.

**Example:**
```simple
# Should work:
let response = {
    "jsonrpc": "2.0",
    "id": id,
    "error": {
        "code": code,
        "message": message
    }
}

# Currently must be single-line:
let error_obj = {"code": code, "message": message}
let response = {"jsonrpc": "2.0", "id": id, "error": error_obj}
```

**Benefits:**
- More readable code for complex data structures
- Consistent with other languages (Python, JavaScript, JSON)
- Reduces need for intermediate variables

**Alternatives Considered:**
- Single-line only (current) - forces awkward splitting into multiple statements
- Builder pattern - too verbose for simple dictionaries

**Impact:**
- Breaking changes: No (feature addition)
- Files affected: All LMS files can now use multiline Dicts
- Related: #1200-1209 (LMS implementation)

**Implementation:**
Modified Dict literal parsing in `src/parser/src/expressions/primary.rs` to skip `Newline` tokens at key positions: after opening brace, before/after colon, after comma, and after values. This allows Dict literals to span multiple lines with arbitrary formatting.

---

### [Stdlib] Comprehensive File I/O API ‚úÖ PARTIALLY IMPLEMENTED

**Type:** Improvement
**Category:** Stdlib
**Priority:** High
**Proposed:** 2025-12-26
**Status:** ‚úÖ Partially Implemented (2026-01-04)

**Implementation:**
Native file I/O functions are now available via extern function declarations:

```simple
# Currently Available ‚úÖ
extern fn native_fs_read(path: Str) -> Any      # Read file as byte array
extern fn native_fs_write(path: Str, data: Array[Int]) -> Any  # Write bytes
extern fn native_fs_metadata(path: Str) -> Any  # Get file metadata

# Async file operations
extern fn native_async_file_open(path: Str, mode: Str) -> Any
extern fn native_async_file_read(handle: Any, size: Int) -> Any
extern fn native_async_file_write(handle: Any, data: Array[Int]) -> Any
extern fn native_async_file_close(handle: Any) -> Any
```

**Example:**
```simple
extern fn native_fs_read(path: Str) -> Any
extern fn native_fs_write(path: Str, data: Array[Int]) -> Any

# Read file (returns Ok([bytes...]) or Err(message))
let result = native_fs_read("/path/to/file")

# Write file (data as byte array)
let data = [104, 101, 108, 108, 111, 10]  # "hello\n"
let result = native_fs_write("/tmp/output.txt", data)
```

**Remaining Work:**
- Higher-level wrapper functions (read_file returning String, etc.)
- Directory listing operations
- Path manipulation utilities
- Integration with stdlib module structure

**Files Implemented:**
- `src/runtime/src/value/file_io/file_ops.rs` - Core file operations
- `src/runtime/src/value/file_io/mmap.rs` - Memory-mapped files
- `src/compiler/src/interpreter_call/block_execution.rs` - Extern fn in BDD blocks

---

### [Core] Enhanced String Methods ‚úÖ IMPLEMENTED

**Type:** Improvement
**Category:** API Design
**Priority:** High
**Proposed:** 2025-12-26
**Status:** ‚úÖ Implemented (2026-01-04)

**Implementation:**
Comprehensive string methods are now available in the interpreter. All requested methods work:

```simple
# Substring operations ‚úÖ
text.substring(0, 5)      # Extract substring by indices
text.slice(0, 5)          # Alias for substring
text.char_at(0)           # Get character at index
text.at(0)                # Alias for char_at
text.chars()              # List of characters

# Search operations ‚úÖ
text.find("pattern")      # Returns Some(index) or None
text.rfind("pattern")     # Find from right
text.index_of("pattern")  # Alias for find
text.contains("sub")      # Check if contains
text.starts_with("pre")   # Check prefix
text.ends_with("suf")     # Check suffix

# Whitespace operations ‚úÖ
text.strip()              # Remove leading/trailing whitespace
text.trim()               # Alias for strip
text.trimmed()            # Alias for strip
text.trim_start()         # Remove leading whitespace
text.trim_end()           # Remove trailing whitespace

# Case operations ‚úÖ
text.to_upper()           # Uppercase
text.to_lower()           # Lowercase

# Splitting/joining ‚úÖ
text.split(",")           # Split by delimiter
text.lines()              # Split by newlines
text.split_lines()        # Alias for lines

# Replacement ‚úÖ
text.replace("old", "new")       # Replace first occurrence
text.replace_first("old", "new") # Alias for replace

# Additional methods ‚úÖ
text.repeat(3)            # Repeat string n times
text.reverse()            # Reverse string
text.sorted()             # Sort characters
text.take(5)              # First n characters
text.drop(5)              # Skip first n characters
text.pad_left(10, " ")    # Left pad
text.pad_right(10, " ")   # Right pad
text.is_numeric()         # Check if all numeric
text.is_alpha()           # Check if all alphabetic
text.is_alphanumeric()    # Check if alphanumeric
text.is_whitespace()      # Check if all whitespace
text.is_empty()           # Check if empty
text.len()                # String length
text.count("sub")         # Count occurrences
text.parse_int()          # Parse to integer
text.parse_float()        # Parse to float
```

**Files Changed:**
- `src/compiler/src/interpreter_method/string.rs` - All string method implementations

---

### [MCP] JSON Library for Structured Output ‚úÖ IMPLEMENTED

**Type:** Improvement
**Category:** Stdlib
**Priority:** Medium
**Proposed:** 2025-12-26
**Status:** ‚úÖ Implemented (2026-01-05)

**Implementation:**
Full JSON library implemented in `simple/std_lib/src/compiler_core/json.spl` (448 lines):

**Features:**
- `JsonValue` enum: Null, Bool, Number, Integer, String, Array, Object
- `JsonParser` class with complete recursive descent parser
- `parse()` function - Parse JSON string to JsonValue
- `stringify()` function - Serialize JsonValue to string
- `stringify_pretty()` function - Pretty-print with indentation
- `JsonBuilder` class with fluent API
- Helper functions: `get_string`, `get_int`, `get_object`, `get_array`

**Example:**
```simple
import core.json

# Parse JSON
result = json.parse("{\"name\": \"alice\", \"age\": 30}")
match result.unwrap():
    case JsonValue.Object(obj):
        print(obj.get("name"))

# Build JSON with builder
s = JsonBuilder.new()
    .set_string("name", "bob")
    .set_int("age", 25)
    .to_string()
# {"name": "bob", "age": 25}

# Serialize manually
val = JsonValue.Object({"key": JsonValue.String("value")})
json.stringify(val)  # {"key": "value"}
```

**Files:**
- Implementation: `simple/std_lib/src/compiler_core/json.spl`
- Tests: `simple/std_lib/test/unit/compiler_core/json_spec.spl`

---

### [Language] Better Error Handling for Option/Result ‚úÖ IMPLEMENTED

**Type:** Improvement
**Category:** DX
**Priority:** Medium
**Proposed:** 2025-12-26
**Status:** ‚úÖ Implemented (2026-01-05)

**Implementation:**
The `?` operator for Result/Option propagation is fully implemented in parser and interpreter.

**How it works:**
- For `Result[T, E]`: Unwraps `Ok(value)` or early-returns `Err(e)`
- For `Option[T]`: Unwraps `Some(value)` or early-returns `None`

**Example:**
```simple
fn divide(a: i64, b: i64) -> Result[i64, String]:
    if b == 0:
        return Err("division by zero")
    return Ok(a / b)

fn compute(a: i64, b: i64, c: i64) -> Result[i64, String]:
    step1 = divide(a, b)?    # Returns Err if b == 0
    step2 = divide(step1, c)?  # Returns Err if c == 0
    return Ok(step2)

# Usage
result = compute(100, 5, 2)  # Ok(10)
result = compute(100, 0, 2)  # Err("division by zero")
```

**Files Changed:**
- Parser: `src/parser/src/expressions/mod.rs:855-858` - `Expr::Try` postfix operator
- Interpreter: `src/compiler/src/interpreter_expr.rs:1383+` - Try expression evaluation
- Error type: `src/compiler/src/error.rs:331` - `CompileError::TryError(Value)`
- Call handling: `src/compiler/src/interpreter_call/core.rs:50,479` - Error propagation

**Tests:**
- Rust tests: `src/driver/tests/interpreter_advanced_features_tests.rs:221-290`
- Simple tests: `simple/std_lib/test/unit/compiler_core/try_operator_spec.spl`

**Benefits:**
- Cleaner error handling code
- Encourages proper error propagation
- Familiar to Rust developers
- Reduces boilerplate

---

### [MCP] Symbol Table with Cross-Reference Support ‚úÖ IMPLEMENTED

**Type:** Improvement
**Category:** Feature
**Priority:** Low
**Proposed:** 2025-12-26
**Status:** ‚úÖ Implemented (2026-01-05)

**Implementation:**

Full symbol table with cross-reference support implemented in `simple/std_lib/src/mcp/simple_lang/symbol_table.spl`.

**Features Implemented:**

1. **RefKind enum** - Reference types: Import, Call, Implements, Inherits, Uses, Instantiates, Overrides
2. **SourceLocation class** - File, line, column tracking
3. **Reference class** - Tracks from_symbol ‚Üí to_symbol with kind and location
4. **QualifiedSymbol class** - Symbol with module path and optional parent
5. **SymbolTable class** - Main symbol table with all query methods

**Query Methods:**
- `find_references(symbol)` - Find all references TO a symbol
- `find_outgoing_references(symbol)` - Find all references FROM a symbol
- `find_implementations(trait)` - Find all implementations of a trait
- `find_subclasses(class)` - Find all subclasses of a class
- `find_callers(func)` - Find all callers of a function
- `find_callees(func)` - Find all functions called by a function
- `find_type_usages(type)` - Find all usages of a type
- `find_instantiations(type)` - Find all instantiations of a type
- `build_call_graph()` - Build function ‚Üí [called functions] graph
- `build_reverse_call_graph()` - Build function ‚Üí [callers] graph
- `get_inheritance_chain(class)` - Get full inheritance chain
- `get_symbols_by_kind(kind)` - Filter by SymbolKind
- `get_public_symbols()` - Get all public symbols
- `stats()` - Get symbol table statistics

**Helper Functions:**
- `extract_references(source, module_path, symbols)` - Extract refs from source
- `build_symbol_table(files)` - Build table from FileContext list

**Example:**
```simple
use mcp.simple_lang.*

# Build symbol table from files
ctx1 = FileContext.new("parser.spl", source1)
ctx1.symbols = parse_file(source1)

ctx2 = FileContext.new("main.spl", source2)
ctx2.symbols = parse_file(source2)

table = build_symbol_table([ctx1, ctx2])

# Find all references to a symbol
refs = table.find_references("Parser")

# Find all implementations of a trait
impls = table.find_implementations("Serializer")

# Build call graph
graph = table.build_call_graph()

# Get statistics
stats = table.stats()
print("Total symbols: {stats.get('total_symbols')}")
print("Call references: {stats.get('call_refs')}")
```

**Files:**
- Implementation: `simple/std_lib/src/mcp/simple_lang/symbol_table.spl`
- Tests: `simple/std_lib/test/unit/mcp/symbol_table_spec.spl`
- Export: `simple/std_lib/src/mcp/simple_lang/__init__.spl`

**Benefits:**
- Better code navigation in MCP
- Foundation for LSP implementation
- Call graph visualization
- Impact analysis
