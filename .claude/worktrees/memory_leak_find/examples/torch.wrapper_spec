# PyTorch Wrapper Specification
# Auto-generates three-tier SFFI wrapper for PyTorch

wrapper_lib:
  name: torch
  version: "0.1.0"
  link: [torch, c10]
  search_paths: ["/usr/local/lib", "/opt/libtorch/lib"]
  cpp_include: "torch/torch.h"
  include_paths: ["/opt/libtorch/include", "/opt/libtorch/include/torch/csrc/api/include"]

handle_types:
  - name: TorchTensor
    cpp_type: "torch::Tensor"
    drop_fn: "rt_torch_torchtensor_free"

  - name: TorchStream
    cpp_type: "c10::Stream"
    drop_fn: "rt_torch_stream_free"

functions:
  # Tensor creation
  - name: tensor_zeros
    cpp_fn: "torch::zeros"
    params:
      - name: dims
        type: "[i64]"
    return: TorchTensor

  - name: tensor_ones
    cpp_fn: "torch::ones"
    params:
      - name: dims
        type: "[i64]"
    return: TorchTensor

  - name: tensor_randn
    cpp_fn: "torch::randn"
    params:
      - name: dims
        type: "[i64]"
    return: TorchTensor

  # Backend detection
  - name: available
    cpp_fn: "[]() { return true; }"
    params: []
    return: bool

  - name: cuda_available
    cpp_fn: "torch::cuda::is_available"
    params: []
    return: bool

  - name: version
    cpp_fn: "[]() { return std::string(\"torch 0.1.0 (cxx bridge)\"); }"
    params: []
    return: text

  # Stream management
  - name: stream_create
    cpp_fn: "[](i32 device_id) { auto device = torch::Device(torch::kCUDA, device_id); return c10::cuda::getStreamFromPool(false, device.index()); }"
    params:
      - name: device_id
        type: i32
    return: TorchStream

methods:
  # Tensor operations
  - handle: TorchTensor
    name: add
    cpp_method: "add"
    params:
      - name: other
        type: TorchTensor
    return: TorchTensor

  - handle: TorchTensor
    name: mul
    cpp_method: "mul"
    params:
      - name: other
        type: TorchTensor
    return: TorchTensor

  - handle: TorchTensor
    name: matmul
    cpp_method: "matmul"
    params:
      - name: other
        type: TorchTensor
    return: TorchTensor

  # Tensor properties
  - handle: TorchTensor
    name: ndim
    cpp_method: "dim"
    params: []
    return: i64

  - handle: TorchTensor
    name: numel
    cpp_method: "numel"
    params: []
    return: i64

  - handle: TorchTensor
    name: shape
    cpp_method: "sizes"
    params: []
    return: "[i64]"

  # Activations
  - handle: TorchTensor
    name: relu
    cpp_method: "relu"
    params: []
    return: TorchTensor

  - handle: TorchTensor
    name: sigmoid
    cpp_method: "sigmoid"
    params: []
    return: TorchTensor

  - handle: TorchTensor
    name: tanh
    cpp_method: "tanh"
    params: []
    return: TorchTensor

  # Device management
  - handle: TorchTensor
    name: cuda
    cpp_method: "[](const auto& t, i32 device_id) { auto device = torch::Device(torch::kCUDA, device_id); return t.to(device); }"
    params:
      - name: device_id
        type: i32
    return: TorchTensor

  - handle: TorchTensor
    name: cpu
    cpp_method: "cpu"
    params: []
    return: TorchTensor

  - handle: TorchTensor
    name: is_cuda
    cpp_method: "is_cuda"
    params: []
    return: bool

  # Stream operations
  - handle: TorchTensor
    name: to_stream
    cpp_method: ""
    params:
      - name: device_id
        type: i32
      - name: stream
        type: TorchStream
    return: TorchTensor

  - handle: TorchStream
    name: sync
    cpp_method: ""
    params: []
    return: void

  - handle: TorchStream
    name: query
    cpp_method: ""
    params: []
    return: bool
