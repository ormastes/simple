# Thread & Concurrency - SFFI + Shell Fallbacks
#
# Thread operations and atomic stubs.
# Self-contained: uses rt_process_run directly to avoid circular import from mod.spl.

extern fn rt_thread_available_parallelism() -> i64
extern fn rt_getpid() -> i64
extern fn rt_process_run(cmd: text, args: [text]) -> (text, text, i64)

fn thread_available_parallelism() -> i64:
    # Number of logical CPUs via SFFI
    rt_thread_available_parallelism()

fn thread_sleep_ms(duration_ms: i64):
    # Sleep for specified milliseconds using shell sleep command
    val seconds = duration_ms / 1000
    val remainder = duration_ms % 1000
    var sleep_arg = ""
    if seconds > 0 and remainder > 0:
        sleep_arg = "{seconds}.{remainder}"
    elif seconds > 0:
        sleep_arg = "{seconds}"
    elif remainder > 0:
        sleep_arg = "0.{remainder}"
    if sleep_arg != "":
        rt_process_run("/bin/sh", ["-c", "sleep {sleep_arg}"])

fn thread_yield():
    # Yield current thread (no-op - rt_thread_yield not in runtime)
    pass

fn thread_current_id() -> i64:
    # Current thread ID (use PID as fallback - rt_thread_current_id not in runtime)
    rt_getpid()

# --- Atomic Operations (stubs - rt_atomic_* not in runtime) ---
# These provide correct single-threaded semantics.
# True atomic ops require runtime support.

fn atomic_i64_load(atomic_ref: i64) -> i64:
    atomic_ref

fn atomic_i64_store(atomic_ref: i64, new_value: i64) -> i64:
    new_value

fn atomic_i64_fetch_add(atomic_ref: i64, add_value: i64) -> i64:
    atomic_ref

fn atomic_i64_compare_exchange(atomic_ref: i64, expected: i64, desired: i64) -> i64:
    if atomic_ref == expected:
        desired
    else:
        atomic_ref

export thread_available_parallelism, thread_sleep_ms, thread_yield, thread_current_id
export atomic_i64_load, atomic_i64_store, atomic_i64_fetch_add, atomic_i64_compare_exchange
