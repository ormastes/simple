# Database Statistics Module
#
# Shared statistical analysis functions for database libraries.
# Used by TestDatabase (flaky detection, timing analysis) and BugDatabase (trends).
#
# Functions:
# - Percentile calculations (p50, p90, p95, p99)
# - Outlier detection (IQR method)
# - Mean, median, standard deviation
# - Flaky test detection (coefficient of variation)

# Statistics result structure
struct Stats:
    mean: f64
    median: f64      # p50
    std_dev: f64
    p50: f64
    p90: f64
    p95: f64
    p99: f64
    min: f64
    max: f64
    count: i64
    iqr: f64         # Interquartile range (p75 - p25)

# Create Stats from array of values (standalone function for bootstrap runtime)
fn stats_from_values(values: [f64]) -> Stats:
    if values.len() == 0:
        return Stats(
            mean: 0.0, median: 0.0, std_dev: 0.0,
            p50: 0.0, p90: 0.0, p95: 0.0, p99: 0.0,
            min: 0.0, max: 0.0, count: 0, iqr: 0.0
        )

    var sorted = values.clone()
    sorted.sort()

    val n = sorted.len()
    val mean_val = calculate_mean(sorted)
    val std_val = calculate_std_dev(sorted, mean_val)

    Stats(
        mean: mean_val,
        median: percentile(sorted, 50.0),
        std_dev: std_val,
        p50: percentile(sorted, 50.0),
        p90: percentile(sorted, 90.0),
        p95: percentile(sorted, 95.0),
        p99: percentile(sorted, 99.0),
        min: sorted[0],
        max: sorted[n - 1],
        count: n,
        iqr: percentile(sorted, 75.0) - percentile(sorted, 25.0)
    )

impl Stats:
    fn from_values(values: [f64]) -> Stats:
        stats_from_values(values)

# Calculate percentile from sorted values
fn percentile(sorted_values: [f64], p: f64) -> f64:
    if sorted_values.len() == 0:
        return 0.0

    val n = sorted_values.len()
    val index = (p / 100.0) * (n - 1)
    val lower = index.floor()
    val upper = index.ceil()

    if lower == upper:
        return sorted_values[lower as i64]

    # Linear interpolation
    val lower_val = sorted_values[lower as i64]
    val upper_val = sorted_values[upper as i64]
    val fraction = index - lower

    lower_val + (upper_val - lower_val) * fraction

# Calculate mean
fn calculate_mean(values: [f64]) -> f64:
    if values.len() == 0:
        return 0.0

    var sum = 0.0
    for v in values:
        sum = sum + v

    sum / values.len() as f64

# Calculate standard deviation
fn calculate_std_dev(values: [f64], mean: f64) -> f64:
    if values.len() <= 1:
        return 0.0

    var sum_sq_diff = 0.0
    for v in values:
        val diff = v - mean
        sum_sq_diff = sum_sq_diff + (diff * diff)

    val variance = sum_sq_diff / (values.len() - 1) as f64
    variance.sqrt()

# Calculate coefficient of variation (std_dev / mean)
# Used for flaky test detection: high CV = flaky
fn coefficient_of_variation(values: [f64]) -> f64:
    if values.len() == 0:
        return 0.0

    val mean_val = calculate_mean(values)
    if mean_val == 0.0:
        return 0.0

    val std_val = calculate_std_dev(values, mean_val)
    std_val / mean_val

# Detect outliers using IQR method
# Returns indices of outlier values
fn detect_outliers_iqr(values: [f64]) -> [i64]:
    if values.len() < 4:
        return []

    var sorted = values.clone()
    sorted.sort()

    val q1 = percentile(sorted, 25.0)
    val q3 = percentile(sorted, 75.0)
    val iqr = q3 - q1

    # Outliers are > 1.5 * IQR beyond Q1/Q3
    val lower_bound = q1 - 1.5 * iqr
    val upper_bound = q3 + 1.5 * iqr

    var outlier_indices: [i64] = []
    var i = 0
    while i < values.len():
        val v = values[i]
        if v < lower_bound or v > upper_bound:
            outlier_indices.push(i)
        i = i + 1

    outlier_indices

# Detect if test is flaky based on timing variance
# Returns true if coefficient of variation > threshold
fn is_flaky(timings: [f64], cv_threshold: f64) -> bool:
    if timings.len() < 3:
        return false  # Need multiple runs to detect flaky

    val cv = coefficient_of_variation(timings)
    cv > cv_threshold

# Calculate rolling average (last N values)
fn rolling_average(values: [f64], window_size: i64) -> f64:
    if values.len() == 0:
        return 0.0

    val start = if values.len() > window_size:
        values.len() - window_size
    else:
        0

    var sum = 0.0
    var i = start
    while i < values.len():
        sum = sum + values[i]
        i = i + 1

    sum / (values.len() - start) as f64

# Update baseline with exponential moving average
# alpha = smoothing factor (0.0-1.0), higher = more weight on new value
fn update_baseline(current_baseline: f64, new_value: f64, alpha: f64) -> f64:
    alpha * new_value + (1.0 - alpha) * current_baseline

# Detect significant change from baseline
# Returns true if new_value is > threshold% different from baseline
fn is_significant_change(baseline: f64, new_value: f64, threshold_percent: f64) -> bool:
    if baseline == 0.0:
        return false

    val percent_diff = ((new_value - baseline).abs() / baseline) * 100.0
    percent_diff > threshold_percent

export Stats, stats_from_values
export percentile, calculate_mean, calculate_std_dev
export coefficient_of_variation, detect_outliers_iqr
export is_flaky, rolling_average, update_baseline, is_significant_change
