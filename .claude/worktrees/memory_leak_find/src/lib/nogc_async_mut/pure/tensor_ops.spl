# Pure Simple Tensor Operations
#
# All tensor operations implemented in pure Simple
# Zero external dependencies

use std.pure.tensor.{PureTensor, tensor_from_data}

# ============================================================================
# Element-wise Operations
# ============================================================================

fn add(a: PureTensor<f64>, b: PureTensor<f64>) -> PureTensor<f64>:
    """Element-wise addition."""
    var result_data: [f64] = []
    var i = 0
    while i < a.data.len():
        result_data.push(a.data[i] + b.data[i])
        i = i + 1
    tensor_from_data(result_data, a.shape)

fn sub(a: PureTensor<f64>, b: PureTensor<f64>) -> PureTensor<f64>:
    """Element-wise subtraction."""
    var result_data: [f64] = []
    var i = 0
    while i < a.data.len():
        result_data.push(a.data[i] - b.data[i])
        i = i + 1
    tensor_from_data(result_data, a.shape)

fn mul(a: PureTensor<f64>, b: PureTensor<f64>) -> PureTensor<f64>:
    """Element-wise multiplication."""
    var result_data: [f64] = []
    var i = 0
    while i < a.data.len():
        result_data.push(a.data[i] * b.data[i])
        i = i + 1
    tensor_from_data(result_data, a.shape)

fn div(a: PureTensor<f64>, b: PureTensor<f64>) -> PureTensor<f64>:
    """Element-wise division."""
    var result_data: [f64] = []
    var i = 0
    while i < a.data.len():
        result_data.push(a.data[i] / b.data[i])
        i = i + 1
    tensor_from_data(result_data, a.shape)

fn mul_scalar(t: PureTensor<f64>, scalar: f64) -> PureTensor<f64>:
    """Multiply tensor by scalar."""
    var result_data: [f64] = []
    for v in t.data:
        result_data.push(v * scalar)
    tensor_from_data(result_data, t.shape)

fn add_scalar(t: PureTensor<f64>, scalar: f64) -> PureTensor<f64>:
    """Add scalar to tensor."""
    var result_data: [f64] = []
    for v in t.data:
        result_data.push(v + scalar)
    tensor_from_data(result_data, t.shape)

fn div_scalar(t: PureTensor<f64>, scalar: f64) -> PureTensor<f64>:
    """Divide tensor by scalar."""
    var result_data: [f64] = []
    for v in t.data:
        result_data.push(v / scalar)
    tensor_from_data(result_data, t.shape)

fn neg(t: PureTensor<f64>) -> PureTensor<f64>:
    """Element-wise negation."""
    var result_data: [f64] = []
    for v in t.data:
        result_data.push(0.0 - v)
    tensor_from_data(result_data, t.shape)

fn abs_val(t: PureTensor<f64>) -> PureTensor<f64>:
    """Element-wise absolute value."""
    var result_data: [f64] = []
    for v in t.data:
        val a = if v < 0.0: 0.0 - v else: v
        result_data.push(a)
    tensor_from_data(result_data, t.shape)

# ============================================================================
# Matrix Operations
# ============================================================================

fn matmul(a: PureTensor<f64>, b: PureTensor<f64>) -> PureTensor<f64>:
    """Matrix multiplication: C = A @ B

    Assumes: A is [M, K], B is [K, N] -> C is [M, N]
    Algorithm: Naive triple loop (O(nÂ³))
    """
    val M = a.shape[0]
    val K = a.shape[1]
    val N = b.shape[1]

    var result_data: [f64] = []
    var i = 0
    while i < M:
        var j = 0
        while j < N:
            var sum = 0.0
            var k = 0
            while k < K:
                sum = sum + a.get([i, k]) * b.get([k, j])
                k = k + 1
            result_data.push(sum)
            j = j + 1
        i = i + 1

    tensor_from_data(result_data, [M, N])

fn transpose(t: PureTensor<f64>) -> PureTensor<f64>:
    """Transpose 2D tensor."""
    val rows = t.shape[0]
    val cols = t.shape[1]

    var result_data: [f64] = []
    var i = 0
    while i < cols:
        var j = 0
        while j < rows:
            result_data.push(t.get([j, i]))
            j = j + 1
        i = i + 1

    tensor_from_data(result_data, [cols, rows])

# ============================================================================
# Reductions
# ============================================================================

fn sum(t: PureTensor<f64>) -> f64:
    """Sum all elements."""
    var total = 0.0
    for v in t.data:
        total = total + v
    total

fn mean(t: PureTensor<f64>) -> f64:
    """Mean of all elements."""
    sum(t) / t.numel()

fn max(t: PureTensor<f64>) -> f64:
    """Maximum element."""
    var max_val = t.data[0]
    for v in t.data:
        if v > max_val:
            max_val = v
    max_val

fn min(t: PureTensor<f64>) -> f64:
    """Minimum element."""
    var min_val = t.data[0]
    for v in t.data:
        if v < min_val:
            min_val = v
    min_val

# ============================================================================
# Math Helpers
# ============================================================================

fn exp(x: f64) -> f64:
    """Exponential function using Taylor series."""
    var result = 1.0
    var term = 1.0
    var i = 1
    while i < 20:
        term = term * x / i
        result = result + term
        i = i + 1
    result

# ============================================================================
# Activation Functions
# ============================================================================

fn relu(x: PureTensor<f64>) -> PureTensor<f64>:
    """ReLU: max(0, x)."""
    var result_data: [f64] = []
    for v in x.data:
        result_data.push(if v > 0.0: v else: 0.0)
    tensor_from_data(result_data, x.shape)

fn sigmoid(x: PureTensor<f64>) -> PureTensor<f64>:
    """Sigmoid: 1 / (1 + exp(-x))."""
    var result_data: [f64] = []
    for v in x.data:
        val exp_neg = exp(-v)
        val sig = 1.0 / (1.0 + exp_neg)
        result_data.push(sig)
    tensor_from_data(result_data, x.shape)

fn tanh(x: PureTensor<f64>) -> PureTensor<f64>:
    """Tanh: (exp(x) - exp(-x)) / (exp(x) + exp(-x))."""
    var result_data: [f64] = []
    for v in x.data:
        val exp_pos = exp(v)
        val exp_neg = exp(-v)
        val tanh_val = (exp_pos - exp_neg) / (exp_pos + exp_neg)
        result_data.push(tanh_val)
    tensor_from_data(result_data, x.shape)

# ============================================================================
# Advanced Math Functions
# ============================================================================

fn tensor_exp(t: PureTensor<f64>) -> PureTensor<f64>:
    """Element-wise exponential using Taylor series (20 terms)."""
    var result_data: [f64] = []
    for x in t.data:
        result_data.push(exp(x))
    tensor_from_data(result_data, t.shape)

fn tensor_log(t: PureTensor<f64>) -> PureTensor<f64>:
    """Element-wise natural logarithm.

    Uses series: ln(x) = 2 * atanh((x-1)/(x+1))
    where atanh(z) = z + z^3/3 + z^5/5 + ... (20 terms)
    For x <= 0, returns -999999.0 as sentinel.
    """
    var result_data: [f64] = []
    for x in t.data:
        var log_val = -999999.0
        if x > 0.0:
            val z = (x - 1.0) / (x + 1.0)
            var sum = 0.0
            var z_pow = z
            var i = 0
            while i < 20:
                val denom = 2 * i + 1
                sum = sum + z_pow / denom
                z_pow = z_pow * z * z
                i = i + 1
            log_val = 2.0 * sum
        result_data.push(log_val)
    tensor_from_data(result_data, t.shape)

fn tensor_sqrt(t: PureTensor<f64>) -> PureTensor<f64>:
    """Element-wise square root via Newton's method (15 iterations).

    For x <= 0, returns 0.0.
    """
    var result_data: [f64] = []
    for x in t.data:
        var sqrt_val = 0.0
        if x > 0.0:
            var guess = x / 2.0
            var i = 0
            while i < 15:
                guess = (guess + x / guess) / 2.0
                i = i + 1
            sqrt_val = guess
        result_data.push(sqrt_val)
    tensor_from_data(result_data, t.shape)

fn clamp(t: PureTensor<f64>, min_val: f64, max_val: f64) -> PureTensor<f64>:
    """Clamp tensor elements to [min_val, max_val] range."""
    var result_data: [f64] = []
    for v in t.data:
        val clamped = if v < min_val: min_val elif v > max_val: max_val else: v
        result_data.push(clamped)
    tensor_from_data(result_data, t.shape)

fn softmax(t: PureTensor<f64>) -> PureTensor<f64>:
    """Numerically stable softmax over all elements.

    Subtracts max before exp to prevent overflow.
    """
    var max_v = t.data[0]
    for v in t.data:
        if v > max_v:
            max_v = v

    var exp_data: [f64] = []
    var exp_sum = 0.0
    for v in t.data:
        val x = v - max_v
        val exp_val = exp(x)
        exp_data.push(exp_val)
        exp_sum = exp_sum + exp_val

    var result_data: [f64] = []
    for e in exp_data:
        result_data.push(e / exp_sum)
    tensor_from_data(result_data, t.shape)

fn pow_scalar(t: PureTensor<f64>, power: f64) -> PureTensor<f64>:
    """Raise each element to the given power.

    Uses exp(power * log(x)) for positive values.
    For x <= 0, returns 0.0.
    """
    var result_data: [f64] = []
    for x in t.data:
        var pow_val = 0.0
        if x > 0.0:
            val z = (x - 1.0) / (x + 1.0)
            var log_sum = 0.0
            var z_pow = z
            var k = 0
            while k < 20:
                val denom = 2 * k + 1
                log_sum = log_sum + z_pow / denom
                z_pow = z_pow * z * z
                k = k + 1
            val log_x = 2.0 * log_sum
            val y = power * log_x
            pow_val = exp(y)
        result_data.push(pow_val)
    tensor_from_data(result_data, t.shape)

# ============================================================================
# Reduction Operations (return tensors)
# ============================================================================

fn tensor_sum_to_scalar(t: PureTensor<f64>) -> PureTensor<f64>:
    """Sum all elements into a [1] shape tensor."""
    tensor_from_data([sum(t)], [1])

fn tensor_mean_to_scalar(t: PureTensor<f64>) -> PureTensor<f64>:
    """Mean of all elements into a [1] shape tensor."""
    tensor_from_data([mean(t)], [1])

# ============================================================================
# Exports
# ============================================================================

export add, sub, mul, div, mul_scalar, add_scalar, div_scalar, neg, abs_val
export matmul, transpose
export sum, mean, max, min
export relu, sigmoid, tanh
export tensor_exp, tensor_log, tensor_sqrt, clamp, softmax, pow_scalar
export tensor_sum_to_scalar, tensor_mean_to_scalar
