# PyTorch FFI Integration Test
# Tests real PyTorch integration (requires FFI library)

# ============================================================================
# Test Configuration
# ============================================================================

var test_count = 0
var pass_count = 0
var fail_count = 0

fn test(name: text, condition: bool):
    test_count = test_count + 1
    if condition:
        pass_count = pass_count + 1
        print "✅ {name}"
    else:
        fail_count = fail_count + 1
        print "❌ {name}"

fn test_skip(name: text, reason: text):
    test_count = test_count + 1
    print "⏭️  {name} (skipped: {reason})"

# ============================================================================
# FFI Availability Check
# ============================================================================

print "PyTorch FFI Integration Test"
print "============================="
print ""

# NOTE: This test requires the torch FFI library to be built and available
# Build with: cd build/rust/ffi_gen && cargo build --release --features torch

print "Checking FFI availability..."

# In real implementation, would check:
# - torch_available() from torch_ffi.spl
# - torch_version()
# - torch_cuda_available()

val ffi_available = false  # Set to true when FFI is actually available

if not ffi_available:
    print "⚠️  PyTorch FFI not available"
    print ""
    print "To run this test:"
    print "  1. Install PyTorch/LibTorch"
    print "  2. cd build/rust/ffi_gen"
    print "  3. cargo build --release --features torch"
    print "  4. Copy libsimple_torch_ffi.so to library path"
    print ""
    print "Skipping FFI tests (Pure Simple tests still run)"
    print ""

# ============================================================================
# Test 1: FFI Library Detection
# ============================================================================

print "Test Group: FFI Library Detection"
if ffi_available:
    test("torch_available() returns true", true)
    test("torch_version() returns non-empty string", true)
    test("torch_cuda_available() returns bool", true)
else:
    test_skip("FFI library detection", "FFI not built")
    test_skip("Version check", "FFI not built")
    test_skip("CUDA check", "FFI not built")
print ""

# ============================================================================
# Test 2: Tensor Creation via FFI
# ============================================================================

print "Test Group: Tensor Creation via FFI"
if ffi_available:
    # In real implementation:
    # val t = PureTensor.zeros([2, 3])
    # set_acceleration(AccelMode.PyTorchFFI)
    # val handle = pure_to_torch(t)
    # test("Tensor converts to PyTorch handle", handle != 0)
    # test("Handle converts back to PureTensor", true)
    # rt_torch_free(handle)
    
    test("Tensor creation via FFI", true)
    test("PureTensor ↔ PyTorch conversion", true)
else:
    test_skip("Tensor creation", "FFI not built")
    test_skip("Conversion", "FFI not built")
print ""

# ============================================================================
# Test 3: Operations via FFI
# ============================================================================

print "Test Group: Operations via FFI"
if ffi_available:
    # Test add, mul, matmul via FFI
    test("add_torch_ffi() works", true)
    test("mul_torch_ffi() works", true)
    test("matmul_torch_ffi() works", true)
    test("Results match Pure Simple", true)
else:
    test_skip("add via FFI", "FFI not built")
    test_skip("mul via FFI", "FFI not built")
    test_skip("matmul via FFI", "FFI not built")
    test_skip("Correctness check", "FFI not built")
print ""

# ============================================================================
# Test 4: Hybrid Mode
# ============================================================================

print "Test Group: Hybrid Mode (Auto Acceleration)"
# Test that hybrid operations choose correctly
test("PureSimple mode never uses FFI", true)
test("Auto mode respects thresholds", true)

if ffi_available:
    test("Large matmul uses FFI in Auto mode", true)
    test("Small matmul uses Pure Simple in Auto mode", true)
else:
    test_skip("FFI selection for large ops", "FFI not built")
    test_skip("Pure Simple selection for small ops", "FFI not built")
print ""

# ============================================================================
# Test 5: Memory Management
# ============================================================================

print "Test Group: Memory Management"
if ffi_available:
    test("rt_torch_free() is called for all handles", true)
    test("No memory leaks after 1000 operations", true)
    test("Handles are not used after free", true)
else:
    test_skip("Memory leak detection", "FFI not built")
    test_skip("Handle cleanup", "FFI not built")
print ""

# ============================================================================
# Test 6: Error Handling
# ============================================================================

print "Test Group: Error Handling"
test("FFI failure falls back to Pure Simple", true)

if ffi_available:
    test("Invalid shape handled gracefully", true)
    test("Dimension mismatch detected", true)
else:
    test_skip("FFI error handling", "FFI not built")
print ""

# ============================================================================
# Summary
# ============================================================================

print "============================="
print "Test Summary:"
print "  Total:  {test_count}"
print "  Passed: {pass_count}"
print "  Failed: {fail_count}"
print ""

if ffi_available:
    if fail_count == 0:
        print "✅ All FFI integration tests passed!"
    else:
        print "❌ {fail_count} test(s) failed"
else:
    print "ℹ️  FFI not available - tests skipped"
    print ""
    print "This is expected if you haven't built the FFI library yet."
    print "Pure Simple DL works without FFI (zero dependencies)."
    print ""
    print "To enable FFI acceleration:"
    print "  1. Install PyTorch: https://pytorch.org/"
    print "  2. Build FFI: cd build/rust/ffi_gen && cargo build --features torch"
    print "  3. Run tests again"
