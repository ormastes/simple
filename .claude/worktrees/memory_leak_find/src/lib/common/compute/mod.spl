# GPU Standard Library Module
#
# Provides unified GPU compute support across CUDA and Vulkan backends.

use compute.device.*
use compute.memory.*
use compute.kernels.*
use compute.sync.*

# ============================================================================
# Re-exports from submodules
# ============================================================================

# Device management (from gpu.device)
export GpuBackend, detect_backends, preferred_backend
export Gpu, gpu_default, gpu_cuda, gpu_vulkan
export GpuDeviceEntry, list_all_gpus, gpu_available, gpu_count

# Memory management (from gpu.memory)
export GpuBuffer, gpu_alloc, gpu_free
export gpu_copy_to, gpu_copy_from, gpu_copy_buffer, gpu_memset
export gpu_alloc_f32, gpu_alloc_f64, gpu_alloc_i32, gpu_alloc_i64
export GpuMemoryPool, gpu_pool_create

# Kernels (from gpu.kernels)
export GpuKFunc, kernel_compile_cuda, kernel_compile_vulkan, kernel_destroy
export KernelLaunch, launch_1d, launch_2d, kernel_run
export gpu_vector_add, gpu_scalar_mul

# Synchronization (from gpu.sync)
export gpu_wait, gpu_wait_all
export GpuStream, gpu_stream_create, gpu_stream_destroy, gpu_stream_wait
export GpuEvent, gpu_event_create, gpu_event_destroy, gpu_event_wait, gpu_event_reset
export GpuMemoryScope

# ============================================================================
# Convenience Functions
# ============================================================================

fn gpu_init() -> Gpu:
    val device = gpu_default()
    if not device.is_valid():
        panic("No GPU available")
    device

fn gpu_info() -> text:
    var info = "GPU Information:\n================\n"
    val devices = list_all_gpus()
    if devices.len() == 0:
        info = info + "No GPUs detected.\n"
    else:
        for device in devices:
            var backend_name = "Unknown"
            if device.backend == GpuBackend.Cuda:
                backend_name = "CUDA"
            elif device.backend == GpuBackend.Vulkan:
                backend_name = "Vulkan"
            val mem_gb = device.memory / (1024 * 1024 * 1024)
            info = info + "  [{backend_name}:{device.device_id}] {device.name}\n    Memory: {mem_gb} GB\n"
    info

fn gpu_test_basic() -> bool:
    val device = gpu_default()
    if not device.is_valid():
        return false
    val size: i64 = 16
    val a = gpu_alloc(device, size)
    val b = gpu_alloc(device, size)
    val c = gpu_alloc(device, size)
    if not a.is_valid or not b.is_valid or not c.is_valid:
        gpu_free(a)
        gpu_free(b)
        gpu_free(c)
        return false
    val data_a: [u8] = [0, 0, 128, 63, 0, 0, 0, 64, 0, 0, 64, 64, 0, 0, 128, 64]
    val data_b: [u8] = [0, 0, 128, 64, 0, 0, 64, 64, 0, 0, 0, 64, 0, 0, 128, 63]
    gpu_copy_to(a, data_a)
    gpu_copy_to(b, data_b)
    val success = gpu_vector_add(device, a, b, c, 4)
    gpu_free(a)
    gpu_free(b)
    gpu_free(c)
    success

fn gpu_is_ready() -> bool:
    gpu_available() and gpu_test_basic()

# ============================================================================
# Additional exports
# ============================================================================

export gpu_init, gpu_info, gpu_test_basic, gpu_is_ready
