# GPU Memory Management
#
# Unified GPU memory allocation and transfer across CUDA and Vulkan backends.

use compute.device.*
use app.io.cuda_ffi.*
use app.io.vulkan_ffi.*

# ============================================================================
# GPU Buffer Abstraction
# ============================================================================

struct GpuBuffer:
    backend: GpuBackend
    cuda_ptr: CudaPtr?
    vulkan_buf: VulkanBuffer?
    size: i64
    is_valid: bool

fn gpu_alloc(device: Gpu, size: i64) -> GpuBuffer:
    if not device.is_valid():
        GpuBuffer(backend: GpuBackend.NoGpu, cuda_ptr: nil, vulkan_buf: nil, size: 0, is_valid: false)
    elif device.backend == GpuBackend.Cuda:
        val ptr = cuda_alloc(size)
        GpuBuffer(backend: GpuBackend.Cuda, cuda_ptr: Some(ptr), vulkan_buf: nil, size: size, is_valid: ptr.is_valid)
    elif device.backend == GpuBackend.Vulkan:
        val buf = vulkan_alloc_storage(size)
        GpuBuffer(backend: GpuBackend.Vulkan, cuda_ptr: nil, vulkan_buf: Some(buf), size: size, is_valid: buf.is_valid)
    else:
        GpuBuffer(backend: GpuBackend.NoGpu, cuda_ptr: nil, vulkan_buf: nil, size: 0, is_valid: false)

fn gpu_free(buf: GpuBuffer) -> bool:
    if not buf.is_valid:
        true
    elif buf.backend == GpuBackend.Cuda:
        if buf.cuda_ptr.?:
            val ptr = buf.cuda_ptr?
            cuda_free(ptr)
        else:
            true
    elif buf.backend == GpuBackend.Vulkan:
        if buf.vulkan_buf.?:
            val vbuf = buf.vulkan_buf?
            vulkan_free_buffer(vbuf)
        else:
            true
    else:
        true

impl GpuBuffer:
    fn valid() -> bool:
        self.is_valid

    fn len() -> i64:
        self.size

    fn raw_ptr() -> i64:
        if self.cuda_ptr.?:
            val ptr = self.cuda_ptr?
            ptr.ptr
        else:
            0

    fn raw_handle() -> i64:
        if self.vulkan_buf.?:
            val buf = self.vulkan_buf?
            buf.handle
        else:
            0

# ============================================================================
# Data Transfer
# ============================================================================

fn gpu_copy_to(buf: GpuBuffer, data: [u8]) -> bool:
    if not buf.is_valid:
        false
    elif buf.backend == GpuBackend.Cuda:
        if buf.cuda_ptr.?:
            val ptr = buf.cuda_ptr?
            cuda_copy_to_device(ptr, data)
        else:
            false
    elif buf.backend == GpuBackend.Vulkan:
        if buf.vulkan_buf.?:
            val vbuf = buf.vulkan_buf?
            vulkan_copy_to(vbuf, data)
        else:
            false
    else:
        false

fn gpu_copy_from(data: [u8], buf: GpuBuffer) -> bool:
    if not buf.is_valid:
        false
    elif buf.backend == GpuBackend.Cuda:
        if buf.cuda_ptr.?:
            val ptr = buf.cuda_ptr?
            cuda_copy_from_device(data, ptr)
        else:
            false
    elif buf.backend == GpuBackend.Vulkan:
        if buf.vulkan_buf.?:
            val vbuf = buf.vulkan_buf?
            vulkan_copy_from(data, vbuf)
        else:
            false
    else:
        false

fn gpu_copy_buffer(dst: GpuBuffer, src: GpuBuffer, size: i64) -> bool:
    if not dst.is_valid or not src.is_valid:
        false
    elif dst.backend != src.backend:
        false
    elif dst.backend == GpuBackend.Cuda:
        if dst.cuda_ptr.? and src.cuda_ptr.?:
            val d = dst.cuda_ptr?
            val s = src.cuda_ptr?
            cuda_copy_device_to_device(d, s, size)
        else:
            false
    elif dst.backend == GpuBackend.Vulkan:
        if dst.vulkan_buf.? and src.vulkan_buf.?:
            val d = dst.vulkan_buf?
            val s = src.vulkan_buf?
            vulkan_copy_buffer(d, s, size)
        else:
            false
    else:
        false

fn gpu_memset(buf: GpuBuffer, value: i64) -> bool:
    if not buf.is_valid:
        false
    elif buf.backend == GpuBackend.Cuda:
        if buf.cuda_ptr.?:
            val ptr = buf.cuda_ptr?
            cuda_memset(ptr, value)
        else:
            false
    else:
        false

# ============================================================================
# Convenience Functions for Common Types
# ============================================================================

fn gpu_alloc_f32(device: Gpu, count: i64) -> GpuBuffer:
    gpu_alloc(device, count * 4)

fn gpu_alloc_f64(device: Gpu, count: i64) -> GpuBuffer:
    gpu_alloc(device, count * 8)

fn gpu_alloc_i32(device: Gpu, count: i64) -> GpuBuffer:
    gpu_alloc(device, count * 4)

fn gpu_alloc_i64(device: Gpu, count: i64) -> GpuBuffer:
    gpu_alloc(device, count * 8)

# ============================================================================
# Memory Pool (Advanced)
# ============================================================================

struct GpuMemoryPool:
    device: Gpu
    chunk_size: i64
    chunks: [GpuBuffer]
    free_offsets: [i64]

fn gpu_pool_create(device: Gpu, chunk_size: i64) -> GpuMemoryPool:
    GpuMemoryPool(device: device, chunk_size: chunk_size, chunks: [], free_offsets: [])

impl GpuMemoryPool:
    me alloc_chunk(size: i64) -> GpuBuffer:
        if size > self.chunk_size:
            gpu_alloc(self.device, size)
        else:
            val chunk = gpu_alloc(self.device, self.chunk_size)
            self.chunks.push(chunk)
            chunk

    me clear_pool() -> bool:
        var success = true
        for chunk in self.chunks:
            if not gpu_free(chunk):
                success = false
        self.chunks = []
        self.free_offsets = []
        success

# ============================================================================
# Exports
# ============================================================================

export GpuBuffer, gpu_alloc, gpu_free
export gpu_copy_to, gpu_copy_from, gpu_copy_buffer, gpu_memset
export gpu_alloc_f32, gpu_alloc_f64, gpu_alloc_i32, gpu_alloc_i64
export GpuMemoryPool, gpu_pool_create
