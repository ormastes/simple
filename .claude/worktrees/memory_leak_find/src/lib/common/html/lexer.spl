# HTML Lexer and Tokenization
#
# Tokenizes HTML input into structured tokens for parsing.

# =============================================================================
# Character Classification
# =============================================================================

fn is_whitespace(c: text) -> bool:
    var result = false
    if c == " ":
        result = true
    if c == "\t":
        result = true
    if c == "\n":
        result = true
    if c == "\r":
        result = true
    result

fn is_alpha(c: text) -> bool:
    val code = c.char_code_at(0)
    var result = false
    if code >= 65:
        if code <= 90:
            result = true
    if code >= 97:
        if code <= 122:
            result = true
    result

fn is_digit(c: text) -> bool:
    val code = c.char_code_at(0)
    var result = false
    if code >= 48:
        if code <= 57:
            result = true
    result

fn is_alphanumeric(c: text) -> bool:
    var result = is_alpha(c)
    if is_digit(c):
        result = true
    result

fn is_tag_name_char(c: text) -> bool:
    var result = is_alphanumeric(c)
    if c == "-":
        result = true
    if c == "_":
        result = true
    if c == ":":
        result = true
    result

fn is_attr_name_char(c: text) -> bool:
    var result = is_alphanumeric(c)
    if c == "-":
        result = true
    if c == "_":
        result = true
    if c == ":":
        result = true
    if c == ".":
        result = true
    result

# =============================================================================
# Tokenization Helpers
# =============================================================================

fn skip_whitespace(html: text, pos: i64) -> i64:
    var result = pos
    while result < html.length():
        val c = html.substring(result, result + 1)
        if is_whitespace(c):
            result = result + 1
        else:
            result = html.length()
    result

fn read_tag_name(html: text, pos: i64) -> (text, i64):
    var name = ""
    var current = pos
    while current < html.length():
        val c = html.substring(current, current + 1)
        if is_tag_name_char(c):
            name = name + c
            current = current + 1
        else:
            current = html.length()
    (name, current)

fn read_attr_name(html: text, pos: i64) -> (text, i64):
    var name = ""
    var current = pos
    while current < html.length():
        val c = html.substring(current, current + 1)
        if is_attr_name_char(c):
            name = name + c
            current = current + 1
        else:
            current = html.length()
    (name, current)

fn read_attr_value(html: text, pos: i64) -> (text, i64):
    var current = pos
    var value = ""

    if current < html.length():
        val first_char = html.substring(current, current + 1)
        if first_char == "\"":
            # Double-quoted value
            current = current + 1
            while current < html.length():
                val c = html.substring(current, current + 1)
                if c == "\"":
                    current = current + 1
                    current = html.length()
                else:
                    value = value + c
                    current = current + 1
        else:
            if first_char == "'":
                # Single-quoted value
                current = current + 1
                while current < html.length():
                    val c = html.substring(current, current + 1)
                    if c == "'":
                        current = current + 1
                        current = html.length()
                    else:
                        value = value + c
                        current = current + 1
            else:
                # Unquoted value
                while current < html.length():
                    val c = html.substring(current, current + 1)
                    var is_end = is_whitespace(c)
                    if c == ">":
                        is_end = true
                    if is_end:
                        current = html.length()
                    else:
                        value = value + c
                        current = current + 1

    (value, current)

fn parse_attributes(html: text, start_pos: i64, end_pos: i64) -> list:
    var attrs = []
    var pos = start_pos

    while pos < end_pos:
        pos = skip_whitespace(html, pos)
        if pos >= end_pos:
            pos = end_pos
        else:
            # Read attribute name
            val name_result = read_attr_name(html, pos)
            val attr_name = name_result[0]
            pos = name_result[1]

            if attr_name.length() > 0:
                pos = skip_whitespace(html, pos)
                var attr_value = ""

                if pos < end_pos:
                    val next_char = html.substring(pos, pos + 1)
                    if next_char == "=":
                        pos = pos + 1
                        pos = skip_whitespace(html, pos)
                        val value_result = read_attr_value(html, pos)
                        attr_value = value_result[0]
                        pos = value_result[1]
                    else:
                        # Boolean attribute
                        attr_value = attr_name

                attrs = attrs.append((attr_name, attr_value))
            else:
                pos = end_pos

    attrs

# =============================================================================
# Tokenization
# =============================================================================

fn tokenize_next(html: text, pos: i64) -> (text, text, list, i64):
    var token_type = TOKEN_EOF
    var token_value = ""
    var token_attrs = []
    var new_pos = pos

    if pos >= html.length():
        token_type = TOKEN_EOF
        new_pos = pos
    else:
        val c = html.substring(pos, pos + 1)
        if c == "<":
            # Could be tag, comment, or doctype
            if pos + 1 < html.length():
                val next_c = html.substring(pos + 1, pos + 2)
                if next_c == "!":
                    # Comment or doctype
                    if pos + 3 < html.length():
                        val prefix = html.substring(pos, pos + 4)
                        if prefix == "<!--":
                            # Comment
                            token_type = TOKEN_COMMENT
                            var end_pos = pos + 4
                            var found_end = false
                            while end_pos < html.length() - 2:
                                val ending = html.substring(end_pos, end_pos + 3)
                                if ending == "-->":
                                    token_value = html.substring(pos + 4, end_pos)
                                    new_pos = end_pos + 3
                                    found_end = true
                                    end_pos = html.length()
                                else:
                                    end_pos = end_pos + 1
                            if not found_end:
                                token_value = html.substring(pos + 4, html.length())
                                new_pos = html.length()
                        else:
                            # DOCTYPE
                            val doctype_prefix = html.substring(pos, pos + 9)
                            var is_doctype = false
                            if doctype_prefix.to_lowercase() == "<!doctype":
                                is_doctype = true
                            if is_doctype:
                                token_type = TOKEN_DOCTYPE
                                var end_pos = pos + 9
                                while end_pos < html.length():
                                    val ec = html.substring(end_pos, end_pos + 1)
                                    if ec == ">":
                                        token_value = html.substring(pos + 9, end_pos)
                                        new_pos = end_pos + 1
                                        end_pos = html.length()
                                    else:
                                        end_pos = end_pos + 1
                            else:
                                # Invalid, skip
                                token_type = TOKEN_TEXT
                                token_value = c
                                new_pos = pos + 1
                    else:
                        # Invalid
                        token_type = TOKEN_TEXT
                        token_value = c
                        new_pos = pos + 1
                else:
                    if next_c == "/":
                        # Closing tag
                        token_type = TOKEN_TAG_CLOSE
                        var tag_start = pos + 2
                        val tag_result = read_tag_name(html, tag_start)
                        token_value = tag_result[0]
                        var tag_end = tag_result[1]
                        tag_end = skip_whitespace(html, tag_end)
                        if tag_end < html.length():
                            val close_c = html.substring(tag_end, tag_end + 1)
                            if close_c == ">":
                                new_pos = tag_end + 1
                            else:
                                new_pos = tag_end
                        else:
                            new_pos = tag_end
                    else:
                        # Opening tag or self-closing tag
                        var tag_start = pos + 1
                        val tag_result = read_tag_name(html, tag_start)
                        token_value = tag_result[0]
                        var tag_end = tag_result[1]
                        tag_end = skip_whitespace(html, tag_end)

                        # Parse attributes
                        var attr_start = tag_end
                        var found_close = false
                        var is_self_closing = false
                        while tag_end < html.length():
                            val ec = html.substring(tag_end, tag_end + 1)
                            if ec == ">":
                                token_attrs = parse_attributes(html, attr_start, tag_end)
                                found_close = true
                                new_pos = tag_end + 1
                                tag_end = html.length()
                            else:
                                if ec == "/":
                                    if tag_end + 1 < html.length():
                                        val next_ec = html.substring(tag_end + 1, tag_end + 2)
                                        if next_ec == ">":
                                            token_attrs = parse_attributes(html, attr_start, tag_end)
                                            is_self_closing = true
                                            found_close = true
                                            new_pos = tag_end + 2
                                            tag_end = html.length()
                                        else:
                                            tag_end = tag_end + 1
                                    else:
                                        tag_end = tag_end + 1
                                else:
                                    tag_end = tag_end + 1

                        if found_close:
                            if is_self_closing:
                                token_type = TOKEN_TAG_SELF_CLOSE
                            else:
                                token_type = TOKEN_TAG_OPEN
                        else:
                            token_type = TOKEN_TEXT
                            token_value = c
                            new_pos = pos + 1
            else:
                # Just "<" at end
                token_type = TOKEN_TEXT
                token_value = c
                new_pos = pos + 1
        else:
            # Text content
            token_type = TOKEN_TEXT
            var text_end = pos
            while text_end < html.length():
                val tc = html.substring(text_end, text_end + 1)
                if tc == "<":
                    text_end = html.length()
                else:
                    text_end = text_end + 1
            token_value = html.substring(pos, text_end)
            new_pos = text_end

    (token_type, token_value, token_attrs, new_pos)

fn tokenize_html(html: text) -> list:
    var tokens = []
    var pos = 0

    while pos < html.length():
        val result = tokenize_next(html, pos)
        val token_type = result[0]
        val token_value = result[1]
        val token_attrs = result[2]
        pos = result[3]

        if token_type != TOKEN_EOF:
            tokens = tokens.append((token_type, token_value, token_attrs))

    tokens

# =============================================================================
# Token Type Constants (Dependencies)
# =============================================================================

val TOKEN_TAG_OPEN = "tag_open"
val TOKEN_TAG_CLOSE = "tag_close"
val TOKEN_TAG_SELF_CLOSE = "tag_self"
val TOKEN_TEXT = "text"
val TOKEN_COMMENT = "comment"
val TOKEN_DOCTYPE = "doctype"
val TOKEN_EOF = "eof"
