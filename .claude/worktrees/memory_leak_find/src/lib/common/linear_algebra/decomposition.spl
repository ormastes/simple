# Linear Algebra - Matrix Decomposition
#
# LU, QR, Cholesky, and SVD decompositions.

from .types import LA_EPSILON
from .matrix_ops import la_matrix_identity, la_matrix_copy, la_matrix_is_square
from .matrix_ops import la_matrix_zero, la_matrix_get_column, la_matrix_from_columns
from .matrix_ops import la_matrix_from_rows, la_matrix_subtract, la_matrix_scalar_multiply
from .matrix_ops import la_matrix_transpose, la_matrix_is_symmetric
from .vector_ops import la_vector_dot, la_vector_magnitude, la_vector_normalize
from .vector_ops import la_vector_scalar_multiply, la_vector_subtract, la_vector_outer_product
from .eigenvalues import la_power_iteration

# ============================================================================
# Matrix Decomposition
# ============================================================================

fn la_matrix_lu_decomposition(matrix: [[f64]]) -> ([[f64]], [[f64]], f64)?:
    """LU decomposition with partial pivoting.

    Returns (L, U, parity) where:
    - L is lower triangular
    - U is upper triangular
    - parity is 1.0 or -1.0 for determinant sign
    """
    if not la_matrix_is_square(matrix):
        return nil
    val n = matrix.len()
    var lower = la_matrix_identity(n)
    var upper = la_matrix_copy(matrix)
    var parity = 1.0
    var k = 0
    while k < n - 1:
        var max_row = k
        var max_val = upper[k][k]
        if max_val < 0.0:
            max_val = -max_val
        var i = k + 1
        while i < n:
            var abs_val = upper[i][k]
            if abs_val < 0.0:
                abs_val = -abs_val
            if abs_val > max_val:
                max_val = abs_val
                max_row = i
            i = i + 1
        if max_row != k:
            val temp_row = upper[k]
            upper[k] = upper[max_row]
            upper[max_row] = temp_row
            parity = -parity
        i = k + 1
        while i < n:
            val factor = upper[i][k] / upper[k][k]
            lower[i][k] = factor
            var j = k
            while j < n:
                upper[i][j] = upper[i][j] - factor * upper[k][j]
                j = j + 1
            i = i + 1
        k = k + 1
    (lower, upper, parity)

fn la_matrix_qr_decomposition(matrix: [[f64]]) -> ([[f64]], [[f64]])?:
    """QR decomposition using Gram-Schmidt process.

    Returns (Q, R) where Q is orthogonal and R is upper triangular.
    """
    val dims = la_matrix_dimensions(matrix)
    val rows = dims[0]
    val cols = dims[1]
    var q_cols = []
    var r_matrix = la_matrix_zero(cols, cols)
    var j = 0
    while j < cols:
        val a_j = la_matrix_get_column(matrix, j)
        if not a_j.?:
            return nil
        var q_j = a_j
        var i = 0
        while i < j:
            val q_i = q_cols[i]
            val r_ij = la_vector_dot(q_i, a_j)
            if not r_ij.?:
                return nil
            r_matrix[i][j] = r_ij
            val proj = la_vector_scalar_multiply(q_i, r_ij)
            val diff = la_vector_subtract(q_j, proj)
            if not diff.?:
                return nil
            q_j = diff
            i = i + 1
        val norm = la_vector_magnitude(q_j)
        if not norm.?:
            return nil
        if norm < LA_EPSILON:
            return nil
        r_matrix[j][j] = norm
        val normalized = la_vector_normalize(q_j)
        if not normalized.?:
            return nil
        q_cols.push(normalized)
        j = j + 1
    val q_matrix = la_matrix_from_columns(q_cols)
    (q_matrix, r_matrix)

fn la_matrix_cholesky_decomposition(matrix: [[f64]]) -> [[f64]]?:
    """Cholesky decomposition for symmetric positive-definite matrices.

    Returns lower triangular matrix L where A = L * L^T.
    """
    if not la_matrix_is_square(matrix):
        return nil
    if not la_matrix_is_symmetric(matrix):
        return nil
    val n = matrix.len()
    var lower = la_matrix_zero(n, n)
    var i = 0
    while i < n:
        var j = 0
        while j <= i:
            var sum = 0.0
            if j == i:
                var k = 0
                while k < j:
                    sum = sum + (lower[j][k] * lower[j][k])
                    k = k + 1
                val diff = matrix[j][j] - sum
                if diff <= 0.0:
                    return nil
                var sqrt_val = diff
                var iteration = 0
                while iteration < 20:
                    sqrt_val = (sqrt_val + diff / sqrt_val) / 2.0
                    iteration = iteration + 1
                lower[j][j] = sqrt_val
            else:
                var k = 0
                while k < j:
                    sum = sum + (lower[i][k] * lower[j][k])
                    k = k + 1
                lower[i][j] = (matrix[i][j] - sum) / lower[j][j]
            j = j + 1
        i = i + 1
    lower

fn la_matrix_svd_power_iteration(matrix: [[f64]], num_components: i64) -> ([[f64]], [f64], [[f64]])?:
    """Simplified SVD using power iteration.

    Returns approximation of (U, singular_values, V^T) for first num_components.
    This is a simplified implementation - not full SVD.
    """
    val dims = la_matrix_dimensions(matrix)
    val rows = dims[0]
    val cols = dims[1]
    if num_components > rows or num_components > cols:
        return nil
    var u_cols = []
    var singular_values = []
    var v_cols = []
    var remaining = matrix
    var comp = 0
    while comp < num_components:
        val result = la_power_iteration(remaining, 50)
        if not result.?:
            return nil
        val eigenvalue = result[0]
        val eigenvector = result[1]
        var sigma = eigenvalue
        if sigma < 0.0:
            sigma = -sigma
        var sqrt_sigma = sigma
        var iteration = 0
        while iteration < 20:
            sqrt_sigma = (sqrt_sigma + sigma / sqrt_sigma) / 2.0
            iteration = iteration + 1
        singular_values.push(sqrt_sigma)
        u_cols.push(eigenvector)
        val at_times_u = la_matrix_vector_multiply(la_matrix_transpose(remaining), eigenvector)
        if not at_times_u.?:
            return nil
        val v = la_vector_scalar_multiply(at_times_u, 1.0 / sqrt_sigma)
        v_cols.push(v)
        val outer = la_vector_outer_product(eigenvector, v)
        val deflate = la_matrix_scalar_multiply(outer, sqrt_sigma)
        val diff = la_matrix_subtract(remaining, deflate)
        if not diff.?:
            return nil
        remaining = diff
        comp = comp + 1
    val u_matrix = la_matrix_from_columns(u_cols)
    val vt_matrix = la_matrix_from_rows(v_cols)
    (u_matrix, singular_values, vt_matrix)

# Helper functions from matrix_ops (need to be available here)
fn la_matrix_dimensions(matrix: [[f64]]) -> (i64, i64):
    """Get matrix dimensions (rows, cols)."""
    if matrix.len() == 0:
        return (0, 0)
    (matrix.len(), matrix[0].len())

fn la_matrix_vector_multiply(matrix: [[f64]], vector: [f64]) -> [f64]?:
    """Multiply matrix by column vector."""
    val dims = la_matrix_dimensions(matrix)
    val rows = dims[0]
    val cols = dims[1]
    if cols != vector.len():
        return nil
    var result = []
    var i = 0
    while i < rows:
        var sum = 0.0
        var j = 0
        while j < cols:
            sum = sum + matrix[i][j] * vector[j]
            j = j + 1
        result.push(sum)
        i = i + 1
    result

# ============================================================================
# Exports
# ============================================================================

# Matrix Decomposition (4 functions)
export la_matrix_lu_decomposition, la_matrix_qr_decomposition
export la_matrix_cholesky_decomposition, la_matrix_svd_power_iteration
