# LZ77 Utility Functions
#
# Helper utilities for token manipulation, statistics, and validation.

# ============================================================================
# Exports
# ============================================================================

export token_to_string, tokens_to_string_list
export count_literal_tokens, count_match_tokens, get_token_at
export extract_literals, extract_matches
export stats_add_literal, stats_add_match, stats_add_input_bytes
export stats_get_compression_ratio, stats_get_average_match_length, stats_get_average_match_distance
export stats_to_string, stats_reset
export bytes_to_string
export validate_window_size, validate_lookahead_size
export validate_match_length, validate_match_distance
export calculate_token_size, calculate_tokens_size

# ============================================================================
# Constants
# ============================================================================

val DEFAULT_WINDOW_SIZE = 32768
val DEFAULT_LOOKAHEAD_SIZE = 258
val MIN_MATCH_LENGTH = 3
val MAX_MATCH_LENGTH = 258

# ============================================================================
# Token Manipulation
# ============================================================================

fn token_to_string(token: any) -> text:
    # Convert token to string representation
    val t = token
    if t.is_literal():
        val v = t.get_literal_value()
        "L({v})"
    else:
        val d = t.get_match_distance()
        val l = t.get_match_length()
        "M({d},{l})"

fn tokens_to_string_list(tokens: list) -> list:
    # Convert token list to string list
    val result = []
    var i = 0
    val len = tokens.len()
    while i < len:
        val tok = tokens[i]
        val str = token_to_string(tok)
        result.push(str)
        i = i + 1
    result

fn count_literal_tokens(tokens: list) -> i64:
    # Count literal tokens in list
    var count = 0
    var i = 0
    val len = tokens.len()
    while i < len:
        val tok = tokens[i]
        if tok.is_literal():
            count = count + 1
        i = i + 1
    count

fn count_match_tokens(tokens: list) -> i64:
    # Count match tokens in list
    var count = 0
    var i = 0
    val len = tokens.len()
    while i < len:
        val tok = tokens[i]
        if tok.is_match():
            count = count + 1
        i = i + 1
    count

fn get_token_at(tokens: list, index: i64) -> any:
    # Get token at index with bounds checking
    val len = tokens.len()
    if index >= 0:
        if index < len:
            tokens[index]
        else:
            nil
    else:
        nil

fn extract_literals(tokens: list) -> list:
    # Extract all literal values from token list
    val result = []
    var i = 0
    val len = tokens.len()
    while i < len:
        val tok = tokens[i]
        if tok.is_literal():
            val v = tok.get_literal_value()
            result.push(v)
        i = i + 1
    result

fn extract_matches(tokens: list) -> list:
    # Extract all match tuples from token list
    val result = []
    var i = 0
    val len = tokens.len()
    while i < len:
        val tok = tokens[i]
        if tok.is_match():
            val d = tok.get_match_distance()
            val l = tok.get_match_length()
            val match_tuple = (d, l)
            result.push(match_tuple)
        i = i + 1
    result

# ============================================================================
# Statistics
# ============================================================================

fn stats_add_literal(stats: any):
    # Record literal token
    val new_literal = stats.literal_count + 1
    stats.literal_count = new_literal
    val new_tokens = stats.output_tokens + 1
    stats.output_tokens = new_tokens

fn stats_add_match(stats: any, distance: i64, length: i64):
    # Record match token
    val new_match = stats.match_count + 1
    stats.match_count = new_match
    val new_tokens = stats.output_tokens + 1
    stats.output_tokens = new_tokens
    val new_total_len = stats.total_match_length + length
    stats.total_match_length = new_total_len
    val new_total_dist = stats.total_match_distance + distance
    stats.total_match_distance = new_total_dist
    if length > stats.max_match_length:
        stats.max_match_length = length
    if distance > stats.max_match_distance:
        stats.max_match_distance = distance

fn stats_add_input_bytes(stats: any, count: i64):
    # Add input bytes to statistics
    val new_input = stats.input_bytes + count
    stats.input_bytes = new_input

fn stats_get_compression_ratio(stats: any) -> i64:
    # Get compression ratio percentage
    stats.compression_ratio()

fn stats_get_average_match_length(stats: any) -> i64:
    # Get average match length
    val count = stats.match_count
    if count == 0:
        0
    else:
        val total = stats.total_match_length
        total / count

fn stats_get_average_match_distance(stats: any) -> i64:
    # Get average match distance
    val count = stats.match_count
    if count == 0:
        0
    else:
        val total = stats.total_match_distance
        total / count

fn stats_to_string(stats: any) -> text:
    # Convert stats to string
    val input = stats.input_bytes
    val output = stats.output_tokens
    val literals = stats.literal_count
    val matches = stats.match_count
    val ratio = stats_get_compression_ratio(stats)
    "Input: {input} bytes, Tokens: {output}, Literals: {literals}, Matches: {matches}, Ratio: {ratio}%"

fn stats_reset(stats: any):
    # Reset statistics
    stats.input_bytes = 0
    stats.output_tokens = 0
    stats.literal_count = 0
    stats.match_count = 0
    stats.total_match_length = 0
    stats.total_match_distance = 0
    stats.max_match_length = 0
    stats.max_match_distance = 0

# ============================================================================
# Utility Functions
# ============================================================================

fn bytes_to_string(bytes: list) -> text:
    # Convert byte list to string representation
    val len = bytes.len()
    if len == 0:
        "[]"
    else:
        var result = "["
        var i = 0
        while i < len:
            val byte = bytes[i]
            if i > 0:
                result = result + ", "
            result = result + "{byte}"
            i = i + 1
        result = result + "]"
        result

fn validate_window_size(size: i64) -> i64:
    # Validate and normalize window size
    if size <= 0:
        DEFAULT_WINDOW_SIZE
    else:
        if size > 65536:
            65536
        else:
            size

fn validate_lookahead_size(size: i64) -> i64:
    # Validate and normalize lookahead size
    if size <= 0:
        DEFAULT_LOOKAHEAD_SIZE
    else:
        if size > MAX_MATCH_LENGTH:
            MAX_MATCH_LENGTH
        else:
            size

fn validate_match_length(length: i64) -> bool:
    # Validate match length
    if length < MIN_MATCH_LENGTH:
        false
    else:
        length <= MAX_MATCH_LENGTH

fn validate_match_distance(distance: i64, window_size: i64) -> bool:
    # Validate match distance
    if distance <= 0:
        false
    else:
        distance <= window_size

fn calculate_token_size(token: any) -> i64:
    # Calculate encoded size of token in bytes
    if token.is_literal():
        1
    else:
        3

fn calculate_tokens_size(tokens: list) -> i64:
    # Calculate total encoded size of tokens
    var total = 0
    var i = 0
    val len = tokens.len()
    while i < len:
        val token = tokens[i]
        val size = calculate_token_size(token)
        total = total + size
        i = i + 1
    total
