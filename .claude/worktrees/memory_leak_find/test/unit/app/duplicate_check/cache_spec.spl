# Tests for duplicate_check cache module

use app.duplicate_check.cache.{TokenCacheManager, new_token_cache_manager, get_tokens_cached, invalidate_file, clear_cache, get_cache_stats, get_file_mtime}
use app.duplicate_check.tokenizer.{SimpleToken, SimpleTokenKind}
use app.io.mod.{file_write, file_exists, shell}

fn create_test_file(path: text, content: text):
    file_write(path, content)

fn delete_test_file(path: text):
    shell("rm -f '{path}'")

fn create_sample_tokens() -> [SimpleToken]:
    [
        SimpleToken(kind: SimpleTokenKind.Keyword, value: "fn", line: 1, column: 1),
        SimpleToken(kind: SimpleTokenKind.Identifier, value: "test", line: 1, column: 4)
    ]

describe "TokenCacheManager creation":
    it "creates empty cache manager":
        val manager = new_token_cache_manager()
        val stats = get_cache_stats(manager)
        expect(stats).to_contain("0 files")

describe "File modification time":
    it "gets mtime for existing file":
        val test_file = "/tmp/test_cache_mtime.txt"
        create_test_file(test_file, "test content")

        val mtime = get_file_mtime(test_file)
        expect(mtime).to_be_greater_than(0)

        delete_test_file(test_file)

    it "returns 0 for non-existent file":
        val mtime = get_file_mtime("/tmp/nonexistent_file_xyz.txt")
        expect(mtime).to_equal(0)

describe "Token caching":
    it "caches tokens on first access":
        val manager = new_token_cache_manager()
        val test_file = "/tmp/test_cache_tokens.spl"
        create_test_file(test_file, "fn test(): 42")

        var call_count = 0
        fn tokenize_fn(path: text) -> [SimpleToken]:
            call_count = call_count + 1
            create_sample_tokens()

        val tokens1 = get_tokens_cached(manager, test_file, tokenize_fn)
        expect(call_count).to_equal(1)
        expect(tokens1.len()).to_equal(2)

        delete_test_file(test_file)

    it "returns cached tokens without re-tokenizing":
        val manager = new_token_cache_manager()
        val test_file = "/tmp/test_cache_reuse.spl"
        create_test_file(test_file, "fn test(): 42")

        var call_count = 0
        fn tokenize_fn(path: text) -> [SimpleToken]:
            call_count = call_count + 1
            create_sample_tokens()

        val tokens1 = get_tokens_cached(manager, test_file, tokenize_fn)
        val tokens2 = get_tokens_cached(manager, test_file, tokenize_fn)

        expect(call_count).to_equal(1)
        expect(tokens1.len()).to_equal(tokens2.len())

        delete_test_file(test_file)

    slow_it "invalidates cache when file changes":
        # Requires sleep to change mtime, too slow for regular tests
        val manager = new_token_cache_manager()
        val test_file = "/tmp/test_cache_invalidate.spl"

        create_test_file(test_file, "fn test(): 42")

        var call_count = 0
        fn tokenize_fn(path: text) -> [SimpleToken]:
            call_count = call_count + 1
            create_sample_tokens()

        val tokens1 = get_tokens_cached(manager, test_file, tokenize_fn)

        shell("sleep 1")
        create_test_file(test_file, "fn test(): 99")

        val tokens2 = get_tokens_cached(manager, test_file, tokenize_fn)

        expect(call_count).to_equal(2)

        delete_test_file(test_file)

describe "Cache operations":
    it "invalidates specific file":
        val manager = new_token_cache_manager()
        val test_file1 = "/tmp/test_cache_inv1.spl"
        val test_file2 = "/tmp/test_cache_inv2.spl"

        create_test_file(test_file1, "fn test1(): 1")
        create_test_file(test_file2, "fn test2(): 2")

        fn tokenize_fn(path: text) -> [SimpleToken]:
            create_sample_tokens()

        val tokens1 = get_tokens_cached(manager, test_file1, tokenize_fn)
        val tokens2 = get_tokens_cached(manager, test_file2, tokenize_fn)

        val stats_before = get_cache_stats(manager)
        expect(stats_before).to_contain("2 files")

        invalidate_file(manager, test_file1)

        val stats_after = get_cache_stats(manager)
        expect(stats_after).to_contain("1 files")

        delete_test_file(test_file1)
        delete_test_file(test_file2)

    it "clears all cache entries":
        val manager = new_token_cache_manager()
        val test_file = "/tmp/test_cache_clear.spl"

        create_test_file(test_file, "fn test(): 42")

        fn tokenize_fn(path: text) -> [SimpleToken]:
            create_sample_tokens()

        val tokens = get_tokens_cached(manager, test_file, tokenize_fn)

        val stats_before = get_cache_stats(manager)
        expect(stats_before).to_contain("1 files")

        clear_cache(manager)

        val stats_after = get_cache_stats(manager)
        expect(stats_after).to_contain("0 files")

        delete_test_file(test_file)

describe "Cache statistics":
    it "reports correct token count":
        val manager = new_token_cache_manager()
        val test_file = "/tmp/test_cache_stats.spl"

        create_test_file(test_file, "fn test(): 42")

        fn tokenize_fn(path: text) -> [SimpleToken]:
            create_sample_tokens()

        val tokens = get_tokens_cached(manager, test_file, tokenize_fn)

        val stats = get_cache_stats(manager)
        expect(stats).to_contain("1 files")
        expect(stats).to_contain("2 tokens")

        delete_test_file(test_file)
