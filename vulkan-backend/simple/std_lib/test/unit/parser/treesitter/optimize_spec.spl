# Unit tests for tree-sitter optimization module

import spec.{describe, it, expect}
import parser.treesitter.optimize as optimize

describe("StringInterner"):
    it("interns new strings"):
        var interner = optimize.StringInterner.new()

        val id1 = interner.intern("function")
        val id2 = interner.intern("variable")

        expect(id1).to_equal(0)
        expect(id2).to_equal(1)

    it("returns same ID for duplicate strings"):
        var interner = optimize.StringInterner.new()

        val id1 = interner.intern("function")
        val id2 = interner.intern("function")

        expect(id1).to_equal(id2)

    it("looks up strings by ID"):
        var interner = optimize.StringInterner.new()

        val id = interner.intern("keyword")
        val result = interner.lookup(id)

        expect(result.is_some()).to_be(true)

        match result:
            case Some(s):
                expect(s).to_equal("keyword")
            case None:
                expect(false).to_be(true)

    it("returns None for unknown ID"):
        val interner = optimize.StringInterner.new()

        val result = interner.lookup(999)

        expect(result.is_none()).to_be(true)

    it("gets ID for string"):
        var interner = optimize.StringInterner.new()

        interner.intern("identifier")

        val id = interner.get_id("identifier")

        expect(id.is_some()).to_be(true)

    it("returns None for unknown string"):
        val interner = optimize.StringInterner.new()

        val id = interner.get_id("unknown")

        expect(id.is_none()).to_be(true)

    it("tracks size correctly"):
        var interner = optimize.StringInterner.new()

        interner.intern("a")
        interner.intern("b")
        interner.intern("a")  # Duplicate

        expect(interner.size()).to_equal(2)

describe("QueryCache"):
    it("creates cache with max size"):
        val cache = optimize.QueryCache.new(100)

        expect(cache.max_size).to_equal(100)

    it("caches query results"):
        var cache = optimize.QueryCache.new(10)

        val matches = []
        cache.put("query1", matches)

        val result = cache.get("query1")

        expect(result.is_some()).to_be(true)

    it("returns None for cache miss"):
        val cache = optimize.QueryCache.new(10)

        val result = cache.get("unknown")

        expect(result.is_none()).to_be(true)

    it("evicts entries when at capacity"):
        var cache = optimize.QueryCache.new(2)

        # Fill cache
        cache.put("q1", [])
        cache.put("q2", [])

        # This should evict q1 (least recently used)
        cache.put("q3", [])

        expect(cache.size()).to_equal(2)

    it("updates access count on get"):
        var cache = optimize.QueryCache.new(10)

        cache.put("query1", [])

        # Access multiple times
        cache.get("query1")
        cache.get("query1")

        val count = cache.access_count.get("query1").unwrap_or(0)
        expect(count).to_be_greater_than(1)

    it("clears cache"):
        var cache = optimize.QueryCache.new(10)

        cache.put("q1", [])
        cache.put("q2", [])

        cache.clear()

        expect(cache.size()).to_equal(0)

describe("ArenaOptimizer"):
    it("creates optimizer with pool and block size"):
        val optimizer = optimize.ArenaOptimizer.new(1000, 100)

        expect(optimizer.pool_size).to_equal(1000)
        expect(optimizer.block_size).to_equal(100)

    it("estimates nodes needed for source"):
        val optimizer = optimize.ArenaOptimizer.new(1000, 100)

        # 1000 chars â‰ˆ 100 nodes * 1.2 = 120 nodes
        val estimate = optimizer.estimate_nodes_needed(1000)

        expect(estimate).to_be_greater_than(0)

    it("recommends pool size"):
        val optimizer = optimize.ArenaOptimizer.new(1000, 100)

        val pool_size = optimizer.recommend_pool_size(1000)

        # Should be rounded to block size
        expect(pool_size % optimizer.block_size).to_equal(0)

    it("allocates pool"):
        var optimizer = optimize.ArenaOptimizer.new(1000, 100)

        optimizer.allocate_pool(150)

        expect(optimizer.total_nodes).to_equal(150)
        expect(optimizer.allocated_blocks).to_be_greater_than(0)

    it("provides statistics"):
        var optimizer = optimize.ArenaOptimizer.new(1000, 100)

        optimizer.allocate_pool(200)

        val stats = optimizer.get_statistics()

        expect(stats.contains_key("pool_size")).to_be(true)
        expect(stats.contains_key("total_nodes")).to_be(true)
        expect(stats["total_nodes"]).to_equal(200)

describe("QueryOptimizer"):
    it("compiles and caches query"):
        var optimizer = optimize.QueryOptimizer.new()

        # First compilation
        val result1 = optimizer.get_or_compile("simple", "")

        expect(result1.is_ok()).to_be(true)

        # Second call should use cache
        val result2 = optimizer.get_or_compile("simple", "")

        expect(result2.is_ok()).to_be(true)
        expect(optimizer.cache_size()).to_equal(1)

    it("tracks query stats"):
        var optimizer = optimize.QueryOptimizer.new()

        # Compile query
        optimizer.get_or_compile("simple", "")

        # Access from cache
        optimizer.get_or_compile("simple", "")
        optimizer.get_or_compile("simple", "")

        val stats = optimizer.get_stats("simple", "")

        expect(stats.is_some()).to_be(true)

        match stats:
            case Some(s):
                expect(s.hit_count).to_be_greater_than(0)
            case None:
                expect(false).to_be(true)

    it("clears cache"):
        var optimizer = optimize.QueryOptimizer.new()

        optimizer.get_or_compile("simple", "")
        optimizer.get_or_compile("simple", "query2")

        optimizer.clear_cache()

        expect(optimizer.cache_size()).to_equal(0)

    it("returns error for invalid query"):
        var optimizer = optimize.QueryOptimizer.new()

        # Invalid query should fail
        val result = optimizer.get_or_compile("invalid_language", "bad query")

        # May or may not error depending on implementation
        # Just ensure it doesn't crash

describe("Debouncer"):
    it("creates debouncer with delay"):
        val debouncer = optimize.Debouncer.new(300)

        expect(debouncer.delay_ms).to_equal(300)

    it("triggers on first call"):
        var debouncer = optimize.Debouncer.new(300)

        val should_trigger = debouncer.should_trigger(0)

        expect(should_trigger).to_be(true)

    it("does not trigger if too soon"):
        var debouncer = optimize.Debouncer.new(300)

        debouncer.should_trigger(0)

        # 100ms later (< 300ms delay)
        val should_trigger = debouncer.should_trigger(100)

        expect(should_trigger).to_be(false)

    it("triggers after delay expires"):
        var debouncer = optimize.Debouncer.new(300)

        debouncer.should_trigger(0)

        # 400ms later (> 300ms delay)
        val should_trigger = debouncer.should_trigger(400)

        expect(should_trigger).to_be(true)

    it("marks as pending"):
        var debouncer = optimize.Debouncer.new(300)

        debouncer.mark_pending()

        expect(debouncer.has_pending()).to_be(true)

    it("resets pending state"):
        var debouncer = optimize.Debouncer.new(300)

        debouncer.mark_pending()
        debouncer.reset()

        expect(debouncer.has_pending()).to_be(false)

describe("PerformanceMetrics"):
    it("records parse times"):
        var metrics = optimize.PerformanceMetrics.new()

        metrics.record_parse(10.5)
        metrics.record_parse(12.3)

        expect(metrics.parse_times.len()).to_equal(2)

    it("records incremental parse times"):
        var metrics = optimize.PerformanceMetrics.new()

        metrics.record_incremental_parse(2.5)
        metrics.record_incremental_parse(3.1)

        expect(metrics.incremental_parse_times.len()).to_equal(2)

    it("records query times"):
        var metrics = optimize.PerformanceMetrics.new()

        metrics.record_query(5.2)

        expect(metrics.query_times.len()).to_equal(1)

    it("records memory usage"):
        var metrics = optimize.PerformanceMetrics.new()

        metrics.record_memory(1024000)

        expect(metrics.memory_usage.len()).to_equal(1)

    it("computes parse stats"):
        var metrics = optimize.PerformanceMetrics.new()

        metrics.record_parse(10.0)
        metrics.record_parse(20.0)
        metrics.record_parse(15.0)

        val stats = metrics.get_parse_stats()

        expect(stats.avg).to_equal(15.0)
        expect(stats.min).to_equal(10.0)
        expect(stats.max).to_equal(20.0)
        expect(stats.count).to_equal(3)

    it("computes incremental parse stats"):
        var metrics = optimize.PerformanceMetrics.new()

        metrics.record_incremental_parse(2.0)
        metrics.record_incremental_parse(4.0)

        val stats = metrics.get_incremental_parse_stats()

        expect(stats.avg).to_equal(3.0)

    it("computes query stats"):
        var metrics = optimize.PerformanceMetrics.new()

        metrics.record_query(5.0)
        metrics.record_query(7.0)

        val stats = metrics.get_query_stats()

        expect(stats.avg).to_equal(6.0)

    it("computes memory stats"):
        var metrics = optimize.PerformanceMetrics.new()

        metrics.record_memory(1024 * 1024)  # 1 MB
        metrics.record_memory(2 * 1024 * 1024)  # 2 MB

        val mem_stats = metrics.get_memory_stats()

        expect(mem_stats.avg_mb).to_be_greater_than(0.0)
        expect(mem_stats.max_bytes).to_equal(2 * 1024 * 1024)

    it("handles empty metrics gracefully"):
        val metrics = optimize.PerformanceMetrics.new()

        val stats = metrics.get_parse_stats()

        expect(stats.count).to_equal(0)
        expect(stats.avg).to_equal(0.0)

    it("handles empty memory metrics"):
        val metrics = optimize.PerformanceMetrics.new()

        val mem_stats = metrics.get_memory_stats()

        expect(mem_stats.avg_bytes).to_equal(0)

describe("Integration"):
    it("combines string interning with query caching"):
        var interner = optimize.StringInterner.new()
        var cache = optimize.QueryCache.new(10)

        # Intern node kinds
        val id1 = interner.intern("function")
        val id2 = interner.intern("variable")

        # Cache query results
        cache.put("query1", [])

        # Verify both work
        expect(interner.size()).to_equal(2)
        expect(cache.size()).to_equal(1)

    it("tracks metrics with optimizer"):
        var metrics = optimize.PerformanceMetrics.new()
        var optimizer = optimize.ArenaOptimizer.new(1000, 100)

        # Allocate pool
        optimizer.allocate_pool(200)

        # Record timing
        metrics.record_parse(15.5)

        # Get stats
        val arena_stats = optimizer.get_statistics()
        val parse_stats = metrics.get_parse_stats()

        expect(arena_stats["total_nodes"]).to_equal(200)
        expect(parse_stats.avg).to_equal(15.5)

describe("Edge Cases"):
    it("handles debouncer with zero delay"):
        var debouncer = optimize.Debouncer.new(0)

        # Should always trigger
        expect(debouncer.should_trigger(0)).to_be(true)
        expect(debouncer.should_trigger(1)).to_be(true)

    it("handles cache with size 1"):
        var cache = optimize.QueryCache.new(1)

        cache.put("q1", [])
        cache.put("q2", [])

        # Should only have 1 entry
        expect(cache.size()).to_equal(1)

    it("handles arena with small block size"):
        var optimizer = optimize.ArenaOptimizer.new(100, 1)

        optimizer.allocate_pool(10)

        # Should allocate 10 blocks of size 1
        expect(optimizer.allocated_blocks).to_equal(10)
