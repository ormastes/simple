# Unit tests for grammar compilation pipeline

import spec.{describe, it, expect}
import parser.treesitter.grammar_compile as compile
import parser.treesitter.{Grammar}

describe("CompiledGrammar"):
    it("creates compiled grammar"):
        val grammar = compile.CompiledGrammar.new("test", "source_file")

        expect(grammar.name).to_equal("test")
        expect(grammar.entry_point).to_equal("source_file")
        expect(grammar.rules.len()).to_equal(0)

    it("stores rules"):
        var grammar = compile.CompiledGrammar.new("test", "source_file")

        val rule = compile.CompiledRule.new("test_rule", compile.RulePattern.Token("Identifier"))
        grammar.rules["test_rule"] = rule

        expect(grammar.rules.len()).to_equal(1)
        expect(grammar.get_rule("test_rule").is_some()).to_be(true)

    it("checks nullable rules"):
        var grammar = compile.CompiledGrammar.new("test", "source_file")
        grammar.nullable_rules.insert("optional_rule")

        expect(grammar.is_nullable("optional_rule")).to_be(true)
        expect(grammar.is_nullable("required_rule")).to_be(false)

    it("gets first sets"):
        var grammar = compile.CompiledGrammar.new("test", "source_file")
        var first_set = Set()
        first_set.insert("Identifier")
        first_set.insert("Number")
        grammar.first_sets["expr"] = first_set

        val result = grammar.get_first_set("expr")

        expect(result.contains("Identifier")).to_be(true)
        expect(result.contains("Number")).to_be(true)

    it("gets follow sets"):
        var grammar = compile.CompiledGrammar.new("test", "source_file")
        var follow_set = Set()
        follow_set.insert("Semicolon")
        grammar.follow_sets["statement"] = follow_set

        val result = grammar.get_follow_set("statement")

        expect(result.contains("Semicolon")).to_be(true)

describe("CompiledRule"):
    it("creates compiled rule"):
        val pattern = compile.RulePattern.Token("Identifier")
        val rule = compile.CompiledRule.new("identifier", pattern)

        expect(rule.name).to_equal("identifier")
        expect(rule.is_terminal).to_be(false)
        expect(rule.is_nullable).to_be(false)

describe("RulePattern"):
    it("creates token pattern"):
        val pattern = compile.RulePattern.Token("Identifier")

        match pattern:
            case Token(token_type):
                expect(token_type).to_equal("Identifier")
            case _:
                fail("Expected Token pattern")

    it("creates sequence pattern"):
        val patterns = [
            compile.RulePattern.Token("Fn"),
            compile.RulePattern.Token("Identifier")
        ]
        val pattern = compile.RulePattern.Sequence(patterns)

        match pattern:
            case Sequence(ps):
                expect(ps.len()).to_equal(2)
            case _:
                fail("Expected Sequence pattern")

    it("creates choice pattern"):
        val patterns = [
            compile.RulePattern.Token("Int"),
            compile.RulePattern.Token("Float")
        ]
        val pattern = compile.RulePattern.Choice(patterns)

        match pattern:
            case Choice(ps):
                expect(ps.len()).to_equal(2)
            case _:
                fail("Expected Choice pattern")

    it("creates repeat pattern"):
        val inner = compile.RulePattern.Token("Identifier")
        val pattern = compile.RulePattern.Repeat(inner)

        match pattern:
            case Repeat(p):
                match p:
                    case Token(t):
                        expect(t).to_equal("Identifier")
                    case _:
                        fail("Expected Token inside Repeat")
            case _:
                fail("Expected Repeat pattern")

    it("creates optional pattern"):
        val inner = compile.RulePattern.Token("Comma")
        val pattern = compile.RulePattern.Optional(inner)

        match pattern:
            case Optional(p):
                match p:
                    case Token(t):
                        expect(t).to_equal("Comma")
                    case _:
                        fail("Expected Token inside Optional")
            case _:
                fail("Expected Optional pattern")

    it("creates reference pattern"):
        val pattern = compile.RulePattern.Reference("expression")

        match pattern:
            case Reference(name):
                expect(name).to_equal("expression")
            case _:
                fail("Expected Reference pattern")

describe("GrammarCompiler"):
    it("creates compiler"):
        val compiler = compile.GrammarCompiler.new()

        # Compiler created successfully
        expect(true).to_be(true)

    it("compiles simple grammar"):
        val compiler = compile.GrammarCompiler.new()
        val grammar = Grammar.new("test")

        val compiled = compiler.compile(grammar).unwrap()

        expect(compiled.name).to_equal("test")

describe("Nullable rules"):
    it("detects token as not nullable"):
        val compiler = compile.GrammarCompiler.new()
        var compiled = compile.CompiledGrammar.new("test", "source_file")

        val pattern = compile.RulePattern.Token("Identifier")
        val is_nullable = compiler.is_pattern_nullable(pattern, &compiled)

        expect(is_nullable).to_be(false)

    it("detects repeat as nullable"):
        val compiler = compile.GrammarCompiler.new()
        val compiled = compile.CompiledGrammar.new("test", "source_file")

        val inner = compile.RulePattern.Token("Identifier")
        val pattern = compile.RulePattern.Repeat(inner)
        val is_nullable = compiler.is_pattern_nullable(pattern, &compiled)

        expect(is_nullable).to_be(true)

    it("detects optional as nullable"):
        val compiler = compile.GrammarCompiler.new()
        val compiled = compile.CompiledGrammar.new("test", "source_file")

        val inner = compile.RulePattern.Token("Identifier")
        val pattern = compile.RulePattern.Optional(inner)
        val is_nullable = compiler.is_pattern_nullable(pattern, &compiled)

        expect(is_nullable).to_be(true)

    it("detects sequence with all nullable as nullable"):
        val compiler = compile.GrammarCompiler.new()
        val compiled = compile.CompiledGrammar.new("test", "source_file")

        val patterns = [
            compile.RulePattern.Optional(compile.RulePattern.Token("A")),
            compile.RulePattern.Repeat(compile.RulePattern.Token("B"))
        ]
        val pattern = compile.RulePattern.Sequence(patterns)
        val is_nullable = compiler.is_pattern_nullable(pattern, &compiled)

        expect(is_nullable).to_be(true)

    it("detects sequence with non-nullable as not nullable"):
        val compiler = compile.GrammarCompiler.new()
        val compiled = compile.CompiledGrammar.new("test", "source_file")

        val patterns = [
            compile.RulePattern.Token("A"),
            compile.RulePattern.Optional(compile.RulePattern.Token("B"))
        ]
        val pattern = compile.RulePattern.Sequence(patterns)
        val is_nullable = compiler.is_pattern_nullable(pattern, &compiled)

        expect(is_nullable).to_be(false)

    it("detects choice with any nullable as nullable"):
        val compiler = compile.GrammarCompiler.new()
        val compiled = compile.CompiledGrammar.new("test", "source_file")

        val patterns = [
            compile.RulePattern.Token("A"),
            compile.RulePattern.Optional(compile.RulePattern.Token("B"))
        ]
        val pattern = compile.RulePattern.Choice(patterns)
        val is_nullable = compiler.is_pattern_nullable(pattern, &compiled)

        expect(is_nullable).to_be(true)

describe("First sets"):
    it("adds token to first set"):
        val compiler = compile.GrammarCompiler.new()
        val compiled = compile.CompiledGrammar.new("test", "source_file")
        var first_set = Set()

        val pattern = compile.RulePattern.Token("Identifier")
        compiler.add_first_tokens(pattern, &compiled, &mut first_set)

        expect(first_set.contains("Identifier")).to_be(true)

    it("adds first token from sequence"):
        val compiler = compile.GrammarCompiler.new()
        val compiled = compile.CompiledGrammar.new("test", "source_file")
        var first_set = Set()

        val patterns = [
            compile.RulePattern.Token("Fn"),
            compile.RulePattern.Token("Identifier")
        ]
        val pattern = compile.RulePattern.Sequence(patterns)
        compiler.add_first_tokens(pattern, &compiled, &mut first_set)

        # Should contain first token
        expect(first_set.contains("Fn")).to_be(true)

    it("adds all choices to first set"):
        val compiler = compile.GrammarCompiler.new()
        val compiled = compile.CompiledGrammar.new("test", "source_file")
        var first_set = Set()

        val patterns = [
            compile.RulePattern.Token("Int"),
            compile.RulePattern.Token("Float")
        ]
        val pattern = compile.RulePattern.Choice(patterns)
        compiler.add_first_tokens(pattern, &compiled, &mut first_set)

        expect(first_set.contains("Int")).to_be(true)
        expect(first_set.contains("Float")).to_be(true)

describe("GrammarCache"):
    it("creates cache"):
        val cache = compile.GrammarCache.new()

        expect(cache.size()).to_equal(0)

    it("adds and gets compiled grammar"):
        var cache = compile.GrammarCache.new()
        val compiled = compile.CompiledGrammar.new("test", "source_file")

        cache.add("test", compiled)

        expect(cache.contains("test")).to_be(true)
        expect(cache.size()).to_equal(1)

        val retrieved = cache.get("test").unwrap()
        expect(retrieved.name).to_equal("test")

    it("returns None for missing language"):
        val cache = compile.GrammarCache.new()

        val result = cache.get("nonexistent")

        expect(result.is_none()).to_be(true)

    it("clears cache"):
        var cache = compile.GrammarCache.new()
        val compiled = compile.CompiledGrammar.new("test", "source_file")
        cache.add("test", compiled)

        expect(cache.size()).to_equal(1)

        cache.clear()

        expect(cache.size()).to_equal(0)
        expect(cache.contains("test")).to_be(false)

describe("GrammarPipeline"):
    it("creates pipeline"):
        val pipeline = compile.GrammarPipeline.new()

        expect(pipeline.cache.size()).to_equal(0)

    it("compiles grammar"):
        var pipeline = compile.GrammarPipeline.new()
        val grammar = Grammar.new("test")

        val compiled = pipeline.compile(grammar).unwrap()

        expect(compiled.name).to_equal("test")

    it("caches compiled grammar"):
        var pipeline = compile.GrammarPipeline.new()
        val grammar = Grammar.new("test")

        # First compilation
        pipeline.compile(grammar).unwrap()
        expect(pipeline.cache.size()).to_equal(1)

        # Second compilation (should use cache)
        val compiled = pipeline.compile(grammar).unwrap()
        expect(compiled.name).to_equal("test")

    it("clears pipeline cache"):
        var pipeline = compile.GrammarPipeline.new()
        val grammar = Grammar.new("test")
        pipeline.compile(grammar).unwrap()

        expect(pipeline.cache.size()).to_equal(1)

        pipeline.clear_cache()

        expect(pipeline.cache.size()).to_equal(0)

describe("Convenience functions"):
    it("compiles grammar"):
        val grammar = Grammar.new("test")

        val compiled = compile.compile_grammar(grammar).unwrap()

        expect(compiled.name).to_equal("test")

describe("Token extraction"):
    it("extracts token types from grammar"):
        val compiler = compile.GrammarCompiler.new()
        var token_set = Set()

        val pattern = compile.RulePattern.Token("Identifier")
        compiler.collect_token_types(pattern, &mut token_set)

        expect(token_set.contains("Identifier")).to_be(true)

    it("extracts tokens from sequence"):
        val compiler = compile.GrammarCompiler.new()
        var token_set = Set()

        val patterns = [
            compile.RulePattern.Token("Fn"),
            compile.RulePattern.Token("Identifier")
        ]
        val pattern = compile.RulePattern.Sequence(patterns)
        compiler.collect_token_types(pattern, &mut token_set)

        expect(token_set.contains("Fn")).to_be(true)
        expect(token_set.contains("Identifier")).to_be(true)

    it("extracts tokens from nested patterns"):
        val compiler = compile.GrammarCompiler.new()
        var token_set = Set()

        val inner = compile.RulePattern.Token("Number")
        val pattern = compile.RulePattern.Repeat(inner)
        compiler.collect_token_types(pattern, &mut token_set)

        expect(token_set.contains("Number")).to_be(true)

describe("Integration"):
    it("compiles and caches grammar"):
        var pipeline = compile.GrammarPipeline.new()
        val grammar = Grammar.new("simple")

        # Compile
        val compiled = pipeline.compile(grammar).unwrap()

        expect(compiled.name).to_equal("simple")
        expect(pipeline.cache.contains("simple")).to_be(true)

        # Use cache
        val cached = pipeline.compile(grammar).unwrap()
        expect(cached.name).to_equal("simple")
