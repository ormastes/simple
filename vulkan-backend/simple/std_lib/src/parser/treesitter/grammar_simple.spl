# Simple Language Grammar for Tree-sitter
# Complete grammar definition for the Simple programming language

import parser.treesitter.{Grammar, Rule, Token, Pattern}

# Grammar for Simple language
class SimpleGrammar:
    grammar: Grammar

    static fn new() -> SimpleGrammar:
        var grammar = Grammar.new("simple")

        # Entry point: module/source file
        grammar.add_rule("source_file", repeat(choice([
            ref("statement"),
            ref("declaration"),
            token(Newline)
        ])))

        # Top-level declarations
        grammar.add_rule("declaration", choice([
            ref("function_def"),
            ref("class_def"),
            ref("struct_def"),
            ref("enum_def"),
            ref("trait_def"),
            ref("import_stmt")
        ]))

        # Function definition
        grammar.add_rule("function_def", seq([
            token(Fn),
            field("name", ref("identifier")),
            token(LParen),
            optional(ref("parameter_list")),
            token(RParen),
            optional(seq([token(Arrow), field("return_type", ref("type"))])),
            token(Colon),
            ref("block")
        ]))

        # Parameter list
        grammar.add_rule("parameter_list", seq([
            ref("parameter"),
            repeat(seq([token(Comma), ref("parameter")]))
        ]))

        # Parameter
        grammar.add_rule("parameter", seq([
            field("name", ref("identifier")),
            token(Colon),
            field("type", ref("type"))
        ]))

        # Class definition
        grammar.add_rule("class_def", seq([
            token(Class),
            field("name", ref("type_identifier")),
            optional(ref("type_parameters")),
            token(Colon),
            ref("class_block")
        ]))

        # Class block
        grammar.add_rule("class_block", seq([
            token(Newline),
            token(Indent),
            repeat(choice([
                ref("field_def"),
                ref("function_def"),
                token(Newline)
            ])),
            token(Dedent)
        ]))

        # Field definition
        grammar.add_rule("field_def", seq([
            field("name", ref("identifier")),
            token(Colon),
            field("type", ref("type")),
            token(Newline)
        ]))

        # Struct definition
        grammar.add_rule("struct_def", seq([
            token(Struct),
            field("name", ref("type_identifier")),
            optional(ref("type_parameters")),
            token(Colon),
            ref("struct_block")
        ]))

        # Struct block (same as class block)
        grammar.add_rule("struct_block", ref("class_block"))

        # Enum definition
        grammar.add_rule("enum_def", seq([
            token(Enum),
            field("name", ref("type_identifier")),
            optional(ref("type_parameters")),
            token(Colon),
            ref("enum_block")
        ]))

        # Enum block
        grammar.add_rule("enum_block", seq([
            token(Newline),
            token(Indent),
            repeat(choice([
                ref("enum_variant"),
                token(Newline)
            ])),
            token(Dedent)
        ]))

        # Enum variant
        grammar.add_rule("enum_variant", choice([
            # Simple variant: Red
            field("name", ref("type_identifier")),
            # Tuple variant: Some(T)
            seq([
                field("name", ref("type_identifier")),
                token(LParen),
                ref("type_list"),
                token(RParen)
            ]),
            # Struct variant: Point { x: Int, y: Int }
            seq([
                field("name", ref("type_identifier")),
                token(LBrace),
                ref("field_list"),
                token(RBrace)
            ])
        ]))

        # Trait definition
        grammar.add_rule("trait_def", seq([
            token(Trait),
            field("name", ref("type_identifier")),
            optional(ref("type_parameters")),
            token(Colon),
            ref("trait_block")
        ]))

        # Trait block
        grammar.add_rule("trait_block", seq([
            token(Newline),
            token(Indent),
            repeat(choice([
                ref("trait_method"),
                token(Newline)
            ])),
            token(Dedent)
        ]))

        # Trait method (function signature)
        grammar.add_rule("trait_method", seq([
            token(Fn),
            field("name", ref("identifier")),
            token(LParen),
            optional(ref("parameter_list")),
            token(RParen),
            optional(seq([token(Arrow), field("return_type", ref("type"))])),
            token(Newline)
        ]))

        # Import statement
        grammar.add_rule("import_stmt", seq([
            token(Import),
            ref("import_path"),
            optional(seq([
                token(As),
                ref("identifier")
            ])),
            token(Newline)
        ]))

        # Import path
        grammar.add_rule("import_path", seq([
            ref("identifier"),
            repeat(seq([token(Dot), ref("identifier")]))
        ]))

        # Statements
        grammar.add_rule("statement", choice([
            ref("let_stmt"),
            ref("return_stmt"),
            ref("if_stmt"),
            ref("match_stmt"),
            ref("for_stmt"),
            ref("while_stmt"),
            ref("loop_stmt"),
            ref("break_stmt"),
            ref("continue_stmt"),
            ref("expression_stmt")
        ]))

        # Let statement
        grammar.add_rule("let_stmt", seq([
            token(Let),
            optional(token(Mut)),
            field("pattern", ref("pattern")),
            optional(seq([token(Colon), field("type", ref("type"))])),
            token(Eq),
            field("value", ref("expression")),
            token(Newline)
        ]))

        # Return statement
        grammar.add_rule("return_stmt", seq([
            token(Return),
            optional(ref("expression")),
            token(Newline)
        ]))

        # If statement
        grammar.add_rule("if_stmt", seq([
            token(If),
            field("condition", ref("expression")),
            token(Colon),
            ref("block"),
            repeat(ref("elif_clause")),
            optional(ref("else_clause"))
        ]))

        # Elif clause
        grammar.add_rule("elif_clause", seq([
            token(Elif),
            field("condition", ref("expression")),
            token(Colon),
            ref("block")
        ]))

        # Else clause
        grammar.add_rule("else_clause", seq([
            token(Else),
            token(Colon),
            ref("block")
        ]))

        # Match statement
        grammar.add_rule("match_stmt", seq([
            token(Match),
            field("value", ref("expression")),
            token(Colon),
            ref("match_block")
        ]))

        # Match block
        grammar.add_rule("match_block", seq([
            token(Newline),
            token(Indent),
            repeat(ref("match_case")),
            token(Dedent)
        ]))

        # Match case
        grammar.add_rule("match_case", seq([
            token(Case),
            field("pattern", ref("pattern")),
            optional(seq([token(If), field("guard", ref("expression"))])),
            token(Colon),
            choice([
                # Single-line body
                seq([ref("expression"), token(Newline)]),
                # Multi-line body
                ref("block")
            ])
        ]))

        # For statement
        grammar.add_rule("for_stmt", seq([
            token(For),
            field("pattern", ref("pattern")),
            token(In),
            field("iterable", ref("expression")),
            token(Colon),
            ref("block")
        ]))

        # While statement
        grammar.add_rule("while_stmt", seq([
            token(While),
            field("condition", ref("expression")),
            token(Colon),
            ref("block")
        ]))

        # Loop statement
        grammar.add_rule("loop_stmt", seq([
            token(Loop),
            token(Colon),
            ref("block")
        ]))

        # Break statement
        grammar.add_rule("break_stmt", seq([
            token(Break),
            token(Newline)
        ]))

        # Continue statement
        grammar.add_rule("continue_stmt", seq([
            token(Continue),
            token(Newline)
        ]))

        # Expression statement
        grammar.add_rule("expression_stmt", seq([
            ref("expression"),
            token(Newline)
        ]))

        # Block
        grammar.add_rule("block", seq([
            token(Newline),
            token(Indent),
            repeat(choice([
                ref("statement"),
                token(Newline)
            ])),
            token(Dedent)
        ]))

        # Expressions (Pratt parser priorities)
        grammar.add_rule("expression", choice([
            ref("binary_expr"),
            ref("unary_expr"),
            ref("call_expr"),
            ref("index_expr"),
            ref("field_expr"),
            ref("lambda_expr"),
            ref("if_expr"),
            ref("match_expr"),
            ref("primary_expr")
        ]))

        # Binary expressions
        grammar.add_rule("binary_expr", prec_left(1, seq([
            field("left", ref("expression")),
            field("operator", choice([
                token(Plus), token(Minus), token(Star), token(Slash),
                token(Percent), token(DoubleStar),
                token(DoubleEq), token(NotEq),
                token(Lt), token(Gt), token(LtEq), token(GtEq),
                token(And), token(Or),
                token(Pipe), token(Ampersand), token(Caret),
                token(LtLt), token(GtGt)
            ])),
            field("right", ref("expression"))
        ])))

        # Unary expressions
        grammar.add_rule("unary_expr", prec_right(2, seq([
            field("operator", choice([
                token(Minus), token(Not), token(Tilde)
            ])),
            field("operand", ref("expression"))
        ])))

        # Call expression
        grammar.add_rule("call_expr", prec_left(3, seq([
            field("callee", ref("expression")),
            token(LParen),
            optional(ref("argument_list")),
            token(RParen)
        ])))

        # Argument list
        grammar.add_rule("argument_list", seq([
            ref("expression"),
            repeat(seq([token(Comma), ref("expression")]))
        ]))

        # Index expression
        grammar.add_rule("index_expr", prec_left(3, seq([
            field("value", ref("expression")),
            token(LBracket),
            field("index", ref("expression")),
            token(RBracket)
        ])))

        # Field expression
        grammar.add_rule("field_expr", prec_left(3, seq([
            field("value", ref("expression")),
            token(Dot),
            field("field", ref("identifier"))
        ])))

        # Lambda expression
        grammar.add_rule("lambda_expr", seq([
            token(Pipe),
            optional(ref("parameter_list")),
            token(Pipe),
            choice([
                # Expression body
                ref("expression"),
                # Block body
                seq([token(Colon), ref("block")])
            ])
        ]))

        # If expression
        grammar.add_rule("if_expr", seq([
            token(If),
            field("condition", ref("expression")),
            token(Then),
            field("then_value", ref("expression")),
            token(Else),
            field("else_value", ref("expression"))
        ]))

        # Match expression
        grammar.add_rule("match_expr", seq([
            token(Match),
            field("value", ref("expression")),
            token(Colon),
            ref("match_expr_block")
        ]))

        # Match expression block (inline)
        grammar.add_rule("match_expr_block", seq([
            token(LBrace),
            ref("match_case"),
            repeat(seq([token(Comma), ref("match_case")])),
            optional(token(Comma)),
            token(RBrace)
        ]))

        # Primary expressions
        grammar.add_rule("primary_expr", choice([
            ref("literal"),
            ref("identifier"),
            ref("array_literal"),
            ref("tuple_literal"),
            ref("dict_literal"),
            ref("struct_literal"),
            ref("paren_expr")
        ]))

        # Literals
        grammar.add_rule("literal", choice([
            ref("integer_literal"),
            ref("float_literal"),
            ref("string_literal"),
            ref("fstring_literal"),
            ref("boolean_literal"),
            ref("nil_literal")
        ]))

        # Integer literal
        grammar.add_rule("integer_literal", token(Integer))

        # Float literal
        grammar.add_rule("float_literal", token(Float))

        # String literal
        grammar.add_rule("string_literal", token(String))

        # F-string literal
        grammar.add_rule("fstring_literal", seq([
            token(FStringStart),
            repeat(choice([
                token(FStringText),
                ref("fstring_interpolation")
            ])),
            token(FStringEnd)
        ]))

        # F-string interpolation
        grammar.add_rule("fstring_interpolation", seq([
            token(LBrace),
            ref("expression"),
            optional(seq([token(Colon), ref("format_spec")])),
            token(RBrace)
        ]))

        # Format spec
        grammar.add_rule("format_spec", token(FStringFormatSpec))

        # Boolean literal
        grammar.add_rule("boolean_literal", choice([
            token(True),
            token(False)
        ]))

        # Nil literal
        grammar.add_rule("nil_literal", token(Nil))

        # Array literal
        grammar.add_rule("array_literal", seq([
            token(LBracket),
            optional(ref("expression_list")),
            token(RBracket)
        ]))

        # Tuple literal
        grammar.add_rule("tuple_literal", seq([
            token(LParen),
            ref("expression"),
            token(Comma),
            optional(ref("expression_list")),
            token(RParen)
        ]))

        # Dict literal
        grammar.add_rule("dict_literal", seq([
            token(LBrace),
            optional(ref("dict_entry_list")),
            token(RBrace)
        ]))

        # Dict entry list
        grammar.add_rule("dict_entry_list", seq([
            ref("dict_entry"),
            repeat(seq([token(Comma), ref("dict_entry")])),
            optional(token(Comma))
        ]))

        # Dict entry
        grammar.add_rule("dict_entry", seq([
            field("key", ref("expression")),
            token(Colon),
            field("value", ref("expression"))
        ]))

        # Struct literal
        grammar.add_rule("struct_literal", seq([
            field("name", ref("type_identifier")),
            token(LParen),
            optional(ref("field_init_list")),
            token(RParen)
        ]))

        # Field init list
        grammar.add_rule("field_init_list", seq([
            ref("field_init"),
            repeat(seq([token(Comma), ref("field_init")])),
            optional(token(Comma))
        ]))

        # Field init
        grammar.add_rule("field_init", seq([
            field("name", ref("identifier")),
            token(Colon),
            field("value", ref("expression"))
        ]))

        # Parenthesized expression
        grammar.add_rule("paren_expr", seq([
            token(LParen),
            ref("expression"),
            token(RParen)
        ]))

        # Expression list
        grammar.add_rule("expression_list", seq([
            ref("expression"),
            repeat(seq([token(Comma), ref("expression")])),
            optional(token(Comma))
        ]))

        # Patterns
        grammar.add_rule("pattern", choice([
            ref("identifier_pattern"),
            ref("wildcard_pattern"),
            ref("literal_pattern"),
            ref("tuple_pattern"),
            ref("struct_pattern"),
            ref("enum_pattern"),
            ref("or_pattern")
        ]))

        # Identifier pattern
        grammar.add_rule("identifier_pattern", ref("identifier"))

        # Wildcard pattern
        grammar.add_rule("wildcard_pattern", token(Underscore))

        # Literal pattern
        grammar.add_rule("literal_pattern", ref("literal"))

        # Tuple pattern
        grammar.add_rule("tuple_pattern", seq([
            token(LParen),
            ref("pattern"),
            token(Comma),
            optional(ref("pattern_list")),
            token(RParen)
        ]))

        # Pattern list
        grammar.add_rule("pattern_list", seq([
            ref("pattern"),
            repeat(seq([token(Comma), ref("pattern")])),
            optional(token(Comma))
        ]))

        # Struct pattern
        grammar.add_rule("struct_pattern", seq([
            field("name", ref("type_identifier")),
            token(LParen),
            optional(ref("field_pattern_list")),
            token(RParen)
        ]))

        # Field pattern list
        grammar.add_rule("field_pattern_list", seq([
            ref("field_pattern"),
            repeat(seq([token(Comma), ref("field_pattern")])),
            optional(token(Comma))
        ]))

        # Field pattern
        grammar.add_rule("field_pattern", seq([
            field("name", ref("identifier")),
            token(Colon),
            field("pattern", ref("pattern"))
        ]))

        # Enum pattern
        grammar.add_rule("enum_pattern", seq([
            field("variant", ref("type_identifier")),
            optional(choice([
                # Tuple variant pattern: Some(x)
                seq([
                    token(LParen),
                    optional(ref("pattern_list")),
                    token(RParen)
                ]),
                # Struct variant pattern: Point { x, y }
                seq([
                    token(LBrace),
                    optional(ref("field_pattern_list")),
                    token(RBrace)
                ])
            ]))
        ]))

        # Or pattern
        grammar.add_rule("or_pattern", seq([
            ref("pattern"),
            token(Pipe),
            ref("pattern")
        ]))

        # Types
        grammar.add_rule("type", choice([
            ref("named_type"),
            ref("generic_type"),
            ref("function_type"),
            ref("tuple_type"),
            ref("array_type"),
            ref("dict_type"),
            ref("option_type"),
            ref("result_type")
        ]))

        # Named type
        grammar.add_rule("named_type", ref("type_identifier"))

        # Generic type
        grammar.add_rule("generic_type", seq([
            field("name", ref("type_identifier")),
            token(Lt),
            ref("type_list"),
            token(Gt)
        ]))

        # Type list
        grammar.add_rule("type_list", seq([
            ref("type"),
            repeat(seq([token(Comma), ref("type")])),
            optional(token(Comma))
        ]))

        # Function type
        grammar.add_rule("function_type", seq([
            token(Fn),
            token(LParen),
            optional(ref("type_list")),
            token(RParen),
            token(Arrow),
            ref("type")
        ]))

        # Tuple type
        grammar.add_rule("tuple_type", seq([
            token(LParen),
            ref("type"),
            token(Comma),
            optional(ref("type_list")),
            token(RParen)
        ]))

        # Array type
        grammar.add_rule("array_type", seq([
            token(LBracket),
            ref("type"),
            token(RBracket)
        ]))

        # Dict type
        grammar.add_rule("dict_type", seq([
            token(LBrace),
            field("key", ref("type")),
            token(Colon),
            field("value", ref("type")),
            token(RBrace)
        ]))

        # Option type (sugar for Option<T>)
        grammar.add_rule("option_type", seq([
            ref("type"),
            token(Question)
        ]))

        # Result type (sugar for Result<T, E>)
        grammar.add_rule("result_type", seq([
            ref("type"),
            token(Exclamation)
        ]))

        # Type parameters
        grammar.add_rule("type_parameters", seq([
            token(Lt),
            ref("type_parameter_list"),
            token(Gt)
        ]))

        # Type parameter list
        grammar.add_rule("type_parameter_list", seq([
            ref("type_parameter"),
            repeat(seq([token(Comma), ref("type_parameter")])),
            optional(token(Comma))
        ]))

        # Type parameter
        grammar.add_rule("type_parameter", seq([
            field("name", ref("type_identifier")),
            optional(seq([
                token(Colon),
                ref("trait_bounds")
            ]))
        ]))

        # Trait bounds
        grammar.add_rule("trait_bounds", seq([
            ref("type_identifier"),
            repeat(seq([token(Plus), ref("type_identifier")]))
        ]))

        # Field list (for struct/enum variants)
        grammar.add_rule("field_list", seq([
            ref("field_def"),
            repeat(seq([token(Comma), ref("field_def")])),
            optional(token(Comma))
        ]))

        # Identifiers
        grammar.add_rule("identifier", token(Identifier))
        grammar.add_rule("type_identifier", token(TypeIdentifier))

        SimpleGrammar(grammar: grammar)

    fn get_grammar() -> Grammar:
        self.grammar

# Helper functions for grammar construction

fn token(kind: TokenKind) -> Rule:
    Rule.Token(kind)

fn ref(name: String) -> Rule:
    Rule.Ref(name)

fn seq(rules: List<Rule>) -> Rule:
    Rule.Seq(rules)

fn choice(rules: List<Rule>) -> Rule:
    Rule.Choice(rules)

fn optional(rule: Rule) -> Rule:
    Rule.Optional(rule)

fn repeat(rule: Rule) -> Rule:
    Rule.Repeat(rule)

fn repeat1(rule: Rule) -> Rule:
    Rule.Repeat1(rule)

fn field(name: String, rule: Rule) -> Rule:
    Rule.Field(name, rule)

fn prec_left(precedence: Int, rule: Rule) -> Rule:
    Rule.PrecLeft(precedence, rule)

fn prec_right(precedence: Int, rule: Rule) -> Rule:
    Rule.PrecRight(precedence, rule)

# Token kinds (from lexer)
enum TokenKind:
    # Keywords
    Fn, Let, Mut, Return, If, Elif, Else, Match, Case,
    For, In, While, Loop, Break, Continue,
    Class, Struct, Enum, Trait,
    Import, As, From,
    True, False, Nil,
    And, Or, Not,
    Then,  # For if-expressions

    # Operators
    Plus, Minus, Star, Slash, Percent, DoubleStar,
    Eq, DoubleEq, NotEq,
    Lt, Gt, LtEq, GtEq,
    Pipe, Ampersand, Caret, Tilde,
    LtLt, GtGt,
    Dot, Comma, Colon, Arrow, Question, Exclamation,
    Underscore,

    # Delimiters
    LParen, RParen,
    LBracket, RBracket,
    LBrace, RBrace,
    Newline, Indent, Dedent,

    # Literals
    Integer, Float, String,
    FStringStart, FStringText, FStringEnd, FStringFormatSpec,

    # Identifiers
    Identifier, TypeIdentifier
