/**
Isolated Threads

Isolated threads provide safe parallel execution without shared mutable state.
Communication between threads is only possible through channels.

Core Principles:
1. No shared mutable state - Cannot access mutable globals
2. Copy or const only - Data must be copied or const
3. Channel-only communication - Use channels for inter-thread communication
4. Global const access - Can read global constants

Basic Usage:
```sdoctest
>>> val data = [1, 2, 3]
>>> val ch = Channel.new()
>>> val handle = spawn_isolated(data, ch) \copied_data, chan:
...     chan.send(copied_data.sum())
>>> ch.recv()
6
```
*/

# FFI declarations for isolated thread operations
extern fn rt_thread_spawn_isolated(closure_ptr: i64, data: Any) -> i64
extern fn rt_thread_spawn_isolated2(closure_ptr: i64, data1: Any, data2: Any) -> i64
extern fn rt_thread_join(handle: i64) -> Any
extern fn rt_thread_is_done(handle: i64) -> i64
extern fn rt_thread_id(handle: i64) -> i64
extern fn rt_thread_free(handle: i64)
extern fn rt_thread_available_parallelism() -> i64
extern fn rt_thread_sleep(millis: i64)
extern fn rt_thread_yield()

/**
Handle for an isolated thread.

Used to join threads and get their results.
*/
struct ThreadHandle:
    _handle: i64

    /**
    Wait for the thread to complete and get its result.

    ```sdoctest
    >>> val handle = spawn_isolated(42) \x: x * 2
    >>> handle.join()
    84
    ```
    */
    fn join() -> Any:
        return rt_thread_join(self._handle)

    /**
    Check if the thread has completed without blocking.

    ```sdoctest
    >>> val handle = spawn_isolated(42) \x: x
    >>> handle.is_done()  # May be true or false
    ...
    ```
    */
    fn is_done() -> Bool:
        return rt_thread_is_done(self._handle) == 1

    /**
    Get the unique ID of this thread.
    */
    fn id() -> i64:
        return rt_thread_id(self._handle)

    /**
    Free the thread handle.
    If the thread hasn't been joined, it will be detached.
    */
    fn free():
        rt_thread_free(self._handle)

/**
Spawn an isolated thread with a single data argument.

The data is deep-copied for the thread, ensuring no shared mutable state.
The closure receives the copied data and executes in a separate OS thread.

Arguments:
- data: Data to copy into the thread
- closure: Function to execute with the copied data

Returns:
A ThreadHandle that can be used to join the thread.

```sdoctest
>>> val result_channel = Channel.new()
>>> val handle = spawn_isolated([1, 2, 3], result_channel) \data, chan:
...     chan.send(data.sum())
>>> result_channel.recv()
6
```
*/
fn spawn_isolated(data: Any, closure: fn(Any) -> Any) -> ThreadHandle:
    val handle = rt_thread_spawn_isolated(closure as i64, data)
    return ThreadHandle(_handle: handle)

/**
Spawn an isolated thread with two data arguments (e.g., data + channel).

```sdoctest
>>> val ch = Channel.new()
>>> val handle = spawn_isolated2([1, 2, 3], ch) \data, chan:
...     chan.send(data.sum())
>>> ch.recv()
6
```
*/
fn spawn_isolated2(data1: Any, data2: Any, closure: fn(Any, Any) -> Any) -> ThreadHandle:
    val handle = rt_thread_spawn_isolated2(closure as i64, data1, data2)
    return ThreadHandle(_handle: handle)

/**
Get the number of available CPU cores.

Useful for determining the optimal parallelism level.

```sdoctest
>>> available_parallelism() >= 1
true
```
*/
fn available_parallelism() -> i64:
    return rt_thread_available_parallelism()

/**
Sleep the current thread for the specified milliseconds.

```sdoctest
>>> sleep(10)  # Sleep for 10ms
```
*/
fn sleep(millis: i64):
    rt_thread_sleep(millis)

/**
Yield the current thread, allowing other threads to run.

This is a hint to the scheduler that the current thread is willing
to give up its time slice.

```sdoctest
>>> yield_thread()
```
*/
fn yield_thread():
    rt_thread_yield()

/**
Execute a function in parallel across multiple isolated threads.

Divides work into chunks and processes them in parallel.
Returns results in order.

```sdoctest
>>> val data = [1, 2, 3, 4, 5, 6, 7, 8]
>>> val results = parallel_map(data, \x: x * 2, 4)
>>> results
[2, 4, 6, 8, 10, 12, 14, 16]
```
*/
fn parallel_map[T, R](items: List[T], func: fn(T) -> R, num_threads: i64) -> List[R]:
    val n = len(items)
    if n == 0:
        return []

    # Use available parallelism if not specified
    val threads = if num_threads <= 0:
        available_parallelism()
    else:
        num_threads

    # For small workloads, just do it sequentially
    if n <= threads:
        return items.map(func)

    # Divide work into chunks
    val chunk_size = (n + threads - 1) / threads
    val result_channels = []
    val handles = []

    for i in range(threads):
        val start = i * chunk_size
        val end = min(start + chunk_size, n)
        if start >= n:
            break

        val chunk = items[start:end]
        val ch = Channel.new()
        result_channels.push(ch)

        val handle = spawn_isolated2(chunk, ch) \data, result_ch:
            val results = data.map(func)
            result_ch.send(results)
            return nil
        handles.push(handle)

    # Collect results
    val results = []
    for ch in result_channels:
        val chunk_results = ch.recv()
        results.extend(chunk_results)

    # Clean up handles
    for handle in handles:
        handle.join()
        handle.free()

    return results

/**
Execute a reduction in parallel across multiple isolated threads.

```sdoctest
>>> val data = [1, 2, 3, 4, 5, 6, 7, 8]
>>> val sum = parallel_reduce(data, \a, b: a + b, 0, 4)
>>> sum
36
```
*/
fn parallel_reduce[T, R](items: List[T], reducer: fn(R, T) -> R, initial: R, num_threads: i64) -> R:
    val n = len(items)
    if n == 0:
        return initial

    val threads = if num_threads <= 0:
        available_parallelism()
    else:
        num_threads

    # For small workloads, do it sequentially
    if n <= threads:
        val result = initial
        for item in items:
            result = reducer(result, item)
        return result

    # Divide work into chunks
    val chunk_size = (n + threads - 1) / threads
    val result_channels = []
    val handles = []

    for i in range(threads):
        val start = i * chunk_size
        val end = min(start + chunk_size, n)
        if start >= n:
            break

        val chunk = items[start:end]
        val ch = Channel.new()
        result_channels.push(ch)

        val handle = spawn_isolated2(chunk, ch) \data, result_ch:
            val partial = initial
            for item in data:
                partial = reducer(partial, item)
            result_ch.send(partial)
            return nil
        handles.push(handle)

    # Combine partial results
    val result = initial
    for ch in result_channels:
        val partial = ch.recv()
        result = reducer(result, partial)

    # Clean up handles
    for handle in handles:
        handle.join()
        handle.free()

    return result
