# Incremental Compilation Support
# Only recompile changed files and their dependencies

use host.async_nogc_mut.io.fs
use core.result.{Result, Ok, Err}
use tooling.core.project.Language

# File change tracking entry
pub class FileEntry:
    pub path: String
    pub mtime: i64
    pub hash: String
    pub language: Language

    pub fn new(path: String, language: Language): FileEntry =
        """Create file entry for tracking.

        Args:
            path: File path
            language: Source language

        Returns:
            File entry with current mtime and hash
        """
        FileEntry {
            path: path,
            mtime: 0,  # TODO: [stdlib][P3] Get file mtime
            hash: "",  # TODO: [stdlib][P3] Compute SHA256 hash
            language: language
        }

    pub fn has_changed(self, old_entry: FileEntry): bool =
        """Check if file has changed since last build.

        Args:
            old_entry: Previous file entry

        Returns:
            True if file modified
        """
        self.mtime != old_entry.mtime or self.hash != old_entry.hash

# Incremental build cache
pub class IncrementalCache:
    pub entries: Dict[String, FileEntry]
    pub dependencies: Dict[String, List[String]]
    pub cache_path: String

    pub fn new(cache_path: String): IncrementalCache =
        """Create empty incremental cache.

        Args:
            cache_path: Path to cache file

        Returns:
            Empty cache
        """
        IncrementalCache {
            entries: {},
            dependencies: {},
            cache_path: cache_path
        }

    pub fn load(cache_path: String): IncrementalCache =
        """Load cache from disk.

        Args:
            cache_path: Path to cache file

        Returns:
            Loaded cache or empty if file doesn't exist

        Example:
            let cache = IncrementalCache.load(".build_cache")
            if cache.is_empty():
                print("No previous build cache found")
        """
        # TODO: [stdlib][P1] Implement cache serialization/deserialization
        # For now, return empty cache
        IncrementalCache.new(cache_path)

    pub fn save(self): Result[(), String] =
        """Save cache to disk.

        Returns:
            Ok if successful, Err with error message
        """
        # TODO: [stdlib][P3] Serialize cache to JSON/SDN and write to file
        Ok(())

    pub fn add_file(self, path: String, language: Language):
        """Add file to cache.

        Args:
            path: File path
            language: Source language
        """
        let entry = FileEntry.new(path, language)
        self.entries[path] = entry

    pub fn add_dependency(self, file: String, dependency: String):
        """Add dependency relationship.

        Args:
            file: Source file
            dependency: Dependency file

        Example:
            cache.add_dependency("app.spl", "lib.spl")
        """
        if not self.dependencies.contains_key(file):
            self.dependencies[file] = []

        self.dependencies[file].append(dependency)

    pub fn get_changed_files(self, current_files: List[String]): List[String] =
        """Detect changed files since last build.

        Args:
            current_files: Current source files

        Returns:
            List of changed file paths

        Algorithm:
        1. For each current file, check if mtime/hash changed
        2. Include new files not in cache
        3. Include files whose dependencies changed
        """
        let changed: List[String] = []

        # Check existing files for changes
        for path in current_files:
            if not self.entries.contains_key(path):
                # New file
                changed.append(path)
            else:
                # Check if modified
                let old_entry = self.entries[path]
                let current_entry = FileEntry.new(path, old_entry.language)

                if current_entry.has_changed(old_entry):
                    changed.append(path)

        changed

    pub fn get_dirty_files(
        self,
        changed_files: List[String]
    ): List[String] =
        """Get all files that need recompilation.

        Args:
            changed_files: Files that changed

        Returns:
            All files affected by changes (transitive)

        Algorithm:
        1. Start with changed files
        2. Find all files that depend on changed files
        3. Recursively find transitive dependents
        4. Return union of all dirty files
        """
        let dirty: List[String] = []
        let visited: Dict[String, bool] = {}

        # Add changed files
        for file in changed_files:
            self.mark_dirty_recursive(file, dirty, visited)

        dirty

    fn mark_dirty_recursive(
        self,
        file: String,
        dirty: List[String],
        visited: Dict[String, bool]
    ):
        """Recursively mark files as dirty.

        Args:
            file: File to mark
            dirty: List of dirty files (output)
            visited: Set of visited files
        """
        if visited.contains_key(file):
            return

        visited[file] = true
        dirty.append(file)

        # Find reverse dependencies (files that depend on this file)
        let reverse_deps = self.get_reverse_dependencies(file)
        for dep in reverse_deps:
            self.mark_dirty_recursive(dep, dirty, visited)

    pub fn get_reverse_dependencies(self, file: String): List[String] =
        """Get files that depend on given file.

        Args:
            file: File to find dependents of

        Returns:
            List of dependent files
        """
        let dependents: List[String] = []

        for (source, deps) in self.dependencies.items():
            if deps.contains(file):
                dependents.append(source)

        dependents

    pub fn is_empty(self): bool =
        """Check if cache is empty.

        Returns:
            True if no entries
        """
        self.entries.len() == 0

    pub fn clear(self):
        """Clear all cache entries."""
        self.entries = {}
        self.dependencies = {}

# Incremental compiler - manages incremental compilation
pub class IncrementalCompiler:
    pub cache: IncrementalCache
    pub verbose: bool

    pub fn new(cache_path: String): IncrementalCompiler =
        """Create incremental compiler.

        Args:
            cache_path: Path to build cache

        Returns:
            Compiler with loaded or empty cache
        """
        IncrementalCompiler {
            cache: IncrementalCache.load(cache_path),
            verbose: false
        }

    pub fn set_verbose(self, enabled: bool):
        """Enable verbose logging.

        Args:
            enabled: True to log incremental decisions
        """
        self.verbose = enabled

    pub fn analyze_changes(
        self,
        all_files: List[String]
    ): IncrementalAnalysis =
        """Analyze which files need recompilation.

        Args:
            all_files: All source files in project

        Returns:
            Analysis with changed and dirty files

        Example:
            let compiler = IncrementalCompiler.new(".build_cache")
            let analysis = compiler.analyze_changes(all_files)

            print("Changed: {analysis.changed_files.len()}")
            print("Dirty: {analysis.dirty_files.len()}")
            print("Clean: {analysis.clean_files.len()}")
        """
        let changed = self.cache.get_changed_files(all_files)
        let dirty = self.cache.get_dirty_files(changed)
        let clean = self.get_clean_files(all_files, dirty)

        if self.verbose:
            print("Incremental analysis:")
            print("  Total files: {all_files.len()}")
            print("  Changed: {changed.len()}")
            print("  Dirty: {dirty.len()}")
            print("  Clean: {clean.len()}")

        IncrementalAnalysis {
            changed_files: changed,
            dirty_files: dirty,
            clean_files: clean
        }

    fn get_clean_files(
        self,
        all_files: List[String],
        dirty_files: List[String]
    ): List[String] =
        """Get files that don't need recompilation.

        Args:
            all_files: All source files
            dirty_files: Files that need recompilation

        Returns:
            Clean files
        """
        let clean: List[String] = []

        for file in all_files:
            if not dirty_files.contains(file):
                clean.append(file)

        clean

    pub fn update_cache(
        self,
        compiled_files: List[String],
        dependencies: Dict[String, List[String]]
    ):
        """Update cache after compilation.

        Args:
            compiled_files: Files that were compiled
            dependencies: Dependency map for each file

        Example:
            compiler.update_cache(
                compiled_files: ["app.spl", "lib.spl"],
                dependencies: {
                    "app.spl": ["lib.spl", "core.spl"],
                    "lib.spl": ["core.spl"]
                }
            )
            compiler.save_cache()
        """
        # Update file entries
        for file in compiled_files:
            # TODO: [stdlib][P3] Detect language from file extension
            let language = Language::Simple
            self.cache.add_file(file, language)

        # Update dependencies
        for (file, deps) in dependencies.items():
            for dep in deps:
                self.cache.add_dependency(file, dep)

        if self.verbose:
            print("Updated cache with {compiled_files.len()} files")

    pub fn save_cache(self): Result[(), String] =
        """Save cache to disk.

        Returns:
            Ok if successful
        """
        self.cache.save()

# Incremental analysis result
pub class IncrementalAnalysis:
    pub changed_files: List[String]
    pub dirty_files: List[String]
    pub clean_files: List[String]

    pub fn is_clean_build(self): bool =
        """Check if this is a clean build.

        Returns:
            True if all files are dirty
        """
        self.clean_files.len() == 0

    pub fn speedup_ratio(self): f64 =
        """Calculate speedup from incremental compilation.

        Returns:
            Ratio of files skipped (e.g., 0.9 = 90% speedup)
        """
        let total = self.clean_files.len() + self.dirty_files.len()
        if total == 0:
            return 0.0

        (self.clean_files.len() as f64) / (total as f64)
