# Training Engine
#
# Event-driven training loops inspired by PyTorch Ignite.
# Eliminates boilerplate while maintaining flexibility.
#
# ## Features
# - Generic Engine for any training/evaluation process
# - Event system (STARTED, EPOCH_COMPLETED, etc.)
# - Periodic events (every=N, once=N)
# - Custom events
# - Reusable handlers (Checkpoint, EarlyStopping)
# - Metrics computation
#
# ## Example
# ```simple
# import ml.engine.{Engine, Events}
#
# fn train_step(engine: Engine, batch: any):
#     model.train()
#     x, y = batch
#     pred = model(x)
#     loss = loss_fn(pred, y)
#     loss.backward()
#     optimizer.step()
#     return {"loss": loss.item()}
#
# val trainer = Engine(train_step)
#
# @trainer.on(EPOCH_COMPLETED)
# fn log_metrics(engine: Engine):
#     print(f"Epoch {engine.state.epoch}: loss={engine.state.output.loss}")
#
# trainer.run(train_loader, max_epochs=10)
# ```

export Engine, State, Metric, Loss, Accuracy, MSE, MAE, RMSE
export Precision, Recall, F1Score, ConfusionMatrix
export ITERATION_COMPLETED_EVERY, EPOCH_COMPLETED_EVERY
export STARTED, EPOCH_STARTED, ITERATION_STARTED, ITERATION_COMPLETED
export EPOCH_COMPLETED, COMPLETED, EXCEPTION_RAISED


# ============================================================================
# Events - Built-in engine events
# ============================================================================

# Events fired during engine execution:
# - STARTED: Engine started
# - EPOCH_STARTED: Epoch started
# - ITERATION_STARTED: Before batch processing
# - ITERATION_COMPLETED: After batch processing
# - EPOCH_COMPLETED: Epoch completed
# - COMPLETED: Engine completed all epochs
# - EXCEPTION_RAISED: Exception during execution

val STARTED: str = "started"
val EPOCH_STARTED: str = "epoch_started"
val ITERATION_STARTED: str = "iteration_started"
val ITERATION_COMPLETED: str = "iteration_completed"
val EPOCH_COMPLETED: str = "epoch_completed"
val COMPLETED: str = "completed"
val EXCEPTION_RAISED: str = "exception_raised"


fn ITERATION_COMPLETED_EVERY(n: i64) -> str:
    """Create periodic event (every N iterations).

    Args:
        n: Iteration frequency

    Returns:
        Event name
    """
    return f"iteration_completed_every_{n}"


fn EPOCH_COMPLETED_EVERY(n: i64) -> str:
    """Create periodic event (every N epochs).

    Args:
        n: Epoch frequency

    Returns:
        Event name
    """
    return f"epoch_completed_every_{n}"


# ============================================================================
# Helper Functions
# ============================================================================

fn _sort_handlers_by_priority(handlers: any):
    """Sort handlers by priority (descending) in place.

    Uses insertion sort since we typically have few handlers.
    Each handler is a (priority, fn) tuple.

    Args:
        handlers: List of (priority, handler) tuples
    """
    val n = handlers.len()
    for i in 1..n:
        val key = handlers[i]
        val key_priority = key[0]
        var j = i - 1

        # Move elements with lower priority to the right
        while j >= 0 and handlers[j][0] < key_priority:
            handlers[j + 1] = handlers[j]
            j = j - 1

        handlers[j + 1] = key


# ============================================================================
# State Class
# ============================================================================

class State:
    """Engine state.

    Tracks current progress and output during execution.

    Attributes:
        epoch: Current epoch (0-indexed)
        iteration: Global iteration counter
        epoch_iteration: Iteration within current epoch
        max_epochs: Total epochs to run
        output: Return value of process function
        metrics: Computed metrics dict
        dataloader: Current dataloader
        batch: Current batch
    """
    epoch: i64 = 0
    iteration: i64 = 0
    epoch_iteration: i64 = 0
    max_epochs: i64 = 0
    output: any = 0
    metrics: any = {}
    dataloader: any = 0
    batch: any = 0


# ============================================================================
# Metric Base Class
# ============================================================================

class Metric:
    """Base class for metrics.

    Subclasses must implement reset(), update(), and compute().

    Example:
        ```simple
        class Accuracy(Metric):
            static fn new():
                self.correct = 0
                self.total = 0

            me reset():
                self.correct = 0
                self.total = 0

            me update(output: any):
                pred, labels = output
                self.correct += (pred == labels).sum()
                self.total += labels.len()

            fn compute() -> f64:
                return self.correct / self.total
        ```
    """

    me reset():
        """Reset metric state for new epoch."""
        return

    me update(output: any):
        """Update metric with batch output.

        Args:
            output: Process function output
        """
        return

    fn compute() -> f64:
        """Compute final metric value.

        Returns:
            Metric value
        """
        return 0.0


# ============================================================================
# Engine Class
# ============================================================================

class Engine:
    """Generic training/evaluation engine.

    Executes a process function on each batch and fires events.

    Example:
        ```simple
        fn train_step(engine: Engine, batch: any):
            # Training logic here
            return {"loss": loss.item()}

        val trainer = Engine(train_step)

        @trainer.on(ITERATION_COMPLETED)
        fn log(engine):
            print(f"Step {engine.state.iteration}")

        trainer.run(dataloader, max_epochs=10)
        ```

    Attributes:
        process_function: Function to execute per batch
        state: Engine state
        _event_handlers: Event handlers dict
        _metrics: Metrics dict
        _should_terminate: Termination flag
    """
    process_function: any
    state: State
    _event_handlers: any
    _metrics: any
    _should_terminate: bool

    fn __init__(process_function: any):
        """Initialize engine.

        Args:
            process_function: Function(engine, batch) -> output
        """
        self.process_function = process_function
        self.state = State()
        self._event_handlers = {}
        self._metrics = {}
        self._should_terminate = false

    fn attach_handler(event: str, handler: any, priority: i32):
        """Attach event handler.

        Args:
            event: Event name
            handler: Handler function(engine)
            priority: Priority (higher = earlier)

        Example:
            ```simple
            trainer.attach_handler(EPOCH_COMPLETED, log_epoch, 0)
            ```
        """
        if not (event in self._event_handlers):
            self._event_handlers[event] = []

        # Add handler with priority
        self._event_handlers[event].append((priority, handler))

        # Sort by priority (descending) using simple insertion
        # Workaround for lambda not being supported yet
        _sort_handlers_by_priority(self._event_handlers[event])

    fn fire_event(event: str):
        """Fire event and execute handlers.

        Args:
            event: Event name
        """
        if event in self._event_handlers:
            for (priority, handler) in self._event_handlers[event]:
                handler(self)

    fn add_metric(metric: Metric, name: str):
        """Add metric to engine.

        Args:
            metric: Metric instance
            name: Metric name
        """
        self._metrics[name] = metric

    fn add_metrics(metrics: any):
        """Add multiple metrics.

        Args:
            metrics: Dict of name -> metric
        """
        for (name, metric) in metrics.items():
            self.add_metric(metric, name)

    fn run(data: any, max_epochs: i64):
        """Run engine on data.

        Args:
            data: Iterable dataloader
            max_epochs: Number of epochs to run

        Example:
            ```simple
            trainer.run(train_loader, max_epochs=10)
            ```
        """
        self.state.max_epochs = max_epochs
        self.state.dataloader = data

        # Fire STARTED event
        self.fire_event(STARTED)

        try:
            for epoch in range(max_epochs):
                if self._should_terminate:
                    break

                self.state.epoch = epoch
                self.state.epoch_iteration = 0

                # Reset metrics for new epoch
                for metric in self._metrics.values():
                    metric.reset()

                # Fire EPOCH_STARTED event
                self.fire_event(EPOCH_STARTED)

                # Iterate over data
                for batch in data:
                    if self._should_terminate:
                        break

                    self.state.batch = batch
                    self.state.epoch_iteration += 1
                    self.state.iteration += 1

                    # Fire ITERATION_STARTED event
                    self.fire_event(ITERATION_STARTED)

                    # Execute process function
                    self.state.output = self.process_function(self, batch)

                    # Update metrics
                    for metric in self._metrics.values():
                        metric.update(self.state.output)

                    # Fire ITERATION_COMPLETED event
                    self.fire_event(ITERATION_COMPLETED)

                    # Fire periodic events
                    self._fire_periodic_events()

                # Compute final metrics for epoch
                for (name, metric) in self._metrics.items():
                    self.state.metrics[name] = metric.compute()

                # Fire EPOCH_COMPLETED event
                self.fire_event(EPOCH_COMPLETED)

                # Fire periodic epoch events
                self._fire_periodic_epoch_events()

        except Exception as e:
            # Fire EXCEPTION_RAISED event
            self.fire_event(EXCEPTION_RAISED)
            raise e

        # Fire COMPLETED event
        self.fire_event(COMPLETED)

    fn terminate():
        """Terminate engine execution."""
        self._should_terminate = true

    # ========================================================================
    # Helper Methods
    # ========================================================================

    fn _fire_periodic_events():
        """Fire periodic iteration events."""
        # Check for every_N events
        for event_name in self._event_handlers.keys():
            if event_name.startswith("iteration_completed_every_"):
                # Extract N from event name
                val parts = event_name.split("_")
                val n = i32(parts[-1])

                if self.state.iteration % n == 0:
                    self.fire_event(event_name)

    fn _fire_periodic_epoch_events():
        """Fire periodic epoch events."""
        # Check for every_N events
        for event_name in self._event_handlers.keys():
            if event_name.startswith("epoch_completed_every_"):
                # Extract N from event name
                val parts = event_name.split("_")
                val n = i32(parts[-1])

                if (self.state.epoch + 1) % n == 0:
                    self.fire_event(event_name)


# ============================================================================
# Common Metrics
# ============================================================================

class Accuracy(Metric):
    """Accuracy metric for classification.

    Expects output to be dict with "pred" and "labels" keys, or tuple (pred, labels).
    Predictions and labels can be lists/arrays of class indices.

    Example:
        ```simple
        val accuracy = Accuracy()
        trainer.add_metric(accuracy, "acc")

        # Output format options:
        # 1. Dict: {"pred": [0, 1, 2], "labels": [0, 1, 1]}
        # 2. Tuple: ([0, 1, 2], [0, 1, 1])
        ```
    """
    correct: i64
    total: i64

    static fn new():
        """Initialize accuracy metric."""
        self.correct = 0
        self.total = 0

    me reset():
        """Reset for new epoch."""
        self.correct = 0
        self.total = 0

    me update(output: any):
        """Update with batch output.

        Args:
            output: Dict with "pred" and "labels" keys

        Supported formats:
            - Dict: {"pred": [0, 1, 2], "labels": [0, 1, 1]}
            - Dict: {"y_pred": [...], "y_true": [...]}
        """
        var pred = []
        var labels = []

        # Extract predictions and labels from output dict
        if "pred" in output and "labels" in output:
            pred = output["pred"]
            labels = output["labels"]
        elif "y_pred" in output and "y_true" in output:
            pred = output["y_pred"]
            labels = output["y_true"]

        # Compute matches
        if len(pred) > 0 and len(labels) > 0:
            val n = min(len(pred), len(labels))
            for i in range(n):
                self.total += 1
                if pred[i] == labels[i]:
                    self.correct += 1

    fn compute() -> f64:
        """Compute accuracy.

        Returns:
            Accuracy value in range [0.0, 1.0]
        """
        if self.total == 0:
            return 0.0
        return (self.correct.to_float()) / (self.total.to_float())


class ConfusionMatrix:
    """Confusion matrix for binary and multi-class classification.

    Tracks true positives, false positives, true negatives, false negatives
    for each class.

    Example:
        ```simple
        val cm = ConfusionMatrix(num_classes=3)
        cm.update([0, 1, 2], [0, 1, 1])  # pred, labels
        print(cm.tp(1))  # True positives for class 1
        ```
    """
    num_classes: i64
    _matrix: any  # 2D array [actual][predicted]

    fn __init__(num_classes: i64 = 2):
        """Initialize confusion matrix.

        Args:
            num_classes: Number of classes (default: 2 for binary)
        """
        self.num_classes = num_classes
        # Initialize NxN matrix with zeros
        self._matrix = []
        for i in range(num_classes):
            var row = []
            for j in range(num_classes):
                row = row + [0]
            self._matrix = self._matrix + [row]

    me reset():
        """Reset confusion matrix."""
        for i in range(self.num_classes):
            for j in range(self.num_classes):
                self._matrix[i][j] = 0

    me update(pred: any, labels: any):
        """Update confusion matrix with predictions.

        Args:
            pred: Predicted class indices
            labels: True class indices
        """
        val n = min(len(pred), len(labels))
        for i in range(n):
            val actual = labels[i]
            val predicted = pred[i]
            if actual >= 0 and actual < self.num_classes:
                if predicted >= 0 and predicted < self.num_classes:
                    self._matrix[actual][predicted] += 1

    fn tp(class_idx: i64) -> i64:
        """True positives for a class."""
        return self._matrix[class_idx][class_idx]

    fn fp(class_idx: i64) -> i64:
        """False positives for a class (predicted as class but was other)."""
        var total: i64 = 0
        for i in range(self.num_classes):
            if i != class_idx:
                total += self._matrix[i][class_idx]
        return total

    fn fn_(class_idx: i64) -> i64:
        """False negatives for a class (was class but predicted as other)."""
        var total: i64 = 0
        for j in range(self.num_classes):
            if j != class_idx:
                total += self._matrix[class_idx][j]
        return total

    fn tn(class_idx: i64) -> i64:
        """True negatives for a class."""
        var total: i64 = 0
        for i in range(self.num_classes):
            for j in range(self.num_classes):
                if i != class_idx and j != class_idx:
                    total += self._matrix[i][j]
        return total

    fn total_samples() -> i64:
        """Total samples in confusion matrix."""
        var total: i64 = 0
        for i in range(self.num_classes):
            for j in range(self.num_classes):
                total += self._matrix[i][j]
        return total


class Precision(Metric):
    """Precision metric for classification.

    Precision = TP / (TP + FP)

    For multi-class, computes macro-averaged precision.

    Example:
        ```simple
        val precision = Precision(num_classes=3)
        trainer.add_metric(precision, "precision")
        ```
    """
    num_classes: i64
    _cm: ConfusionMatrix

    fn __init__(num_classes: i64 = 2):
        """Initialize precision metric.

        Args:
            num_classes: Number of classes
        """
        self.num_classes = num_classes
        self._cm = ConfusionMatrix(num_classes)

    me reset():
        """Reset for new epoch."""
        self._cm.reset()

    me update(output: any):
        """Update with batch output.

        Args:
            output: Dict with "pred" and "labels" keys
        """
        var pred = []
        var labels = []

        if "pred" in output and "labels" in output:
            pred = output["pred"]
            labels = output["labels"]
        elif "y_pred" in output and "y_true" in output:
            pred = output["y_pred"]
            labels = output["y_true"]

        if len(pred) > 0:
            self._cm.update(pred, labels)

    fn compute() -> f64:
        """Compute macro-averaged precision.

        Returns:
            Precision value in range [0.0, 1.0]
        """
        var total_precision = 0.0
        var valid_classes = 0

        for c in range(self.num_classes):
            val tp = self._cm.tp(c)
            val fp = self._cm.fp(c)
            val denominator = tp + fp
            if denominator > 0:
                total_precision += tp.to_float() / denominator.to_float()
                valid_classes += 1

        if valid_classes == 0:
            return 0.0
        return total_precision / valid_classes.to_float()

    fn compute_per_class(class_idx: i64) -> f64:
        """Compute precision for a specific class.

        Args:
            class_idx: Class index

        Returns:
            Precision for the specified class
        """
        val tp = self._cm.tp(class_idx)
        val fp = self._cm.fp(class_idx)
        val denominator = tp + fp
        if denominator == 0:
            return 0.0
        return tp.to_float() / denominator.to_float()


class Recall(Metric):
    """Recall metric for classification.

    Recall = TP / (TP + FN)

    For multi-class, computes macro-averaged recall.

    Example:
        ```simple
        val recall = Recall(num_classes=3)
        trainer.add_metric(recall, "recall")
        ```
    """
    num_classes: i64
    _cm: ConfusionMatrix

    fn __init__(num_classes: i64 = 2):
        """Initialize recall metric.

        Args:
            num_classes: Number of classes
        """
        self.num_classes = num_classes
        self._cm = ConfusionMatrix(num_classes)

    me reset():
        """Reset for new epoch."""
        self._cm.reset()

    me update(output: any):
        """Update with batch output.

        Args:
            output: Dict with "pred" and "labels" keys
        """
        var pred = []
        var labels = []

        if "pred" in output and "labels" in output:
            pred = output["pred"]
            labels = output["labels"]
        elif "y_pred" in output and "y_true" in output:
            pred = output["y_pred"]
            labels = output["y_true"]

        if len(pred) > 0:
            self._cm.update(pred, labels)

    fn compute() -> f64:
        """Compute macro-averaged recall.

        Returns:
            Recall value in range [0.0, 1.0]
        """
        var total_recall = 0.0
        var valid_classes = 0

        for c in range(self.num_classes):
            val tp = self._cm.tp(c)
            val fn = self._cm.fn_(c)
            val denominator = tp + fn
            if denominator > 0:
                total_recall += tp.to_float() / denominator.to_float()
                valid_classes += 1

        if valid_classes == 0:
            return 0.0
        return total_recall / valid_classes.to_float()

    fn compute_per_class(class_idx: i64) -> f64:
        """Compute recall for a specific class.

        Args:
            class_idx: Class index

        Returns:
            Recall for the specified class
        """
        val tp = self._cm.tp(class_idx)
        val fn = self._cm.fn_(class_idx)
        val denominator = tp + fn
        if denominator == 0:
            return 0.0
        return tp.to_float() / denominator.to_float()


class F1Score(Metric):
    """F1 Score metric for classification.

    F1 = 2 * (Precision * Recall) / (Precision + Recall)

    Harmonic mean of precision and recall.

    Example:
        ```simple
        val f1 = F1Score(num_classes=3)
        trainer.add_metric(f1, "f1")
        ```
    """
    num_classes: i64
    _cm: ConfusionMatrix

    fn __init__(num_classes: i64 = 2):
        """Initialize F1 metric.

        Args:
            num_classes: Number of classes
        """
        self.num_classes = num_classes
        self._cm = ConfusionMatrix(num_classes)

    me reset():
        """Reset for new epoch."""
        self._cm.reset()

    me update(output: any):
        """Update with batch output.

        Args:
            output: Dict with "pred" and "labels" keys
        """
        var pred = []
        var labels = []

        if "pred" in output and "labels" in output:
            pred = output["pred"]
            labels = output["labels"]
        elif "y_pred" in output and "y_true" in output:
            pred = output["y_pred"]
            labels = output["y_true"]

        if len(pred) > 0:
            self._cm.update(pred, labels)

    fn compute() -> f64:
        """Compute macro-averaged F1 score.

        Returns:
            F1 score in range [0.0, 1.0]
        """
        var total_f1 = 0.0
        var valid_classes = 0

        for c in range(self.num_classes):
            val tp = self._cm.tp(c)
            val fp = self._cm.fp(c)
            val fn = self._cm.fn_(c)

            val precision_denom = tp + fp
            val recall_denom = tp + fn

            if precision_denom > 0 and recall_denom > 0:
                val precision = tp.to_float() / precision_denom.to_float()
                val recall = tp.to_float() / recall_denom.to_float()

                if precision + recall > 0.0:
                    val f1 = 2.0 * precision * recall / (precision + recall)
                    total_f1 += f1
                    valid_classes += 1

        if valid_classes == 0:
            return 0.0
        return total_f1 / valid_classes.to_float()

    fn compute_per_class(class_idx: i64) -> f64:
        """Compute F1 score for a specific class.

        Args:
            class_idx: Class index

        Returns:
            F1 score for the specified class
        """
        val tp = self._cm.tp(class_idx)
        val fp = self._cm.fp(class_idx)
        val fn = self._cm.fn_(class_idx)

        val precision_denom = tp + fp
        val recall_denom = tp + fn

        if precision_denom == 0 or recall_denom == 0:
            return 0.0

        val precision = tp.to_float() / precision_denom.to_float()
        val recall = tp.to_float() / recall_denom.to_float()

        if precision + recall == 0.0:
            return 0.0

        return 2.0 * precision * recall / (precision + recall)


class Loss(Metric):
    """Average loss metric.

    Example:
        ```simple
        val loss_metric = Loss()
        trainer.add_metric(loss_metric, "loss")
        ```
    """
    total_loss: f64
    count: i64

    static fn new():
        """Initialize loss metric."""
        self.total_loss = 0.0
        self.count = 0

    me reset():
        """Reset for new epoch."""
        self.total_loss = 0.0
        self.count = 0

    me update(output: any):
        """Update with batch output.

        Args:
            output: Dict with "loss" key
        """
        # Check for dict with "loss" key
        if "loss" in output:
            self.total_loss += output["loss"]
            self.count += 1

    fn compute() -> f64:
        """Compute average loss.

        Returns:
            Average loss
        """
        if self.count == 0:
            return 0.0
        return self.total_loss / (self.count.to_float())


# ============================================================================
# Regression Metrics
# ============================================================================

class MSE(Metric):
    """Mean Squared Error metric for regression.

    Computes: (1/n) * sum((pred - actual)^2)

    Example:
        ```simple
        val mse = MSE()
        trainer.add_metric(mse, "mse")

        # Output format: {"pred": [1.0, 2.0], "actual": [1.1, 2.2]}
        ```
    """
    total_squared_error: f64 = 0.0
    count: i64 = 0

    me reset():
        """Reset for new epoch."""
        self.total_squared_error = 0.0
        self.count = 0

    me update(output: any):
        """Update with batch output.

        Args:
            output: Dict with "pred" and "actual" keys
        """
        var pred = []
        var actual = []

        # Extract predictions and actuals from output dict
        if "pred" in output and "actual" in output:
            pred = output["pred"]
            actual = output["actual"]
        elif "y_pred" in output and "y_true" in output:
            pred = output["y_pred"]
            actual = output["y_true"]

        # Compute squared errors
        if len(pred) > 0 and len(actual) > 0:
            val n = min(len(pred), len(actual))
            for i in range(n):
                val p = pred[i]
                val a = actual[i]
                val diff = p - a
                self.total_squared_error += diff * diff
                self.count += 1

    fn compute() -> f64:
        """Compute mean squared error.

        Returns:
            MSE value
        """
        if self.count == 0:
            return 0.0
        return self.total_squared_error / (self.count.to_float())


class MAE(Metric):
    """Mean Absolute Error metric for regression.

    Computes: (1/n) * sum(|pred - actual|)

    Example:
        ```simple
        val mae = MAE()
        trainer.add_metric(mae, "mae")

        # Output format: {"pred": [1.0, 2.0], "actual": [1.1, 2.2]}
        ```
    """
    total_absolute_error: f64 = 0.0
    count: i64 = 0

    me reset():
        """Reset for new epoch."""
        self.total_absolute_error = 0.0
        self.count = 0

    me update(output: any):
        """Update with batch output.

        Args:
            output: Dict with "pred" and "actual" keys
        """
        var pred = []
        var actual = []

        # Extract predictions and actuals from output dict
        if "pred" in output and "actual" in output:
            pred = output["pred"]
            actual = output["actual"]
        elif "y_pred" in output and "y_true" in output:
            pred = output["y_pred"]
            actual = output["y_true"]

        # Compute absolute errors
        if len(pred) > 0 and len(actual) > 0:
            val n = min(len(pred), len(actual))
            for i in range(n):
                val p = pred[i]
                val a = actual[i]
                val diff = p - a
                self.total_absolute_error += abs(diff)
                self.count += 1

    fn compute() -> f64:
        """Compute mean absolute error.

        Returns:
            MAE value
        """
        if self.count == 0:
            return 0.0
        return self.total_absolute_error / (self.count.to_float())


class RMSE(Metric):
    """Root Mean Squared Error metric for regression.

    Computes: sqrt((1/n) * sum((pred - actual)^2))

    Example:
        ```simple
        val rmse = RMSE()
        trainer.add_metric(rmse, "rmse")
        ```
    """
    total_squared_error: f64 = 0.0
    count: i64 = 0

    me reset():
        """Reset for new epoch."""
        self.total_squared_error = 0.0
        self.count = 0

    me update(output: any):
        """Update with batch output.

        Args:
            output: Dict with "pred" and "actual" keys
        """
        var pred = []
        var actual = []

        # Extract predictions and actuals from output dict
        if "pred" in output and "actual" in output:
            pred = output["pred"]
            actual = output["actual"]
        elif "y_pred" in output and "y_true" in output:
            pred = output["y_pred"]
            actual = output["y_true"]

        # Compute squared errors
        if len(pred) > 0 and len(actual) > 0:
            val n = min(len(pred), len(actual))
            for i in range(n):
                val p = pred[i]
                val a = actual[i]
                val diff = p - a
                self.total_squared_error += diff * diff
                self.count += 1

    fn compute() -> f64:
        """Compute root mean squared error.

        Returns:
            RMSE value
        """
        if self.count == 0:
            return 0.0
        val mse_val = self.total_squared_error / (self.count.to_float())
        return sqrt(mse_val)


# ============================================================================
# Helper Functions
# ============================================================================

fn abs(x: f64) -> f64:
    """Absolute value."""
    if x < 0.0:
        return -x
    return x


fn sqrt(x: f64) -> f64:
    """Square root using Newton's method."""
    if x <= 0.0:
        return 0.0
    var guess = x / 2.0
    for _ in range(20):  # Newton iterations
        guess = (guess + x / guess) / 2.0
    return guess


fn min(a: i64, b: i64) -> i64:
    """Minimum of two integers."""
    if a < b:
        return a
    return b
