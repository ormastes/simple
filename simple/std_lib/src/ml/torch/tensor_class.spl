# Tensor - Multi-dimensional Array with GPU Support (Simplified)

export Tensor

import device.{Device, device_code, device_from_code}
import dtype.{DType, dtype_code, dtype_from_code}
import tensor_ffi.{rt_torch_zeros, rt_torch_ones, rt_torch_randn, rt_torch_arange, rt_torch_free, rt_torch_clone, rt_torch_shape, rt_torch_numel, rt_torch_dtype, rt_torch_device, rt_torch_add, rt_torch_sub, rt_torch_mul, rt_torch_div, rt_torch_matmul, rt_torch_reshape, rt_torch_sum, rt_torch_mean, rt_torch_item, rt_torch_set_requires_grad, rt_torch_requires_grad, rt_torch_backward, rt_torch_grad, rt_torch_detach}

class Tensor:
    """Multi-dimensional array with GPU support."""
    handle: u64

    fn __init__(handle: u64):
        """Initialize tensor from handle."""
        self.handle = handle

    fn __del__():
        """Free tensor memory."""
        if self.handle != 0:
            rt_torch_free(self.handle)

    # Factory Methods
    static fn zeros(shape: [i64], dtype: DType = DType::Float32, device: Device = Device::CPU) -> Tensor:
        """Create tensor filled with zeros."""
        val handle = rt_torch_zeros(shape.data_ptr(), shape.len() as i32, dtype_code(dtype), device_code(device))
        return Tensor(handle)

    static fn ones(shape: [i64], dtype: DType = DType::Float32, device: Device = Device::CPU) -> Tensor:
        """Create tensor filled with ones."""
        val handle = rt_torch_ones(shape.data_ptr(), shape.len() as i32, dtype_code(dtype), device_code(device))
        return Tensor(handle)

    static fn randn(shape: [i64], dtype: DType = DType::Float32, device: Device = Device::CPU) -> Tensor:
        """Create tensor with random values from N(0, 1)."""
        val handle = rt_torch_randn(shape.data_ptr(), shape.len() as i32, dtype_code(dtype), device_code(device))
        return Tensor(handle)

    # Properties
    fn numel() -> i64:
        """Get total number of elements."""
        return rt_torch_numel(self.handle)

    fn shape() -> [i64]:
        """Get tensor shape (dimensions).

        Returns:
            Array of dimension sizes

        Example:
            val t = Tensor::zeros([2, 3, 4])
            t.shape()  # → [2, 3, 4]
        """
        # Create buffer for shape (max 8 dimensions)
        var buf: [i64] = [0i64, 0i64, 0i64, 0i64, 0i64, 0i64, 0i64, 0i64]
        val ndim = rt_torch_shape(self.handle, buf.data_ptr(), 8)
        # Build result array with actual dimensions
        var result: [i64] = []
        var i = 0
        while i < ndim:
            result = result + [buf[i]]
            i = i + 1
        return result

    fn ndim() -> i64:
        """Get number of dimensions.

        Returns:
            Number of dimensions (rank)

        Example:
            val t = Tensor::zeros([2, 3, 4])
            t.ndim()  # → 3
        """
        return self.shape().len() as i64

    fn dtype() -> DType:
        """Get tensor data type.

        Returns:
            DType enum (Float32, Float64, Int32, Int64)

        Example:
            val t = Tensor::zeros([2, 3], dtype=DType::Float64)
            t.dtype()  # → DType::Float64
        """
        val code = rt_torch_dtype(self.handle)
        return dtype_from_code(code)

    fn device() -> Device:
        """Get tensor device.

        Returns:
            Device enum (CPU or CUDA(id))

        Example:
            val t = Tensor::zeros([2, 3], device=Device::CPU)
            t.device()  # → Device::CPU
        """
        val code = rt_torch_device(self.handle)
        return device_from_code(code)

    # Arithmetic Operations
    fn add(other: Tensor) -> Tensor:
        """Add two tensors."""
        return Tensor(rt_torch_add(self.handle, other.handle))

    fn sub(other: Tensor) -> Tensor:
        """Subtract two tensors."""
        return Tensor(rt_torch_sub(self.handle, other.handle))

    fn mul(other: Tensor) -> Tensor:
        """Multiply two tensors."""
        return Tensor(rt_torch_mul(self.handle, other.handle))

    fn div(other: Tensor) -> Tensor:
        """Divide two tensors."""
        return Tensor(rt_torch_div(self.handle, other.handle))

    fn matmul(other: Tensor) -> Tensor:
        """Matrix multiply two tensors."""
        return Tensor(rt_torch_matmul(self.handle, other.handle))

    # Reduction Operations
    fn sum() -> Tensor:
        """Sum all elements."""
        return Tensor(rt_torch_sum(self.handle, -1, 0))

    fn mean() -> Tensor:
        """Mean of all elements."""
        return Tensor(rt_torch_mean(self.handle, -1, 0))

    # Data Access
    fn item() -> f64:
        """Get scalar value (for single-element tensors)."""
        return rt_torch_item(self.handle)

    fn clone() -> Tensor:
        """Create a copy of this tensor."""
        return Tensor(rt_torch_clone(self.handle))

    # Autograd
    fn set_requires_grad(requires_grad: bool):
        """Enable or disable gradient tracking."""
        rt_torch_set_requires_grad(self.handle, requires_grad as i32)

    fn requires_grad() -> bool:
        """Check if gradients are tracked."""
        return rt_torch_requires_grad(self.handle) != 0

    fn backward():
        """Compute gradients via backpropagation."""
        rt_torch_backward(self.handle, 0u64, 0)

    fn grad() -> Tensor:
        """Get accumulated gradients."""
        return Tensor(rt_torch_grad(self.handle))

    fn detach() -> Tensor:
        """Create a tensor detached from computation graph."""
        return Tensor(rt_torch_detach(self.handle))
