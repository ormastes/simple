# Neural Network - Dropout Layer
#
# Dropout regularization for neural networks.

export Dropout

import ml.torch.tensor_class.{Tensor}
import base.{Module}

class Dropout(Module):
    """Dropout regularization layer.

    Randomly zeroes elements with probability p during training.

    Example:
        ```simple
        val dropout = nn.Dropout(p=0.5)
        dropout.train()  # Enable dropout
        val train_out = dropout(x)  # Some elements zeroed

        dropout.eval()  # Disable dropout
        val eval_out = dropout(x)  # No elements zeroed
        ```
    """
    module_handle: u64
    p: f64

    fn __init__(p: f64 = 0.5):
        """Initialize dropout layer.

        Args:
            p: Probability of zeroing each element (default: 0.5)
        """
        super().__init__()
        self.p = p

        # Create module via FFI
        self.module_handle = @rt_torch_dropout_new(p, 0)  # inplace=0
        if self.module_handle == 0:
            panic("Failed to create Dropout layer")

    fn __del__():
        """Free module resources."""
        if self.module_handle != 0:
            @rt_torch_module_free(self.module_handle)

    fn forward(x: Tensor) -> Tensor:
        """Apply dropout.

        Args:
            x: Input tensor

        Returns:
            Output tensor (same shape as input)
        """
        val handle = @rt_torch_dropout_forward(
            self.module_handle,
            x.handle,
            self.training as i32
        )
        if handle == 0:
            panic("Dropout forward pass failed")
        return Tensor(handle)
