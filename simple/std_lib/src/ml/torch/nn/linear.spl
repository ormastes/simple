# Neural Network - Linear Layer
#
# Fully connected (dense) layer for neural networks.

export Linear

import ml.torch.tensor_class.{Tensor}
import base.{Module}

class Linear(Module):
    """Fully connected (dense) layer.

    Applies linear transformation: y = xW^T + b

    Attributes:
        weight: Weight matrix [out_features, in_features]
        bias: Bias vector [out_features] (optional)

    Example:
        ```simple
        val fc = nn.Linear(784, 128)
        val output = fc(input)  # [batch, 784] -> [batch, 128]
        ```
    """
    module_handle: u64
    in_features: i32
    out_features: i32
    has_bias: bool

    fn __init__(in_features: i32, out_features: i32, bias: bool = true):
        """Initialize linear layer.

        Args:
            in_features: Input size
            out_features: Output size
            bias: Whether to include bias term (default: True)
        """
        super().__init__()
        self.in_features = in_features
        self.out_features = out_features
        self.has_bias = bias

        # Create module via FFI
        self.module_handle = @rt_torch_linear_new(
            in_features,
            out_features,
            bias as i32
        )
        if self.module_handle == 0:
            panic("Failed to create Linear layer")

    fn __del__():
        """Free module resources."""
        if self.module_handle != 0:
            @rt_torch_module_free(self.module_handle)

    fn forward(x: Tensor) -> Tensor:
        """Apply linear transformation.

        Args:
            x: Input tensor [..., in_features]

        Returns:
            Output tensor [..., out_features]
        """
        val handle = @rt_torch_linear_forward(self.module_handle, x.handle)
        if handle == 0:
            panic("Linear forward pass failed")
        return Tensor(handle)
