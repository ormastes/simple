# Grammar Compilation Pipeline
# Compiles grammar definitions into optimized runtime structures

import parser.treesitter.{Grammar, GrammarRule, Token}
import parser.treesitter.language_detect as detect
import core.collections as collections

# Compiled grammar with optimizations
class CompiledGrammar:
    name: text
    rules: Dict<text, CompiledRule>
    entry_point: text
    token_types: List<text>
    # Optimizations
    first_sets: Dict<text, Set<text>>   # First tokens for each rule
    follow_sets: Dict<text, Set<text>>  # Follow tokens for each rule
    nullable_rules: Set<text>             # Rules that can match empty

    fn new(name: text, entry_point: text) -> CompiledGrammar:
        CompiledGrammar(
            name: name,
            rules: {},
            entry_point: entry_point,
            token_types: [],
            first_sets: {},
            follow_sets: {},
            nullable_rules: Set()
        )

    # Get rule by name
    fn get_rule(name: text) -> Option<CompiledRule>:
        self.rules.get(name)

    # Check if rule is nullable (can match empty)
    fn is_nullable(rule_name: text) -> bool:
        self.nullable_rules.contains(rule_name)

    # Get first tokens for a rule
    fn get_first_set(rule_name: text) -> Set<text>:
        match self.first_sets.get(rule_name):
            case Some(set):
                return set
            case None:
                return Set()

    # Get follow tokens for a rule
    fn get_follow_set(rule_name: text) -> Set<text>:
        match self.follow_sets.get(rule_name):
            case Some(set):
                return set
            case None:
                return Set()

# Compiled grammar rule with optimizations
class CompiledRule:
    name: text
    pattern: RulePattern
    is_terminal: bool
    is_nullable: bool

    fn new(name: text, pattern: RulePattern) -> CompiledRule:
        CompiledRule(
            name: name,
            pattern: pattern,
            is_terminal: false,
            is_nullable: false
        )

# Rule pattern (simplified for compilation)
enum RulePattern:
    Token(token_type: text)
    Sequence(patterns: List<RulePattern>)
    Choice(patterns: List<RulePattern>)
    Repeat(pattern: RulePattern)
    Optional(pattern: RulePattern)
    Reference(rule_name: text)

impl RulePattern:
    # =========================================================================
    # Helper Methods
    # =========================================================================

    fn is_token() -> bool:
        """Check if pattern is Token.

        Returns:
            true for Token

        Example:
            RulePattern::Token("identifier").is_token()  # → true
        """
        match self:
            case Token(_): true
            case _: false

    fn is_sequence() -> bool:
        """Check if pattern is Sequence.

        Returns:
            true for Sequence

        Example:
            RulePattern::Sequence([...]).is_sequence()  # → true
        """
        match self:
            case Sequence(_): true
            case _: false

    fn is_choice() -> bool:
        """Check if pattern is Choice.

        Returns:
            true for Choice

        Example:
            RulePattern::Choice([...]).is_choice()  # → true
        """
        match self:
            case Choice(_): true
            case _: false

    fn is_repeat() -> bool:
        """Check if pattern is Repeat.

        Returns:
            true for Repeat

        Example:
            RulePattern::Repeat(pattern).is_repeat()  # → true
        """
        match self:
            case Repeat(_): true
            case _: false

    fn is_optional() -> bool:
        """Check if pattern is Optional.

        Returns:
            true for Optional

        Example:
            RulePattern::Optional(pattern).is_optional()  # → true
        """
        match self:
            case Optional(_): true
            case _: false

    fn is_reference() -> bool:
        """Check if pattern is Reference.

        Returns:
            true for Reference

        Example:
            RulePattern::Reference("rule_name").is_reference()  # → true
        """
        match self:
            case Reference(_): true
            case _: false

    fn is_terminal() -> bool:
        """Check if pattern is terminal (Token).

        Returns:
            true for Token

        Example:
            RulePattern::Token("keyword").is_terminal()  # → true
            RulePattern::Reference("rule").is_terminal()  # → false
        """
        return self.is_token()

    fn is_composite() -> bool:
        """Check if pattern is composite (Sequence or Choice).

        Returns:
            true for Sequence or Choice

        Example:
            RulePattern::Sequence([...]).is_composite()  # → true
            RulePattern::Token("id").is_composite()  # → false
        """
        match self:
            case Sequence(_): true
            case Choice(_): true
            case _: false

    fn is_quantified() -> bool:
        """Check if pattern has quantifier (Repeat or Optional).

        Returns:
            true for Repeat or Optional

        Example:
            RulePattern::Repeat(pattern).is_quantified()  # → true
            RulePattern::Optional(pattern).is_quantified()  # → true
        """
        match self:
            case Repeat(_): true
            case Optional(_): true
            case _: false

    fn is_nullable() -> bool:
        """Check if pattern can match empty input.

        Returns:
            true for Optional or Repeat

        Example:
            RulePattern::Optional(pattern).is_nullable()  # → true
            RulePattern::Token("id").is_nullable()  # → false
        """
        match self:
            case Optional(_): true
            case Repeat(_): true
            case _: false

    fn has_children() -> bool:
        """Check if pattern contains sub-patterns.

        Returns:
            true for Sequence, Choice, Repeat, Optional

        Example:
            RulePattern::Sequence([...]).has_children()  # → true
            RulePattern::Token("id").has_children()  # → false
        """
        match self:
            case Sequence(_): true
            case Choice(_): true
            case Repeat(_): true
            case Optional(_): true
            case _: false

    fn to_string() -> text:
        """Convert pattern to string.

        Returns:
            Pattern type name

        Example:
            RulePattern::Token("id").to_string()  # → "token"
        """
        match self:
            case Token(_): "token"
            case Sequence(_): "sequence"
            case Choice(_): "choice"
            case Repeat(_): "repeat"
            case Optional(_): "optional"
            case Reference(_): "reference"

    fn description() -> text:
        """Get pattern description.

        Returns:
            Human-readable description

        Example:
            RulePattern::Token("identifier").description()
            # → "Token: identifier"
        """
        match self:
            case Token(t): "Token: {t}"
            case Sequence(patterns): "Sequence of {patterns.len()} patterns"
            case Choice(patterns): "Choice between {patterns.len()} alternatives"
            case Repeat(pattern): "Repeat (zero or more)"
            case Optional(pattern): "Optional (zero or one)"
            case Reference(name): "Reference to rule: {name}"

    fn summary() -> text:
        """Get summary of rule pattern.

        Returns:
            Human-readable summary

        Example:
            RulePattern::Repeat(pattern).summary()
            # → "RulePattern: repeat (quantified, nullable, has children)"
        """
        val name = self.to_string()
        var attrs: List<text> = []

        if self.is_terminal():
            attrs.push("terminal")
        if self.is_composite():
            attrs.push("composite")
        if self.is_quantified():
            attrs.push("quantified")
        if self.is_nullable():
            attrs.push("nullable")
        if self.has_children():
            attrs.push("has children")

        val attrs_str = attrs.join(", ")
        return if attrs.is_empty():
            "RulePattern: {name}"
        else:
            "RulePattern: {name} ({attrs_str})"

# Grammar compiler
class GrammarCompiler:
    static fn new() -> GrammarCompiler:
        GrammarCompiler()

    # Compile a grammar
    fn compile(grammar: Grammar) -> Result<CompiledGrammar, text>:
        var compiled = CompiledGrammar.new(grammar.name, grammar.entry_point)

        # Step 1: Convert rules to compiled format
        for (name, rule) in grammar.rules.items():
            val compiled_rule = self.compile_rule(name, rule)?
            compiled.rules[name] = compiled_rule

        # Step 2: Compute nullable rules
        self.compute_nullable_rules(&mut compiled)?

        # Step 3: Compute first sets
        self.compute_first_sets(&mut compiled)?

        # Step 4: Compute follow sets
        self.compute_follow_sets(&mut compiled)?

        # Step 5: Extract token types
        self.extract_token_types(&mut compiled)?

        Ok(compiled)

    # Compile a single rule
    fn compile_rule(name: text, rule: GrammarRule) -> Result<CompiledRule, text>:
        # Simplified compilation - just wrap the rule for now
        # In real implementation, would analyze and optimize the pattern
        val pattern = RulePattern.Reference(name)  # Placeholder
        Ok(CompiledRule.new(name, pattern))

    # Compute which rules can match empty
    fn compute_nullable_rules(compiled: &mut CompiledGrammar) -> Result<Nil, text>:
        # Fixed-point iteration
        var changed = true
        while changed:
            changed = false

            for (name, rule) in compiled.rules.items():
                if not compiled.nullable_rules.contains(name):
                    if self.is_pattern_nullable(rule.pattern, compiled):
                        compiled.nullable_rules.insert(name)
                        changed = true

        Ok(nil)

    # Check if pattern is nullable
    fn is_pattern_nullable(pattern: RulePattern, compiled: &CompiledGrammar) -> bool:
        match pattern:
            case Token(_):
                return false
            case Sequence(patterns):
                # All must be nullable
                for p in patterns:
                    if not self.is_pattern_nullable(p, compiled):
                        return false
                return true
            case Choice(patterns):
                # Any can be nullable
                for p in patterns:
                    if self.is_pattern_nullable(p, compiled):
                        return true
                return false
            case Repeat(_):
                return true  # Can match zero times
            case Optional(_):
                return true  # Can be absent
            case Reference(rule_name):
                return compiled.nullable_rules.contains(rule_name)

    # Compute first sets (which tokens can start each rule)
    fn compute_first_sets(compiled: &mut CompiledGrammar) -> Result<Nil, text>:
        # Initialize empty sets
        for (name, _) in compiled.rules.items():
            compiled.first_sets[name] = Set()

        # Fixed-point iteration
        var changed = true
        while changed:
            changed = false

            for (name, rule) in compiled.rules.items():
                val old_size = compiled.first_sets[name].size()
                self.add_first_tokens(rule.pattern, compiled, &mut compiled.first_sets[name])
                if compiled.first_sets[name].size() > old_size:
                    changed = true

        Ok(nil)

    # Add first tokens from pattern to set
    fn add_first_tokens(pattern: RulePattern,
        compiled: &CompiledGrammar,
        first_set: &mut Set<text>
    ):
        match pattern:
            case Token(token_type):
                first_set.insert(token_type)
            case Sequence(patterns):
                for p in patterns:
                    self.add_first_tokens(p, compiled, first_set)
                    if not self.is_pattern_nullable(p, compiled):
                        break
            case Choice(patterns):
                for p in patterns:
                    self.add_first_tokens(p, compiled, first_set)
            case Repeat(p):
                self.add_first_tokens(p, compiled, first_set)
            case Optional(p):
                self.add_first_tokens(p, compiled, first_set)
            case Reference(rule_name):
                match compiled.first_sets.get(rule_name):
                    case Some(set):
                        first_set.union(set)
                    case None:
                        pass

    # Compute follow sets (which tokens can follow each rule)
    fn compute_follow_sets(compiled: &mut CompiledGrammar) -> Result<Nil, text>:
        # Initialize empty sets
        for (name, _) in compiled.rules.items():
            compiled.follow_sets[name] = Set()

        # Entry point can be followed by EOF
        compiled.follow_sets[compiled.entry_point].insert("EOF")

        # Fixed-point iteration
        var changed = true
        while changed:
            changed = false

            for (name, rule) in compiled.rules.items():
                val old_sizes = self.get_total_follow_set_size(compiled)
                self.propagate_follow_sets(name, rule.pattern, compiled)
                if self.get_total_follow_set_size(compiled) > old_sizes:
                    changed = true

        Ok(nil)

    # Get total size of all follow sets (for change detection)
    fn get_total_follow_set_size(compiled: &CompiledGrammar) -> i32:
        var total = 0
        for (_, set) in compiled.follow_sets.items():
            total = total + set.size()
        total

    # Propagate follow sets through pattern
    fn propagate_follow_sets(rule_name: text,
        pattern: RulePattern,
        compiled: &mut CompiledGrammar
    ):
        match pattern:
            case Token(_):
                pass  # Terminals don't have follow sets
            case Sequence(patterns):
                # Each element's follow includes first of next elements
                # If next element is nullable, also include first of element after that
                for i in 0..patterns.len():
                    # Recursively process this pattern
                    self.propagate_follow_sets(rule_name, patterns[i], compiled)

                    # For each pattern, compute what can follow it
                    if i + 1 < patterns.len():
                        # Get the reference names from this pattern to update their follow sets
                        val refs = self.get_references(patterns[i])

                        for ref_name in refs:
                            # Add FIRST of all subsequent nullable patterns
                            for j in (i + 1)..patterns.len():
                                self.add_first_tokens(patterns[j], compiled, &mut compiled.follow_sets[ref_name])
                                if not self.is_pattern_nullable(patterns[j], compiled):
                                    break

                            # If all remaining patterns are nullable, add FOLLOW(rule)
                            var all_nullable = true
                            for j in (i + 1)..patterns.len():
                                if not self.is_pattern_nullable(patterns[j], compiled):
                                    all_nullable = false
                                    break

                            if all_nullable:
                                match compiled.follow_sets.get(rule_name):
                                    case Some(follow):
                                        compiled.follow_sets[ref_name].union(follow)
                                    case None:
                                        pass
            case Choice(patterns):
                for p in patterns:
                    self.propagate_follow_sets(rule_name, p, compiled)
            case Repeat(p):
                self.propagate_follow_sets(rule_name, p, compiled)
            case Optional(p):
                self.propagate_follow_sets(rule_name, p, compiled)
            case Reference(ref_name):
                # Propagate this rule's follow to referenced rule
                match compiled.follow_sets.get(rule_name):
                    case Some(follow):
                        compiled.follow_sets[ref_name].union(follow)
                    case None:
                        pass

    # Extract all token types used in grammar
    fn extract_token_types(compiled: &mut CompiledGrammar) -> Result<Nil, text>:
        var token_set: Set<text> = Set()

        for (_, rule) in compiled.rules.items():
            self.collect_token_types(rule.pattern, &mut token_set)

        compiled.token_types = token_set.to_list()

        Ok(nil)

    # Collect token types from pattern
    fn collect_token_types(pattern: RulePattern, token_set: &mut Set<text>):
        match pattern:
            case Token(token_type):
                token_set.insert(token_type)
            case Sequence(patterns):
                for p in patterns:
                    self.collect_token_types(p, token_set)
            case Choice(patterns):
                for p in patterns:
                    self.collect_token_types(p, token_set)
            case Repeat(p):
                self.collect_token_types(p, token_set)
            case Optional(p):
                self.collect_token_types(p, token_set)
            case Reference(_):
                pass  # References don't contain tokens directly

    # Get all reference names from a pattern
    fn get_references(pattern: RulePattern) -> List<text>:
        var refs: List<text> = []
        self.collect_references(pattern, &mut refs)
        return refs

    # Collect reference names from pattern
    fn collect_references(pattern: RulePattern, refs: &mut List<text>):
        match pattern:
            case Token(_):
                pass
            case Sequence(patterns):
                for p in patterns:
                    self.collect_references(p, refs)
            case Choice(patterns):
                for p in patterns:
                    self.collect_references(p, refs)
            case Repeat(p):
                self.collect_references(p, refs)
            case Optional(p):
                self.collect_references(p, refs)
            case Reference(rule_name):
                refs.append(rule_name)

# Grammar cache for compiled grammars
class GrammarCache:
    cache: Dict<text, CompiledGrammar>

    static fn new() -> GrammarCache:
        GrammarCache(cache: {})

    # Get compiled grammar from cache
    fn get(language: text) -> Option<CompiledGrammar>:
        self.cache.get(language)

    # Add compiled grammar to cache
    var fn add(language: text, compiled: CompiledGrammar):
        self.cache[language] = compiled

    # Check if language is cached
    fn contains(language: text) -> bool:
        self.cache.contains_key(language)

    # Clear cache
    var fn clear():
        self.cache = {}

    # Get cache size
    fn size() -> i32:
        self.cache.len()

# Grammar compilation pipeline
class GrammarPipeline:
    compiler: GrammarCompiler
    cache: GrammarCache

    static fn new() -> GrammarPipeline:
        GrammarPipeline(
            compiler: GrammarCompiler.new(),
            cache: GrammarCache.new()
        )

    # Compile grammar with caching
    var fn compile(grammar: Grammar) -> Result<CompiledGrammar, text>:
        # Check cache first
        match self.cache.get(grammar.name):
            case Some(compiled):
                return Ok(compiled)
            case None:
                pass

        # Compile grammar
        val compiled = self.compiler.compile(grammar)?

        # Add to cache
        self.cache.add(grammar.name, compiled)

        Ok(compiled)

    # Compile grammar for language name
    var fn compile_language(language: text) -> Result<CompiledGrammar, text>:
        # Check cache first
        match self.cache.get(language):
            case Some(compiled):
                return Ok(compiled)
            case None:
                pass

        # Load and compile grammar for supported languages
        val grammar = match language:
            case "simple":
                import parser.treesitter.grammar.{build_simple_grammar}
                build_simple_grammar()
            case "python":
                import parser.treesitter.grammar_python.{PythonGrammarBuilder}
                var builder = PythonGrammarBuilder.new()
                builder.build_grammar()
                builder.grammar
            case "rust":
                import parser.treesitter.grammar_rust.{RustGrammarBuilder}
                var builder = RustGrammarBuilder.new()
                builder.build_grammar()
                builder.grammar
            case _:
                return Err("Grammar for language '{language}' not found")

        # Compile and cache the grammar
        val compiled = self.compiler.compile(grammar)?
        self.cache.add(language, compiled)
        Ok(compiled)

    # Clear compilation cache
    var fn clear_cache():
        self.cache.clear()

# Convenience functions

# Compile a grammar
fn compile_grammar(grammar: Grammar) -> Result<CompiledGrammar, text>:
    val compiler = GrammarCompiler.new()
    compiler.compile(grammar)

# Compile grammar for a language
fn compile_language(language: text) -> Result<CompiledGrammar, text>:
    var pipeline = GrammarPipeline.new()
    pipeline.compile_language(language)
