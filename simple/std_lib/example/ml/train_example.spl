# ML Infrastructure Example
#
# Complete example showing config, caching, validation, tracking, and engine.

import config.Conf
import ml.torch as torch
import ml.torch.cache.{CacheManager, CacheMode}
import ml.torch.validation.{RuntimeValidator, ValidationMode}
import ml.tracking.Track
import ml.engine.{Engine, Events, Loss}


# ============================================================================
# Example 1: Configuration System
# ============================================================================

fn example_config():
    """Example: Load and merge configurations."""
    print("\n" + "=" * 70)
    print("EXAMPLE 1: Configuration System")
    print("=" * 70)

    # Create base config dict
    let base_config = {
        "project": "mnist-example",
        "seed": 42,
        "train": {
            "epochs": 10,
            "batch_size": 64,
            "lr": 0.001
        },
        "model": {
            "type": "simple_nn",
            "hidden_size": 128
        }
    }

    let base = Conf.from_dict(base_config)
    print("Base config:")
    print(f"  Project: {base.get('project')}")
    print(f"  Epochs: {base.get('train.epochs')}")
    print(f"  Learning rate: {base.get('train.lr')}")

    # Parse CLI overrides
    let cli_args = ["train.epochs=20", "train.lr=0.005", "model.hidden_size=256"]
    let cli = Conf.from_cli_dotlist(cli_args)

    print("\nCLI overrides:")
    for arg in cli_args:
        print(f"  {arg}")

    # Merge configs
    let cfg = Conf.merge(base, cli)

    print("\nMerged config:")
    print(f"  Project: {cfg.get('project')}")
    print(f"  Epochs: {cfg.get('train.epochs')}")  # Overridden to 20
    print(f"  Learning rate: {cfg.get('train.lr')}")  # Overridden to 0.005
    print(f"  Hidden size: {cfg.get('model.hidden_size')}")  # Overridden to 256

    # Freeze config
    Conf.freeze(cfg)
    print("\nConfig frozen for production safety")


# ============================================================================
# Example 2: Smart Caching
# ============================================================================

fn example_caching():
    """Example: Memory-aware file caching."""
    print("\n" + "=" * 70)
    print("EXAMPLE 2: Smart Caching System")
    print("=" * 70)

    # Create cache manager with 1GB limit
    let cache = CacheManager(memory_limit=1_000_000_000)

    print("Cache Manager initialized:")
    print(f"  Memory limit: {cache.memory_limit / 1e9:.2f} GB")

    # Simulate file scanning
    let files = [
        "data/vocab.txt",      # 10 MB
        "data/train.tar",      # 500 MB
        "data/val.tar"         # 600 MB
    ]

    let priorities = {
        "data/vocab.txt": 2,   # High priority
        "data/train.tar": 1,   # Normal priority
        "data/val.tar": 0      # Low priority
    }

    print("\nFile priorities:")
    for file, priority in priorities.items():
        print(f"  {file}: priority={priority}")

    # Note: scan_files would fail without actual files
    # In real usage:
    # let stats = cache.scan_files(files, priorities=priorities)
    # print(f"\nCache stats:")
    # print(f"  Cached files: {stats['cached_files']}")
    # print(f"  Total size: {stats['total_size'] / 1e9:.2f} GB")

    print("\nCache strategy:")
    print("  - vocab.txt (10MB, priority=2) → mmap (high priority, small)")
    print("  - train.tar (500MB, priority=1) → mmap (fits in limit)")
    print("  - val.tar (600MB, priority=0) → normal I/O (exceeds limit)")


# ============================================================================
# Example 3: Runtime Validation
# ============================================================================

fn example_validation():
    """Example: Runtime validation system."""
    print("\n" + "=" * 70)
    print("EXAMPLE 3: Runtime Validation")
    print("=" * 70)

    # Create validator with check_and_train mode
    let validator = RuntimeValidator(ValidationMode.CheckAndTrain)

    print("Validator created with mode: check_and_train")
    print("\nValidation checks:")
    print("  1. Memory validation (model + activation)")
    print("  2. Shape validation (tensor dimensions)")
    print("  3. Gradient flow (NaN/Inf detection)")
    print("  4. Numeric stability")
    print("  5. Device placement (CPU/GPU)")
    print("  6. DataLoader pipeline")
    print("  7. Optimizer configuration")
    print("  8. Training loop (mini-epochs)")

    # In real usage with actual model:
    # let report = validator.validate_all(model, dataloader, optimizer, loss_fn)
    # report.print()
    #
    # if report.has_errors():
    #     print("\nValidation failed! Aborting training.")
    #     sys.exit(1)

    print("\nExample CLI usage:")
    print("  simple train.spl --mode=check_only      # Validate without training")
    print("  simple train.spl --mode=train_only      # Skip validation")
    print("  simple train.spl --mode=check_and_train # Validate then train")


# ============================================================================
# Example 4: Experiment Tracking
# ============================================================================

fn example_tracking():
    """Example: Experiment tracking."""
    print("\n" + "=" * 70)
    print("EXAMPLE 4: Experiment Tracking")
    print("=" * 70)

    # Set offline mode
    Track.set_mode("offline")
    print("Tracking mode: offline")

    # Create run
    let config = {"lr": 0.001, "batch_size": 64, "epochs": 10}
    let run = Track.run(project="mnist-example", name="baseline", config=config, tags=["baseline"])

    print(f"\nRun created:")
    print(f"  ID: {run.id}")
    print(f"  Name: {run.name}")
    print(f"  Project: {run.project}")
    print(f"  Directory: {run.dir}")

    # Log metrics
    print("\nLogging metrics...")
    for step in range(5):
        let fake_loss = 2.0 - (step * 0.3)
        let fake_acc = 0.2 + (step * 0.15)

        run.log({
            "train/loss": fake_loss,
            "train/acc": fake_acc
        }, step=step)

        print(f"  Step {step}: loss={fake_loss:.3f}, acc={fake_acc:.3f}")

    # Create and log artifact
    print("\nLogging model artifact...")
    let artifact = Track.Artifact("mnist-model-v1", type="model", description="Baseline model")
    # In real usage: artifact.add_file("checkpoint.pt")
    run.log_artifact(artifact, aliases=["latest", "baseline"])

    print(f"  Artifact: {artifact.name}")
    print(f"  Type: {artifact.type}")

    # Finish run
    run.finish()
    print("\nRun finished!")
    print(f"  Duration: {run.end_time - run.start_time:.2f}s")


# ============================================================================
# Example 5: Training Engine
# ============================================================================

fn example_engine():
    """Example: Event-driven training engine."""
    print("\n" + "=" * 70)
    print("EXAMPLE 5: Training Engine")
    print("=" * 70)

    # Define training step
    fn train_step(engine: Engine, batch: any) -> {str: any}:
        # Simulate training
        let fake_loss = 1.0 - (engine.state.iteration * 0.01)
        return {"loss": fake_loss}

    # Create engine
    let trainer = Engine(train_step)

    print("Engine created with train_step function")

    # Attach event handlers
    print("\nAttaching event handlers:")

    @trainer.on(Events.STARTED)
    fn on_start(engine: Engine):
        print(f"  [Event] Training started")

    @trainer.on(Events.EPOCH_STARTED)
    fn on_epoch_start(engine: Engine):
        print(f"  [Event] Epoch {engine.state.epoch + 1}/{engine.state.max_epochs} started")

    @trainer.on(Events.EPOCH_COMPLETED)
    fn on_epoch_complete(engine: Engine):
        print(f"  [Event] Epoch {engine.state.epoch + 1} completed")
        print(f"          Avg loss: {engine.state.metrics.get('loss', 0.0):.4f}")

    @trainer.on(Events.COMPLETED)
    fn on_complete(engine: Engine):
        print(f"  [Event] Training completed!")
        print(f"          Total iterations: {engine.state.iteration}")

    # Add metrics
    let loss_metric = Loss()
    trainer.add_metric(loss_metric, "loss")
    print("\nMetrics added: loss")

    # Simulate dataloader
    let fake_dataloader = [[1, 2], [3, 4], [5, 6]]  # 3 batches

    # Run engine
    print(f"\nRunning engine (3 batches, 2 epochs)...")
    trainer.run(fake_dataloader, max_epochs=2)


# ============================================================================
# Example 6: Complete Training Workflow
# ============================================================================

fn example_complete_workflow():
    """Example: Complete ML workflow with all modules."""
    print("\n" + "=" * 70)
    print("EXAMPLE 6: Complete Training Workflow")
    print("=" * 70)

    # 1. Load configuration
    print("\n[1/6] Loading configuration...")
    let config = {
        "project": "complete-example",
        "train": {"epochs": 3, "batch_size": 32, "lr": 0.001},
        "validation_mode": "check_and_train"
    }
    let cfg = Conf.from_dict(config)
    print(f"  Config loaded: {cfg.get('project')}")

    # 2. Initialize caching
    print("\n[2/6] Initializing cache...")
    let cache = CacheManager(memory_limit=1_000_000_000)
    print(f"  Cache ready with {cache.memory_limit / 1e9:.2f}GB limit")

    # 3. Create validator
    print("\n[3/6] Creating validator...")
    let validator = RuntimeValidator(ValidationMode.CheckAndTrain)
    print("  Validator created (mode: check_and_train)")

    # 4. Initialize tracking
    print("\n[4/6] Initializing experiment tracking...")
    Track.set_mode("offline")
    let run = Track.run(
        project=cfg.get("project"),
        config=Conf.to_dict(cfg),
        tags=["example", "complete"]
    )
    print(f"  Run created: {run.id}")

    # 5. Setup training engine
    print("\n[5/6] Setting up training engine...")

    fn train_step(engine: Engine, batch: any) -> {str: any}:
        let fake_loss = 1.0 - (engine.state.iteration * 0.05)
        return {"loss": fake_loss}

    let trainer = Engine(train_step)

    # Log to tracking system
    @trainer.on(Events.ITERATION_COMPLETED)
    fn log_iteration(engine: Engine):
        run.log({
            "train/loss": engine.state.output["loss"]
        }, step=engine.state.iteration)

    @trainer.on(Events.EPOCH_COMPLETED)
    fn log_epoch(engine: Engine):
        print(f"  Epoch {engine.state.epoch + 1} completed")

    let loss_metric = Loss()
    trainer.add_metric(loss_metric, "loss")
    print("  Engine configured with metrics and tracking")

    # 6. Run training
    print("\n[6/6] Running training...")
    let fake_data = [[1], [2], [3]]
    trainer.run(fake_data, max_epochs=cfg.get("train.epochs"))

    # Finish
    run.finish()
    print(f"\n  Training complete!")
    print(f"  Run directory: {run.dir}")
    print(f"  Total iterations: {trainer.state.iteration}")


# ============================================================================
# Main
# ============================================================================

fn main():
    """Run all examples."""
    print("\n")
    print("╔" + "=" * 68 + "╗")
    print("║" + " " * 15 + "ML INFRASTRUCTURE EXAMPLES" + " " * 27 + "║")
    print("╚" + "=" * 68 + "╝")

    example_config()
    example_caching()
    example_validation()
    example_tracking()
    example_engine()
    example_complete_workflow()

    print("\n" + "=" * 70)
    print("All examples completed successfully!")
    print("=" * 70 + "\n")


# Run examples
main()
