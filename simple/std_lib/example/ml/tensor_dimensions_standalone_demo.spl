# Tensor Dimension Inference - Standalone Demo
# This demonstrates the core concepts without module imports

print("============================================================")
print("  TENSOR DIMENSION INFERENCE - STANDALONE DEMO")
print("============================================================")
print("")

# ============================================================================
# Dimension Types
# ============================================================================

enum Dim:
    Literal(value: Int)
    Named(name: String, lo: Int, hi: Int)
    Unknown

print("Example 1: Dimension Types")
print("------------------------------------------------------------")

val d1 = Dim.Literal(value: 64)
print("Exact dimension: {d1}")

val d2 = Dim.Named(name: "batch", lo: 1, hi: 64)
print("Named dimension with range: {d2}")

val d3 = Dim.Unknown
print("Dynamic dimension: {d3}")

print("")

# ============================================================================
# Dimension Unification
# ============================================================================

print("Example 2: Dimension Unification")
print("------------------------------------------------------------")

fn can_unify_dims(d1: Dim, d2: Dim) -> Bool:
    match (d1, d2):
        case (Dim::Literal(v1), Dim.Literal(v2)):
            return v1 == v2
        case (Dim::Named(n1, _, _), Dim.Named(n2, _, _)):
            return n1 == n2
        case (Dim::Unknown, _):
            return true
        case (_, Dim.Unknown):
            return true
        case _:
            return false

val lit1 = Dim.Literal(value: 10)
val lit2 = Dim.Literal(value: 10)
val lit3 = Dim.Literal(value: 20)

print("Can unify Literal(10) with Literal(10)? {can_unify_dims(lit1, lit2)}")
print("Can unify Literal(10) with Literal(20)? {can_unify_dims(lit1, lit3)}")

val named1 = Dim.Named(name: "batch", lo: 1, hi: 64)
val unknown_dim = Dim.Unknown

print("Can unify Named('batch') with Unknown? {can_unify_dims(named1, unknown_dim)}")

print("")

# ============================================================================
# Shape Representation
# ============================================================================

struct TensorShape:
    dims: List[Dim]

fn dim_to_string(d: Dim) -> String:
    match d:
        case Dim::Literal(v):
            return "{v}"
        case Dim::Named(n, lo, hi):
            return "{n}:{lo}..{hi}"
        case Dim::Unknown:
            return "*"

fn shape_to_string(shape: TensorShape) -> String:
    if shape.dims.len() == 0:
        return "[]"
    if shape.dims.len() == 1:
        return "[" + dim_to_string(shape.dims[0]) + "]"
    if shape.dims.len() == 2:
        return "[" + dim_to_string(shape.dims[0]) + ", " + dim_to_string(shape.dims[1]) + "]"
    if shape.dims.len() == 3:
        return "[" + dim_to_string(shape.dims[0]) + ", " + dim_to_string(shape.dims[1]) + ", " + dim_to_string(shape.dims[2]) + "]"
    return "[...]"  # For higher dimensions

print("Example 3: Tensor Shapes")
print("------------------------------------------------------------")

val input_shape = TensorShape(dims: [
    Dim.Named(name: "batch", lo: 1, hi: 64),
    Dim.Literal(value: 784)
])

print("Input shape (MNIST): {shape_to_string(input_shape)}")

val weight_shape = TensorShape(dims: [
    Dim.Literal(value: 784),
    Dim.Literal(value: 10)
])

print("Weight shape: {shape_to_string(weight_shape)}")

print("")

# ============================================================================
# Matrix Multiplication Shape Inference
# ============================================================================

print("Example 4: Matrix Multiplication Shape Inference")
print("------------------------------------------------------------")

enum ShapeResult:
    Ok(shape: TensorShape)
    Error(message: String)

fn infer_matmul_shape(left: TensorShape, right: TensorShape) -> ShapeResult:
    # Check rank
    if left.dims.len() != 2 or right.dims.len() != 2:
        return ShapeResult.Error(message: "Matmul requires 2D tensors")

    val m = left.dims[0]
    val k1 = left.dims[1]
    val k2 = right.dims[0]
    val n = right.dims[1]

    # Check K dimensions match
    if not can_unify_dims(k1, k2):
        return ShapeResult.Error(message: "K dimensions don't match")

    # Result is [M, N]
    return ShapeResult.Ok(shape: TensorShape(dims: [m, n]))

# Test: [batch:1..64, 784] @ [784, 10] -> [batch:1..64, 10]
val result = infer_matmul_shape(input_shape, weight_shape)

match result:
    case ShapeResult.Ok(shape):
        print("✓ Matmul inference successful!")
        print("  Input:  {shape_to_string(input_shape)}")
        print("  Weight: {shape_to_string(weight_shape)}")
        print("  Output: {shape_to_string(shape)}")
    case ShapeResult.Error(msg):
        print("✗ Matmul inference failed: {msg}")

print("")

# ============================================================================
# Error Detection
# ============================================================================

print("Example 5: Catching Shape Mismatches")
print("------------------------------------------------------------")

val bad_weight = TensorShape(dims: [
    Dim.Literal(value: 512),  # Wrong! Should be 784
    Dim.Literal(value: 10)
])

val bad_result = infer_matmul_shape(input_shape, bad_weight)

match bad_result:
    case ShapeResult.Ok(shape):
        print("✗ Should have failed!")
    case ShapeResult.Error(msg):
        print("✓ Caught shape mismatch!")
        print("  Input:      {shape_to_string(input_shape)}")
        print("  Bad weight: {shape_to_string(bad_weight)}")
        print("  Error:      {msg}")

print("")

# ============================================================================
# Memory Estimation
# ============================================================================

print("Example 6: Memory Estimation")
print("------------------------------------------------------------")

fn estimate_memory(shape: TensorShape, elem_size: Int) -> (Int, Int):
    var min_elems = 1
    var max_elems = 1

    for dim in shape.dims:
        match dim:
            case Dim::Literal(v):
                min_elems = min_elems * v
                max_elems = max_elems * v
            case Dim::Named(_, lo, hi):
                min_elems = min_elems * lo
                max_elems = max_elems * hi
            case Dim::Unknown:
                # Can't estimate for dynamic
                min_elems = min_elems * 1
                max_elems = max_elems * 1000  # Assume large

    return (min_elems * elem_size, max_elems * elem_size)

val elem_size = 4  # Float32

val (min_bytes, max_bytes) = estimate_memory(input_shape, elem_size)

print("Memory estimation for {shape_to_string(input_shape)}:")
print("  Element size: {elem_size} bytes (Float32)")
print("  Min memory: {min_bytes} bytes ({min_bytes / 1024} KB)")
print("  Max memory: {max_bytes} bytes ({max_bytes / 1024} KB)")

print("")

# ============================================================================
# Multi-Layer Network
# ============================================================================

print("Example 7: Multi-Layer Network Dimension Propagation")
print("------------------------------------------------------------")

val layer1_weight = TensorShape(dims: [Dim.Literal(value: 784), Dim.Literal(value: 256)])
val layer2_weight = TensorShape(dims: [Dim.Literal(value: 256), Dim.Literal(value: 128)])
val layer3_weight = TensorShape(dims: [Dim.Literal(value: 128), Dim.Literal(value: 10)])

print("Input:   {shape_to_string(input_shape)}")
print("Layer 1: {shape_to_string(layer1_weight)}")

val h1_result = infer_matmul_shape(input_shape, layer1_weight)
match h1_result:
    case ShapeResult.Ok(h1):
        print("Hidden 1: {shape_to_string(h1)}")

        print("Layer 2: {shape_to_string(layer2_weight)}")
        val h2_result = infer_matmul_shape(h1, layer2_weight)
        match h2_result:
            case ShapeResult.Ok(h2):
                print("Hidden 2: {shape_to_string(h2)}")

                print("Layer 3: {shape_to_string(layer3_weight)}")
                val output_result = infer_matmul_shape(h2, layer3_weight)
                match output_result:
                    case ShapeResult.Ok(output):
                        print("Output:   {shape_to_string(output)}")
                        print("")
                        print("✓ Dimensions propagated successfully through 3-layer network!")
                    case ShapeResult.Error(msg):
                        print("✗ Layer 3 failed: {msg}")
            case ShapeResult.Error(msg):
                print("✗ Layer 2 failed: {msg}")
    case ShapeResult.Error(msg):
        print("✗ Layer 1 failed: {msg}")

print("")

# ============================================================================
# Summary
# ============================================================================

print("============================================================")
print("  SUMMARY")
print("============================================================")
print("")
print("Tensor dimension inference provides:")
print("  ✓ Compile-time dimension tracking")
print("  ✓ Shape inference through operations")
print("  ✓ Runtime constraint verification")
print("  ✓ Memory estimation from ranges")
print("  ✓ Early error detection")
print("")
print("Key Benefits:")
print("  • Catch shape mismatches before runtime")
print("  • Document tensor shapes in code")
print("  • Plan GPU memory requirements")
print("  • Type-safe neural network construction")
print("")
