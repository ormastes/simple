# Simple Math Integration Tests
# Tests for Simple Math #1910-#1959 features
# Integration tests for @ operator, grid literals, and tensor literals

import spec
import ml.torch as torch

describe "Simple Math: @ matrix multiplication operator":
    it "should multiply 2x2 matrices":
        # [[1, 2], [3, 4]] @ [[5, 6], [7, 8]]
        A = torch.from_data([[1.0, 2.0], [3.0, 4.0]])
        B = torch.from_data([[5.0, 6.0], [7.0, 8.0]])

        C = A @ B

        # Expected: [[19, 22], [43, 50]]
        # (1*5 + 2*7 = 19, 1*6 + 2*8 = 22)
        # (3*5 + 4*7 = 43, 3*6 + 4*8 = 50)
        expected = torch.from_data([[19.0, 22.0], [43.0, 50.0]])

        spec.expect(C.allclose(expected)).to_be(True)

    it "should handle matrix-vector multiplication":
        # [[1, 2, 3], [4, 5, 6]] @ [1, 2, 3]
        A = torch.from_data([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])
        v = torch.from_data([1.0, 2.0, 3.0])

        result = A @ v

        # Expected: [14, 32] (1*1+2*2+3*3=14, 4*1+5*2+6*3=32)
        expected = torch.from_data([14.0, 32.0])

        spec.expect(result.allclose(expected)).to_be(True)

    it "should chain multiple matrix multiplications":
        # A @ B @ C
        A = torch.from_data([[1.0, 2.0]])  # 1x2
        B = torch.from_data([[3.0], [4.0]])  # 2x1
        C = torch.from_data([[5.0]])  # 1x1

        # (A @ B) @ C = [11] @ [5] = [55]
        result = A @ B @ C

        spec.expect(result.item()).to_be_close(55.0, tolerance=1e-5)

    it "should work with identity matrix":
        A = torch.from_data([[1.0, 2.0], [3.0, 4.0]])
        I = torch.eye(2)

        # A @ I = A
        result = A @ I

        spec.expect(result.allclose(A)).to_be(True)

    it "should respect operator precedence with @ vs *":
        # Test: A @ B * 2.0 should be (A @ B) * 2.0
        A = torch.from_data([[1.0, 0.0], [0.0, 1.0]])
        B = torch.from_data([[2.0, 0.0], [0.0, 2.0]])

        result = A @ B * 2.0

        # Expected: (I @ 2I) * 2 = 2I * 2 = 4I
        expected = torch.from_data([[4.0, 0.0], [0.0, 4.0]])

        spec.expect(result.allclose(expected)).to_be(True)

describe "Simple Math: grid literals":
    it "should create 2D grid from pipe-delimited syntax":
        # Grid literal syntax (will be implemented in parser)
        # For now, test the equivalent torch.tensor call
        grid = torch.from_data([[1.0, 2.0, 3.0],
                             [4.0, 5.0, 6.0]])

        # Shape should be (2, 3)
        spec.expect(grid.shape()).to_equal([2, 3])

        # Verify values
        spec.expect(grid.select(0, 0).select(0, 0).item()).to_be(1.0)
        spec.expect(grid.select(0, 0).select(0, 2).item()).to_be(3.0)
        spec.expect(grid.select(0, 1).select(0, 1).item()).to_be(5.0)

    it "should support CUDA device parameter":
        # grid device="cuda": ...
        # For now, test device movement
        grid = torch.from_data([[1.0, 2.0], [3.0, 4.0]])

        # Verify it's on CPU by default
        spec.expect(grid.device()).to_contain("cpu")

        # Can be moved to CUDA (if available)
        # cuda_grid = grid.to("cuda")  # Requires CUDA

    it "should work with @ operator for matrix operations":
        # grid1: | 1 | 2 |
        #        | 3 | 4 |
        grid1 = torch.from_data([[1.0, 2.0], [3.0, 4.0]])

        # grid2: | 5 | 6 |
        #        | 7 | 8 |
        grid2 = torch.from_data([[5.0, 6.0], [7.0, 8.0]])

        result = grid1 @ grid2

        expected = torch.from_data([[19.0, 22.0], [43.0, 50.0]])
        spec.expect(result.allclose(expected)).to_be(True)

describe "Simple Math: tensor literals":
    it "should create 3D tensor from slice mode":
        # tensor Float (x: 2, y: 2, z: 3) slice: ...
        # Equivalent to 3D tensor
        t = torch.from_data([[[1.0, 2.0, 3.0],
                           [4.0, 5.0, 6.0]],
                          [[7.0, 8.0, 9.0],
                           [10.0, 11.0, 12.0]]])

        # Shape should be (2, 2, 3)
        spec.expect(t.shape()).to_equal([2, 2, 3])

        # Verify slice access
        slice0 = t.select(0, 0)  # First z-slice
        spec.expect(slice0.shape()).to_equal([2, 3])

    it "should create sparse tensor from flat mode with defaults":
        # tensor Int (x: 10, y: 10) flat default=0:
        #     (0, 0) = 5
        #     (5, 5) = 9
        # Equivalent to 10x10 matrix with mostly zeros
        t = torch.zeros([10, 10])
        t[0, 0] = 5.0
        t[5, 5] = 9.0

        # Verify sparse values
        spec.expect(t.select(0, 0).select(0, 0).item()).to_be(5.0)
        spec.expect(t.select(0, 5).select(0, 5).item()).to_be(9.0)

        # Verify default values
        spec.expect(t.select(0, 1).select(0, 1).item()).to_be(0.0)
        spec.expect(t.select(0, 9).select(0, 9).item()).to_be(0.0)

    it "should support different data types":
        # tensor Float ...
        t_float = torch.from_data([[1.5, 2.5]])
        spec.expect(t_float.dtype()).to_contain("float")

        # tensor Int ...
        t_int = torch.from_data([[1, 2]], dtype="int64")
        spec.expect(t_int.dtype()).to_contain("int")

describe "Simple Math: combined operations":
    it "should combine grid literals with linalg operations":
        # Create grid and compute determinant
        A = torch.from_data([[1.0, 2.0], [3.0, 4.0]])

        det = torch.linalg.det(A)

        spec.expect(det.item()).to_be_close(-2.0, tolerance=1e-6)

    it "should use @ operator in linear system solving":
        # Solve A @ x = b, then verify with @
        A = torch.from_data([[2.0, 1.0], [1.0, 2.0]])
        b = torch.from_data([[5.0], [4.0]])

        x = torch.linalg.solve(A, b)

        # Verify: A @ x should equal b
        result = A @ x

        spec.expect(result.allclose(b, rtol=1e-5, atol=1e-5)).to_be(True)

    it "should apply FFT to grid data":
        # Create 2D grid and apply FFT
        grid = torch.from_data([[1.0, 2.0, 3.0, 4.0],
                             [5.0, 6.0, 7.0, 8.0]])

        # FFT along rows (dim=1)
        freq = torch.fft.fft(grid, n=-1, dim=1, norm=0)

        # Should preserve shape
        spec.expect(freq.shape()).to_equal([2, 4])

    it "should use where with grid comparisons":
        # Create grid and apply conditional operations
        grid = torch.from_data([[1.0, 5.0, 3.0],
                             [7.0, 2.0, 9.0]])

        # Select values > 4, otherwise 0
        cond = grid.gt(torch.from_data([[4.0]]))
        result = torch.select(cond, grid, torch.zeros_like(grid))

        expected = torch.from_data([[0.0, 5.0, 0.0],
                                 [7.0, 0.0, 9.0]])

        spec.expect(result.allclose(expected)).to_be(True)

    it "should combine clamp with matrix operations":
        # Create matrix, clamp, then multiply
        A = torch.from_data([[10.0, -5.0], [3.0, 8.0]])
        B = torch.from_data([[1.0, 2.0], [3.0, 4.0]])

        # Clamp A to [0, 5]
        A_clamped = A.clamp(0.0, 5.0)

        # Multiply: clamped @ B
        result = A_clamped @ B

        # Expected: [[5, 0], [3, 5]] @ [[1, 2], [3, 4]]
        # = [[5, 10], [18, 26]]
        expected_A = torch.from_data([[5.0, 0.0], [3.0, 5.0]])
        expected = expected_A @ B

        spec.expect(result.allclose(expected, rtol=1e-5)).to_be(True)
