# Unit tests for LSP semantic tokens handler

import spec.{describe, it, expect}
import lsp.handlers.semantic_tokens as semantic_tokens
import parser.treesitter.{TreeSitterParser, Tree}

describe("Semantic Tokens Handler"):
    it("converts capture names to token types"):
        expect(semantic_tokens.capture_to_token_type("keyword")).to_equal(semantic_tokens.TokenType.Keyword)
        expect(semantic_tokens.capture_to_token_type("function")).to_equal(semantic_tokens.TokenType.Function)
        expect(semantic_tokens.capture_to_token_type("type")).to_equal(semantic_tokens.TokenType.Type)
        expect(semantic_tokens.capture_to_token_type("number")).to_equal(semantic_tokens.TokenType.Number)
        expect(semantic_tokens.capture_to_token_type("string")).to_equal(semantic_tokens.TokenType.String)
        expect(semantic_tokens.capture_to_token_type("unknown")).to_equal(semantic_tokens.TokenType.Variable)

    it("encodes tokens in LSP delta format"):
        # Create test tokens
        let token1 = semantic_tokens.SemanticToken.new(0, 0, 2, semantic_tokens.TokenType.Keyword, 0)
        let token2 = semantic_tokens.SemanticToken.new(0, 3, 3, semantic_tokens.TokenType.Function, 0)
        let token3 = semantic_tokens.SemanticToken.new(1, 0, 6, semantic_tokens.TokenType.Keyword, 0)

        let tokens = [token1, token2, token3]
        let encoded = semantic_tokens.encode_tokens(tokens)

        # Should be 15 integers (3 tokens Ã— 5 values each)
        expect(encoded.len()).to_equal(15)

        # First token: deltaLine=0, deltaCol=0, length=2, type=Keyword, mod=0
        expect(encoded[0]).to_equal(0)  # deltaLine
        expect(encoded[1]).to_equal(0)  # deltaColumn
        expect(encoded[2]).to_equal(2)  # length
        expect(encoded[3]).to_equal(semantic_tokens.TokenType.Keyword)
        expect(encoded[4]).to_equal(0)  # modifiers

        # Second token: deltaLine=0, deltaCol=3, length=3
        expect(encoded[5]).to_equal(0)  # same line
        expect(encoded[6]).to_equal(3)  # column delta
        expect(encoded[7]).to_equal(3)

        # Third token: deltaLine=1, deltaCol=0 (new line resets column)
        expect(encoded[10]).to_equal(1)  # new line
        expect(encoded[11]).to_equal(0)  # column from start
        expect(encoded[12]).to_equal(6)

    it("generates semantic tokens from simple source"):
        let parser = TreeSitterParser.new("simple").unwrap()
        let source = "fn foo(): return 1"
        let tree = parser.parse(source).unwrap()

        let result = semantic_tokens.handle_semantic_tokens_full(tree, source).unwrap()

        # Should have data field
        expect(result.contains_key("data")).to_be(true)

        # Data should be a list of integers
        let data = result["data"]
        expect(data.is_list()).to_be(true)

        # Should have found some tokens
        expect(data.len()).to_be_greater_than(0)

        # Data should be divisible by 5 (5 values per token)
        expect(data.len() % 5).to_equal(0)

    it("handles source with keywords"):
        let parser = TreeSitterParser.new("simple").unwrap()
        let source = "let x = 42\nreturn x"
        let tree = parser.parse(source).unwrap()

        let result = semantic_tokens.handle_semantic_tokens_full(tree, source).unwrap()
        let data = result["data"]

        # Should have found keywords (let, return)
        expect(data.len()).to_be_greater_than(0)

    it("handles source with functions"):
        let parser = TreeSitterParser.new("simple").unwrap()
        let source = "fn add(x: i32, y: i32): return x + y"
        let tree = parser.parse(source).unwrap()

        let result = semantic_tokens.handle_semantic_tokens_full(tree, source).unwrap()
        let data = result["data"]

        # Should have found function keyword and name
        expect(data.len()).to_be_greater_than(0)

    it("handles empty source"):
        let parser = TreeSitterParser.new("simple").unwrap()
        let source = ""
        let tree = parser.parse(source).unwrap()

        let result = semantic_tokens.handle_semantic_tokens_full(tree, source).unwrap()
        let data = result["data"]

        # Empty source should produce no tokens
        expect(data.len()).to_equal(0)

    it("provides token types legend"):
        let types = semantic_tokens.get_token_types_legend()

        expect(types.len()).to_be_greater_than(0)
        expect(types).to_contain("keyword")
        expect(types).to_contain("function")
        expect(types).to_contain("type")
        expect(types).to_contain("number")
        expect(types).to_contain("string")

    it("provides token modifiers legend"):
        let modifiers = semantic_tokens.get_token_modifiers_legend()

        expect(modifiers.len()).to_be_greater_than(0)
        expect(modifiers).to_contain("declaration")
        expect(modifiers).to_contain("definition")
        expect(modifiers).to_contain("readonly")

describe("Semantic Token Types"):
    it("has correct integer values"):
        expect(semantic_tokens.TokenType.Keyword).to_equal(0)
        expect(semantic_tokens.TokenType.Function).to_equal(1)
        expect(semantic_tokens.TokenType.Type).to_equal(2)
        expect(semantic_tokens.TokenType.Variable).to_equal(3)
        expect(semantic_tokens.TokenType.Number).to_equal(6)

describe("Semantic Token Modifiers"):
    it("has correct bitmask values"):
        expect(semantic_tokens.TokenModifier.None).to_equal(0)
        expect(semantic_tokens.TokenModifier.Declaration).to_equal(1)
        expect(semantic_tokens.TokenModifier.Definition).to_equal(2)
        expect(semantic_tokens.TokenModifier.Readonly).to_equal(4)
        expect(semantic_tokens.TokenModifier.Static).to_equal(8)
