# Typed Tensor Specification Tests
# Tests for compile-time dimension inference

import ml.torch.typed_tensor.{
    TypedTensor, TensorType, DimSpec,
    zeros, ones, randn
}
import ml.torch.dtype.{DType}
import ml.torch.device.{Device}
import verification.models.tensor_dimensions.{
    Dim, TensorShape, DimInferenceContext, ShapeError,
    unify_dims, unify_shapes, infer_matmul_shape, infer_broadcast_shape
}

# ============================================================================
# Dimension Inference Tests
# ============================================================================

describe "Dimension Inference":

    describe "Literal Dimensions":
        it "should unify same literals":
            var ctx = DimInferenceContext.new()
            val d1 = Dim.Literal(value: 10)
            val d2 = Dim.Literal(value: 10)
            val result = unify_dims(ctx, d1, d2)
            assert result.is_ok()
            assert result.unwrap() == Dim.Literal(value: 10)

        it "should fail on different literals":
            var ctx = DimInferenceContext.new()
            val d1 = Dim.Literal(value: 10)
            val d2 = Dim.Literal(value: 20)
            val result = unify_dims(ctx, d1, d2)
            assert result.is_err()

    describe "Variable Dimensions":
        it "should bind variable to literal":
            var ctx = DimInferenceContext.new()
            val var_dim = ctx.fresh_var()
            val literal = Dim.Literal(value: 32)
            val result = unify_dims(ctx, var_dim, literal)
            assert result.is_ok()
            assert result.unwrap() == Dim.Literal(value: 32)

        it "should bind two variables":
            var ctx = DimInferenceContext.new()
            val v1 = ctx.fresh_var()
            val v2 = ctx.fresh_var()
            val result = unify_dims(ctx, v1, v2)
            assert result.is_ok()

    describe "Named Dimensions":
        it "should unify same named dimensions":
            var ctx = DimInferenceContext.new()
            val d1 = Dim.Named(name: "batch", range: Some((1, 64)))
            val d2 = Dim.Named(name: "batch", range: Some((1, 32)))
            val result = unify_dims(ctx, d1, d2)
            assert result.is_ok()
            # Range intersection: (1, 32)

        it "should bind named to literal":
            var ctx = DimInferenceContext.new()
            val named = Dim.Named(name: "batch", range: Some((1, 64)))
            val literal = Dim.Literal(value: 32)
            val result = unify_dims(ctx, named, literal)
            assert result.is_ok()
            assert result.unwrap() == Dim.Literal(value: 32)

        it "should fail when literal out of range":
            var ctx = DimInferenceContext.new()
            val named = Dim.Named(name: "batch", range: Some((1, 64)))
            val literal = Dim.Literal(value: 128)
            val result = unify_dims(ctx, named, literal)
            assert result.is_err()

    describe "Dynamic Dimensions":
        it "should match anything":
            var ctx = DimInferenceContext.new()
            val dyn = Dim.Dynamic
            val literal = Dim.Literal(value: 100)
            val result = unify_dims(ctx, dyn, literal)
            assert result.is_ok()
            assert result.unwrap() == Dim.Literal(value: 100)

    describe "Broadcast Dimensions":
        it "should broadcast 1 to any size":
            var ctx = DimInferenceContext.new()
            val bcast = Dim.Broadcast
            val literal = Dim.Literal(value: 64)
            val result = unify_dims(ctx, bcast, literal)
            assert result.is_ok()
            assert result.unwrap() == Dim.Literal(value: 64)

# ============================================================================
# Shape Inference Tests
# ============================================================================

describe "Shape Inference":

    describe "Shape Unification":
        it "should unify same shapes":
            var ctx = DimInferenceContext.new()
            val s1 = TensorShape.from_literals([2, 3, 4])
            val s2 = TensorShape.from_literals([2, 3, 4])
            val result = unify_shapes(ctx, s1, s2)
            assert result.is_ok()
            assert result.unwrap().ndim() == 3

        it "should fail on rank mismatch":
            var ctx = DimInferenceContext.new()
            val s1 = TensorShape.from_literals([2, 3])
            val s2 = TensorShape.from_literals([2, 3, 4])
            val result = unify_shapes(ctx, s1, s2)
            assert result.is_err()

    describe "Matmul Shape":
        it "should infer 2D matmul shape":
            var ctx = DimInferenceContext.new()
            val left = TensorShape.from_literals([2, 3])   # [M=2, K=3]
            val right = TensorShape.from_literals([3, 4])  # [K=3, N=4]
            val result = infer_matmul_shape(ctx, left, right)
            assert result.is_ok()
            val output = result.unwrap()
            assert output.ndim() == 2
            # Should be [2, 4]

        it "should fail on incompatible K dimensions":
            var ctx = DimInferenceContext.new()
            val left = TensorShape.from_literals([2, 3])   # [M=2, K=3]
            val right = TensorShape.from_literals([5, 4])  # [K=5, N=4] - mismatch!
            val result = infer_matmul_shape(ctx, left, right)
            assert result.is_err()

        it "should infer matmul with named dimensions":
            var ctx = DimInferenceContext.new()
            val left = TensorShape(dims: [
                Dim.Named(name: "batch", range: Some((1, 64))),
                Dim.Literal(value: 128)
            ])
            val right = TensorShape(dims: [
                Dim.Literal(value: 128),
                Dim.Literal(value: 256)
            ])
            val result = infer_matmul_shape(ctx, left, right)
            assert result.is_ok()

    describe "Broadcast Shape":
        it "should broadcast scalar to matrix":
            var ctx = DimInferenceContext.new()
            val scalar = TensorShape.from_literals([])
            val matrix = TensorShape.from_literals([3, 4])
            val result = infer_broadcast_shape(ctx, [scalar, matrix])
            assert result.is_ok()
            assert result.unwrap().ndim() == 2

        it "should broadcast [1, 4] with [3, 1]":
            var ctx = DimInferenceContext.new()
            val s1 = TensorShape.from_literals([1, 4])
            val s2 = TensorShape.from_literals([3, 1])
            val result = infer_broadcast_shape(ctx, [s1, s2])
            assert result.is_ok()
            # Should be [3, 4]

        it "should fail on incompatible broadcast":
            var ctx = DimInferenceContext.new()
            val s1 = TensorShape.from_literals([2, 4])
            val s2 = TensorShape.from_literals([3, 4])
            val result = infer_broadcast_shape(ctx, [s1, s2])
            assert result.is_err()

# ============================================================================
# Typed Tensor Tests
# ============================================================================

describe "TypedTensor":

    describe "Creation":
        it "should create zeros with exact dimensions":
            val t = TypedTensor.zeros([
                DimSpec.exact(2),
                DimSpec.exact(3)
            ])
            assert t.ndim() == 2
            assert t.actual_shape() == [2, 3]

        it "should create randn with named dimensions":
            val t = TypedTensor.randn([
                DimSpec.named("batch", 32),
                DimSpec.named("features", 128)
            ])
            assert t.ndim() == 2

        it "should create with range constraints":
            val t = TypedTensor.zeros([
                DimSpec.ranged("batch", 16, 1, 64),
                DimSpec.exact(784)
            ])
            assert t.verify().is_ok()

    describe "Operations with Inference":
        it "should infer matmul output shape":
            val a = TypedTensor.randn([
                DimSpec.exact(4),
                DimSpec.exact(8)
            ])
            val b = TypedTensor.randn([
                DimSpec.exact(8),
                DimSpec.exact(16)
            ])
            val result = a.matmul(b)
            assert result.is_ok()
            val c = result.unwrap()
            assert c.ndim() == 2
            # Shape should be [4, 16]

        it "should fail matmul on shape mismatch":
            val a = TypedTensor.randn([DimSpec.exact(4), DimSpec.exact(8)])
            val b = TypedTensor.randn([DimSpec.exact(10), DimSpec.exact(16)])  # K mismatch
            val result = a.matmul(b)
            assert result.is_err()

        it "should infer broadcast add shape":
            val a = TypedTensor.randn([DimSpec.exact(3), DimSpec.exact(4)])
            val b = TypedTensor.randn([DimSpec.exact(1), DimSpec.exact(4)])
            val result = a.add(b)
            assert result.is_ok()

        it "should infer reshape shape":
            val t = TypedTensor.randn([DimSpec.exact(4), DimSpec.exact(6)])
            val result = t.reshape([DimSpec.exact(2), DimSpec.exact(12)])
            assert result.is_ok()  # 4*6 = 2*12 = 24

        it "should fail reshape on element count mismatch":
            val t = TypedTensor.randn([DimSpec.exact(4), DimSpec.exact(6)])
            val result = t.reshape([DimSpec.exact(2), DimSpec.exact(10)])
            # 4*6=24, 2*10=20, should fail

    describe "Reduction Operations":
        it "should infer sum shape":
            val t = TypedTensor.randn([DimSpec.exact(3), DimSpec.exact(4)])
            val result = t.sum(dim: 1)
            assert result.is_ok()
            val s = result.unwrap()
            assert s.ndim() == 1  # [3]

        it "should infer sum with keepdim":
            val t = TypedTensor.randn([DimSpec.exact(3), DimSpec.exact(4)])
            val result = t.sum(dim: 1, keepdim: True)
            assert result.is_ok()
            val s = result.unwrap()
            assert s.ndim() == 2  # [3, 1]

# ============================================================================
# Memory Estimation Tests
# ============================================================================

describe "Memory Estimation":

    describe "TensorType Memory":
        it "should estimate memory for exact dimensions":
            val tt = TensorType.new([
                DimSpec.exact(64),
                DimSpec.exact(256)
            ], DType.Float32)
            val mem = tt.min_memory_bytes()
            assert mem == 64 * 256 * 4  # 65536 bytes

        it "should estimate memory range for ranged dimensions":
            val tt = TensorType.new([
                DimSpec.ranged("batch", 32, 1, 64),
                DimSpec.exact(256)
            ], DType.Float32)
            val min_mem = tt.min_memory_bytes()
            val max_mem = tt.max_memory_bytes()
            assert min_mem == 1 * 256 * 4     # 1024 bytes
            assert max_mem == 64 * 256 * 4    # 65536 bytes

# ============================================================================
# Multi-Dimensional Inference Tests
# ============================================================================

describe "Multi-Dimensional Inference":

    describe "3D Tensor Operations":
        it "should infer batch matmul shape":
            # [B, M, K] @ [B, K, N] -> [B, M, N]
            var ctx = DimInferenceContext.new()
            val left = TensorShape(dims: [
                Dim.Named(name: "batch", range: Some((1, 32))),
                Dim.Literal(value: 4),
                Dim.Literal(value: 8)
            ])
            val right = TensorShape(dims: [
                Dim.Named(name: "batch", range: Some((1, 32))),
                Dim.Literal(value: 8),
                Dim.Literal(value: 16)
            ])
            val result = infer_matmul_shape(ctx, left, right)
            assert result.is_ok()

    describe "4D Tensor Operations (CNN)":
        it "should handle NCHW format":
            # Typical CNN input: [N, C, H, W]
            val input_shape = TensorShape(dims: [
                Dim.Named(name: "batch", range: Some((1, 128))),
                Dim.Literal(value: 3),    # RGB
                Dim.Literal(value: 224),  # Height
                Dim.Literal(value: 224)   # Width
            ])
            assert input_shape.ndim() == 4
            assert input_shape.is_concrete() == False  # Has named dim with range

    describe "Transformer Dimensions":
        it "should infer attention shape":
            # Q: [B, H, S, D], K: [B, H, S, D] -> QK^T: [B, H, S, S]
            var ctx = DimInferenceContext.new()
            val batch = Dim.Named(name: "batch", range: Some((1, 64)))
            val heads = Dim.Literal(value: 12)
            val seq = Dim.Named(name: "seq", range: Some((1, 512)))
            val head_dim = Dim.Literal(value: 64)

            val q_shape = TensorShape(dims: [batch, heads, seq, head_dim])
            val k_shape = TensorShape(dims: [batch, heads, seq, head_dim])

            # For attention, we do Q @ K^T
            # This requires more complex shape manipulation (transpose K)
            assert q_shape.ndim() == 4
            assert k_shape.ndim() == 4

    describe "Chain of Operations":
        it "should propagate dimensions through chain":
            var ctx = DimInferenceContext.new()

            # Input: [B=32, 784]
            val input = TensorShape(dims: [
                Dim.Named(name: "batch", range: Some((1, 64))),
                Dim.Literal(value: 784)
            ])

            # Layer 1: [784, 256]
            val w1 = TensorShape.from_literals([784, 256])

            # After matmul: [B, 256]
            val h1_result = infer_matmul_shape(ctx, input, w1)
            assert h1_result.is_ok()
            val h1 = h1_result.unwrap()
            assert h1.ndim() == 2

            # Layer 2: [256, 128]
            val w2 = TensorShape.from_literals([256, 128])

            # After matmul: [B, 128]
            val h2_result = infer_matmul_shape(ctx, h1, w2)
            assert h2_result.is_ok()
            val h2 = h2_result.unwrap()
            assert h2.ndim() == 2

            # Final: [128, 10]
            val w3 = TensorShape.from_literals([128, 10])

            # After matmul: [B, 10]
            val output_result = infer_matmul_shape(ctx, h2, w3)
            assert output_result.is_ok()
            val output = output_result.unwrap()
            assert output.ndim() == 2
