# Linear Algebra Operations Test Suite
# Tests for Simple Math #1950-#1959 linalg features
# Tests: det (determinant), inv (inverse), solve (linear system solver)

import spec
import ml.torch as torch

describe "Linear Algebra: determinant":
    it "should compute determinant of 2x2 matrix":
        # Matrix: [[1, 2], [3, 4]]
        # det = 1*4 - 2*3 = -2
        A = torch.from_data([[1.0, 2.0], [3.0, 4.0]])

        det = torch.linalg.det(A)

        spec.expect(det.item()).to_be_close(-2.0, tolerance=1e-6)

    it "should compute determinant of 3x3 identity matrix":
        # Identity matrix has determinant 1
        I = torch.eye(3)

        det = torch.linalg.det(I)

        spec.expect(det.item()).to_be_close(1.0, tolerance=1e-6)

    it "should compute determinant of diagonal matrix":
        # Diagonal matrix: diag([2, 3, 4])
        # det = 2 * 3 * 4 = 24
        D = torch.diag(torch.from_data([2.0, 3.0, 4.0]))

        det = torch.linalg.det(D)

        spec.expect(det.item()).to_be_close(24.0, tolerance=1e-6)

    it "should return zero for singular matrix":
        # Singular matrix (rows are linearly dependent)
        # [[1, 2], [2, 4]]
        A = torch.from_data([[1.0, 2.0], [2.0, 4.0]])

        det = torch.linalg.det(A)

        spec.expect(det.item()).to_be_close(0.0, tolerance=1e-6)

describe "Linear Algebra: matrix inverse":
    it "should compute inverse of 2x2 matrix":
        # Matrix: [[1, 2], [3, 4]]
        # Inverse: [[-2, 1], [1.5, -0.5]]
        A = torch.from_data([[1.0, 2.0], [3.0, 4.0]])

        A_inv = torch.linalg.inv(A)

        # Verify: A @ A_inv = I
        I = A.matmul(A_inv)
        expected = torch.eye(2)

        spec.expect(I.allclose(expected, rtol=1e-5, atol=1e-5)).to_be(True)

    it "should compute inverse of identity matrix":
        # inv(I) = I
        I = torch.eye(3)

        I_inv = torch.linalg.inv(I)

        spec.expect(I_inv.allclose(I)).to_be(True)

    it "should compute inverse of diagonal matrix":
        # Diagonal matrix: diag([2, 4, 5])
        # Inverse: diag([0.5, 0.25, 0.2])
        D = torch.diag(torch.from_data([2.0, 4.0, 5.0]))

        D_inv = torch.linalg.inv(D)

        expected = torch.diag(torch.from_data([0.5, 0.25, 0.2]))

        spec.expect(D_inv.allclose(expected, rtol=1e-5)).to_be(True)

    it "should satisfy A @ inv(A) = I for random matrix":
        # Create random invertible matrix
        A = torch.from_data([[3.0, 1.0], [2.0, 2.0]])

        A_inv = torch.linalg.inv(A)

        # Verify: A @ A_inv ≈ I
        I = A.matmul(A_inv)
        expected = torch.eye(2)

        spec.expect(I.allclose(expected, rtol=1e-5, atol=1e-5)).to_be(True)

describe "Linear Algebra: solve linear system":
    it "should solve 2x2 system Ax = b":
        # System: [[1, 2], [3, 4]] @ x = [5, 11]
        # Solution: x = [1, 2]
        A = torch.from_data([[1.0, 2.0], [3.0, 4.0]])
        b = torch.from_data([[5.0], [11.0]])

        x = torch.linalg.solve(A, b)

        # Verify solution
        expected = torch.from_data([[1.0], [2.0]])

        spec.expect(x.allclose(expected, rtol=1e-5, atol=1e-5)).to_be(True)

    it "should solve system with identity matrix":
        # I @ x = b  →  x = b
        I = torch.eye(3)
        b = torch.from_data([[2.0], [4.0], [6.0]])

        x = torch.linalg.solve(I, b)

        spec.expect(x.allclose(b)).to_be(True)

    it "should solve multiple right-hand sides":
        # Solve A @ X = B where B has multiple columns
        A = torch.from_data([[2.0, 1.0], [1.0, 2.0]])
        B = torch.from_data([[3.0, 6.0], [3.0, 9.0]])

        X = torch.linalg.solve(A, B)

        # Verify: A @ X = B
        result = A.matmul(X)

        spec.expect(result.allclose(B, rtol=1e-5, atol=1e-5)).to_be(True)

    it "should solve diagonal system efficiently":
        # Diagonal system: diag([2, 3, 4]) @ x = [4, 9, 16]
        # Solution: x = [2, 3, 4]
        A = torch.diag(torch.from_data([2.0, 3.0, 4.0]))
        b = torch.from_data([[4.0], [9.0], [16.0]])

        x = torch.linalg.solve(A, b)

        expected = torch.from_data([[2.0], [3.0], [4.0]])

        spec.expect(x.allclose(expected, rtol=1e-5, atol=1e-5)).to_be(True)

describe "Linear Algebra: integration tests":
    it "should verify det(A) * det(inv(A)) = 1 for invertible matrix":
        A = torch.from_data([[2.0, 3.0], [1.0, 4.0]])

        det_A = torch.linalg.det(A)
        A_inv = torch.linalg.inv(A)
        det_A_inv = torch.linalg.det(A_inv)

        # det(A) * det(inv(A)) = 1
        product = det_A.item() * det_A_inv.item()

        spec.expect(product).to_be_close(1.0, tolerance=1e-5)

    it "should solve system using explicit inverse: x = inv(A) @ b":
        A = torch.from_data([[1.0, 2.0], [3.0, 5.0]])
        b = torch.from_data([[7.0], [19.0]])

        # Method 1: solve
        x_solve = torch.linalg.solve(A, b)

        # Method 2: explicit inverse
        A_inv = torch.linalg.inv(A)
        x_inv = A_inv.matmul(b)

        # Both methods should give same result
        spec.expect(x_solve.allclose(x_inv, rtol=1e-5, atol=1e-5)).to_be(True)

    it "should verify det(AB) = det(A) * det(B)":
        A = torch.from_data([[1.0, 2.0], [3.0, 4.0]])
        B = torch.from_data([[2.0, 1.0], [1.0, 3.0]])

        det_A = torch.linalg.det(A)
        det_B = torch.linalg.det(B)
        det_AB = torch.linalg.det(A.matmul(B))

        # det(AB) = det(A) * det(B)
        expected = det_A.item() * det_B.item()

        spec.expect(det_AB.item()).to_be_close(expected, tolerance=1e-5)
