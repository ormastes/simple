# PyTorch Dataset Tests
#
# Tests for dataset loaders including MNIST and CIFAR-10, along with
# DataLoader batching and sampling strategies.

import spec
import ml.torch as torch
import ml.torch.data as data
import ml.torch.nn as nn


describe "PyTorch Dataset Loaders":
    describe "MNIST Dataset":
        it "should create MNIST dataset with default parameters":
            let dataset = data.MNISTDataset(root="./test_data", download=false)
            spec.expect(dataset.root).to_be("./test_data")
            spec.expect(dataset.train).to_be(true)

        it "should load training data":
            let dataset = data.MNISTDataset(root="./test_data", train=true, download=false)

            # MNIST training set has 60,000 images
            spec.expect(dataset.num_samples).to_be(60000)

        it "should load test data":
            let dataset = data.MNISTDataset(root="./test_data", train=false, download=false)

            # MNIST test set has 10,000 images
            spec.expect(dataset.num_samples).to_be(10000)

        it "should return correct image and label shapes":
            let dataset = data.MNISTDataset(root="./test_data", train=true, download=false)

            let (image, label) = dataset[0]

            # MNIST images are 28x28 grayscale
            spec.expect(image.shape()[0]).to_be(28)
            spec.expect(image.shape()[1]).to_be(28)

            # Label is a single value (0-9)
            spec.expect(label.numel()).to_be(1)

        it "should support indexing":
            let dataset = data.MNISTDataset(root="./test_data", train=true, download=false)

            # Get first and last samples
            let (img0, lbl0) = dataset[0]
            let (img_last, lbl_last) = dataset[dataset.num_samples - 1]

            spec.expect(img0.numel()).to_be(28 * 28)
            spec.expect(img_last.numel()).to_be(28 * 28)

        it "should apply transform if provided":
            # Define a simple transform that normalizes to [-1, 1]
            fn normalize(x: torch.Tensor) -> torch.Tensor:
                return (x - 0.5) * 2.0

            let dataset = data.MNISTDataset(root="./test_data", train=true, transform=normalize, download=false)

            let (image, label) = dataset[0]

            # After normalization, values should be in [-1, 1]
            # Original MNIST pixel values are in [0, 1]
            spec.expect(image.min().item()).to_be_greater_than_or_equal(-1.1)
            spec.expect(image.max().item()).to_be_less_than_or_equal(1.1)

        it "should download dataset when requested":
            # Note: This test requires network access and will actually download
            # In a real test suite, this might be mocked or skipped
            let dataset = data.MNISTDataset(root="./test_data_download", train=true, download=true)

            # If download succeeds, dataset should be loaded
            spec.expect(dataset.num_samples).to_be(60000)

    describe "CIFAR-10 Dataset":
        it "should create CIFAR-10 dataset with default parameters":
            let dataset = data.CIFAR10Dataset(root="./test_data", download=false)
            spec.expect(dataset.root).to_be("./test_data")
            spec.expect(dataset.train).to_be(true)

        it "should load training data":
            let dataset = data.CIFAR10Dataset(root="./test_data", train=true, download=false)

            # CIFAR-10 training set has 50,000 images
            spec.expect(dataset.num_samples).to_be(50000)

        it "should load test data":
            let dataset = data.CIFAR10Dataset(root="./test_data", train=false, download=false)

            # CIFAR-10 test set has 10,000 images
            spec.expect(dataset.num_samples).to_be(10000)

        it "should return correct image and label shapes":
            let dataset = data.CIFAR10Dataset(root="./test_data", train=true, download=false)

            let (image, label) = dataset[0]

            # CIFAR-10 images are 32x32 RGB (3 channels)
            spec.expect(image.shape()[0]).to_be(3)   # channels
            spec.expect(image.shape()[1]).to_be(32)  # height
            spec.expect(image.shape()[2]).to_be(32)  # width

            # Label is a single value (0-9)
            spec.expect(label.numel()).to_be(1)

        it "should have 10 classes":
            let dataset = data.CIFAR10Dataset(root="./test_data", train=true, download=false)

            # CIFAR-10 has 10 classes
            let class_names = dataset.classes()
            spec.expect(class_names.len()).to_be(10)

        it "should support indexing":
            let dataset = data.CIFAR10Dataset(root="./test_data", train=true, download=false)

            # Get samples
            let (img0, lbl0) = dataset[0]
            let (img100, lbl100) = dataset[100]

            spec.expect(img0.numel()).to_be(3 * 32 * 32)
            spec.expect(img100.numel()).to_be(3 * 32 * 32)

        it "should apply transform if provided":
            fn normalize_rgb(x: torch.Tensor) -> torch.Tensor:
                # Normalize RGB channels to [-1, 1]
                return (x - 0.5) * 2.0

            let dataset = data.CIFAR10Dataset(root="./test_data", train=true, transform=normalize_rgb, download=false)

            let (image, label) = dataset[0]

            # After normalization, values should be in [-1, 1]
            spec.expect(image.min().item()).to_be_greater_than_or_equal(-1.1)
            spec.expect(image.max().item()).to_be_less_than_or_equal(1.1)

    describe "DataLoader":
        it "should create DataLoader with default parameters":
            let dataset = data.MNISTDataset(root="./test_data", download=false)
            let loader = data.DataLoader(dataset, batch_size=32)

            spec.expect(loader.batch_size).to_be(32)
            spec.expect(loader.shuffle).to_be(false)

        it "should batch samples correctly":
            let dataset = data.MNISTDataset(root="./test_data", train=true, download=false)
            let loader = data.DataLoader(dataset, batch_size=64)

            # Get first batch
            let (images, labels) = loader.next()

            # Batch should have 64 samples
            spec.expect(images.shape()[0]).to_be(64)
            spec.expect(labels.shape()[0]).to_be(64)

            # Each image should be 28x28
            spec.expect(images.shape()[1]).to_be(28)
            spec.expect(images.shape()[2]).to_be(28)

        it "should support shuffling":
            let dataset = data.MNISTDataset(root="./test_data", train=true, download=false)

            # Create two loaders with different shuffle settings
            let loader_no_shuffle = data.DataLoader(dataset, batch_size=10, shuffle=false)
            let loader_shuffle = data.DataLoader(dataset, batch_size=10, shuffle=true)

            # Get first batch from each
            let (imgs_no_shuffle, lbls_no_shuffle) = loader_no_shuffle.next()
            let (imgs_shuffle, lbls_shuffle) = loader_shuffle.next()

            # Both should have same batch size
            spec.expect(imgs_no_shuffle.shape()[0]).to_be(10)
            spec.expect(imgs_shuffle.shape()[0]).to_be(10)

        it "should iterate through entire dataset":
            let dataset = data.MNISTDataset(root="./test_data", train=true, download=false)
            let loader = data.DataLoader(dataset, batch_size=100)

            let mut num_batches = 0
            let mut total_samples = 0

            for (images, labels) in loader:
                num_batches = num_batches + 1
                total_samples = total_samples + images.shape()[0]

            # Should have 600 batches (60,000 / 100)
            spec.expect(num_batches).to_be(600)
            spec.expect(total_samples).to_be(60000)

        it "should handle partial batches at end":
            let dataset = data.MNISTDataset(root="./test_data", train=true, download=false)

            # Use batch size that doesn't divide evenly
            let loader = data.DataLoader(dataset, batch_size=128, drop_last=false)

            let mut last_batch_size = 0
            for (images, labels) in loader:
                last_batch_size = images.shape()[0]

            # Last batch should be smaller (60,000 % 128 = 96)
            spec.expect(last_batch_size).to_be(96)

        it "should drop last incomplete batch if requested":
            let dataset = data.MNISTDataset(root="./test_data", train=true, download=false)
            let loader = data.DataLoader(dataset, batch_size=128, drop_last=true)

            let mut num_batches = 0
            for (images, labels) in loader:
                num_batches = num_batches + 1
                # Every batch should be full size
                spec.expect(images.shape()[0]).to_be(128)

            # Should have 468 full batches (60,000 / 128 = 468.75, drop last)
            spec.expect(num_batches).to_be(468)

        it "should support multiple workers":
            let dataset = data.MNISTDataset(root="./test_data", train=true, download=false)
            let loader = data.DataLoader(dataset, batch_size=32, num_workers=4)

            spec.expect(loader.num_workers).to_be(4)

            # Should still load correctly with multiple workers
            let (images, labels) = loader.next()
            spec.expect(images.shape()[0]).to_be(32)

    describe "Sampling Strategies":
        it "should support sequential sampling":
            let dataset = data.MNISTDataset(root="./test_data", train=true, download=false)
            let sampler = data.SequentialSampler(dataset)

            # Sequential sampler should produce indices in order
            let indices = []
            for i in range(10):
                indices.append(sampler.next())

            # Should be [0, 1, 2, ..., 9]
            for i in range(10):
                spec.expect(indices[i]).to_be(i)

        it "should support random sampling":
            let dataset = data.MNISTDataset(root="./test_data", train=true, download=false)
            let sampler = data.RandomSampler(dataset)

            # Random sampler should produce random indices
            let indices = []
            for i in range(100):
                indices.append(sampler.next())

            # All indices should be valid
            for idx in indices:
                spec.expect(idx).to_be_greater_than_or_equal(0)
                spec.expect(idx).to_be_less_than(dataset.num_samples)

        it "should support custom sampler":
            let dataset = data.MNISTDataset(root="./test_data", train=true, download=false)

            # Define custom sampler that only samples even indices
            class EvenSampler:
                dataset: any
                current: i64

                fn __init__(self, dataset: any):
                    self.dataset = dataset
                    self.current = 0

                fn __len__(self) -> i64:
                    return self.dataset.num_samples / 2

                fn next(self) -> i64:
                    let idx = self.current
                    self.current = self.current + 2
                    return idx

            let even_sampler = EvenSampler(dataset)
            let loader = data.DataLoader(dataset, batch_size=10, sampler=even_sampler)

            let (images, labels) = loader.next()
            spec.expect(images.shape()[0]).to_be(10)

    describe "Training with DataLoader":
        it "should work in training loop":
            import ml.torch.optim as optim

            # Create simple model
            let model = nn.Linear(28 * 28, 10)
            let optimizer = optim.SGD(model.parameters(), lr=0.01)

            # Create dataset and loader
            let dataset = data.MNISTDataset(root="./test_data", train=true, download=false)
            let loader = data.DataLoader(dataset, batch_size=32, shuffle=true)

            # Train for one batch
            let (images, labels) = loader.next()

            # Flatten images
            let flat_images = images.reshape([32, 28 * 28])

            # Forward pass
            let outputs = model(flat_images)
            spec.expect(outputs.shape()[0]).to_be(32)
            spec.expect(outputs.shape()[1]).to_be(10)

        it "should support validation and test splits":
            # Training set
            let train_dataset = data.MNISTDataset(root="./test_data", train=true, download=false)
            let train_loader = data.DataLoader(train_dataset, batch_size=64, shuffle=true)

            # Test set
            let test_dataset = data.MNISTDataset(root="./test_data", train=false, download=false)
            let test_loader = data.DataLoader(test_dataset, batch_size=64, shuffle=false)

            spec.expect(train_loader.dataset.num_samples).to_be(60000)
            spec.expect(test_loader.dataset.num_samples).to_be(10000)

    describe "Data augmentation":
        it "should support custom transforms":
            # Define augmentation pipeline
            class AugmentPipeline:
                fn __call__(self, x: torch.Tensor) -> torch.Tensor:
                    # Normalize
                    let normalized = (x - 0.5) * 2.0

                    # Add small random noise
                    let noise = torch.randn(x.shape()) * 0.01
                    return normalized + noise

            let transform = AugmentPipeline()
            let dataset = data.MNISTDataset(root="./test_data", train=true, transform=transform, download=false)

            let (image, label) = dataset[0]

            # Image should be transformed
            spec.expect(image.mean().item()).to_not_be_close_to(0.5, 0.1)

        it "should support chained transforms":
            # Define multiple transforms
            class Normalize:
                fn __call__(self, x: torch.Tensor) -> torch.Tensor:
                    return (x - 0.5) * 2.0

            class AddNoise:
                fn __call__(self, x: torch.Tensor) -> torch.Tensor:
                    let noise = torch.randn(x.shape()) * 0.01
                    return x + noise

            class Compose:
                transforms: list

                fn __init__(self, transforms: list):
                    self.transforms = transforms

                fn __call__(self, x: torch.Tensor) -> torch.Tensor:
                    let mut result = x
                    for transform in self.transforms:
                        result = transform(result)
                    return result

            let pipeline = Compose([Normalize(), AddNoise()])
            let dataset = data.MNISTDataset(root="./test_data", train=true, transform=pipeline, download=false)

            let (image, label) = dataset[0]
            spec.expect(image.numel()).to_be(28 * 28)
