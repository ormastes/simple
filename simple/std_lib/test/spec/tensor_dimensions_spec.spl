# ============================================================================
# Tensor Dimension Inference Specification
# ============================================================================
#
# Status: Complete
# Feature IDs: #193
# Keywords: tensors, dimensions, shape, inference, types, verification, machine-learning
# Topics: data-structures, type-system, verification
#
# Overview:
#   Compile-time dimension tracking for N-dimensional tensors with:
#   - Exact dimensions (Dim.Literal(10))
#   - Named dimensions with ranges (Dim.Named("batch", 1, 64))
#   - Dynamic dimensions (Dim.Dynamic)
#   - Broadcast semantics (Dim.Broadcast)
#
#   Enables shape inference through operations (matmul, reshape, broadcast) with
#   compile-time verification and runtime memory estimation.
#
# Specification:
#
#   Dimension Types:
#     1. Literal: Exact known size (Dim.Literal(784))
#     2. Named: Dimension with name and range constraint (Dim.Named("batch", 1, 64))
#     3. Variable: Unbound type variable for inference (Dim.Var(id))
#     4. Dynamic: Matches any size (Dim.Dynamic)
#     5. Broadcast: Size-1 dimension that broadcasts (Dim.Broadcast)
#
#   Unification Rules:
#     - Literal(n) ∪ Literal(n) → Literal(n)
#     - Literal(n) ∪ Literal(m) → Error (n ≠ m)
#     - Named("x", a, b) ∪ Named("x", c, d) → Named("x", max(a,c), min(b,d))
#     - Broadcast ∪ Literal(n) → Literal(n)
#     - Dynamic ∪ d → d
#
#   Shape Inference Operations:
#     1. Matmul: [M, K] @ [K, N] → [M, N]
#        - Unifies contraction dimension K
#        - Preserves outer dimensions M, N
#     2. Broadcast: [A₁, A₂, ...] + [B₁, B₂, ...] → [max(A₁, B₁), ...]
#        - Aligns dimensions right-to-left
#        - Size-1 dimensions broadcast to any size
#     3. Reshape: [∏ dims_in] → [∏ dims_out]
#        - Verifies element count equality
#        - Supports inferred dimension (-1)
#     4. Reduction: [D₁, ..., Dᵢ, ...] → [D₁, ..., Dᵢ₋₁, Dᵢ₊₁, ...]
#        - Removes reduced dimension
#        - Optional keepdim preserves dimension as size 1
#
#   Memory Estimation:
#     For dimension d:
#       - Literal(n): min = max = n
#       - Named("x", lo, hi): min = lo, max = hi
#       - Dynamic: min = 1, max = ∞
#     Total memory: ∏(dims) × dtype_size (in bytes)
#
# Examples:
#   Basic Matmul:
#     [4, 8] @ [8, 16] → [4, 16]
#
#   MNIST Neural Network:
#     Input:  [batch:1..64, 784]
#     W1:     [784, 256]
#     H1:     [batch:1..64, 256]  ← inferred
#     W2:     [256, 10]
#     Output: [batch:1..64, 10]   ← inferred
#
#   Error Detection:
#     [batch:1..64, 784] @ [512, 10]  → ShapeError (Expected 784)
#
# Related Specifications:
#   - Tensor Literals (#192) - Creating and initializing tensors
#   - Type Inference (#8-9) - Type inference system
#   - Match Expressions (#90) - Pattern matching for error handling
#
# ============================================================================

import std.spec
import ml.torch.typed_tensor.{TypedTensor, TensorType, DimSpec, zeros, ones, randn}
import ml.torch.dtype.{DType}
import ml.torch.device.{Device}
import verification.models.tensor_dimensions.{Dim, TensorShape, DimInferenceContext, ShapeError, unify_dims, unify_shapes, infer_matmul_shape, infer_broadcast_shape}

# ============================================================================
# Dimension Inference Tests
# ============================================================================

describe "Dimension Inference":

    describe "Literal Dimensions":
        it "should unify same literals":
            var ctx = DimInferenceContext.new()
            val d1 = Dim.Literal(value: 10)
            val d2 = Dim.Literal(value: 10)
            val result = unify_dims(ctx, d1, d2)
            expect result.is_ok()
            expect result.unwrap() == Dim.Literal(value: 10)

        it "should fail on different literals":
            var ctx = DimInferenceContext.new()
            val d1 = Dim.Literal(value: 10)
            val d2 = Dim.Literal(value: 20)
            val result = unify_dims(ctx, d1, d2)
            expect result.is_err()

    describe "Variable Dimensions":
        it "should bind variable to literal":
            var ctx = DimInferenceContext.new()
            val var_dim = ctx.fresh_var()
            val literal = Dim.Literal(value: 32)
            val result = unify_dims(ctx, var_dim, literal)
            expect result.is_ok()
            expect result.unwrap() == Dim.Literal(value: 32)

        it "should bind two variables":
            var ctx = DimInferenceContext.new()
            val v1 = ctx.fresh_var()
            val v2 = ctx.fresh_var()
            val result = unify_dims(ctx, v1, v2)
            expect result.is_ok()

    describe "Named Dimensions":
        it "should unify same named dimensions":
            var ctx = DimInferenceContext.new()
            val d1 = Dim.Named(name: "batch", range: Some((1, 64)))
            val d2 = Dim.Named(name: "batch", range: Some((1, 32)))
            val result = unify_dims(ctx, d1, d2)
            expect result.is_ok()
            # Range intersection: (1, 32)

        it "should bind named to literal":
            var ctx = DimInferenceContext.new()
            val named = Dim.Named(name: "batch", range: Some((1, 64)))
            val literal = Dim.Literal(value: 32)
            val result = unify_dims(ctx, named, literal)
            expect result.is_ok()
            expect result.unwrap() == Dim.Literal(value: 32)

        it "should fail when literal out of range":
            var ctx = DimInferenceContext.new()
            val named = Dim.Named(name: "batch", range: Some((1, 64)))
            val literal = Dim.Literal(value: 128)
            val result = unify_dims(ctx, named, literal)
            expect result.is_err()

    describe "Dynamic Dimensions":
        it "should match anything":
            var ctx = DimInferenceContext.new()
            val dynamic = Dim.Dynamic
            val literal = Dim.Literal(value: 100)
            val result = unify_dims(ctx, dynamic, literal)
            expect result.is_ok()
            expect result.unwrap() == Dim.Literal(value: 100)

    describe "Broadcast Dimensions":
        it "should broadcast 1 to any size":
            var ctx = DimInferenceContext.new()
            val bcast = Dim.Broadcast
            val literal = Dim.Literal(value: 64)
            val result = unify_dims(ctx, bcast, literal)
            expect result.is_ok()
            expect result.unwrap() == Dim.Literal(value: 64)

# ============================================================================
# Shape Inference Tests
# ============================================================================

describe "Shape Inference":

    describe "Shape Unification":
        it "should unify same shapes":
            var ctx = DimInferenceContext.new()
            val s1 = TensorShape.from_literals([2, 3, 4])
            val s2 = TensorShape.from_literals([2, 3, 4])
            val result = unify_shapes(ctx, s1, s2)
            expect result.is_ok()
            expect result.unwrap().ndim() == 3

        it "should fail on rank mismatch":
            var ctx = DimInferenceContext.new()
            val s1 = TensorShape.from_literals([2, 3])
            val s2 = TensorShape.from_literals([2, 3, 4])
            val result = unify_shapes(ctx, s1, s2)
            expect result.is_err()

    describe "Matmul Shape":
        it "should infer 2D matmul shape":
            var ctx = DimInferenceContext.new()
            val left = TensorShape.from_literals([2, 3])   # [M=2, K=3]
            val right = TensorShape.from_literals([3, 4])  # [K=3, N=4]
            val result = infer_matmul_shape(ctx, left, right)
            expect result.is_ok()
            val output = result.unwrap()
            expect output.ndim() == 2
            # Should be [2, 4]

        it "should fail on incompatible K dimensions":
            var ctx = DimInferenceContext.new()
            val left = TensorShape.from_literals([2, 3])   # [M=2, K=3]
            val right = TensorShape.from_literals([5, 4])  # [K=5, N=4] - mismatch!
            val result = infer_matmul_shape(ctx, left, right)
            expect result.is_err()

        it "should infer matmul with named dimensions":
            var ctx = DimInferenceContext.new()
            val left = TensorShape(dims: [
                Dim.Named(name: "batch", range: Some((1, 64))),
                Dim.Literal(value: 128)
            ])
            val right = TensorShape(dims: [
                Dim.Literal(value: 128),
                Dim.Literal(value: 256)
            ])
            val result = infer_matmul_shape(ctx, left, right)
            expect result.is_ok()

    describe "Broadcast Shape":
        it "should broadcast scalar to matrix":
            var ctx = DimInferenceContext.new()
            val scalar = TensorShape.from_literals([])
            val matrix = TensorShape.from_literals([3, 4])
            val result = infer_broadcast_shape(ctx, [scalar, matrix])
            expect result.is_ok()
            expect result.unwrap().ndim() == 2

        it "should broadcast [1, 4] with [3, 1]":
            var ctx = DimInferenceContext.new()
            val s1 = TensorShape.from_literals([1, 4])
            val s2 = TensorShape.from_literals([3, 1])
            val result = infer_broadcast_shape(ctx, [s1, s2])
            expect result.is_ok()
            # Should be [3, 4]

        it "should fail on incompatible broadcast":
            var ctx = DimInferenceContext.new()
            val s1 = TensorShape.from_literals([2, 4])
            val s2 = TensorShape.from_literals([3, 4])
            val result = infer_broadcast_shape(ctx, [s1, s2])
            expect result.is_err()

# ============================================================================
# Typed Tensor Tests
# ============================================================================

describe "TypedTensor":

    describe "Creation":
        it "should create zeros with exact dimensions":
            val t = TypedTensor.zeros([
                DimSpec.exact(2),
                DimSpec.exact(3)
            ])
            expect t.ndim() == 2
            expect t.actual_shape() == [2, 3]

        it "should create randn with named dimensions":
            val t = TypedTensor.randn([
                DimSpec.named("batch", 32),
                DimSpec.named("features", 128)
            ])
            expect t.ndim() == 2

        it "should create with range constraints":
            val t = TypedTensor.zeros([
                DimSpec.ranged("batch", 16, 1, 64),
                DimSpec.exact(784)
            ])
            expect t.verify().is_ok()

    describe "Operations with Inference":
        it "should infer matmul output shape":
            val a = TypedTensor.randn([
                DimSpec.exact(4),
                DimSpec.exact(8)
            ])
            val b = TypedTensor.randn([
                DimSpec.exact(8),
                DimSpec.exact(16)
            ])
            val result = a.matmul(b)
            expect result.is_ok()
            val c = result.unwrap()
            expect c.ndim() == 2
            # Shape should be [4, 16]

        it "should fail matmul on shape mismatch":
            val a = TypedTensor.randn([DimSpec.exact(4), DimSpec.exact(8)])
            val b = TypedTensor.randn([DimSpec.exact(10), DimSpec.exact(16)])  # K mismatch
            val result = a.matmul(b)
            expect result.is_err()

        it "should infer broadcast add shape":
            val a = TypedTensor.randn([DimSpec.exact(3), DimSpec.exact(4)])
            val b = TypedTensor.randn([DimSpec.exact(1), DimSpec.exact(4)])
            val result = a.add(b)
            expect result.is_ok()

        it "should infer reshape shape":
            val t = TypedTensor.randn([DimSpec.exact(4), DimSpec.exact(6)])
            val result = t.reshape([DimSpec.exact(2), DimSpec.exact(12)])
            expect result.is_ok()  # 4*6 = 2*12 = 24

        it "should fail reshape on element count mismatch":
            val t = TypedTensor.randn([DimSpec.exact(4), DimSpec.exact(6)])
            val result = t.reshape([DimSpec.exact(2), DimSpec.exact(10)])
            # 4*6=24, 2*10=20, should fail

    describe "Reduction Operations":
        it "should infer sum shape":
            val t = TypedTensor.randn([DimSpec.exact(3), DimSpec.exact(4)])
            val result = t.sum(dim: 1)
            expect result.is_ok()
            val s = result.unwrap()
            expect s.ndim() == 1  # [3]

        it "should infer sum with keepdim":
            val t = TypedTensor.randn([DimSpec.exact(3), DimSpec.exact(4)])
            val result = t.sum(dim: 1, keepdim: True)
            expect result.is_ok()
            val s = result.unwrap()
            expect s.ndim() == 2  # [3, 1]

# ============================================================================
# Memory Estimation Tests
# ============================================================================

describe "Memory Estimation":

    describe "TensorType Memory":
        it "should estimate memory for exact dimensions":
            val tt = TensorType.new([
                DimSpec.exact(64),
                DimSpec.exact(256)
            ], DType.Float32)
            val mem = tt.min_memory_bytes()
            expect mem == 64 * 256 * 4  # 65536 bytes

        it "should estimate memory range for ranged dimensions":
            val tt = TensorType.new([
                DimSpec.ranged("batch", 32, 1, 64),
                DimSpec.exact(256)
            ], DType.Float32)
            val min_mem = tt.min_memory_bytes()
            val max_mem = tt.max_memory_bytes()
            expect min_mem == 1 * 256 * 4     # 1024 bytes
            expect max_mem == 64 * 256 * 4    # 65536 bytes

# ============================================================================
# Multi-Dimensional Inference Tests
# ============================================================================

describe "Multi-Dimensional Inference":

    describe "3D Tensor Operations":
        it "should infer batch matmul shape":
            # [B, M, K] @ [B, K, N] -> [B, M, N]
            var ctx = DimInferenceContext.new()
            val left = TensorShape(dims: [
                Dim.Named(name: "batch", range: Some((1, 32))),
                Dim.Literal(value: 4),
                Dim.Literal(value: 8)
            ])
            val right = TensorShape(dims: [
                Dim.Named(name: "batch", range: Some((1, 32))),
                Dim.Literal(value: 8),
                Dim.Literal(value: 16)
            ])
            val result = infer_matmul_shape(ctx, left, right)
            expect result.is_ok()

    describe "4D Tensor Operations (CNN)":
        it "should handle NCHW format":
            # Typical CNN input: [N, C, H, W]
            val input_shape = TensorShape(dims: [
                Dim.Named(name: "batch", range: Some((1, 128))),
                Dim.Literal(value: 3),    # RGB
                Dim.Literal(value: 224),  # Height
                Dim.Literal(value: 224)   # Width
            ])
            expect input_shape.ndim() == 4
            expect input_shape.is_concrete() == False  # Has named dim with range

    describe "Transformer Dimensions":
        it "should infer attention shape":
            # Q: [B, H, S, D], K: [B, H, S, D] -> QK^T: [B, H, S, S]
            var ctx = DimInferenceContext.new()
            val batch = Dim.Named(name: "batch", range: Some((1, 64)))
            val heads = Dim.Literal(value: 12)
            val seq = Dim.Named(name: "seq", range: Some((1, 512)))
            val head_dim = Dim.Literal(value: 64)

            val q_shape = TensorShape(dims: [batch, heads, seq, head_dim])
            val k_shape = TensorShape(dims: [batch, heads, seq, head_dim])

            # For attention, we do Q @ K^T
            # This requires more complex shape manipulation (transpose K)
            expect q_shape.ndim() == 4
            expect k_shape.ndim() == 4

    describe "Chain of Operations":
        it "should propagate dimensions through chain":
            var ctx = DimInferenceContext.new()

            # Input: [B=32, 784]
            val input = TensorShape(dims: [
                Dim.Named(name: "batch", range: Some((1, 64))),
                Dim.Literal(value: 784)
            ])

            # Layer 1: [784, 256]
            val w1 = TensorShape.from_literals([784, 256])

            # After matmul: [B, 256]
            val h1_result = infer_matmul_shape(ctx, input, w1)
            expect h1_result.is_ok()
            val h1 = h1_result.unwrap()
            expect h1.ndim() == 2

            # Layer 2: [256, 128]
            val w2 = TensorShape.from_literals([256, 128])

            # After matmul: [B, 128]
            val h2_result = infer_matmul_shape(ctx, h1, w2)
            expect h2_result.is_ok()
            val h2 = h2_result.unwrap()
            expect h2.ndim() == 2

            # Final: [128, 10]
            val w3 = TensorShape.from_literals([128, 10])

            # After matmul: [B, 10]
            val output_result = infer_matmul_shape(ctx, h2, w3)
            expect output_result.is_ok()
            val output = output_result.unwrap()
            expect output.ndim() == 2
