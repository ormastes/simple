#!/usr/bin/env simple
# Standalone ML Tensor Test Program
# Tests PyTorch tensor operations without spec DSL

import ml.torch as torch

fn test_device_management():
    print("Testing device management...")

    # Check CUDA availability
    let cuda_available = torch.cuda_available()
    print("  CUDA available: {cuda_available}")

    # Get device count
    let device_count = torch.cuda_device_count()
    print("  CUDA devices: {device_count}")
    assert device_count >= 0, "Device count should be non-negative"
    print("  ✓ Device management works")

fn test_tensor_creation():
    print("Testing tensor creation...")

    # Zeros tensor
    let zeros = torch.zeros([2, 3])
    let shape = zeros.shape()
    assert shape[0] == 2, "Zeros tensor should have shape[0] = 2"
    assert shape[1] == 3, "Zeros tensor should have shape[1] = 3"
    assert zeros.numel() == 6, "Zeros tensor should have 6 elements"
    print("  ✓ zeros() works")

    # Ones tensor
    let ones = torch.ones([3, 4])
    let ones_shape = ones.shape()
    assert ones_shape[0] == 3, "Ones tensor should have shape[0] = 3"
    assert ones_shape[1] == 4, "Ones tensor should have shape[1] = 4"
    assert ones.numel() == 12, "Ones tensor should have 12 elements"
    print("  ✓ ones() works")

    # Randn tensor
    let randn = torch.randn([5, 5])
    let randn_shape = randn.shape()
    assert randn_shape[0] == 5, "Randn tensor should have shape[0] = 5"
    assert randn_shape[1] == 5, "Randn tensor should have shape[1] = 5"
    assert randn.numel() == 25, "Randn tensor should have 25 elements"
    print("  ✓ randn() works")

    # Arange tensor
    let arange = torch.arange(0, 10, 1)
    assert arange.numel() == 10, "Arange tensor should have 10 elements"
    print("  ✓ arange() works")

fn test_arithmetic_operations():
    print("Testing arithmetic operations...")

    # Addition
    let a = torch.ones([2, 2])
    let b = torch.ones([2, 2])
    let c = a + b
    let c_shape = c.shape()
    assert c_shape[0] == 2, "Sum tensor should have shape[0] = 2"
    assert c_shape[1] == 2, "Sum tensor should have shape[1] = 2"
    print("  ✓ Addition works")

    # Subtraction
    let d = a - b
    let d_shape = d.shape()
    assert d_shape[0] == 2, "Diff tensor should have shape[0] = 2"
    assert d_shape[1] == 2, "Diff tensor should have shape[1] = 2"
    print("  ✓ Subtraction works")

    # Element-wise multiplication
    let e = torch.ones([3, 3])
    let f = torch.ones([3, 3])
    let g = e * f
    let g_shape = g.shape()
    assert g_shape[0] == 3, "Product tensor should have shape[0] = 3"
    assert g_shape[1] == 3, "Product tensor should have shape[1] = 3"
    print("  ✓ Element-wise multiplication works")

    # Matrix multiplication
    let h = torch.randn([4, 6])
    let i = torch.randn([6, 8])
    let j = h @ i
    let j_shape = j.shape()
    assert j_shape[0] == 4, "Matmul result should have shape[0] = 4"
    assert j_shape[1] == 8, "Matmul result should have shape[1] = 8"
    print("  ✓ Matrix multiplication works")

fn test_shape_operations():
    print("Testing shape operations...")

    # Reshape
    let t = torch.randn([2, 6])
    let reshaped = t.reshape([3, 4])
    let reshaped_shape = reshaped.shape()
    assert reshaped_shape[0] == 3, "Reshaped tensor should have shape[0] = 3"
    assert reshaped_shape[1] == 4, "Reshaped tensor should have shape[1] = 4"
    assert reshaped.numel() == 12, "Reshaped tensor should have 12 elements"
    print("  ✓ Reshape works")

    # Transpose
    let t2 = torch.randn([3, 5])
    let transposed = t2.transpose(0, 1)
    let t_shape = transposed.shape()
    assert t_shape[0] == 5, "Transposed tensor should have shape[0] = 5"
    assert t_shape[1] == 3, "Transposed tensor should have shape[1] = 3"
    print("  ✓ Transpose works")

fn test_device_transfer():
    print("Testing device transfer...")

    # To CPU
    let t = torch.randn([10, 10])
    let cpu_t = t.to_cpu()
    let cpu_shape = cpu_t.shape()
    assert cpu_shape[0] == 10, "CPU tensor should have shape[0] = 10"
    assert cpu_shape[1] == 10, "CPU tensor should have shape[1] = 10"
    print("  ✓ CPU transfer works")

    # To CUDA (if available)
    let cuda_available = torch.cuda_available()
    if cuda_available:
        let gpu_t = t.to_cuda(0)
        let gpu_shape = gpu_t.shape()
        assert gpu_shape[0] == 10, "GPU tensor should have shape[0] = 10"
        assert gpu_shape[1] == 10, "GPU tensor should have shape[1] = 10"
        print("  ✓ CUDA transfer works")
    else:
        print("  ⊘ CUDA not available, skipping GPU tests")

fn test_data_access():
    print("Testing data access...")

    # Clone
    let t = torch.randn([5, 5])
    let cloned = t.clone()
    assert cloned.numel() == t.numel(), "Cloned tensor should have same number of elements"
    print("  ✓ Clone works")

fn main():
    print("=== ML Tensor Test Suite ===\n")

    test_device_management()
    test_tensor_creation()
    test_arithmetic_operations()
    test_shape_operations()
    test_device_transfer()
    test_data_access()

    print("\n✅ All ML tensor tests passed!")
    return 0
