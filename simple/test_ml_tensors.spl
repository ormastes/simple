#!/usr/bin/env simple
# Standalone ML Tensor Test Program
# Tests PyTorch tensor operations without spec DSL

import ml.torch as torch

fn test_device_management():
    print("Testing device management...")

    # Check CUDA availability
    val cuda_available = torch.cuda_available()
    print("  CUDA available: {cuda_available}")

    # Get device count
    val device_count = torch.cuda_device_count()
    print("  CUDA devices: {device_count}")
    assert device_count >= 0, "Device count should be non-negative"
    print("  ✓ Device management works")

fn test_tensor_creation():
    print("Testing tensor creation...")

    # Zeros tensor
    val zeros = torch.zeros([2, 3])
    val shape = zeros.shape()
    assert shape[0] == 2, "Zeros tensor should have shape[0] = 2"
    assert shape[1] == 3, "Zeros tensor should have shape[1] = 3"
    assert zeros.numel() == 6, "Zeros tensor should have 6 elements"
    print("  ✓ zeros() works")

    # Ones tensor
    val ones = torch.ones([3, 4])
    val ones_shape = ones.shape()
    assert ones_shape[0] == 3, "Ones tensor should have shape[0] = 3"
    assert ones_shape[1] == 4, "Ones tensor should have shape[1] = 4"
    assert ones.numel() == 12, "Ones tensor should have 12 elements"
    print("  ✓ ones() works")

    # Randn tensor
    val randn = torch.randn([5, 5])
    val randn_shape = randn.shape()
    assert randn_shape[0] == 5, "Randn tensor should have shape[0] = 5"
    assert randn_shape[1] == 5, "Randn tensor should have shape[1] = 5"
    assert randn.numel() == 25, "Randn tensor should have 25 elements"
    print("  ✓ randn() works")

    # Arange tensor
    val arange = torch.arange(0, 10, 1)
    assert arange.numel() == 10, "Arange tensor should have 10 elements"
    print("  ✓ arange() works")

fn test_arithmetic_operations():
    print("Testing arithmetic operations...")

    # Addition
    val a = torch.ones([2, 2])
    val b = torch.ones([2, 2])
    val c = a + b
    val c_shape = c.shape()
    assert c_shape[0] == 2, "Sum tensor should have shape[0] = 2"
    assert c_shape[1] == 2, "Sum tensor should have shape[1] = 2"
    print("  ✓ Addition works")

    # Subtraction
    val d = a - b
    val d_shape = d.shape()
    assert d_shape[0] == 2, "Diff tensor should have shape[0] = 2"
    assert d_shape[1] == 2, "Diff tensor should have shape[1] = 2"
    print("  ✓ Subtraction works")

    # Element-wise multiplication
    val e = torch.ones([3, 3])
    val f = torch.ones([3, 3])
    val g = e * f
    val g_shape = g.shape()
    assert g_shape[0] == 3, "Product tensor should have shape[0] = 3"
    assert g_shape[1] == 3, "Product tensor should have shape[1] = 3"
    print("  ✓ Element-wise multiplication works")

    # Matrix multiplication
    val h = torch.randn([4, 6])
    val i = torch.randn([6, 8])
    val j = h @ i
    val j_shape = j.shape()
    assert j_shape[0] == 4, "Matmul result should have shape[0] = 4"
    assert j_shape[1] == 8, "Matmul result should have shape[1] = 8"
    print("  ✓ Matrix multiplication works")

fn test_shape_operations():
    print("Testing shape operations...")

    # Reshape
    val t = torch.randn([2, 6])
    val reshaped = t.reshape([3, 4])
    val reshaped_shape = reshaped.shape()
    assert reshaped_shape[0] == 3, "Reshaped tensor should have shape[0] = 3"
    assert reshaped_shape[1] == 4, "Reshaped tensor should have shape[1] = 4"
    assert reshaped.numel() == 12, "Reshaped tensor should have 12 elements"
    print("  ✓ Reshape works")

    # Transpose
    val t2 = torch.randn([3, 5])
    val transposed = t2.transpose(0, 1)
    val t_shape = transposed.shape()
    assert t_shape[0] == 5, "Transposed tensor should have shape[0] = 5"
    assert t_shape[1] == 3, "Transposed tensor should have shape[1] = 3"
    print("  ✓ Transpose works")

fn test_device_transfer():
    print("Testing device transfer...")

    # To CPU
    val t = torch.randn([10, 10])
    val cpu_t = t.to_cpu()
    val cpu_shape = cpu_t.shape()
    assert cpu_shape[0] == 10, "CPU tensor should have shape[0] = 10"
    assert cpu_shape[1] == 10, "CPU tensor should have shape[1] = 10"
    print("  ✓ CPU transfer works")

    # To CUDA (if available)
    val cuda_available = torch.cuda_available()
    if cuda_available:
        val gpu_t = t.to_cuda(0)
        val gpu_shape = gpu_t.shape()
        assert gpu_shape[0] == 10, "GPU tensor should have shape[0] = 10"
        assert gpu_shape[1] == 10, "GPU tensor should have shape[1] = 10"
        print("  ✓ CUDA transfer works")
    else:
        print("  ⊘ CUDA not available, skipping GPU tests")

fn test_data_access():
    print("Testing data access...")

    # Clone
    val t = torch.randn([5, 5])
    val cloned = t.clone()
    assert cloned.numel() == t.numel(), "Cloned tensor should have same number of elements"
    print("  ✓ Clone works")

fn main():
    print("=== ML Tensor Test Suite ===\n")

    test_device_management()
    test_tensor_creation()
    test_arithmetic_operations()
    test_shape_operations()
    test_device_transfer()
    test_data_access()

    print("\n✅ All ML tensor tests passed!")
    return 0
