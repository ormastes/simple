# CUDA Backend Tests
#
# Tests specific to CUDA backend functionality.
# These tests require NVIDIA CUDA to be available.

use std.gpu.*
use app.io.cuda_ffi.*

fn require_cuda():
    if not cuda_available():
        print "Skipping: CUDA not available"
        return

describe "CUDA Availability":
    it "checks CUDA availability":
        val available = cuda_available()
        assert available or not available

    @tag(skip: "requires_cuda")
    it "reports device count":
        require_cuda()
        val count = cuda_device_count()
        assert count > 0

describe "CUDA Device Selection":
    @tag(skip: "requires_cuda")
    it "sets and gets current device":
        require_cuda()
        assert cuda_set_device(0)
        assert cuda_get_device() == 0

    @tag(skip: "requires_cuda")
    it "gets device info":
        require_cuda()
        val info = cuda_device_info(0)
        assert info.name.len() > 0
        assert info.total_memory > 0

    @tag(skip: "requires_cuda")
    it "gets compute capability":
        require_cuda()
        val info = cuda_device_info(0)
        val (major, minor) = info.compute_capability
        assert major >= 1
        assert minor >= 0

describe "CUDA Memory Operations":
    @tag(skip: "requires_cuda")
    it "allocates CUDA memory":
        require_cuda()
        val ptr = cuda_alloc(1024)
        assert ptr.is_valid
        assert ptr.size == 1024
        assert cuda_free(ptr)

    @tag(skip: "requires_cuda")
    it "performs memset":
        require_cuda()
        val ptr = cuda_alloc(1024)
        assert cuda_memset(ptr, 0)
        cuda_free(ptr)

    @tag(skip: "requires_cuda")
    it "copies host to device":
        require_cuda()
        val ptr = cuda_alloc(16)
        val data: [u8] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
        assert cuda_copy_to_device(ptr, data)
        cuda_free(ptr)

    @tag(skip: "requires_cuda")
    it "copies device to host":
        require_cuda()
        val ptr = cuda_alloc(16)
        val src: [u8] = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160]
        cuda_copy_to_device(ptr, src)
        var dst: [u8] = []
        for i in 0..16:
            dst.push(0)
        assert cuda_copy_from_device(dst, ptr)
        cuda_free(ptr)

    @tag(skip: "requires_cuda")
    it "copies device to device":
        require_cuda()
        val src = cuda_alloc(1024)
        val dst = cuda_alloc(1024)
        assert cuda_copy_device_to_device(dst, src, 1024)
        cuda_free(src)
        cuda_free(dst)

describe "CUDA Kernel Compilation":
    @tag(skip: "requires_cuda")
    it "compiles PTX module":
        require_cuda()
        val ptx = VECTOR_ADD_PTX
        val module = cuda_compile(ptx)
        assert module.is_valid
        cuda_unload(module)

    @tag(skip: "requires_cuda")
    it "gets kernel function from module":
        require_cuda()
        val module = cuda_compile(VECTOR_ADD_PTX)
        assert module.is_valid
        val kfn = cuda_get_kernel(module, "vector_add")
        assert kfn.is_valid
        cuda_unload(module)

describe "CUDA Streams":
    @tag(skip: "requires_cuda")
    it "creates and destroys stream":
        require_cuda()
        val stream = cuda_stream_create()
        assert stream.is_valid
        assert cuda_stream_destroy(stream)

    @tag(skip: "requires_cuda")
    it "synchronizes stream":
        require_cuda()
        val stream = cuda_stream_create()
        assert cuda_stream_sync(stream)
        cuda_stream_destroy(stream)

describe "CUDA Error Handling":
    @tag(skip: "requires_cuda")
    it "gets last error":
        require_cuda()
        val error_text = cuda_last_error()
        assert true

    @tag(skip: "requires_cuda")
    it "peeks at error without clearing":
        require_cuda()
        val error_text = cuda_peek_error()
        assert true

describe "CUDA Synchronization":
    @tag(skip: "requires_cuda")
    it "synchronizes device":
        require_cuda()
        assert cuda_sync()

    @tag(skip: "requires_cuda")
    it "creates gpu_cuda device wrapper":
        require_cuda()
        val device = gpu_cuda(0)
        assert device.is_valid()
        assert device.backend_name() == "CUDA"
