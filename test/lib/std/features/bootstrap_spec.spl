# Bootstrap Self-Compile Specification
#
# Tests that the Simple compiler can compile itself.
# This is the ultimate test of compiler correctness.

# @skip
import compiler.*

describe "Bootstrap Self-Compilation":
    """
    The Simple compiler must be able to compile its own source code,
    producing an identical binary across generations.
    """

    background:
        # Ensure compiler modules are loaded
        val compiler_files = [
            "src/compiler/mod.spl",
            "src/compiler/lexer.spl",
            "src/compiler/treesitter.spl",
            "src/compiler/parser.spl",
            "src/compiler/hir.spl",
            "src/compiler/backend.spl",
            "src/compiler/mir.spl",
            "src/compiler/codegen.spl",
            "src/compiler/driver.spl",
            "src/compiler/main.spl"
        ]

    scenario "Lexer tokenizes compiler source":
        """
        The lexer must correctly tokenize its own source code.
        """
        given "the lexer source file":
            val source = rt_read_file("src/compiler/lexer.spl").unwrap()

        when "tokenizing the source":
            val lexer = Lexer.create(source)
            val tokens: [Token] = []
            var token = lexer.next_token()
            while token.kind != TokenKind.Eof:
                tokens.push(token)
                token = lexer.next_token()

        then "all tokens are valid":
            for t in tokens:
                assert t.kind != TokenKind.Error, "Invalid token at {t.span}"

        then "token count is reasonable":
            # Lexer has ~750 lines, should have many tokens
            assert tokens.len() > 1000, "Expected >1000 tokens, got {tokens.len()}"

    scenario "TreeSitter parses compiler outline":
        """
        TreeSitter must parse the outline of all compiler modules.
        """
        given "all compiler source files":
            val sources = compiler_files.map(\f: (f, rt_read_file(f).unwrap()))

        when "parsing outlines":
            val outlines: [(text, OutlineModule)] = []
            for (path, source) in sources:
                val lexer = Lexer.create(source)
                val ts = TreeSitter(lexer: lexer)
                val outline = ts.parse_outline()
                outlines.push((path, outline))

        then "all outlines have declarations":
            for (path, outline) in outlines:
                val decl_count = outline.functions.len() + outline.classes.len() + outline.structs.len() + outline.enums.len()
                assert decl_count > 0, "No declarations in {path}"

    scenario "Parser parses compiler AST":
        """
        The parser must parse its own source code into a valid AST.
        """
        given "the parser source file":
            val source = rt_read_file("src/compiler/parser.spl").unwrap()

        when "parsing full AST":
            val lexer = Lexer.create(source)
            val ts = TreeSitter(lexer: Lexer.create(source))
            val outline = ts.parse_outline()
            val parser = Parser(
                lexer: lexer,
                treesitter: ts,
                current: lexer.next_token(),
                outline: Some(outline)
            )
            val result = parser.parse()

        then "parsing succeeds":
            assert result.is_ok(), "Parse failed: {result.err()}"

        it "AST has expected structure":
            val module = result.unwrap()
            assert module.functions.len() > 10, "Expected >10 functions"

    scenario "HIR lowering succeeds for compiler":
        """
        All compiler modules must lower to valid HIR.
        """
        given "parsed compiler modules":
            val modules: Dict<text, Module> = {}
            for path in compiler_files:
                val source = rt_read_file(path).unwrap()
                val result = parse_source(source)
                if result.is_ok():
                    val name = path.split("/").last().unwrap().replace(".spl", "")
                    modules[name] = result.unwrap()

        when "lowering to HIR":
            val lowering = HirLowering()
            val hir_modules: Dict<text, HirModule> = {}
            val errors: [text] = []

            for (name, module) in modules:
                match lowering.lower_module(module):
                    Ok(hir) => hir_modules[name] = hir
                    Err(e) => errors.push("{name}: {e}")

        then "all modules lower successfully":
            assert errors.is_empty(), "HIR errors: {errors}"

        it "symbol tables are populated":
            for (name, hir) in hir_modules:
                assert hir.symbols.symbols.len() > 0, "Empty symbol table in {name}"

    scenario "MIR lowering succeeds for compiler":
        """
        All compiler HIR must lower to valid MIR.
        """
        given "HIR modules from compiler":
            # Setup (would normally come from previous stages)
            val hir_modules = compile_to_hir(compiler_files)

        when "lowering to MIR":
            val lowering = MirLowering()
            val mir_modules: Dict<text, MirModule> = {}
            val errors: [text] = []

            for (name, hir) in hir_modules:
                match lowering.lower_module(hir):
                    Ok(mir) => mir_modules[name] = mir
                    Err(e) => errors.push("{name}: {e}")

        then "all modules lower to MIR":
            assert errors.is_empty(), "MIR errors: {errors}"

        it "MIR functions have basic blocks":
            for (name, mir) in mir_modules:
                for fn_ in mir.functions.values():
                    assert fn_.blocks.len() > 0, "No blocks in {name}::{fn_.name}"

    scenario "Codegen produces valid output":
        """
        Code generation must succeed for the compiler.
        """
        tag slow

        given "MIR modules from compiler":
            val mir_modules = compile_to_mir(compiler_files)

        when "generating code":
            val codegen = Codegen()
            val errors: [text] = []

            for (name, mir) in mir_modules:
                for fn_ in mir.functions.values():
                    match codegen.generate(fn_):
                        Ok(_) => ()
                        Err(e) => errors.push("{name}::{fn_.name}: {e}")

        then "codegen succeeds for all functions":
            assert errors.is_empty(), "Codegen errors: {errors}"

    scenario "Full compilation pipeline":
        """
        The complete compilation pipeline must work.
        """
        tag slow

        given "compiler options for AOT":
            val options = CompileOptions(
                mode: CompileMode.Aot,
                input_files: compiler_files,
                output_file: Some("/tmp/simple-compiler-test"),
                optimize: false,
                debug_info: true,
                verbose: false,
                log_level: 4,
                profile: "test"
            )

        when "running full compilation":
            val driver = CompilerDriver.create(options)
            val result = driver.compile()

        then "compilation succeeds":
            assert result.is_success(), "Compilation failed: {result.get_errors()}"

    scenario "Generation equivalence (bootstrap)":
        """
        A compiler compiled by itself must produce identical output
        when compiling itself again.
        """
        tag slow
        tag bootstrap

        given "the bootstrap test function":
            ()

        when "running bootstrap test":
            val success = bootstrap_test()

        then "bootstrap succeeds":
            assert success, "Bootstrap test failed"

# ------------------------------------------------------------------------------
# Helper Functions
# ------------------------------------------------------------------------------

fn parse_source(source: text) -> Result<Module, text>:
    val lexer = Lexer.create(source)
    val ts = TreeSitter(lexer: Lexer.create(source))
    val outline = ts.parse_outline()
    val parser = Parser(
        lexer: lexer,
        treesitter: ts,
        current: lexer.next_token(),
        outline: Some(outline)
    )
    parser.parse()

fn compile_to_hir(files: [text]) -> Dict<text, HirModule>:
    val modules: Dict<text, Module> = {}

    for path in files:
        val source = rt_read_file(path)
        if source.is_some():
            val result = parse_source(source.unwrap())
            if result.is_ok():
                val name = path.split("/").last().unwrap().replace(".spl", "")
                modules[name] = result.unwrap()

    val lowering = HirLowering()
    val hir_modules: Dict<text, HirModule> = {}

    for (name, module) in modules:
        match lowering.lower_module(module):
            Ok(hir) => hir_modules[name] = hir
            Err(_) => ()

    hir_modules

fn compile_to_mir(files: [text]) -> Dict<text, MirModule>:
    val hir_modules = compile_to_hir(files)
    val lowering = MirLowering()
    val mir_modules: Dict<text, MirModule> = {}

    for (name, hir) in hir_modules:
        match lowering.lower_module(hir):
            Ok(mir) => mir_modules[name] = mir
            Err(_) => ()

    mir_modules
