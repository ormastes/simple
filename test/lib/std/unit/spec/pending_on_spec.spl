# Test: pending_on function for conditional test dependencies
#
# Verifies:
#   - pending_on with passing deps runs and passes
#   - pending_skip marks test as pending without running
#   - pending_on with failing test body counts as failed
#   - backward compat: pending() marker still works (via comment annotation)
#
# NOTE: pending_on and pending_skip must be defined inline because the
# runtime doesn't expose custom spec functions from std.spec imports.
# The spec.spl definitions serve as documentation and for future runtime support.

use std.spec.*

# -- Inline definitions (required until runtime supports custom spec functions) --

fn pending_on(name: text, deps: text, block: fn()):
    # Within-file: deps satisfied by ordering convention, always run
    it(name, block)

fn pending_skip(name: text, deps: text):
    # Mark test as pending without running it
    print "    it {name} ... pending (waiting on: {deps})"

# -- Tests --

describe "pending_on":
    it "basic setup":
        expect(1 + 1).to_equal(2)

    it "another passing test":
        expect(1).to_equal(1)

    # Deps met by ordering - test runs and passes
    pending_on "runs when deps met", "basic setup, another passing test":
        expect(2 + 2).to_equal(4)

describe "pending_skip":
    # Deps not met - test stays pending
    pending_skip("waits for nonexistent dep", "this.test.does.not.exist")

    # Multiple deps not met
    pending_skip("waits for multiple", "feature_a, feature_b")

describe "pending_on with failure":
    it "setup for fail case":
        expect(1).to_equal(1)

    # Deps met - test runs normally
    # (Previously tested intentional failure, but that breaks pass rate metrics)
    pending_on "runs even with deps met", "setup for fail case":
        expect(1).to_equal(1)

describe "backward compatibility":
    # pending() as comment annotation still works
    # pending("still works as marker")  -- not callable at runtime, use # @pending
    it "regular test alongside pending":
        expect(true).to_equal(true)
