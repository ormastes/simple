# Test Database Performance & Stress Tests
#
# Benchmarks and stress tests for the test database system:
# - Large test suites (10K+ records)
# - Many runs (500+ history)
# - String interning efficiency
# - Window capping performance
# - Statistics computation speed
# - File size growth tracking

use app.io.mod (getpid, file_exists, file_delete, file_size, time_now_unix_micros)
use app.test_runner_new.test_db_core (TestDatabase, micros_to_rfc3339)
use app.test_runner_new.test_db_types.*
use app.test_runner_new.test_stats (compute_statistics)
use string_interner.StringInterner

# =========================================================================
# Benchmarking Framework
# =========================================================================

struct BenchmarkResult:
    name: text
    iterations: i64
    total_ms: i64
    per_op_us: i64
    throughput_ops_sec: i64

fn benchmark(name: text, iterations: i64, fn_to_test: fn() -> ()) -> BenchmarkResult:
    val start = time_now_unix_micros()

    for i in 0..iterations:
        fn_to_test()

    val end = time_now_unix_micros()
    val duration_us = end - start
    val duration_ms = duration_us / 1000
    val per_op_us = if iterations > 0: duration_us / iterations else: 0
    val throughput = if duration_us > 0: (iterations * 1000000) / duration_us else: 0

    BenchmarkResult(
        name: name,
        iterations: iterations,
        total_ms: duration_ms,
        per_op_us: per_op_us,
        throughput_ops_sec: throughput
    )

fn print_benchmark(result: BenchmarkResult):
    print "Benchmark: {result.name}"
    print "  Iterations: {result.iterations}"
    print "  Total time: {result.total_ms}ms"
    print "  Per operation: {result.per_op_us}μs"
    print "  Throughput: {result.throughput_ops_sec} ops/sec"

# =========================================================================
# Helper Functions
# =========================================================================

fn temp_db_path(test_name: text) -> text:
    "/tmp/test_db_perf_{test_name}_{getpid()}.sdn"

fn cleanup_temp_db(test_name: text):
    val db_path = temp_db_path(test_name)
    if file_exists(db_path):
        file_delete(db_path)
    if file_exists("{db_path}.bak"):
        file_delete("{db_path}.bak")

fn create_large_db(test_count: i64) -> TestDatabase:
    val db = TestDatabase.empty()

    # Create test records
    for i in 0..test_count:
        val file_path = "test/suite_{i % 10}.spl"  # 10 unique paths
        val suite_name = "Suite {i % 20}"           # 20 unique suites
        val test_name = "test_{i}"
        val category = if i % 3 == 0: "unit" elif i % 3 == 1: "integration" else: "e2e"

        db.update_test_result(
            test_name: test_name,
            test_file: file_path,
            suite_name: suite_name,
            category: category,
            status: if i % 5 == 0: TestStatus.Failed else: TestStatus.Passed,
            duration_ms: (i % 100).to_float() + 10.0
        )

    db

# =========================================================================
# Tests
# =========================================================================

describe "Test Database Performance":

    describe "Large Test Suite":

        slow_it "loads 1000 test records in under 1 second":
            val test_name = "load_1k"
            cleanup_temp_db(test_name)

            # Create database with 1000 tests
            val db = create_large_db(1000)
            val save_result = db.save()
            expect(save_result.ok.?).to_be(true)

            # Benchmark load operation
            val result = benchmark("Load 1K tests", 1, \:
                val load_result = TestDatabase.load()
                expect(load_result.ok.?).to_be(true)
            )

            print_benchmark(result)

            # Should load in under 1 second (1000ms)
            expect(result.total_ms).to_be_less_than(1000)

            cleanup_temp_db(test_name)

        slow_it "saves 1000 test records in under 1 second":
            val test_name = "save_1k"
            cleanup_temp_db(test_name)

            # Create database with 1000 tests
            val db = create_large_db(1000)

            # Benchmark save operation
            val result = benchmark("Save 1K tests", 1, \:
                val save_result = db.save()
                expect(save_result.ok.?).to_be(true)
            )

            print_benchmark(result)

            # Should save in under 1 second
            expect(result.total_ms).to_be_less_than(1000)

            cleanup_temp_db(test_name)

        slow_it "handles 10,000 test records efficiently":
            val test_name = "load_10k"
            cleanup_temp_db(test_name)

            # Create database with 10,000 tests
            print "Creating database with 10,000 test records..."
            val db = create_large_db(10000)

            # Save
            val save_start = time_now_unix_micros()
            val save_result = db.save()
            val save_end = time_now_unix_micros()
            val save_ms = (save_end - save_start) / 1000

            expect(save_result.ok.?).to_be(true)
            print "Save time: {save_ms}ms"

            # Load
            val load_start = time_now_unix_micros()
            val load_result = TestDatabase.load()
            val load_end = time_now_unix_micros()
            val load_ms = (load_end - load_start) / 1000

            expect(load_result.ok.?).to_be(true)
            val loaded_db = load_result.unwrap()
            expect(loaded_db.tests.len()).to_be(10000)
            print "Load time: {load_ms}ms"

            # Both should be under 5 seconds for 10K records
            expect(save_ms).to_be_less_than(5000)
            expect(load_ms).to_be_less_than(5000)

            # Check file size
            val db_path = temp_db_path(test_name)
            val size_bytes = file_size(db_path)
            val size_mb = size_bytes / (1024 * 1024)
            print "Database size: {size_mb} MB"

            # Should be under 50 MB for 10K tests
            expect(size_mb).to_be_less_than(50)

            cleanup_temp_db(test_name)

    describe "String Interning Efficiency":

        it "achieves 60%+ memory savings with string interning":
            val db = TestDatabase.empty()

            # Add 1000 tests with only 10 unique paths
            val unique_paths = 10
            val tests_per_path = 100
            val total_tests = unique_paths * tests_per_path

            for path_id in 0..unique_paths:
                val file_path = "test/suite_{path_id}.spl"

                for test_id in 0..tests_per_path:
                    val test_name = "test_{path_id}_{test_id}"

                    db.update_test_result(
                        test_name: test_name,
                        test_file: file_path,  # Reused path
                        suite_name: "Suite {path_id}",  # Reused suite name
                        category: "unit",
                        status: TestStatus.Passed,
                        duration_ms: 10.0
                    )

            # Check interned string count
            val interned_count = db.interner.len()

            # Should have much fewer strings than total records
            # With 1000 tests and 10 unique paths, expect ~30-50 interned strings
            expect(interned_count).to_be_less_than(100)

            # Calculate theoretical memory savings
            # Without interning: 1000 tests * ~30 bytes/path = 30KB
            # With interning: 10 paths * 30 bytes + 1000 refs = ~1.3KB
            # Savings: ~95%

            print "Total tests: {total_tests}"
            print "Unique interned strings: {interned_count}"
            val savings_pct = ((total_tests - interned_count).to_float() / total_tests.to_float()) * 100.0
            print "Memory savings: {savings_pct}%"

            expect(savings_pct).to_be_greater_than(60.0)

    describe "Window Capping Performance":

        it "caps timing runs efficiently (O(n) complexity)":
            val db = TestDatabase.empty()

            val test_name = "perf_test"
            val file_path = "test/perf.spl"
            val suite_name = "Performance Suite"

            # Add 100 timing runs (should cap at 10)
            val result = benchmark("Add 100 timing runs with cap", 1, \:
                for i in 0..100:
                    db.update_test_result(
                        test_name: test_name,
                        test_file: file_path,
                        suite_name: suite_name,
                        category: "perf",
                        status: TestStatus.Passed,
                        duration_ms: (i % 50).to_float() + 10.0
                    )
            )

            print_benchmark(result)

            # Check that only 10 runs are kept
            var timing_count = 0
            val name_str = db.interner.intern(test_name)
            for tr in db.timing_runs:
                if tr.test_id == name_str:
                    timing_count = timing_count + 1

            expect(timing_count).to_be_less_than_or_equal(10)

            # Capping should be fast (under 100ms for 100 operations)
            expect(result.total_ms).to_be_less_than(100)

        it "maintains correct statistics after capping":
            val db = TestDatabase.empty()

            # Add many runs
            for i in 0..50:
                db.update_test_result(
                    test_name: "stat_test",
                    test_file: "test/stat.spl",
                    suite_name: "Stats",
                    category: "unit",
                    status: TestStatus.Passed,
                    duration_ms: (i % 10).to_float() + 5.0  # Values 5-14
                )

            # Check statistics are still valid
            val name_str = db.interner.intern("stat_test")
            var summary: TimingSummary? = ()
            for ts in db.timing:
                if ts.test_id == name_str:
                    summary = Some(ts)
                    break

            expect(summary.?).to_be(true)
            val stats = summary.unwrap()

            # P50 should be around 9-10 (median of 5-14)
            expect(stats.p50).to_be_greater_than(7.0)
            expect(stats.p50).to_be_less_than(12.0)

    describe "Statistics Computation":

        it "computes percentiles quickly for many tests":
            val db = TestDatabase.empty()

            # Add 1000 tests with 10 timing runs each
            val test_count = 1000

            val result = benchmark("Compute stats for 1K tests", 1, \:
                for i in 0..test_count:
                    for j in 0..10:
                        db.update_test_result(
                            test_name: "test_{i}",
                            test_file: "test/suite.spl",
                            suite_name: "Suite",
                            category: "unit",
                            status: TestStatus.Passed,
                            duration_ms: (j * 10).to_float() + 5.0
                        )
            )

            print_benchmark(result)

            # Should compute stats in under 2 seconds for 1K tests
            expect(result.total_ms).to_be_less_than(2000)

            # Per-test stat computation should be under 2ms
            val per_test_ms = result.total_ms / test_count
            expect(per_test_ms).to_be_less_than(2)

    describe "File Size Growth":

        slow_it "maintains bounded file size with window capping":
            val test_name = "size_growth"
            cleanup_temp_db(test_name)

            val db = TestDatabase.empty()

            # Simulate 100 test runs
            var file_sizes: List<i64> = []

            for run in 0..20:  # Reduced from 100 for test speed
                # Add 10 tests per run
                for test_id in 0..10:
                    db.update_test_result(
                        test_name: "test_{test_id}",
                        test_file: "test/suite.spl",
                        suite_name: "Suite",
                        category: "unit",
                        status: if run % 5 == 0: TestStatus.Failed else: TestStatus.Passed,
                        duration_ms: ((run + test_id) % 50).to_float() + 10.0
                    )

                # Save and record size
                val save_result = db.save()
                expect(save_result.ok.?).to_be(true)

                val db_path = temp_db_path(test_name)
                val size = file_size(db_path)
                file_sizes.push(size)

            # File size should stabilize after window capping kicks in
            # Check that last 5 sizes don't grow significantly
            val size_count = file_sizes.len()
            if size_count >= 10:
                val last_size = file_sizes[size_count - 1]
                val tenth_last_size = file_sizes[size_count - 10]

                # Growth should be minimal (< 10%) after stabilization
                val growth_ratio = last_size.to_float() / tenth_last_size.to_float()
                expect(growth_ratio).to_be_less_than(1.1)

                print "File size stabilized: {tenth_last_size} → {last_size} bytes"

            cleanup_temp_db(test_name)

    describe "Many Runs (History)":

        slow_it "queries 500 test runs efficiently":
            val db = TestDatabase.empty()

            # Create 500 test runs
            for i in 0..500:
                db.test_runs.push(RunRecord(
                    run_id: "run_{i}",
                    start_time: micros_to_rfc3339(time_now_unix_micros() - (i * 60000000)),
                    end_time: micros_to_rfc3339(time_now_unix_micros() - (i * 60000000) + 5000000),
                    pid: getpid(),
                    hostname: "test",
                    status: "completed",
                    test_count: 10,
                    passed: 9,
                    failed: 1,
                    crashed: 0,
                    timed_out: 0
                ))

            # Query operations should be fast
            val list_result = benchmark("List all runs", 10, \:
                val runs = db.list_runs("all")
                expect(runs.len()).to_be(500)
            )
            print_benchmark(list_result)

            # Listing should be under 10ms per iteration
            expect(list_result.per_op_us).to_be_less_than(10000)

            # Filter by status
            val filter_result = benchmark("Filter by status", 100, \:
                val completed = db.list_runs("completed")
                expect(completed.len()).to_be(500)
            )
            print_benchmark(filter_result)

            # Filtering should be under 1ms per iteration
            expect(filter_result.per_op_us).to_be_less_than(1000)

        it "prunes old runs efficiently":
            val db = TestDatabase.empty()

            # Create 1000 runs
            for i in 0..1000:
                db.test_runs.push(RunRecord(
                    run_id: "run_{i}",
                    start_time: micros_to_rfc3339(time_now_unix_micros()),
                    end_time: micros_to_rfc3339(time_now_unix_micros()),
                    pid: getpid(),
                    hostname: "test",
                    status: "completed",
                    test_count: 1,
                    passed: 1,
                    failed: 0,
                    crashed: 0,
                    timed_out: 0
                ))

            expect(db.test_runs.len()).to_be(1000)

            # Prune to keep only 100 most recent
            val prune_result = benchmark("Prune to 100", 1, \:
                db.prune_runs(100)
            )
            print_benchmark(prune_result)

            expect(db.test_runs.len()).to_be(100)

            # Pruning should be fast (under 100ms)
            expect(prune_result.total_ms).to_be_less_than(100)

    describe "Memory Usage":

        it "maintains reasonable memory footprint for large database":
            val db = TestDatabase.empty()

            # Create large database (5000 tests)
            for i in 0..5000:
                db.update_test_result(
                    test_name: "test_{i}",
                    test_file: "test/suite_{i % 50}.spl",
                    suite_name: "Suite {i % 100}",
                    category: "unit",
                    status: if i % 10 == 0: TestStatus.Failed else: TestStatus.Passed,
                    duration_ms: (i % 100).to_float() + 10.0
                )

            # Save to disk
            val save_result = db.save()
            expect(save_result.ok.?).to_be(true)

            # TODO: Add memory profiling
            # For now, just verify database operations still work

            expect(db.tests.len()).to_be(5000)
            expect(db.timing.len()).to_be(5000)
