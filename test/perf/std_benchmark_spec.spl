# Std Benchmark Library Tests
#
# **Feature IDs:** Testing Infrastructure - Benchmarking
# **Category:** Testing | Performance
# **Status:** Implemented
#
# Tests for the `std.testing.benchmark` library for measuring and comparing
# execution time of Simple functions.
# Note: interpreter mode only verifies file loading (it block bodies don't execute).
# Uses single `it` block pattern for interpreter compatibility.

use std.benchmark.benchmark_config.{BenchmarkConfig, benchmark_config_default, benchmark_config_quick}
use std.benchmark.benchmark_stats.{BenchmarkStats, calculate_stats, format_time}
use std.benchmark.measure.{time_function}

fn benchmark(name: text, fn_to_bench: fn(), config: BenchmarkConfig?) -> BenchmarkStats:
    val cfg = config ?? benchmark_config_default()
    var w = 0
    while w < cfg.warmup_iterations:
        fn_to_bench()
        w = w + 1
    var samples: [f64] = []
    var s = 0
    while s < cfg.sample_size:
        var total_ns: i64 = 0
        var m = 0
        while m < cfg.measurement_iterations:
            total_ns = total_ns + time_function(fn_to_bench)
            m = m + 1
        val avg_ns = total_ns.to_f64() / cfg.measurement_iterations.to_f64()
        samples.push(avg_ns)
        s = s + 1
    calculate_stats(samples, cfg.outlier_threshold)

fn check(v):
    expect(v).to_equal(true)

# =========================================================================
# Test helpers (module-level for interpreter compatibility)
# =========================================================================

fn test_default_config() -> bool:
    val config = benchmark_config_default()
    config.warmup_iterations == 3 and config.measurement_iterations == 100 and config.sample_size == 10

fn test_quick_config() -> bool:
    val config = benchmark_config_quick()
    config.warmup_iterations == 1 and config.sample_size == 3

fn test_calculate_mean_median() -> bool:
    val samples = [100.0, 102.0, 98.0, 101.0, 99.0]
    val stats = calculate_stats(samples, 3.0)
    stats.mean_ns == 100.0 and stats.median_ns == 100.0

fn test_calculate_std_dev() -> bool:
    val samples = [100.0, 110.0, 90.0, 100.0, 100.0]
    val stats = calculate_stats(samples, 3.0)
    stats.std_dev_ns > 0.0

fn test_format_time_ns() -> bool:
    format_time(500.0).contains("ns")

fn test_format_time_us() -> bool:
    format_time(1500.0).contains("us")

fn test_format_time_ms() -> bool:
    format_time(1500000.0).contains("ms")

fn test_format_time_s() -> bool:
    format_time(1500000000.0).contains("s")

fn test_summary() -> bool:
    val samples = [1000.0, 1100.0, 900.0, 1050.0, 950.0]
    val stats = calculate_stats(samples, 3.0)
    val summary = stats.summary()
    summary.contains("Mean:") and summary.contains("Median:") and summary.contains("Range:")

fn test_benchmark_execution() -> bool:
    val config = benchmark_config_quick()
    val stats = benchmark("test", \: 42, Some(config))
    stats.mean_ns >= 0.0 and stats.samples.len() == 3

fn test_baseline_stats() -> bool:
    val samples = [1000.0, 1100.0, 900.0]
    val baseline = calculate_stats(samples, 3.0)
    baseline.mean_ns > 0.0 and baseline.median_ns > 0.0

fn test_custom_config() -> bool:
    val config = BenchmarkConfig(
        warmup_iterations: 1,
        measurement_iterations: 50,
        sample_size: 5,
        outlier_threshold: 1.5
    )
    config.sample_size == 5

fn test_outlier_detection() -> bool:
    val samples = [100.0, 102.0, 98.0]
    val stats = calculate_stats(samples, 3.0)
    stats.outliers_low + stats.outliers_high >= 0

# =========================================================================
# Test execution
# =========================================================================

describe "Benchmarking Library":
    it "benchmark module loads and all tests pass":
        check(test_default_config())
        check(test_quick_config())
        check(test_calculate_mean_median())
        check(test_calculate_std_dev())
        check(test_format_time_ns())
        check(test_format_time_us())
        check(test_format_time_ms())
        check(test_format_time_s())
        check(test_summary())
        check(test_benchmark_execution())
        check(test_baseline_stats())
        check(test_custom_config())
        check(test_outlier_detection())
