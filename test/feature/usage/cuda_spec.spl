# # CUDA Backend
#
# **Feature ID:** #GPU-001
# **Category:** Runtime
# **Status:** In Progress
#
# ## Overview
#
# Tests NVIDIA CUDA backend functionality including device detection and selection,
# memory allocation and transfer operations (host-to-device, device-to-host,
# device-to-device), PTX kernel compilation and function loading, stream creation
# and synchronization, and error handling. Most tests require CUDA hardware.
#
# ## Syntax
#
# ```simple
# val available = cuda_available()
# val ptr = cuda_alloc(1024)
# cuda_copy_to_device(ptr, data)
# val module = cuda_compile(VECTOR_ADD_PTX)
# ```
# CUDA Backend Tests
#
# Tests specific to CUDA backend functionality.
# These tests require NVIDIA CUDA to be available.

use std.compute.*
use app.io.cuda_ffi.*
fn check(condition: bool):
    expect(condition).to_equal(true)
fn check_msg(condition: bool, message: text):
    if not condition:
        expect(message).to_equal("")

fn require_cuda():
    if not cuda_available():
        print "Skipping: CUDA not available"
        return

describe "CUDA Availability":
    it "checks CUDA availability":
        val available = cuda_available()
        check(available or not available)

    # @tag(reason: "requires_cuda")  # @skip - attributes on test cases not supported
    it "reports device count":
        require_cuda()
        val count = cuda_device_count()
        check(count > 0)

describe "CUDA Device Selection":
    # @tag(reason: "requires_cuda")  # @skip - attributes on test cases not supported
    it "sets and gets current device":
        require_cuda()
        check(cuda_set_device(0))
        check(cuda_get_device() == 0)

    # @tag(reason: "requires_cuda")  # @skip - attributes on test cases not supported
    it "gets device info":
        require_cuda()
        val info = cuda_device_info(0)
        check(info.name.len() > 0)
        check(info.total_memory > 0)

    # @tag(reason: "requires_cuda")  # @skip - attributes on test cases not supported
    it "gets compute capability":
        require_cuda()
        val info = cuda_device_info(0)
        val (major, minor) = info.compute_capability
        check(major >= 1)
        check(minor >= 0)

describe "CUDA Memory Operations":
    # @tag(reason: "requires_cuda")  # @skip - attributes on test cases not supported
    it "allocates CUDA memory":
        require_cuda()
        val ptr = cuda_alloc(1024)
        check(ptr.is_valid)
        expect(ptr.size).to_equal(1024)
        check(cuda_free(ptr))

    # @tag(reason: "requires_cuda")  # @skip - attributes on test cases not supported
    it "performs memset":
        require_cuda()
        val ptr = cuda_alloc(1024)
        check(cuda_memset(ptr, 0))
        cuda_free(ptr)

    # @tag(reason: "requires_cuda")  # @skip - attributes on test cases not supported
    it "copies host to device":
        require_cuda()
        val ptr = cuda_alloc(16)
        val data: [u8] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
        check(cuda_copy_to_device(ptr, data))
        cuda_free(ptr)

    # @tag(reason: "requires_cuda")  # @skip - attributes on test cases not supported
    it "copies device to host":
        require_cuda()
        val ptr = cuda_alloc(16)
        val src: [u8] = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160]
        cuda_copy_to_device(ptr, src)
        var dst: [u8] = []
        for i in 0..16:
            dst.push(0)
        check(cuda_copy_from_device(dst, ptr))
        cuda_free(ptr)

    # @tag(reason: "requires_cuda")  # @skip - attributes on test cases not supported
    it "copies device to device":
        require_cuda()
        val src = cuda_alloc(1024)
        var dst = cuda_alloc(1024)
        check(cuda_copy_device_to_device(dst, src, 1024))
        cuda_free(src)
        cuda_free(dst)

describe "CUDA Kernel Compilation":
    # @tag(reason: "requires_cuda")  # @skip - attributes on test cases not supported
    it "compiles PTX module":
        require_cuda()
        val ptx = VECTOR_ADD_PTX
        val module = cuda_compile(ptx)
        check(module.is_valid)
        cuda_unload(module)

    # @tag(reason: "requires_cuda")  # @skip - attributes on test cases not supported
    it "gets kernel function from module":
        require_cuda()
        val module = cuda_compile(VECTOR_ADD_PTX)
        check(module.is_valid)
        val kfn = cuda_get_kernel(module, "vector_add")
        check(kfn.is_valid)
        cuda_unload(module)

describe "CUDA Streams":
    # @tag(reason: "requires_cuda")  # @skip - attributes on test cases not supported
    it "creates and destroys stream":
        require_cuda()
        val stream = cuda_stream_create()
        check(stream.is_valid)
        check(cuda_stream_destroy(stream))

    # @tag(reason: "requires_cuda")  # @skip - attributes on test cases not supported
    it "synchronizes stream":
        require_cuda()
        val stream = cuda_stream_create()
        check(cuda_stream_sync(stream))
        cuda_stream_destroy(stream)

describe "CUDA Error Handling":
    # @tag(reason: "requires_cuda")  # @skip - attributes on test cases not supported
    it "gets last error":
        require_cuda()
        val error_text = cuda_last_error()
        check(true)

    # @tag(reason: "requires_cuda")  # @skip - attributes on test cases not supported
    it "peeks at error without clearing":
        require_cuda()
        val error_text = cuda_peek_error()
        check(true)

describe "CUDA Synchronization":
    # @tag(reason: "requires_cuda")  # @skip - attributes on test cases not supported
    it "synchronizes device":
        require_cuda()
        check(cuda_sync())

    # @tag(reason: "requires_cuda")  # @skip - attributes on test cases not supported
    it "creates gpu_cuda device wrapper":
        require_cuda()
        val device = gpu_cuda(0)
        check(device.is_valid())
        check(device.backend_name() == "CUDA")
