# Lexer FFI Test
#
# Tests that the lexer FFI correctly exposes token-level behavior.
# Verifies contextual keywords work via FFI.

use std.compiler.lexer.*

describe "Lexer FFI - Basic Tokenization":
    it "tokenizes skip(5) correctly":
        val tokens = tokenize("skip(5)")
        expect tokens.len() == 5
        expect tokens[0].kind == "Identifier"
        val name_matches = tokens[0].name.? and (tokens[0].name ?? "") == "skip"
        expect name_matches == true

describe "Lexer FFI - Contextual Keywords":
    it "tokenizes skip as keyword when standalone":
        val tokens = tokenize("skip")
        expect tokens.len() > 0
        expect tokens[0].kind == "Skip"

    it "tokenizes static as identifier in static()":
        val tokens = tokenize("static()")
        expect tokens.len() > 0
        expect tokens[0].kind == "Identifier"

    it "tokenizes static as keyword in 'static fn'":
        val tokens = tokenize("static fn")
        expect tokens.len() > 0
        expect tokens[0].kind == "Static"

describe "Lexer FFI - Helper Functions":
    it "token_kinds extracts kinds correctly":
        val kinds = token_kinds("fn skip(n)")
        expect kinds[0] == "Fn"
        expect kinds[1] == "Identifier"

    it "identifier_names extracts names correctly":
        val names = identifier_names("obj.skip(x)")
        expect names.contains("obj") == true
        expect names.contains("skip") == true
