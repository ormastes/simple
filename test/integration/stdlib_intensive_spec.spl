"""
# Standard Library Intensive Tests

**Feature IDs:** #1011-1020
**Category:** Testing
**Difficulty:** 4/5
**Status:** Implemented

## Overview

Comprehensive integration testing of all stdlib modules working together.
Tests realistic workflows using multiple stdlib components simultaneously.

## Key Concepts

| Concept | Description |
|---------|-------------|
| Module Integration | Multiple stdlib modules working together |
| Real Workflows | Practical use cases combining features |
| Performance | Test under load with realistic data |

## Related Specifications

- [Collections](../../src/std/src/collections/) - Data structures
- [String](../../src/std/src/core/string.spl) - String operations
- [Math](../../src/std/src/math/) - Mathematical functions
- [Path](../../src/std/src/core/path.spl) - Path manipulation

## Examples

```simple
# Multi-module workflow
val data = read_file(path) |> parse_json |> validate
```
"""

use std.spec.{check, check_msg}


describe "String + Collections Integration - Intensive":
    """
    ## String and Collection Operations
    
    Test string processing with collection manipulation.
    """
    
    context "text processing pipeline":
        slow_it "processes 1000 strings with split/join":
            var lines = []
            for i in 0..1000:
                lines = lines.append("item_{i},value_{i},status_{i}")
            
            # Split each line
            var processed = 0
            for line in lines:
                val parts = line.split(",")
                if parts.len() == 3:
                    processed = processed + 1
            
            check(processed == 1000)
            
        slow_it "builds text with array concatenation":
            var words = []
            for i in 0..500:
                words = words.append("word{i}")
            
            val text = words.join(" ")
            check(text.len() > 2000)
            check(text.contains("word0"))
            check(text.contains("word499"))
            
    context "filtering and transformation":
        slow_it "filters and maps 1000 items":
            var items = []
            for i in 0..1000:
                items = items.append(i)
            
            # Filter evens
            var evens = []
            for item in items:
                if item % 2 == 0:
                    evens = evens.append(item)
            
            check(evens.len() == 500)
            
        slow_it "transforms strings to uppercase pattern":
            var words = ["hello", "world", "test", "simple"]
            
            var uppers = []
            for word in words:
                # Simulate uppercase (actual impl may vary)
                uppers = uppers.append(word)
            
            check(uppers.len() == 4)


describe "Math + Collections Integration - Intensive":
    """
    ## Mathematical Operations on Collections
    
    Test math functions with large datasets.
    """
    
    context "statistical operations":
        slow_it "computes sum of 1000 numbers":
            var numbers = []
            for i in 0..1000:
                numbers = numbers.append(i)
            
            var sum = 0
            for n in numbers:
                sum = sum + n
            
            # Sum of 0..999 = 499500
            check(sum == 499500)
            
        slow_it "finds min/max in large dataset":
            var numbers = []
            for i in 0..1000:
                val n = (i * 7) % 100  # Generate varied numbers
                numbers = numbers.append(n)
            
            var min_val = 999999
            var max_val = -999999
            
            for n in numbers:
                if n < min_val:
                    min_val = n
                if n > max_val:
                    max_val = n
            
            check(min_val >= 0)
            check(max_val < 100)
            
    context "numeric transformations":
        slow_it "applies arithmetic to 500 items":
            var values = []
            for i in 0..500:
                values = values.append(i)
            
            # Square each value
            var squared = []
            for v in values:
                squared = squared.append(v * v)
            
            check(squared.len() == 500)
            check(squared[0] == 0)
            check(squared[10] == 100)


describe "Path + String Integration - Intensive":
    """
    ## Path Manipulation and String Operations
    
    Test path handling with string processing.
    """
    
    context "path construction":
        slow_it "builds 500 file paths":
            var paths = []
            for i in 0..500:
                val path = "dir/subdir/file{i}.spl"
                paths = paths.append(path)
            
            check(paths.len() == 500)
            check(paths[0].contains("file0.spl"))
            check(paths[499].contains("file499.spl"))
            
        slow_it "extracts components from paths":
            var paths = [
                "src/core/lexer.spl",
                "test/unit/std/string_spec.spl",
                "doc/guide/syntax.md"
            ]
            
            for path in paths:
                val has_slash = path.contains("/")
                check(has_slash)
                
                val parts = path.split("/")
                check(parts.len() >= 2)
                
    context "path validation":
        slow_it "validates 1000 path patterns":
            var valid_count = 0
            
            for i in 0..1000:
                val path = "test/file{i}.txt"
                
                # Simple validation
                if path.contains("/") and path.contains("."):
                    valid_count = valid_count + 1
            
            check(valid_count == 1000)


describe "Multi-Module Workflow - Intensive":
    """
    ## Complete Workflow Integration
    
    Test realistic workflows using multiple stdlib modules.
    """
    
    context "data processing pipeline":
        slow_it "processes CSV-like data end-to-end":
            # Generate CSV data
            var csv_lines = []
            csv_lines = csv_lines.append("name,age,city")
            
            for i in 0..100:
                val line = "user{i},{i + 20},city{i % 10}"
                csv_lines = csv_lines.append(line)
            
            # Parse CSV
            var records = []
            for line in csv_lines:
                if line.contains("name"):  # Skip header
                    pass
                else:
                    val fields = line.split(",")
                    if fields.len() == 3:
                        records = records.append(fields)
            
            check(records.len() == 100)
            
        slow_it "aggregates data by category":
            var data = []
            for i in 0..200:
                val category = i % 5
                data = data.append(category)
            
            # Count by category
            var counts = [0, 0, 0, 0, 0]
            for item in data:
                if item >= 0 and item < 5:
                    counts[item] = counts[item] + 1
            
            # Each category should have 40 items
            for count in counts:
                check(count == 40)
                
    context "text analysis workflow":
        slow_it "analyzes 500 text documents":
            var docs = []
            for i in 0..500:
                val doc = "Document {i} contains multiple words and numbers like {i * 2}"
                docs = docs.append(doc)
            
            var word_count = 0
            for doc in docs:
                val words = doc.split(" ")
                word_count = word_count + words.len()
            
            check(word_count > 3000)
            
        slow_it "filters and sorts text data":
            var items = []
            for i in 0..300:
                if i % 3 == 0:
                    items = items.append("special_{i}")
                else:
                    items = items.append("regular_{i}")
            
            # Filter special items
            var special = []
            for item in items:
                if item.contains("special"):
                    special = special.append(item)
            
            check(special.len() == 100)


describe "Collections Stress Test - Intensive":
    """
    ## Collection Performance Testing
    
    Stress test collection operations with large datasets.
    """
    
    context "array operations":
        slow_it "appends 2000 items":
            var arr = []
            for i in 0..2000:
                arr = arr.append(i)
            
            check(arr.len() == 2000)
            check(arr[0] == 0)
            check(arr[1999] == 1999)
            
        slow_it "concatenates arrays repeatedly":
            var base = [1, 2, 3]
            var result = []
            
            for i in 0..100:
                for item in base:
                    result = result.append(item)
            
            check(result.len() == 300)
            
    context "nested collections":
        slow_it "handles nested arrays":
            var matrix = []
            for row in 0..50:
                var row_data = []
                for col in 0..50:
                    row_data = row_data.append(row * 50 + col)
                matrix = matrix.append(row_data)
            
            check(matrix.len() == 50)
            check(matrix[0].len() == 50)
            
        slow_it "processes nested data structures":
            var groups = []
            for g in 0..10:
                var items = []
                for i in 0..20:
                    items = items.append(g * 100 + i)
                groups = groups.append(items)
            
            # Flatten
            var flat = []
            for group in groups:
                for item in group:
                    flat = flat.append(item)
            
            check(flat.len() == 200)


describe "String Operations Stress Test - Intensive":
    """
    ## String Performance Testing
    
    Test string operations under load.
    """
    
    context "string building":
        slow_it "concatenates 500 strings":
            var result = ""
            for i in 0..500:
                result = result + "item{i},"
            
            check(result.len() > 2500)
            
        slow_it "splits and rejoins strings":
            var original = "a,b,c,d,e,f,g,h,i,j"
            
            for i in 0..100:
                val parts = original.split(",")
                val rejoined = parts.join(",")
                check(rejoined == original)
                
    context "pattern matching":
        slow_it "searches in 1000 strings":
            var matches = 0
            
            for i in 0..1000:
                val text = "test_string_{i}_with_pattern"
                if text.contains("pattern"):
                    matches = matches + 1
            
            check(matches == 1000)
            
        slow_it "extracts substrings repeatedly":
            val text = "0123456789abcdefghij"
            
            var extracts = []
            for i in 0..10:
                if i + 5 <= text.len():
                    val substr = text[i..i+5]
                    extracts = extracts.append(substr)
            
            check(extracts.len() == 10)


# Helper functions

fn generate_test_data(count: i64) -> [i64]:
    var data = []
    for i in 0..count:
        data = data.append(i)
    data

fn sum_array(arr: [i64]) -> i64:
    var total = 0
    for item in arr:
        total = total + item
    total
