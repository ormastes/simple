# @Feature 801: Lexer - Comprehensive Tests
# @Description: Test Simple language lexer for branch coverage (398 branches)

# Import lexer implementation
use compiler.lexer.*
use compiler.lexer_types.*
use compiler.blocks.{block_registry, init_blocks}

# Test Lexer creation
describe "Lexer creation":
    it "creates lexer with source":
        val lexer = Lexer.new("val x = 5")
        expect lexer.pos == 0
        expect lexer.line == 1
        expect lexer.col == 1
        expect lexer.at_line_start == true

    it "initializes indent stack with zero":
        val lexer = Lexer.new("code")
        expect lexer.indent_stack.len() == 1
        expect lexer.indent_stack[0] == 0

    it "initializes with no pending dedents":
        val lexer = Lexer.new("code")
        expect lexer.pending_dedents == 0

    it "starts with normal lexer mode":
        val lexer = Lexer.new("code")
        expect lexer.current_lexer_mode == LexerMode.Normal

# Test character operations
describe "Character operations":
    it "checks if at end with empty source":
        val lexer = Lexer.new("")
        expect lexer.is_at_end() == true

    it "checks if at end with content":
        val lexer = Lexer.new("x")
        expect lexer.is_at_end() == false

    it "peeks at current character":
        val lexer = Lexer.new("abc")
        expect lexer.peek() == 'a'

    it "peeks at next character":
        val lexer = Lexer.new("abc")
        expect lexer.peek_next() == 'b'

    it "advances position":
        var lexer = Lexer.new("abc")
        val ch = lexer.advance()
        expect ch == 'a'
        expect lexer.pos == 1

# Test simple token scanning
describe "Simple token scanning":
    it "scans identifier":
        var lexer = Lexer.new("hello")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Identifier

    it "scans integer number":
        var lexer = Lexer.new("42")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Integer

    it "scans plus operator":
        var lexer = Lexer.new("+")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Plus

    it "scans minus operator":
        var lexer = Lexer.new("-")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Minus

    it "scans asterisk operator":
        var lexer = Lexer.new("*")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Star

    it "scans slash operator":
        var lexer = Lexer.new("/")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Slash

    it "scans equals operator":
        var lexer = Lexer.new("=")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Assign

# Test keyword recognition
describe "Keyword recognition":
    it "recognizes val keyword":
        var lexer = Lexer.new("val")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Val

    it "recognizes var keyword":
        var lexer = Lexer.new("var")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Var

    it "recognizes fn keyword":
        var lexer = Lexer.new("fn")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Fn

    it "recognizes if keyword":
        var lexer = Lexer.new("if")
        val token = lexer.next_token()
        expect token.kind == TokenKind.If

    it "recognizes else keyword":
        var lexer = Lexer.new("else")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Else

    it "recognizes while keyword":
        var lexer = Lexer.new("while")
        val token = lexer.next_token()
        expect token.kind == TokenKind.While

    it "recognizes for keyword":
        var lexer = Lexer.new("for")
        val token = lexer.next_token()
        expect token.kind == TokenKind.For

    it "recognizes match keyword":
        var lexer = Lexer.new("match")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Match

    it "recognizes case keyword":
        var lexer = Lexer.new("case")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Case

    it "recognizes return keyword":
        var lexer = Lexer.new("return")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Return

# Test delimiters
describe "Delimiters":
    it "scans left paren":
        var lexer = Lexer.new("(")
        val token = lexer.next_token()
        expect token.kind == TokenKind.LParen

    it "scans right paren":
        var lexer = Lexer.new(")")
        val token = lexer.next_token()
        expect token.kind == TokenKind.RParen

    it "scans left brace":
        var lexer = Lexer.new(r"{")
        val token = lexer.next_token()
        expect token.kind == TokenKind.LBrace

    it "scans right brace":
        var lexer = Lexer.new(r"}")
        val token = lexer.next_token()
        expect token.kind == TokenKind.RBrace

    it "scans left bracket":
        var lexer = Lexer.new("[")
        val token = lexer.next_token()
        expect token.kind == TokenKind.LBracket

    it "scans right bracket":
        var lexer = Lexer.new("]")
        val token = lexer.next_token()
        expect token.kind == TokenKind.RBracket

    it "scans colon":
        var lexer = Lexer.new(":")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Colon

    it "scans comma":
        var lexer = Lexer.new(",")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Comma

    it "scans dot":
        var lexer = Lexer.new(".")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Dot

# Test string scanning
describe "String scanning":
    it "scans simple string":
        var lexer = Lexer.new("\"hello\"")
        val token = lexer.next_token()
        expect token.kind == TokenKind.String

    it "scans empty string":
        var lexer = Lexer.new("\"\"")
        val token = lexer.next_token()
        expect token.kind == TokenKind.String

    it "scans string with spaces":
        var lexer = Lexer.new("\"hello world\"")
        val token = lexer.next_token()
        expect token.kind == TokenKind.String

# Test number scanning
describe "Number scanning":
    it "scans zero":
        var lexer = Lexer.new("0")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Integer

    it "scans single digit":
        var lexer = Lexer.new("5")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Integer

    it "scans multi-digit integer":
        var lexer = Lexer.new("12345")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Integer

    it "scans float with decimal":
        var lexer = Lexer.new("3.14")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Float

    it "scans hex number":
        var lexer = Lexer.new("0x1A")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Integer

    it "scans binary number":
        var lexer = Lexer.new("0b1010")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Integer

    it "scans octal number":
        var lexer = Lexer.new("0o755")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Integer

# Test comment scanning
describe "Comment scanning":
    it "skips single-line comment":
        var lexer = Lexer.new("# comment\nval")
        val token1 = lexer.next_token()
        expect token1.kind == TokenKind.Newline
        val token2 = lexer.next_token()
        expect token2.kind == TokenKind.Val

    it "handles comment at end of file":
        var lexer = Lexer.new("# comment")
        val token1 = lexer.next_token()
        expect token1.kind == TokenKind.Newline
        val token2 = lexer.next_token()
        expect token2.kind == TokenKind.Eof

# Test comparison operators
describe "Comparison operators":
    it "scans less than":
        var lexer = Lexer.new("<")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Less

    it "scans greater than":
        var lexer = Lexer.new(">")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Greater

    it "scans less than or equal":
        var lexer = Lexer.new("<=")
        val token = lexer.next_token()
        expect token.kind == TokenKind.LessEq

    it "scans greater than or equal":
        var lexer = Lexer.new(">=")
        val token = lexer.next_token()
        expect token.kind == TokenKind.GreaterEq

    it "scans equality":
        var lexer = Lexer.new("==")
        val token = lexer.next_token()
        expect token.kind == TokenKind.EqEq

    it "scans not equal":
        var lexer = Lexer.new("!=")
        val token = lexer.next_token()
        expect token.kind == TokenKind.NotEq

# Test logical operators
describe "Logical operators":
    it "scans and operator":
        var lexer = Lexer.new("and")
        val token = lexer.next_token()
        expect token.kind == TokenKind.And

    it "scans or operator":
        var lexer = Lexer.new("or")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Or

    it "scans not operator":
        var lexer = Lexer.new("not")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Not

# Test arrow operators
describe "Arrow operators":
    it "scans right arrow":
        var lexer = Lexer.new("->")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Arrow

    it "scans fat arrow":
        var lexer = Lexer.new("=>")
        val token = lexer.next_token()
        expect token.kind == TokenKind.FatArrow

# Test newline handling
describe "Newline handling":
    it "scans newline":
        var lexer = Lexer.new("\n")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Newline

    it "tracks line numbers":
        var lexer = Lexer.new("a\nb")
        val token1 = lexer.next_token()
        expect token1.line == 1
        val token2 = lexer.next_token()
        expect token2.line == 1
        val token3 = lexer.next_token()
        expect token3.line == 2

# Test EOF handling
describe "EOF handling":
    it "returns EOF at end":
        var lexer = Lexer.new("")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Eof

    it "returns EOF after content":
        var lexer = Lexer.new("x")
        val token1 = lexer.next_token()
        val token2 = lexer.next_token()
        expect token2.kind == TokenKind.Eof

# Test whitespace handling
describe "Whitespace handling":
    it "skips spaces between tokens":
        var lexer = Lexer.new("a   b")
        val token1 = lexer.next_token()
        expect token1.kind == TokenKind.Identifier
        val token2 = lexer.next_token()
        expect token2.kind == TokenKind.Identifier

    it "skips tabs":
        var lexer = Lexer.new("a\tb")
        val token1 = lexer.next_token()
        val token2 = lexer.next_token()
        expect token2.kind == TokenKind.Identifier

# Test identifier patterns
describe "Identifier patterns":
    it "scans underscore identifier":
        var lexer = Lexer.new("_var")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Identifier

    it "scans identifier with numbers":
        var lexer = Lexer.new("var123")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Identifier

    it "scans identifier with underscores":
        var lexer = Lexer.new("my_var")
        val token = lexer.next_token()
        expect token.kind == TokenKind.Identifier
