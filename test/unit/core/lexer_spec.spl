# Core Simple â€” Lexer Tests
use core.lexer.{lex_init, lex_next, lex_token_kind, lex_token_text}
use std.string.{NL}
use core.tokens.*

fn collect_kinds(source: text) -> [i64]:
    var kinds: [i64] = []
    lex_init(source)
    for i in 0..10000:
        val k = lex_next()
        kinds.push(k)
        if k == TOK_EOF:
            break
    kinds

fn collect_texts(source: text) -> [text]:
    var texts: [text] = []
    lex_init(source)
    for i in 0..10000:
        val k = lex_next()
        texts.push(lex_token_text())
        if k == TOK_EOF:
            break
    texts

fn find_kind(kinds: [i64], target: i64) -> bool:
    for k in kinds:
        if k == target:
            return true
    false

fn first_non_trivia(kinds: [i64]) -> i64:
    for k in kinds:
        if k == TOK_NEWLINE or k == TOK_INDENT or k == TOK_DEDENT:
            continue
        return k
    TOK_EOF


describe "core.lexer":
    it "lexes basic tokens":
        val kinds = collect_kinds("val x = 123{NL}")
        expect(kinds[0]).to_equal(TOK_KW_VAL)
        expect(kinds[1]).to_equal(TOK_IDENT)
        expect(kinds[2]).to_equal(TOK_ASSIGN)
        expect(kinds[3]).to_equal(TOK_INT_LIT)
        expect(kinds[kinds.len() - 1]).to_equal(TOK_EOF)

    it "lexes strings":
        val kinds = collect_kinds("val s = \"hi\"{NL}")
        expect(find_kind(kinds, TOK_STRING_LIT)).to_equal(true)
        val texts = collect_texts("\"hi\"")
        expect(texts[0]).to_equal("hi")

    it "lexes floats and exponents":
        val kinds = collect_kinds("val x = 1.5{NL}val y = 2e3{NL}")
        expect(find_kind(kinds, TOK_FLOAT_LIT)).to_equal(true)

    it "lexes hex/bin/oct and separators":
        val kinds = collect_kinds("val a = 0xFF{NL}val b = 0b1010{NL}val c = 0o10{NL}val d = 1_000{NL}")
        expect(find_kind(kinds, TOK_INT_LIT)).to_equal(true)

    it "handles indentation":
        val kinds = collect_kinds("fn main():{NL}    val x = 1{NL}    val y = 2{NL}")
        expect(find_kind(kinds, TOK_INDENT)).to_equal(true)
        expect(find_kind(kinds, TOK_DEDENT)).to_equal(true)

    it "skips comments":
        val kinds = collect_kinds("# comment{NL}val x = 1{NL}")
        expect(first_non_trivia(kinds)).to_equal(TOK_KW_VAL)

    it "lexes special operators":
        val kinds = collect_kinds("a?.b a.? b??c a|>b a**b{NL}")
        expect(find_kind(kinds, TOK_QUESTION_DOT)).to_equal(true)
        expect(find_kind(kinds, TOK_DOT_QUESTION)).to_equal(true)
        expect(find_kind(kinds, TOK_DOUBLE_QUESTION)).to_equal(true)
        expect(find_kind(kinds, TOK_PIPE_FORWARD)).to_equal(true)
        expect(find_kind(kinds, TOK_DOUBLE_STAR)).to_equal(true)

    it "reports unterminated strings":
        val kinds = collect_kinds("\"unterminated{NL}")
        expect(find_kind(kinds, TOK_ERROR)).to_equal(true)
        val texts = collect_texts("\"unterminated{NL}")
        # Error message is stored in token text
        expect(texts[0].contains("unterminated")).to_equal(true)
