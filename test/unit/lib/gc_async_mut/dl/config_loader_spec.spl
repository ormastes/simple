describe "DL Config Loader":
    it "skipped":
        skip("dl config imports not available")

# describe "DL Config Loader":
#     it "skipped":
#         skip("variable msg not found - dl config imports not available")
#
# # # DL Config Loader Specification
# # #
# # # **Feature:** Three-Level DL Configuration System
# # # **Category:** ML, Configuration
# # # **Status:** Complete
# # #
# # # Tests the three-level config loading system:
# # # 1. local (user):     ~/.simple/dl.config.sdn
# # # 2. project (shared): ./dl.config.sdn
# # # 3. project_local:    ./dl.config.local.sdn
# # #
# # # Each level only overrides keys it explicitly contains (partial merge).
# #
# # use std.src.dl.config.{DLConfig, Device, DType, Backend, dl}
# # use std.src.dl.config_loader.{
# #     parse_device, parse_dtype, parse_backend, parse_bool,
# #     apply_sdn_to_global, load_user_config
# # }
# # use std.sdn.{SdnValue}
# #
# # describe "DL Config Loader - Parse Helpers":
# #     context "parse_device":
# #         it "parses cpu":
# #             val dev = parse_device("cpu")
# #             expect dev == Device.CPU
# #
# #         it "parses gpu as CUDA(0)":
# #             val dev = parse_device("gpu")
# #             expect dev == Device.CUDA(0)
# #
# #         it "parses cuda:0":
# #             val dev = parse_device("cuda:0")
# #             expect dev == Device.CUDA(0)
# #
# #         it "parses cuda:1":
# #             val dev = parse_device("cuda:1")
# #             expect dev == Device.CUDA(1)
# #
# #         it "parses cuda:3":
# #             val dev = parse_device("cuda:3")
# #             expect dev == Device.CUDA(3)
# #
# #         it "defaults unknown to CPU":
# #             val dev = parse_device("unknown")
# #             expect dev == Device.CPU
# #
# #     context "parse_dtype":
# #         it "parses f16":
# #             expect parse_dtype("f16") == DType.F16
# #
# #         it "parses f32":
# #             expect parse_dtype("f32") == DType.F32
# #
# #         it "parses f64":
# #             expect parse_dtype("f64") == DType.F64
# #
# #         it "parses bf16":
# #             expect parse_dtype("bf16") == DType.BF16
# #
# #         it "parses i32":
# #             expect parse_dtype("i32") == DType.I32
# #
# #         it "defaults unknown to F32":
# #             expect parse_dtype("unknown") == DType.F32
# #
# #     context "parse_backend":
# #         it "parses native":
# #             expect parse_backend("native") == Backend.Native
# #
# #         it "parses torch":
# #             expect parse_backend("torch") == Backend.PyTorch
# #
# #         it "parses pytorch alias":
# #             expect parse_backend("pytorch") == Backend.PyTorch
# #
# #         it "parses cuda":
# #             expect parse_backend("cuda") == Backend.CUDA
# #
# #         it "defaults unknown to PyTorch":
# #             expect parse_backend("unknown") == Backend.PyTorch
# #
# #     context "parse_bool":
# #         it "parses true":
# #             expect parse_bool("true") == true
# #
# #         it "parses True":
# #             expect parse_bool("True") == true
# #
# #         it "parses 1":
# #             expect parse_bool("1") == true
# #
# #         it "parses false":
# #             expect parse_bool("false") == false
# #
# #         it "parses 0":
# #             expect parse_bool("0") == false
# #
# # describe "DL Config Loader - Partial Merge":
# #     context "when SDN contains only device":
# #         it "overrides device without changing dtype or backend":
# #             dl.default_device = Device.CPU
# #             dl.default_dtype = DType.F64
# #             dl.default_backend = Backend.Native
# #             dl.autograd_enabled = false
# #
# #             var sdn = SdnValue__empty_dict()
# #             sdn.insert("device", SdnValue__string("cuda:1"))
# #
# #             apply_sdn_to_global(sdn)
# #
# #             expect dl.default_device == Device.CUDA(1)
# #             expect dl.default_dtype == DType.F64
# #             expect dl.default_backend == Backend.Native
# #             expect dl.autograd_enabled == false
# #
# #     context "when SDN contains only dtype":
# #         it "overrides dtype without changing device":
# #             dl.default_device = Device.CUDA(2)
# #             dl.default_dtype = DType.F32
# #
# #             var sdn = SdnValue__empty_dict()
# #             sdn.insert("dtype", SdnValue__string("f16"))
# #
# #             apply_sdn_to_global(sdn)
# #
# #             expect dl.default_dtype == DType.F16
# #             expect dl.default_device == Device.CUDA(2)
# #
# #     context "when SDN contains multiple keys":
# #         it "overrides all present keys":
# #             dl.default_device = Device.CPU
# #             dl.default_dtype = DType.F32
# #             dl.default_backend = Backend.PyTorch
# #             dl.autograd_enabled = true
# #
# #             var sdn = SdnValue__empty_dict()
# #             sdn.insert("device", SdnValue__string("cuda:0"))
# #             sdn.insert("dtype", SdnValue__string("bf16"))
# #             sdn.insert("backend", SdnValue__string("native"))
# #
# #             apply_sdn_to_global(sdn)
# #
# #             expect dl.default_device == Device.CUDA(0)
# #             expect dl.default_dtype == DType.BF16
# #             expect dl.default_backend == Backend.Native
# #             expect dl.autograd_enabled == true
# #
# #     context "when SDN contains autograd and amp":
# #         it "overrides boolean flags":
# #             dl.autograd_enabled = true
# #             dl.amp_enabled = false
# #
# #             var sdn = SdnValue__empty_dict()
# #             sdn.insert("autograd", SdnValue__bool(false))
# #             sdn.insert("amp", SdnValue__bool(true))
# #
# #             apply_sdn_to_global(sdn)
# #
# #             expect dl.autograd_enabled == false
# #             expect dl.amp_enabled == true
# #
# #     context "when SDN is empty dict":
# #         it "changes nothing":
# #             dl.default_device = Device.CUDA(1)
# #             dl.default_dtype = DType.F64
# #             dl.default_backend = Backend.Native
# #
# #             var sdn = SdnValue__empty_dict()
# #             apply_sdn_to_global(sdn)
# #
# #             expect dl.default_device == Device.CUDA(1)
# #             expect dl.default_dtype == DType.F64
# #             expect dl.default_backend == Backend.Native
# #
# #     context "when SDN is not a dict":
# #         it "does nothing for non-dict values":
# #             dl.default_device = Device.CPU
# #             dl.default_dtype = DType.F32
# #
# #             var sdn = SdnValue__string("not a dict")
# #             apply_sdn_to_global(sdn)
# #
# #             expect dl.default_device == Device.CPU
# #             expect dl.default_dtype == DType.F32
# #
# # describe "DL Config Loader - Three-Level Override":
# #     context "three-level merge":
# #         it "project_local overrides project which overrides user":
# #             dl.default_device = Device.CPU
# #             dl.default_dtype = DType.F32
# #             dl.default_backend = Backend.PyTorch
# #             dl.autograd_enabled = true
# #             dl.amp_enabled = false
# #
# #             var user_sdn = SdnValue__empty_dict()
# #             user_sdn.insert("device", SdnValue__string("cuda:0"))
# #             user_sdn.insert("dtype", SdnValue__string("f64"))
# #             apply_sdn_to_global(user_sdn)
# #
# #             expect dl.default_device == Device.CUDA(0)
# #             expect dl.default_dtype == DType.F64
# #             expect dl.default_backend == Backend.PyTorch
# #
# #             var project_sdn = SdnValue__empty_dict()
# #             project_sdn.insert("dtype", SdnValue__string("f32"))
# #             project_sdn.insert("backend", SdnValue__string("native"))
# #             apply_sdn_to_global(project_sdn)
# #
# #             expect dl.default_device == Device.CUDA(0)
# #             expect dl.default_dtype == DType.F32
# #             expect dl.default_backend == Backend.Native
# #
# #             var local_sdn = SdnValue__empty_dict()
# #             local_sdn.insert("device", SdnValue__string("cuda:1"))
# #             apply_sdn_to_global(local_sdn)
# #
# #             expect dl.default_device == Device.CUDA(1)
# #             expect dl.default_dtype == DType.F32
# #             expect dl.default_backend == Backend.Native
# #             expect dl.autograd_enabled == true
# #
# # describe "DL Config Loader - User Config Caching":
# #     context "load_user_config":
# #         it "does not crash when called multiple times":
# #             load_user_config()
# #             load_user_config()
# #             load_user_config()
# #             expect true == true
# #
# # describe "DL Config Loader - Defaults":
# #     context "DLConfig defaults":
# #         it "starts with CPU device":
# #             val config = DLConfig__default()
# #             expect config.default_device == Device.CPU
# #
# #         it "starts with F32 dtype":
# #             val config = DLConfig__default()
# #             expect config.default_dtype == DType.F32
# #
# #         it "starts with PyTorch backend":
# #             val config = DLConfig__default()
# #             expect config.default_backend == Backend.PyTorch
# #
# #         it "starts with autograd enabled":
# #             val config = DLConfig__default()
# #             expect config.autograd_enabled == true
# #
# #         it "starts with amp disabled":
# #             val config = DLConfig__default()
# #             expect config.amp_enabled == false
# #
# #         it "starts with no seed":
# #             val config = DLConfig__default()
# #             expect config.seed == nil
#
