# Tests for Pure Simple Tensor Operations

use std.pure.tensor (PureTensor)
use std.pure.tensor_ops (
    add, sub, mul, div, neg, mul_scalar, add_scalar, div_scalar,
    matmul, transpose,
    sum, mean, max, min,
    relu, sigmoid, tanh, softmax,
    tensor_exp, tensor_log, tensor_sqrt, tensor_pow
)

describe "Tensor Operations":
    describe "Element-wise Operations":
        it "adds two tensors":
            val a = PureTensor.from_data([1.0, 2.0, 3.0, 4.0], [2, 2])
            val b = PureTensor.from_data([5.0, 6.0, 7.0, 8.0], [2, 2])
            val c = add(a, b)
            assert c.shape == [2, 2]
            assert c.get([0, 0]) == 6.0
            assert c.get([1, 1]) == 12.0

        it "subtracts tensors":
            val a = PureTensor.from_data([5.0, 6.0, 7.0, 8.0], [2, 2])
            val b = PureTensor.from_data([1.0, 2.0, 3.0, 4.0], [2, 2])
            val c = sub(a, b)
            assert c.get([0, 0]) == 4.0
            assert c.get([1, 1]) == 4.0

        it "multiplies tensors element-wise":
            val a = PureTensor.from_data([2.0, 3.0, 4.0, 5.0], [2, 2])
            val b = PureTensor.from_data([1.0, 2.0, 3.0, 4.0], [2, 2])
            val c = mul(a, b)
            assert c.get([0, 0]) == 2.0
            assert c.get([0, 1]) == 6.0
            assert c.get([1, 0]) == 12.0
            assert c.get([1, 1]) == 20.0

        it "divides tensors":
            val a = PureTensor.from_data([6.0, 8.0, 10.0, 12.0], [2, 2])
            val b = PureTensor.from_data([2.0, 2.0, 2.0, 2.0], [2, 2])
            val c = div(a, b)
            assert c.get([0, 0]) == 3.0
            assert c.get([1, 1]) == 6.0

        it "negates tensor":
            val a = PureTensor.from_data([1.0, -2.0, 3.0, -4.0], [2, 2])
            val b = neg(a)
            assert b.get([0, 0]) == -1.0
            assert b.get([0, 1]) == 2.0
            assert b.get([1, 0]) == -3.0
            assert b.get([1, 1]) == 4.0

        it "multiplies by scalar":
            val a = PureTensor.from_data([1.0, 2.0, 3.0, 4.0], [2, 2])
            val b = mul_scalar(a, 2.0)
            assert b.get([0, 0]) == 2.0
            assert b.get([1, 1]) == 8.0

        it "adds scalar":
            val a = PureTensor.from_data([1.0, 2.0, 3.0, 4.0], [2, 2])
            val b = add_scalar(a, 10.0)
            assert b.get([0, 0]) == 11.0
            assert b.get([1, 1]) == 14.0

        it "divides by scalar":
            val a = PureTensor.from_data([2.0, 4.0, 6.0, 8.0], [2, 2])
            val b = div_scalar(a, 2.0)
            assert b.get([0, 0]) == 1.0
            assert b.get([1, 1]) == 4.0

    describe "Matrix Operations":
        it "performs matrix multiplication":
            val a = PureTensor.from_data([1.0, 2.0, 3.0, 4.0], [2, 2])
            val b = PureTensor.from_data([5.0, 6.0, 7.0, 8.0], [2, 2])
            val c = matmul(a, b)
            # [[1, 2], [3, 4]] @ [[5, 6], [7, 8]]
            # = [[1*5+2*7, 1*6+2*8], [3*5+4*7, 3*6+4*8]]
            # = [[19, 22], [43, 50]]
            assert c.shape == [2, 2]
            assert c.get([0, 0]) == 19.0
            assert c.get([0, 1]) == 22.0
            assert c.get([1, 0]) == 43.0
            assert c.get([1, 1]) == 50.0

        it "multiplies rectangular matrices":
            val a = PureTensor.from_data([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], [2, 3])
            val b = PureTensor.from_data([7.0, 8.0, 9.0, 10.0, 11.0, 12.0], [3, 2])
            val c = matmul(a, b)
            # [[1, 2, 3], [4, 5, 6]] @ [[7, 8], [9, 10], [11, 12]]
            # Result: [2, 2]
            assert c.shape == [2, 2]
            # First row: [1*7+2*9+3*11, 1*8+2*10+3*12] = [58, 64]
            assert c.get([0, 0]) == 58.0
            assert c.get([0, 1]) == 64.0

        it "transposes matrix":
            val a = PureTensor.from_data([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], [2, 3])
            val b = transpose(a)
            assert b.shape == [3, 2]
            assert b.get([0, 0]) == 1.0
            assert b.get([0, 1]) == 4.0
            assert b.get([1, 0]) == 2.0
            assert b.get([2, 1]) == 6.0

    describe "Reductions":
        it "sums all elements":
            val a = PureTensor.from_data([1.0, 2.0, 3.0, 4.0], [2, 2])
            val s = sum(a)
            assert s == 10.0

        it "computes mean":
            val a = PureTensor.from_data([1.0, 2.0, 3.0, 4.0], [2, 2])
            val m = mean(a)
            assert m == 2.5

        it "finds maximum":
            val a = PureTensor.from_data([1.0, 5.0, 3.0, 2.0], [2, 2])
            val m = max(a)
            assert m == 5.0

        it "finds minimum":
            val a = PureTensor.from_data([1.0, 5.0, 3.0, 2.0], [2, 2])
            val m = min(a)
            assert m == 1.0

    describe "Activation Functions":
        it "applies ReLU":
            val a = PureTensor.from_data([-2.0, -1.0, 0.0, 1.0, 2.0], [5])
            val b = relu(a)
            assert b.get([0]) == 0.0
            assert b.get([1]) == 0.0
            assert b.get([2]) == 0.0
            assert b.get([3]) == 1.0
            assert b.get([4]) == 2.0

        # Note: sigmoid, tanh tests would need proper exp() implementation
        # Skipping until we have FFI for math functions

    describe "Math Operations":
        # Note: These tests would need proper math FFI implementations
        # Skipping until exp, log, sqrt are implemented
        it "placeholder - math FFI not yet available":
            expect(true).to_equal(true)
