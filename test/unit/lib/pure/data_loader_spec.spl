# Tests for Pure Simple DataLoader and Dataset
#
# Comprehensive tests for data loading, batching, and iteration
# Note: field name 'feat' used instead of 'feature' because 'feature'
# is a reserved keyword in the runtime parser.

describe "ArrayDataset":
    it "creates dataset from array":
            val data = [[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]]
            val dataset = ArrayDataset(data: data)

            expect(dataset.len()).to_equal(3)

        it "gets item by index":
            val data = [[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]]
            val dataset = ArrayDataset(data: data)

            val item = dataset.get_item(0)
            expect(item.len()).to_equal(2)
            expect(item[0]).to_equal(1.0)
            expect(item[1]).to_equal(2.0)

        it "gets all items":
            val data = [[1.0, 2.0], [3.0, 4.0]]
            val dataset = ArrayDataset(data: data)

            val item0 = dataset.get_item(0)
            val item1 = dataset.get_item(1)

            expect(item0[0]).to_equal(1.0)
            expect(item1[0]).to_equal(3.0)

describe "LabeledDataset":
    it "creates labeled dataset":
            val features = [[1.0, 2.0], [3.0, 4.0]]
            val labels = [0.0, 1.0]
            val dataset = LabeledDataset(features: features, labels: labels)

            expect(dataset.len()).to_equal(2)

        it "gets labeled item":
            val features = [[1.0, 2.0], [3.0, 4.0]]
            val labels = [0.0, 1.0]
            val dataset = LabeledDataset(features: features, labels: labels)

            val item = dataset.get_item(0)
            expect(item.feat.len()).to_equal(2)
            expect(item.feat[0]).to_equal(1.0)
            expect(item.label).to_equal(0.0)

        it "gets all labeled items":
            val features = [[1.0, 2.0], [3.0, 4.0]]
            val labels = [0.0, 1.0]
            val dataset = LabeledDataset(features: features, labels: labels)

            val item0 = dataset.get_item(0)
            val item1 = dataset.get_item(1)

            expect(item0.label).to_equal(0.0)
            expect(item1.label).to_equal(1.0)

describe "DataLoader - Basic Batching":
    it "creates dataloader":
            val data = [[1.0, 2.0], [3.0, 4.0], [5.0, 6.0], [7.0, 8.0]]
            val dataset = ArrayDataset(data: data)
            val loader = create_dataloader(
                dataset,
                2,
                false,
                false
            )

            expect(loader.batch_size).to_equal(2)

        it "calculates number of batches":
            val data = [[1.0, 2.0], [3.0, 4.0], [5.0, 6.0], [7.0, 8.0]]
            val dataset = ArrayDataset(data: data)
            val loader = create_dataloader(dataset, 2, false, false)

            expect(loader.len()).to_equal(2)

        it "calculates batches with remainder":
            val data = [[1.0], [2.0], [3.0], [4.0], [5.0]]
            val dataset = ArrayDataset(data: data)
            val loader = create_dataloader(dataset, 2, false, false)

            expect(loader.len()).to_equal(3)

        it "gets first batch":
            val data = [[1.0, 2.0], [3.0, 4.0], [5.0, 6.0], [7.0, 8.0]]
            val dataset = ArrayDataset(data: data)
            val loader = create_dataloader(dataset, 2, false, false)

            val batch = loader.next_batch()
            expect(batch.len()).to_equal(4)
            expect(batch[0]).to_equal(1.0)
            expect(batch[1]).to_equal(2.0)
            expect(batch[2]).to_equal(3.0)
            expect(batch[3]).to_equal(4.0)

        it "gets multiple batches":
            val data = [[1.0], [2.0], [3.0], [4.0]]
            val dataset = ArrayDataset(data: data)
            val loader = create_dataloader(dataset, 2, false, false)

            val batch1 = loader.next_batch()
            expect(batch1.len()).to_equal(2)
            expect(batch1[0]).to_equal(1.0)
            expect(batch1[1]).to_equal(2.0)

            val batch2 = loader.next_batch()
            expect(batch2.len()).to_equal(2)
            expect(batch2[0]).to_equal(3.0)
            expect(batch2[1]).to_equal(4.0)

        it "handles incomplete final batch":
            val data = [[1.0], [2.0], [3.0]]
            val dataset = ArrayDataset(data: data)
            val loader = create_dataloader(dataset, 2, false, false)

            val batch1 = loader.next_batch()
            expect(batch1.len()).to_equal(2)

            val batch2 = loader.next_batch()
            expect(batch2.len()).to_equal(1)
            expect(batch2[0]).to_equal(3.0)

describe "DataLoader - Drop Last":
    it "drops incomplete final batch":
            val data = [[1.0], [2.0], [3.0]]
            val dataset = ArrayDataset(data: data)
            val loader = create_dataloader(dataset, 2, false, true)

            expect(loader.len()).to_equal(1)

        it "does not return incomplete batch":
            val data = [[1.0], [2.0], [3.0]]
            val dataset = ArrayDataset(data: data)
            val loader = create_dataloader(dataset, 2, false, true)

            val batch1 = loader.next_batch()
            expect(batch1.len()).to_equal(2)

            val batch2 = loader.next_batch()
            expect(batch2.len()).to_equal(0)

        it "keeps complete batches only":
            val data = [[1.0], [2.0], [3.0], [4.0], [5.0]]
            val dataset = ArrayDataset(data: data)
            val loader = create_dataloader(dataset, 2, false, true)

            expect(loader.len()).to_equal(2)

describe "DataLoader - Iterator":
    it "creates iterator":
            val data = [[1.0], [2.0]]
            val dataset = ArrayDataset(data: data)
            val loader = create_dataloader(dataset, 1, false, false)

            val iter = loader.iter()
            expect(iter.has_next()).to_equal(true)

        it "iterates through batches":
            val data = [[1.0], [2.0], [3.0], [4.0]]
            val dataset = ArrayDataset(data: data)
            val loader = create_dataloader(dataset, 2, false, false)

            val iter = loader.iter()

            val batch1 = iter.next()
            expect(batch1.len()).to_equal(2)
            expect(iter.has_next()).to_equal(true)

            val batch2 = iter.next()
            expect(batch2.len()).to_equal(2)
            expect(iter.has_next()).to_equal(false)

        it "resets between epochs":
            val data = [[1.0], [2.0]]
            val dataset = ArrayDataset(data: data)
            val loader = create_dataloader(dataset, 1, false, false)

            val iter1 = loader.iter()
            iter1.next()
            iter1.next()
            expect(iter1.has_next()).to_equal(false)

            val iter2 = loader.iter()
            expect(iter2.has_next()).to_equal(true)

describe "LabeledDataLoader - Basic":
    it "creates labeled dataloader":
            val features = [[1.0, 2.0], [3.0, 4.0]]
            val labels = [0.0, 1.0]
            val dataset = LabeledDataset(features: features, labels: labels)
            val loader = create_dataloader_labeled(dataset, 1, false, false)

            expect(loader.batch_size).to_equal(1)

        it "gets labeled batch":
            val features = [[1.0, 2.0], [3.0, 4.0]]
            val labels = [0.0, 1.0]
            val dataset = LabeledDataset(features: features, labels: labels)
            val loader = create_dataloader_labeled(dataset, 1, false, false)

            val batch = loader.next_batch()
            expect(batch.features.len()).to_equal(2)
            expect(batch.labels.len()).to_equal(1)
            expect(batch.labels[0]).to_equal(0.0)

        it "batches multiple samples":
            val features = [[1.0], [2.0], [3.0], [4.0]]
            val labels = [0.0, 0.0, 1.0, 1.0]
            val dataset = LabeledDataset(features: features, labels: labels)
            val loader = create_dataloader_labeled(dataset, 2, false, false)

            val batch = loader.next_batch()
            expect(batch.features.len()).to_equal(2)
            expect(batch.labels.len()).to_equal(2)
            expect(batch.labels[0]).to_equal(0.0)
            expect(batch.labels[1]).to_equal(0.0)

describe "LabeledDataLoader - Iterator":
    it "iterates labeled batches":
            val features = [[1.0], [2.0], [3.0], [4.0]]
            val labels = [0.0, 0.0, 1.0, 1.0]
            val dataset = LabeledDataset(features: features, labels: labels)
            val loader = create_dataloader_labeled(dataset, 2, false, false)

            val iter = loader.iter()

            val batch1 = iter.next()
            expect(batch1.features.len()).to_equal(2)
            expect(batch1.labels.len()).to_equal(2)

            val batch2 = iter.next()
            expect(batch2.features.len()).to_equal(2)
            expect(batch2.labels.len()).to_equal(2)

describe "DataLoader - Edge Cases":
    it "handles single sample":
            val data = [[1.0, 2.0]]
            val dataset = ArrayDataset(data: data)
            val loader = create_dataloader(dataset, 1, false, false)

            expect(loader.len()).to_equal(1)
            val batch = loader.next_batch()
            expect(batch.len()).to_equal(2)

        it "handles batch size equals dataset size":
            val data = [[1.0], [2.0], [3.0]]
            val dataset = ArrayDataset(data: data)
            val loader = create_dataloader(dataset, 3, false, false)

            expect(loader.len()).to_equal(1)
            val batch = loader.next_batch()
            expect(batch.len()).to_equal(3)

        it "handles batch size larger than dataset":
            val data = [[1.0], [2.0]]
            val dataset = ArrayDataset(data: data)
            val loader = create_dataloader(dataset, 10, false, false)

            expect(loader.len()).to_equal(1)
            val batch = loader.next_batch()
            expect(batch.len()).to_equal(2)

        it "handles empty result after exhaustion":
            val data = [[1.0]]
            val dataset = ArrayDataset(data: data)
            val loader = create_dataloader(dataset, 1, false, false)

            val batch1 = loader.next_batch()
            expect(batch1.len()).to_equal(1)

            val batch2 = loader.next_batch()
            expect(batch2.len()).to_equal(0)

describe "DataLoader - Shuffling":
    it "creates loader with shuffle enabled":
            val data = [[1.0], [2.0], [3.0], [4.0]]
            val dataset = ArrayDataset(data: data)
            val loader = create_dataloader(dataset, 2, true, false)

            expect(loader.shuffle).to_equal(true)

        it "shuffles indices on reset":
            val data = [[1.0], [2.0], [3.0], [4.0]]
            val dataset = ArrayDataset(data: data)
            val loader = create_dataloader(dataset, 4, true, false)

            loader.reset()
            val batch1 = loader.next_batch()

            loader.reset()
            val batch2 = loader.next_batch()

            expect(batch1.len()).to_equal(4)
            expect(batch2.len()).to_equal(4)

# Helper classes (workaround for import limitations)
# Note: field 'feat' used instead of 'feature' because 'feature'
# is a reserved keyword in the runtime parser.
class ArrayDataset:
    data: [[f64]]

    fn len() -> i64:
        self.data.len()

    fn get_item(index: i64) -> [f64]:
        self.data[index]

class LabeledDataset:
    features: [[f64]]
    labels: [f64]

    fn len() -> i64:
        self.features.len()

    fn get_item(index: i64) -> LabeledSample:
        LabeledSample(
            feat: self.features[index],
            label: self.labels[index]
        )

class LabeledSample:
    feat: [f64]
    label: f64

class DataLoader:
    dataset: ArrayDataset
    batch_size: i64
    shuffle: bool
    drop_last: bool
    indices: [i64]
    current_index: i64

    fn len() -> i64:
        val total = self.dataset.len()
        val batches = total / self.batch_size
        val remainder = total % self.batch_size

        if self.drop_last:
            batches
        else:
            if remainder > 0:
                batches + 1
            else:
                batches

    fn reset():
        self.current_index = 0
        if self.shuffle:
            self._shuffle_indices()

    me _shuffle_indices():
        val n = self.indices.len()
        var i = n - 1
        while i > 0:
            val j = self._random_int(i + 1)
            val temp = self.indices[i]
            self.indices[i] = self.indices[j]
            self.indices[j] = temp
            i = i - 1

    fn _random_int(max_val: i64) -> i64:
        val a = 1103515245
        val c = 12345
        val m = 2147483648
        val seed_val = (a * self.current_index + c) % m
        (seed_val % max_val)

    fn next_batch() -> [f64]:
        if self.current_index >= self.dataset.len():
            []
        else:
            self._get_batch()

    me _get_batch() -> [f64]:
        val start = self.current_index
        val dataset_len = self.dataset.len()
        var end = start + self.batch_size

        if end > dataset_len:
            if self.drop_last:
                []
            else:
                end = dataset_len

        if start >= dataset_len:
            []
        else:
            var batch: [f64] = []
            var i = start
            while i < end:
                val idx = self.indices[i]
                val sample = self.dataset.get_item(idx)
                for v in sample:
                    batch.push(v)
                i = i + 1

            self.current_index = end
            batch

    fn iter() -> DataLoaderIterator:
        self.reset()
        DataLoaderIterator(loader: self)

class DataLoaderIterator:
    loader: DataLoader
    done: bool

    fn has_next() -> bool:
        not self.done

    me next() -> [f64]:
        val batch = self.loader.next_batch()
        if batch.len() == 0:
            self.done = true
            []
        else:
            batch

fn create_dataloader(
    dataset: ArrayDataset,
    batch_size: i64,
    shuffle: bool,
    drop_last: bool
) -> DataLoader:
    var indices: [i64] = []
    var i = 0
    while i < dataset.len():
        indices.push(i)
        i = i + 1

    DataLoader(
        dataset: dataset,
        batch_size: batch_size,
        shuffle: shuffle,
        drop_last: drop_last,
        indices: indices,
        current_index: 0
    )

class LabeledDataLoader:
    dataset: LabeledDataset
    batch_size: i64
    shuffle: bool
    drop_last: bool
    indices: [i64]
    current_index: i64

    fn len() -> i64:
        val total = self.dataset.len()
        val batches = total / self.batch_size
        val remainder = total % self.batch_size

        if self.drop_last:
            batches
        else:
            if remainder > 0:
                batches + 1
            else:
                batches

    fn reset():
        self.current_index = 0
        if self.shuffle:
            self._shuffle_indices()

    me _shuffle_indices():
        val n = self.indices.len()
        var i = n - 1
        while i > 0:
            val j = self._random_int(i + 1)
            val temp = self.indices[i]
            self.indices[i] = self.indices[j]
            self.indices[j] = temp
            i = i - 1

    fn _random_int(max_val: i64) -> i64:
        val a = 1103515245
        val c = 12345
        val m = 2147483648
        val seed_val = (a * self.current_index + c) % m
        (seed_val % max_val)

    fn next_batch() -> LabeledBatch:
        if self.current_index >= self.dataset.len():
            LabeledBatch(features: [], labels: [])
        else:
            self._get_batch()

    me _get_batch() -> LabeledBatch:
        val start = self.current_index
        val dataset_len = self.dataset.len()
        var end = start + self.batch_size

        if end > dataset_len:
            if self.drop_last:
                LabeledBatch(features: [], labels: [])
            else:
                end = dataset_len

        if start >= dataset_len:
            LabeledBatch(features: [], labels: [])
        else:
            var features: [f64] = []
            var labels: [f64] = []
            var i = start
            while i < end:
                val idx = self.indices[i]
                val sample = self.dataset.get_item(idx)
                for v in sample.feat:
                    features.push(v)
                labels.push(sample.label)
                i = i + 1

            self.current_index = end
            LabeledBatch(features: features, labels: labels)

    fn iter() -> LabeledDataLoaderIterator:
        self.reset()
        LabeledDataLoaderIterator(loader: self)

class LabeledBatch:
    features: [f64]
    labels: [f64]

class LabeledDataLoaderIterator:
    loader: LabeledDataLoader
    done: bool

    fn has_next() -> bool:
        not self.done

    me next() -> LabeledBatch:
        val batch = self.loader.next_batch()
        if batch.features.len() == 0:
            self.done = true
            LabeledBatch(features: [], labels: [])
        else:
            batch

fn create_dataloader_labeled(
    dataset: LabeledDataset,
    batch_size: i64,
    shuffle: bool,
    drop_last: bool
) -> LabeledDataLoader:
    var indices: [i64] = []
    var i = 0
    while i < dataset.len():
        indices.push(i)
        i = i + 1

    LabeledDataLoader(
        dataset: dataset,
        batch_size: batch_size,
        shuffle: shuffle,
        drop_last: drop_last,
        indices: indices,
        current_index: 0
    )
