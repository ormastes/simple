# NoGC GPU Runtime Tests
#
# Tests verify the NoGC gpu_runtime module structural patterns:
#   - No borrowed-view pattern (no wrapper with owns_handle: false)
#   - Direct FFI function calls
#   - Identical API surface to gc_async_mut/gpu_runtime version

# ============================================================================
# Mock FFI functions (replaces actual FFI for unit testing)
# ============================================================================

var mock_tensor_counter: i64 = 100

fn mock_rt_torch_cuda_available() -> bool:
    false  # Assume no CUDA in test environment

fn mock_rt_torch_tensor_zeros(dims: [i64]) -> i64:
    mock_tensor_counter = mock_tensor_counter + 1
    mock_tensor_counter

fn mock_rt_torch_tensor_ones(dims: [i64]) -> i64:
    mock_tensor_counter = mock_tensor_counter + 1
    mock_tensor_counter

fn mock_rt_torch_torchtensor_cuda(handle: i64, device_id: i32) -> i64:
    # Return new handle for GPU tensor
    mock_tensor_counter = mock_tensor_counter + 1
    mock_tensor_counter

fn mock_rt_torch_torchtensor_is_cuda(handle: i64) -> bool:
    # In test, no actual GPU
    false

fn mock_rt_torch_torchtensor_numel(handle: i64) -> i64:
    4  # Default mock size

fn mock_rt_torch_stream_create(device_id: i32) -> i64:
    mock_tensor_counter = mock_tensor_counter + 1
    mock_tensor_counter

fn mock_rt_torch_torchstream_sync(handle: i64):
    0

fn mock_rt_torch_torchstream_query(handle: i64) -> bool:
    true

fn mock_rt_cuda_device_count() -> i32:
    0  # No CUDA in test environment

# ============================================================================
# NoGC GPU Runtime functions (mirrors nogc_sync_mut/gpu_runtime/mod.spl)
# Uses direct FFI — no borrowed-view wrapper pattern
# ============================================================================

fn mock_gpu_available() -> bool:
    mock_rt_torch_cuda_available()

fn mock_gpu_backend_name() -> text:
    if mock_rt_torch_cuda_available():
        "CUDA"
    else:
        "CPU"

fn mock_gpu_device_count() -> i32:
    if mock_rt_torch_cuda_available():
        mock_rt_cuda_device_count()
    else:
        0

fn mock_gpu_tensor_zeros(rows: i64, cols: i64) -> i64:
    # NoGC: direct FFI call — no wrapper object created
    mock_rt_torch_tensor_zeros([rows, cols])

fn mock_gpu_tensor_ones(rows: i64, cols: i64) -> i64:
    # NoGC: direct FFI call — no wrapper object created
    mock_rt_torch_tensor_ones([rows, cols])

fn mock_gpu_tensor_to_cuda(tensor_handle: i64, device_id: i32) -> i64:
    # NoGC: direct FFI — no TorchTensorWrapper(owns_handle: false) created
    mock_rt_torch_torchtensor_cuda(tensor_handle, device_id)

fn mock_gpu_tensor_is_cuda(tensor_handle: i64) -> bool:
    # NoGC: direct FFI — no TorchTensorWrapper(owns_handle: false) created
    mock_rt_torch_torchtensor_is_cuda(tensor_handle)

fn mock_gpu_tensor_numel(tensor_handle: i64) -> i64:
    # NoGC: direct FFI — no TorchTensorWrapper(owns_handle: false) created
    mock_rt_torch_torchtensor_numel(tensor_handle)

fn mock_gpu_stream_create(device_id: i32) -> i64:
    mock_rt_torch_stream_create(device_id)

fn mock_gpu_stream_sync(stream_handle: i64):
    # NoGC: direct FFI — no TorchStream(owns_handle: false) created
    mock_rt_torch_torchstream_sync(stream_handle)

fn mock_gpu_stream_query(stream_handle: i64) -> bool:
    # NoGC: direct FFI — no TorchStream(owns_handle: false) created
    mock_rt_torch_torchstream_query(stream_handle)

fn mock_gpu_alloc_zeros(rows: i64, cols: i64, use_gpu: bool, device_id: i32) -> i64:
    val t_handle = mock_gpu_tensor_zeros(rows, cols)
    if use_gpu and mock_gpu_available():
        mock_gpu_tensor_to_cuda(t_handle, device_id)
    else:
        t_handle

# ============================================================================
# Tests
# ============================================================================

describe "NoGC GPU Runtime — direct FFI pattern":

    it "gpu_available() returns false when no CUDA":
        val result = mock_gpu_available()
        expect(result).to_equal(false)

    it "gpu_backend_name() returns CPU when no CUDA":
        val name = mock_gpu_backend_name()
        expect(name).to_equal("CPU")

    it "gpu_device_count() returns 0 when no CUDA":
        val count = mock_gpu_device_count()
        expect(count).to_equal(0)

    it "gpu_tensor_zeros returns valid handle (no wrapper created)":
        val handle = mock_gpu_tensor_zeros(2, 3)
        expect(handle).to_be_greater_than(0)

    it "gpu_tensor_ones returns valid handle (no wrapper created)":
        val handle = mock_gpu_tensor_ones(4, 4)
        expect(handle).to_be_greater_than(0)

    it "gpu_tensor_is_cuda returns false for CPU tensor":
        val handle = mock_gpu_tensor_zeros(2, 2)
        val is_gpu = mock_gpu_tensor_is_cuda(handle)
        expect(is_gpu).to_equal(false)

    it "gpu_tensor_numel returns element count":
        val handle = mock_gpu_tensor_zeros(2, 2)
        val count = mock_gpu_tensor_numel(handle)
        expect(count).to_equal(4)

    it "gpu_stream_create returns valid handle":
        val handle = mock_gpu_stream_create(0)
        expect(handle).to_be_greater_than(0)

    it "gpu_stream_query returns bool":
        val handle = mock_gpu_stream_create(0)
        val result = mock_gpu_stream_query(handle)
        expect(result).to_equal(true)

    it "gpu_stream_sync completes without error":
        val handle = mock_gpu_stream_create(0)
        mock_gpu_stream_sync(handle)
        expect(true).to_equal(true)

    it "gpu_alloc_zeros returns CPU handle when no CUDA":
        val handle = mock_gpu_alloc_zeros(3, 3, true, 0)
        # Falls back to CPU because mock_gpu_available() is false
        expect(handle).to_be_greater_than(0)


describe "NoGC vs GC pattern comparison":

    it "NoGC pattern: tensor_is_cuda via direct FFI (no wrapper)":
        val handle = mock_gpu_tensor_zeros(2, 2)
        # NoGC: rt_torch_torchtensor_is_cuda(handle) — direct
        # GC:   TorchTensorWrapper(handle: h, owns_handle: false).is_cuda() — wrapper
        val result = mock_rt_torch_torchtensor_is_cuda(handle)
        expect(result).to_equal(false)

    it "NoGC pattern: stream_sync via direct FFI (no wrapper)":
        val handle = mock_gpu_stream_create(0)
        # NoGC: rt_torch_torchstream_sync(handle) — direct
        # GC:   TorchStream(handle: h, owns_handle: false).sync() — wrapper
        mock_rt_torch_torchstream_sync(handle)
        expect(true).to_equal(true)
