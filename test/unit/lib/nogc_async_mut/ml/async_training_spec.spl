# Tests for async training loop API

use std.nogc_async_mut.ml.async_training.{train_epoch, evaluate_model, train_loop}
use std.pure.data.dataset.{LabeledDataset}
use std.pure.data.dataloader.{create_dataloader_labeled}
use std.pure.tensor.{PureTensor, tensor_from_data}
use std.pure.training.{mse_loss}

describe "Async Training":
    describe "train_epoch":
        it "returns zero loss for empty dataloader":
            val features: [[f64]] = []
            val labels: [f64] = []
            val ds = LabeledDataset(features: features, labels: labels)
            val dl = create_dataloader_labeled(ds, 2, false, false)
            # Simple identity model
            val model = _IdentityModel()
            val optimizer = _NoopOptimizer()
            val loss = train_epoch(model, dl, optimizer, mse_loss)
            expect(loss).to_equal(0.0)

    describe "evaluate_model":
        it "returns zero loss for empty dataloader":
            val features: [[f64]] = []
            val labels: [f64] = []
            val ds = LabeledDataset(features: features, labels: labels)
            val dl = create_dataloader_labeled(ds, 2, false, false)
            val model = _IdentityModel()
            val loss = evaluate_model(model, dl, mse_loss)
            expect(loss).to_equal(0.0)

    describe "train_loop":
        it "returns array of length equal to epochs":
            val features: [[f64]] = [[1.0], [2.0]]
            val labels: [f64] = [1.0, 2.0]
            val ds = LabeledDataset(features: features, labels: labels)
            val train_dl = create_dataloader_labeled(ds, 2, false, false)
            val val_dl = create_dataloader_labeled(ds, 2, false, false)
            val model = _IdentityModel()
            val optimizer = _NoopOptimizer()
            val losses = train_loop(model, train_dl, val_dl, optimizer, mse_loss, 3)
            expect(losses.len()).to_equal(3)

# Helper: identity model that returns input unchanged
class _IdentityModel:
    fn forward(x: PureTensor<f64>) -> PureTensor<f64>:
        x

# Helper: optimizer that does nothing
class _NoopOptimizer:
    fn step():
        0
    fn zero_grad():
        0
