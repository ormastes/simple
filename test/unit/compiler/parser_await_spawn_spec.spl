#!/usr/bin/env simple
# Parser Tests for Await and Spawn Expressions
#
# Tests that the parser correctly recognizes and parses
# await and spawn expressions.

use compiler.parser.{Parser}
use compiler.lexer.{Lexer, LexerMode}
use compiler.lexer_types.{TokenKind}

# Helper to create lexer (workaround for bootstrap runtime)
fn create_lexer(source: text) -> Lexer:
    Lexer(
        source: source,
        pos: 0,
        line: 1,
        col: 1,
        indent_stack: [0],
        pending_dedents: 0,
        at_line_start: true,
        paren_depth: 0,
        in_math_block: false,
        math_brace_depth: 0,
        prev_token_kind: TokenKind.Eof,
        pending_token: nil,
        generic_depth: 0,
        block_registry: nil,
        current_block_kind: nil,
        current_lexer_mode: LexerMode.Normal,
        in_raw_block: false,
        raw_block_start: 0,
        block_brace_depth: 0,
        unified_registry: nil
    )

describe "Parser - Await Expression":
    it "parses simple await expression":
        val source = "await fetch()"
        # val parser = Parser.new(source)  # Skip Parser for now (bootstrap runtime limitation)

        # TODO: Parse and verify the expression
        # val expr = parser.parse_expr()
        # expect(expr.kind).to_match(ExprKind.Await)

        # For now, just verify lexer recognizes await
        val lexer = create_lexer(source)
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.KwAwait)

    it "parses await with function call":
        val source = "await async_operation(arg1, arg2)"
        val lexer = create_lexer(source)

        val token1 = lexer.next_token()
        expect(token1.kind).to_equal(TokenKind.KwAwait)

        val token2 = lexer.next_token()
        expect(token2.kind).to_equal(TokenKind.Ident)
        expect(token2.text).to_equal("async_operation")

    it "parses await with method call":
        val source = "await obj.method()"
        val lexer = create_lexer(source)

        val token1 = lexer.next_token()
        expect(token1.kind).to_equal(TokenKind.KwAwait)

        val token2 = lexer.next_token()
        expect(token2.kind).to_equal(TokenKind.Ident)

describe "Parser - Spawn Expression":
    it "parses simple spawn expression":
        val source = "spawn Worker()"
        val lexer = create_lexer(source)

        val token1 = lexer.next_token()
        expect(token1.kind).to_equal(TokenKind.KwSpawn)

        val token2 = lexer.next_token()
        expect(token2.kind).to_equal(TokenKind.Ident)
        expect(token2.text).to_equal("Worker")

    it "parses spawn with constructor args":
        val source = "spawn Worker(id: 1, name: \"test\")"
        val lexer = create_lexer(source)

        val token1 = lexer.next_token()
        expect(token1.kind).to_equal(TokenKind.KwSpawn)

        val token2 = lexer.next_token()
        expect(token2.kind).to_equal(TokenKind.Ident)

    it "parses spawn in assignment":
        val source = "val worker = spawn Worker()"
        val lexer = create_lexer(source)

        # Skip val and worker tokens
        lexer.next_token()  # val
        lexer.next_token()  # worker
        lexer.next_token()  # =

        val spawn_token = lexer.next_token()
        expect(spawn_token.kind).to_equal(TokenKind.KwSpawn)

describe "Parser - Actor Keyword":
    it "recognizes actor keyword":
        val source = "actor Worker"
        val lexer = create_lexer(source)

        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.KwActor)

    it "recognizes async keyword":
        val source = "async fn test()"
        val lexer = create_lexer(source)

        val token1 = lexer.next_token()
        expect(token1.kind).to_equal(TokenKind.KwAsync)

        val token2 = lexer.next_token()
        expect(token2.kind).to_equal(TokenKind.KwFn)

describe "Parser - Attribute Syntax":
    it "recognizes #[ token":
        val source = "#[timeout(5000)]"
        val lexer = create_lexer(source)

        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.HashLBracket)
        expect(token.text).to_equal("#[")

    it "parses attribute name after #[":
        val source = "#[timeout"
        val lexer = create_lexer(source)

        lexer.next_token()  # #[
        val name_token = lexer.next_token()
        expect(name_token.kind).to_equal(TokenKind.Ident)
        expect(name_token.text).to_equal("timeout")

describe "Parser - Integration":
    it "parses await in async context":
        val source = """
        val result = await fetch_data()
        print result
        """
        val lexer = create_lexer(source)

        # Should successfully tokenize
        var token_count = 0
        while lexer.peek().kind != TokenKind.Eof:
            lexer.next_token()
            token_count += 1

        expect(token_count).to_be_greater_than(0)

    it "parses multiple spawn expressions":
        val source = """
        val w1 = spawn Worker()
        val w2 = spawn Worker()
        """
        val lexer = create_lexer(source)

        var spawn_count = 0
        while lexer.peek().kind != TokenKind.Eof:
            val token = lexer.next_token()
            if token.kind == TokenKind.KwSpawn:
                spawn_count += 1

        expect(spawn_count).to_equal(2)
