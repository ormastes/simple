# @Feature 801: Lexer - Comprehensive Tests
# @Description: Test Simple language lexer for branch coverage (398 branches)

# Import lexer implementation
use compiler.lexer.*
use compiler.lexer_types.*
use compiler.blocks.{block_registry, init_blocks}
use compiler.blocks.modes.{LexerMode}

# Test Lexer creation
describe "Lexer creation":
    it "creates lexer with source":
        val lexer = Lexer.new("val x = 5")
        expect(lexer.pos).to_equal(0)
        expect(lexer.line).to_equal(1)
        expect(lexer.col).to_equal(1)
        expect(lexer.at_line_start).to_equal(true)

    it "initializes indent stack with zero":
        val lexer = Lexer.new("code")
        expect(lexer.indent_stack.len()).to_equal(1)
        expect(lexer.indent_stack[0]).to_equal(0)

    it "initializes with no pending dedents":
        val lexer = Lexer.new("code")
        expect(lexer.pending_dedents).to_equal(0)

    it "starts with normal lexer mode":
        val lexer = Lexer.new("code")
        expect(lexer.current_lexer_mode).to_equal(LexerMode.Normal)

# Test character operations
describe "Character operations":
    it "checks if at end with empty source":
        val lexer = Lexer.new("")
        expect(lexer.is_at_end()).to_equal(true)

    it "checks if at end with content":
        val lexer = Lexer.new("x")
        expect(lexer.is_at_end()).to_equal(false)

    it "peeks at current character":
        val lexer = Lexer.new("abc")
        expect(lexer.peek()).to_equal('a')

    it "peeks at next character":
        val lexer = Lexer.new("abc")
        expect(lexer.peek_next()).to_equal('b')

    it "advances position":
        var lexer = Lexer.new("abc")
        val ch = lexer.advance()
        expect(ch).to_equal('a')
        expect(lexer.pos).to_equal(1)

# Test simple token scanning
describe "Simple token scanning":
    it "scans identifier":
        var lexer = Lexer.new("hello")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.Ident)

    it "scans integer number":
        var lexer = Lexer.new("42")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.IntLit)

    it "scans plus operator":
        var lexer = Lexer.new("+")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.Plus)

    it "scans minus operator":
        var lexer = Lexer.new("-")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.Minus)

    it "scans asterisk operator":
        var lexer = Lexer.new("*")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.Star)

    it "scans slash operator":
        var lexer = Lexer.new("/")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.Slash)

    it "scans equals operator":
        var lexer = Lexer.new("=")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.Assign)

# Test keyword recognition
describe "Keyword recognition":
    it "recognizes val keyword":
        var lexer = Lexer.new("val")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.KwVal)

    it "recognizes var keyword":
        var lexer = Lexer.new("var")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.KwVar)

    it "recognizes fn keyword":
        var lexer = Lexer.new("fn")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.KwFn)

    it "recognizes if keyword":
        var lexer = Lexer.new("if")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.KwIf)

    it "recognizes else keyword":
        var lexer = Lexer.new("else")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.KwElse)

    it "recognizes while keyword":
        var lexer = Lexer.new("while")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.KwWhile)

    it "recognizes for keyword":
        var lexer = Lexer.new("for")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.KwFor)

    it "recognizes match keyword":
        var lexer = Lexer.new("match")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.KwMatch)

    it "recognizes case keyword":
        var lexer = Lexer.new("case")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.KwCase)

    it "recognizes return keyword":
        var lexer = Lexer.new("return")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.KwReturn)

# Test delimiters
describe "Delimiters":
    it "scans left paren":
        var lexer = Lexer.new("(")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.LParen)

    it "scans right paren":
        var lexer = Lexer.new(")")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.RParen)

    it "scans left brace":
        var lexer = Lexer.new(r"{")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.LBrace)

    it "scans right brace":
        var lexer = Lexer.new(r"}")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.RBrace)

    it "scans left bracket":
        var lexer = Lexer.new("[")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.LBracket)

    it "scans right bracket":
        var lexer = Lexer.new("]")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.RBracket)

    it "scans colon":
        var lexer = Lexer.new(":")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.Colon)

    it "scans comma":
        var lexer = Lexer.new(",")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.Comma)

    it "scans dot":
        var lexer = Lexer.new(".")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.Dot)

# Test string scanning
describe "String scanning":
    it "scans simple string":
        var lexer = Lexer.new("\"hello\"")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.StringLit)

    it "scans empty string":
        var lexer = Lexer.new("\"\"")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.StringLit)

    it "scans string with spaces":
        var lexer = Lexer.new("\"hello world\"")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.StringLit)

# Test number scanning
describe "Number scanning":
    it "scans zero":
        var lexer = Lexer.new("0")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.IntLit)

    it "scans single digit":
        var lexer = Lexer.new("5")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.IntLit)

    it "scans multi-digit integer":
        var lexer = Lexer.new("12345")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.IntLit)

    it "scans float with decimal":
        var lexer = Lexer.new("3.14")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.FloatLit)

    it "scans hex number":
        var lexer = Lexer.new("0x1A")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.IntLit)

    it "scans binary number":
        var lexer = Lexer.new("0b1010")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.IntLit)

    it "scans octal number":
        var lexer = Lexer.new("0o755")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.IntLit)

# Test comment scanning
describe "Comment scanning":
    it "skips single-line comment":
        var lexer = Lexer.new("# comment\nval")
        val token1 = lexer.next_token()
        expect(token1.kind).to_equal(TokenKind.Newline)
        val token2 = lexer.next_token()
        expect(token2.kind).to_equal(TokenKind.KwVal)

    it "handles comment at end of file":
        var lexer = Lexer.new("# comment")
        val token1 = lexer.next_token()
        expect(token1.kind).to_equal(TokenKind.Newline)
        val token2 = lexer.next_token()
        expect(token2.kind).to_equal(TokenKind.Eof)

# Test comparison operators
describe "Comparison operators":
    it "scans less than":
        var lexer = Lexer.new("<")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.Lt)

    it "scans greater than":
        var lexer = Lexer.new(">")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.Gt)

    it "scans less than or equal":
        var lexer = Lexer.new("<=")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.LtEq)

    it "scans greater than or equal":
        var lexer = Lexer.new(">=")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.GtEq)

    it "scans equality":
        var lexer = Lexer.new("==")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.Eq)

    it "scans not equal":
        var lexer = Lexer.new("!=")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.NotEq)

# Test logical operators
describe "Logical operators":
    it "scans and operator":
        var lexer = Lexer.new("and")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.KwAnd)

    it "scans or operator":
        var lexer = Lexer.new("or")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.KwOr)

    it "scans not operator":
        var lexer = Lexer.new("not")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.KwNot)

# Test arrow operators
describe "Arrow operators":
    it "scans right arrow":
        var lexer = Lexer.new("->")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.Arrow)

    it "scans fat arrow":
        var lexer = Lexer.new("=>")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.FatArrow)

# Test newline handling
describe "Newline handling":
    it "scans newline":
        var lexer = Lexer.new("\n")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.Newline)

    it "tracks line numbers":
        var lexer = Lexer.new("a\nb")
        val token1 = lexer.next_token()
        expect(token1.span.line).to_equal(1)
        val token2 = lexer.next_token()
        expect(token2.span.line).to_equal(1)
        val token3 = lexer.next_token()
        expect(token3.span.line).to_equal(2)

# Test EOF handling
describe "EOF handling":
    it "returns EOF at end":
        var lexer = Lexer.new("")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.Eof)

    it "returns EOF after content":
        var lexer = Lexer.new("x")
        val token1 = lexer.next_token()
        val token2 = lexer.next_token()
        expect(token2.kind).to_equal(TokenKind.Eof)

# Test whitespace handling
describe "Whitespace handling":
    it "skips spaces between tokens":
        var lexer = Lexer.new("a   b")
        val token1 = lexer.next_token()
        expect(token1.kind).to_equal(TokenKind.Ident)
        val token2 = lexer.next_token()
        expect(token2.kind).to_equal(TokenKind.Ident)

    it "skips tabs":
        var lexer = Lexer.new("a\tb")
        val token1 = lexer.next_token()
        val token2 = lexer.next_token()
        expect(token2.kind).to_equal(TokenKind.Ident)

# Test identifier patterns
describe "Identifier patterns":
    it "scans underscore identifier":
        var lexer = Lexer.new("_var")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.Ident)

    it "scans identifier with numbers":
        var lexer = Lexer.new("var123")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.Ident)

    it "scans identifier with underscores":
        var lexer = Lexer.new("my_var")
        val token = lexer.next_token()
        expect(token.kind).to_equal(TokenKind.Ident)
